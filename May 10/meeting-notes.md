## Meeting Recording

[YouTube link](https://www.youtube.com/watch?v=f9Xuh4YQmeM)

## Mastodon thread

[link](https://neuromatch.social/@OREL/114516356615947992)

## NOTES
How do you show up, be a part of a team?

What conversation should be relevant to what team members?

Duration (how long has progress been stalled) vs. Importance (significance).

high-low, short-protracted.

fewer things defined in an innovation space.

Momentum —> culture of engagement, feedback, and movement.


Discussions in meetings. What do you do in a space?

* projects crystallize.

JoPro —> From Here to There.

* holistic take — not jargon-laden or siloed.


Starter Town vs Final Boss.

* momentum is a better beacon than progress.

* iteration beats stagnation".

* Data x Direction -- WeRobot-related. MIT ethics of computing research. 


AI Venture Studios demo day.

* AI for impact curse (MIT CSAIL).

* how-to do demos, iterative design. Good pacing.

aiforimpact.github.io


Effort-Progress pitfall.

* Success vs. Time (experiment vs. reality).

* effort does not equal immediate output.

* impact is what exactly.

* "Challenge of the Space". 

* Silvia Buglio (JoPro assistant).


Momentum decision matrix (perception and awareness -- couched in innovation).

* the winner is often not the most brilliant idea.

* team navigates uncharted spaces -- how to you deal with this, to safe waypoints.

* progress conflated with polish. Performative progress --> roadmaps, docs, updates, demos that are vaporware.

* timelines --> "launches" to "releases". learning velocity >> idea purity.

* impact vs. effort (quick, easy wins --> major projects --> fill-in --> money pit).

* Gibsonian Information: Movement ---> directing context.


## TRANSCRIPT
0:00     
hello hi how are you bey Morgan     
0:06     
all right morning morning so welcome     
0:14     
um so this week we had a devil war meeting and we had an open source     
0:20     
meeting for the first time in several months so I was glad to see at the open uh open     
0:26     
source meeting uh all the new people we've selected uh     
0:32     
for GOC and the people who want to weren't selected but want to participate     
0:38     
in building their projects and learning about open source so I think that was     
0:44     
great um uh yeah so the open source meetings     
0:49     
will happen on Fridays at noon uh Eastern time which is     
0:56     
in North America Eastern time so I think that's UTC4 or something like that um and you     
1:06     
know we'll be doing that through about October i'd like to congratulate our new Google     
1:12     
Summer of Code people vi that's in in orthogonal lab and then     
1:19     
in divorm we had two people at     
1:26     
leratha and so welcome to those people uh and we discussed yesterday a lot of     
1:32     
the onboarding materials uh you know kind of getting oriented to the     
1:38     
It was a bit overwhelming but I think you know it's it's one of those things where you spend three weeks just trying     
1:45     
to get a handle on the organization and then you know you're     
1:50     
supposed to once you're familiar with it be able to utilize it so a lot of people will join     
1:59     
GSC they want to be involved in an organization they get to know sort of     
2:04     
what the organization has to offer and then eventually they can participate in GOC     
2:11     
but also maybe continue on in the organization or use you know find     
2:18     
connections within the organization professional connections opportunities and so     
2:24     
forth and then you know we've had people from GSO move on to a lot of different types of positions at corporations and     
2:32     
other open source organizations so it often makes it easy to sort of encapsulate your experience     
2:39     
and use that as a way to you know as a career building tool     
2:45     
basically okay um and in this for open meeting     
2:51     
uh we talked about hyperraphs once again now we also had a I presented a     
2:59     
paper on the uh evolution of     
3:04     
ukarotes and how that happened to come about and there was a uh study that the     
3:11     
authors had done on gene length and uh it was a very complexity theory oriented     
3:17     
paper so again you know our DA we're not going to have a D war meeting this     
3:23     
coming week but then the following week we will have an open source meeting this following week and we'll continue to     
3:30     
have those weekly meetings from here on out i wanted to bring your attention to this calendar     
3:37     
this is on the main website orthogonalressearchweekly.com this is     
3:43     
our calendar so if you go to the website this is what it looks like you go down to this calendar i have an a a Google     
3:50     
calendar embedded in the website and you can see that we have um Fridays we have     
3:57     
our 11:00 a.m meeting mondays we have DVORM saturdays we have this meeting and     
4:04     
we also have other meetings throughout the year we have a cybernetics interest     
4:10     
group which last time we met was meeting on Thursdays we had Cognition Futures     
4:16     
last time we met we were meeting on Wednesdays and so that's where you can     
4:22     
go to find the weekly meeting schedule but meetings are happening that week um     
4:29     
some of them of course will be accessible to people in places like Europe or India and some will not     
4:37     
because they're in North America they'll be in the evening yeah um and so what we do in the     
4:45     
lab as well is we record sessions and make them available on YouTube primarily     
4:52     
so that we can a involve people who couldn't make the meeting couldn't make the time busy or whatever and b to go     
5:01     
back and extract things from the meetings because as you know from this     
5:06     
meeting we're at about two and a half hours with these meetings or so and you     
5:11     
know there's a lot of information in the meeting and you know I I in the YouTube     
5:17     
description I usually put the references and a description but we also have     
5:23     
transcripts of these meetings and so u you know this is something that we can     
5:29     
generate with AI we can use uh I use a     
5:34     
tool um called orbit it's put out by Mosilla Foundation     
5:42     
and it basically trans it's a plugin to Firefox and it transcribes the video     
5:47     
it's not you know perfect it does generate some interesting gibberish but     
5:52     
for the most part it gets the job done and we can have a transcript of the     
5:58     
video and so then that's now being posted as sort of an additional     
6:03     
component of the meeting structure if we go to the     
6:09     
Saturday morning neurosim repository which is here this is the readme file this is on the oral group GitHub you     
6:17     
have uh archives going all the way back to August of 2020 that's when we first started this particular iteration of the     
6:25     
Saturday meeting um and you know we have the links to the     
6:30     
video and a social media post okay so if we go to April we see that we have the     
6:37     
meeting recording the social media post the     
6:42     
notes and then a transcript which is by you know searchable by kindpoint in the     
6:49     
video so I can go back to the video I can search this text I can go back to     
6:54     
the video content and catch up on what we're doing we always like to offer these affordances because they help     
7:01     
people to digest what we're doing in the meetings and I think that's useful for     
7:07     
kind of not losing things we've Jesse has a term for this it's called the     
7:12     
twirly bird method of retrieving that sort of information and uh a twirly bird is a     
7:20     
little seed from a maple tree that falls and the idea is it's ephemeral so we     
7:26     
want to avoid the ephemera where we can you were gonna say something Jesse     
7:35     
oh no i just I didn't I caught out and then heard my name but then I get why so     
7:40     
Oh yeah unless you had a question it's okay oh no not quite yet we have uh one     
7:45     
more thing to talk about well I I'll I'll set up your update if you're ready to go are you ready for an update or     
7:53     
um give me give me like I don't know if few more minutes or 10 minutes would be     
8:00     
ideal but I don't know what else you had to do today so I was going to say but not right now so okay well let me yeah     
8:07     
let me I'll do something first yeah finish whatever you wanted to do     
8:13     
so that's our So we have that on GitHub um and then I would like to point out     
8:19     
that we have our GitHub and I know that VD knows where this is because     
8:28     
uh she's been contributing to the git the GSOC repository which is     
8:35     
here and this will be the place where we do Google summar of code but this is our     
8:41     
organizational repository we have different types of uh projects     
8:48     
metabrain models developmental brainberg vehicles um we have our Saturday morning     
8:55     
neurosim repository we have the uh uh the virtual     
9:01     
reality projects that we were doing in 2023 and then I have things for project     
9:07     
manager course on here the practice component of that     
9:13     
so this is a lot of this is you know kind of hard to I wouldn't recommend     
9:18     
diving into everything you know if you have something I think developmental brainberg vehicles G-S Saturday morning     
9:26     
neurosim I think that'd be interesting to kind of use that as a sort of a you     
9:31     
know way to digest some of these meetings you know add things into that repository maybe code demos or whatever     
9:38     
that we do in the meetings and then We have things like metabrain models     
9:43     
these are all projects that we've done papers on and you know these are things that     
9:49     
people can contribute to um a lot of our projects you know won't     
9:54     
have like a lot of code associated with them in this repository there's usually     
10:00     
a link uh but you know if you're interested in something let us     
10:06     
know okay so I'm going to talk about an article and then I'm going to kind of     
10:12     
turn to Jesse if he's if he's available at that time so let me get to the     
10:18     
article I was wanting to talk about here first and that is this article from     
10:24     
Quantum Magazine and I think this ended up in the Slack and I can't remember who posted it     
10:29     
i think it may have been Morgan uh it may have been Vy be's been posting some interesting things morgan     
10:36     
as usual posted some very interesting things um this is an article so Quantum     
10:44     
Magazine is like a popular science magazine or website and they have this     
10:50     
machine learning article uh a new approach to computation reimagines artificial intelligence so     
10:58     
you can see they have this apple and they have vectors coming out the whole apple's made of these four vectors and     
11:05     
yeah it's it's um we'll see what they're getting at here um so it's an intriguing     
11:13     
picture by imbuing enormous vectors of semantic meaning we can get machines to     
11:19     
reason more abstractly and efficiently than before so you know there's been     
11:25     
this So if you go back to like the origins of Goi or good oldfashioned AI there was     
11:34     
of course this rule-based type approach that people were using they would you know throw the     
11:41     
artificial intelligence up against games of strategy like chess checkers or go they     
11:49     
play those games and you know there was this symbolic aspect to a lot of those     
11:55     
programs where you know you you would have this you know these rules but then there     
12:01     
would be this semantic aspect to the the     
12:07     
program and you know at that time it exposed a lot of issues with that type     
12:13     
of approach and so we ended up with this     
12:18     
newer type of data driven approach which is uh characterized by like imageet and     
12:25     
these other types of data driven training and so that's kind of where we     
12:31     
are now of course we find that there are a lot of shortcomings with that approach in terms of moving to semantic meaning     
12:37     
in terms of incorporating semantics into the models and so this is what they're getting at you know now we can kind of     
12:45     
approach things like large language models and uh you know things like deep     
12:50     
learning models with some sort of semantic properties and so that's what     
12:56     
they're going to talk about here so this has relevance to to     
13:02     
NLP machine learning etc so we start um with this despite the     
13:11     
wild success of chat GPT and other large language models the artificial neural     
13:16     
networks that underpin these systems might be on the wrong track okay so that's they motivate this     
13:22     
by saying that and again it may or may not be that they're on the wrong track     
13:27     
but they certainly have shortcomings so for one artificial     
13:33     
neural networks are super power hungry um and then another issue is that they     
13:39     
lack transparency such systems are so complicated that no one truly     
13:44     
understands what they're doing or why they work so well this in turn makes it almost impossible to get them to reason     
13:51     
by analogy which is what humans do using symbols for objects ideas and     
13:58     
relationships between them so this is you know we've talked about world models with respect to like machine     
14:05     
learning and deep learning and large language models but there's this earlier attempt     
14:11     
at this called schema or creating schema mental schema for artificial models and     
14:19     
and that would be you know where we have this framework ultimately of the world     
14:24     
as these sort of analogies or these symbols and you know Douglas Hoffadder     
14:30     
of course who wrote Bud Asherbach um wrote a lot about you know these     
14:36     
sorts of issues with you know analogies fluid analogies and so     
14:42     
forth there were other people you know uh working in like the 70s and 80s and     
14:47     
90s who were also thinking about these things so this is not a new thing it's     
14:53     
just really hard to do and it's certainly not something that's been done in a lot of the neural models at least     
15:00     
very successfully such shortcomings likely stem from the current structure of     
15:06     
ANNN's and their building blocks individual artificial neurons so remember we're using this connectionist     
15:12     
approach where we have these single neurons or units is maybe a more accurate way to put it they're     
15:19     
connections between the units and those connections are you know only are defined by weight they're not defined by     
15:26     
concepts necessarily if you have concepts that are associated they could be you know     
15:32     
actual concepts that are associated or they could be spurious correlations and that may be the root of     
15:39     
some of the hallucinations that you see in models or the false positives that you see in     
15:44     
models okay so that's uh but they kind of get at that building block of a     
15:51     
artificial neural network individual artificial neurons so it's not conceptual it's these units of     
15:58     
processing each neuron receives inputs performs computations and produces     
16:04     
outputs modern artificial neural networks are elaborate networks these computational units trying to do     
16:11     
specific tasks yet the limitations of this kind of     
16:16     
approach have long been obvious uh so let's take the example of how an artificial neural network needs     
16:24     
to be able to tell apart two types of categories circles which are round and     
16:30     
squares which are of course square with corners so let's say that there's this     
16:36     
basic classification task one way to do it is to have two neurons in its output     
16:42     
one that indicates a circle and one that indicates a square so there is one way to do this kind of classification task     
16:49     
where you have an input of some observation you have this hidden layer     
16:55     
of uh you know that decomposes the image into the features and then you have this     
17:01     
output which are two categories so based on those features and based on the input you should be able to put something into     
17:08     
one of those two categories and so you know it could be that you always get the circles and     
17:15     
squares correct or it could be that there are false positives in each     
17:21     
category so that's the way usually an artificial neural network does it does it statistically it does it by breaking     
17:27     
down the thing into its component features and then making a decision     
17:33     
based on there is no semantic value to any of that so if you want your ANN to also     
17:41     
discern the shape's color so let's say we have our circle and our square and we have two units we basically have two     
17:48     
output units one that's basically full of circles hopefully and one that's full of squares     
17:54     
and that does a good job maybe of characterizing the shape but it doesn't     
18:00     
do a very good or it doesn't do any sort of a job in characterizing the color so if we have blue circles and red circles     
18:07     
or blue squares and red squares or just blue shapes and red shapes we can't discern that from that that two unit     
18:15     
output alone we sometimes will need four output units     
18:20     
or more because we might want to say sort things into transparent circles     
18:28     
transparent squares and then blue shapes and red shapes or blue squares and red     
18:33     
squares blue circles and red circles which would be four but then you might     
18:38     
want to have transparent circles and transparent squares which would be six and you can see that for every you know     
18:46     
you have you you decompose your images into features in the hidden layer but if     
18:51     
you want to sort those into classified outputs you need to have more neurons or     
18:57     
more units in the output layer and so you know this adds a lot of     
19:03     
computational overhead to a model because for every distinction you want     
19:09     
to make you need to just keep adding units but you can't just keep adding units without increasing the     
19:16     
computational cost so when you get something like a deep learning network you get this very deep network meaning     
19:22     
that there are a lot of layers you're extracting features you're recombining features and then you have some output     
19:29     
but that all costs you computational power it makes things super power hungry     
19:35     
and it makes things hard to sort of audit you can't trace through the network very easily     
19:41     
because you have so many features and a lot of times with deep learning models you know you have billions or even     
19:49     
trillions of parameters and each of those parameters you know how do you audit a model that big so this is a     
19:56     
problem that you know we have to kind of figure out and of course we could say     
20:02     
okay well one way to do that is to get like a um you know a semantic model so     
20:08     
we could say we could basically assign each of these features     
20:14     
in the hidden layer some semantic value and then put that into the model and be     
20:20     
done and maybe that's true but that also as we know from gi good oldfashioned AI     
20:28     
that also comes with a computational cost so at any rate the this article     
20:33     
continues they interview Brunoin who's a neuroscientist and he says this can't be     
20:39     
how our brains perceive the natural world with all its variations which is true because our brains would be     
20:47     
uh you know much larger they are if we had to do this type of computation to kind of discover or     
20:55     
distinguish all the distinctions in the world that we usually do i mean think of     
21:00     
all the distinctions we can make of a single scene of a single object all the meaning all the different labels that we     
21:08     
put on things etc so we can't you know we it's pretty     
21:13     
incredulous to a neuroscientist to suggest that an ANN is basically how we perceive the world is     
21:20     
the point here um he says you have to propose that well you have a neuron for     
21:26     
all combinations so you have in your brain say a purple Volkswagen detector and     
21:32     
this is an interesting point because there have been people who have proposed in neuroscience     
21:39     
uh things like grandmother cells which are these cells that respond to a     
21:44     
stimulus of showing you a picture of your grandmother or showing people pictures of famous faces and having     
21:51     
specific neurons respond to that there there's this whole history of like this type of thinking where we can reduce     
21:59     
like object recognition to single neurons and we can trace through uh and find you know a pathway between     
22:07     
those neurons and we can isolate these sorts of identities and decisions to a     
22:14     
set of neuron a very small subset of neurons in any case that's that's not necessarily I think a lot of times     
22:21     
that's used as a metaphor So this is another reason why this is     
22:26     
maybe incred neuroscientists find this incredulous     
22:31     
um so you know this is something that again is going to cost you a lot of     
22:38     
computational power or computational overhead so you know what does the brain     
22:44     
do so and others argue that information in the brain is represented by the     
22:50     
activity of numerous neurons okay so their approach is different they advocate for a population view they're     
22:57     
not even talking about semantic value at this point they're just talking about a population of neurons and uh doing     
23:05     
something um on stimuli and then finding maybe like a population     
23:11     
average so this is uh getting into some of the stuff that people have done in computational neuroscience     
23:18     
so the perception of a purple Volkswagen is not encoded in a single neurons actions so there was no grandmother cell     
23:25     
or purple Volkswagen cell or purple Volkswagen detector but is those of thousands of     
23:32     
neurons so a purple Volkswagen say is encoded in thousands of neurons it's     
23:38     
collective action of neurons and then there's some thing that emerges that     
23:44     
gives you this concept of a purple Volkswagen and then you know that's uh     
23:51     
you could have false positives there you can identify purple     
23:58     
uh you know other types of purple cars as purple Volkswagens but that's that's     
24:04     
a category that is not a product of not having a     
24:11     
representation um the same set of neurons firing differently could represent an entirely different concept     
24:18     
for example a pink catalog so you could have these different sort of semantic labels on these     
24:25     
populations um it it's important to you know understand that like it's not so     
24:30     
much putting a label on them as it is that this category emerges that's     
24:35     
consistent in finding these types of objects so you might have a population of neurons that are consistent in find     
24:43     
identifying a purple Volkswagen or a pink Cadillac it's not necessarily a semantic label it's just that the     
24:51     
um the population is good at finding this feature or the set of     
24:56     
features this is the starting point for a radically different approach to computation known as hyperdimensional     
25:03     
computing so now we're taking a concept from computational neuroscience and we're turning it into a computing     
25:09     
concept and some people are calling this hyperdimensional computing the key is that each piece of     
25:16     
information such as the notion of a car or its make model or color or all of it     
25:24     
together is represented as a single entity and that entity is a     
25:29     
hyperdimensional vector so again we go up to the image and we had this ve these     
25:34     
four vectors and it was creating a shape and the idea is that um the image     
25:43     
notwithstanding you have this vector that has multiple dimensions that it     
25:49     
represents and then that's the piece of information that's being     
25:56     
computed a vector is simply an ordered array of numbers a 3D vector for example     
26:01     
comprises three numbers the x y and z coordinates of a point in 3D space a     
26:07     
hyperdimensional vector or hyper vector would be an array of 10,000 numbers say     
26:14     
representing a point in 10,000 dimensional space so this is where again     
26:20     
you know we we're using a vector to represent a point in this space it could     
26:26     
be three dimensions so we have a 3D vector we could have a 10,000 dimension     
26:32     
space or a 10,000 dimension vector and you know we could think of     
26:39     
this in terms of like tpples and how you know each kind of     
26:44     
entry in this vector is like this three tpple or this 10,000 tpple and then we     
26:52     
have this vector which you know is kind of like maybe the reading of     
26:57     
each cell in a in a population or something like that     
27:02     
um but the idea here is to give us a framework for representing objects representing concepts in something that     
27:10     
is has a time dimension and something that has a dimensional aspect to     
27:17     
it okay so I should say that like you know in our deep learning models in our machine     
27:25     
learning models we often describe things with these tpples or sometimes we'll use     
27:30     
vectors we'll use different ways of representing the feature space we might     
27:36     
even use it to represent semantic values so we can encode semantic values but     
27:42     
this is a quite a different way of doing this um it's a way of encoding this all     
27:48     
as a vector or hyper vector and allowing us to sort of do     
27:53     
this uh in a way that's compact much more compact than in the way we do it     
28:00     
now uh these mathematical objects and the algebra to manipulate them are flexible and powerful enough to take     
28:07     
modern computing beyond some of its current limitations this is the thing that I've been most     
28:13     
excited about practically in my entire career and so Wolshen is a big fan of     
28:18     
hyperdimensional computing uh it makes computing efficient and robust and it makes uh decisions     
28:25     
entirely transparent so you can actually see the you know what the encoding is     
28:31     
and you can understand it so to understand how hypervectors make     
28:36     
computing possible let's return to images with red circles and blue squares first we need vectors to represent the     
28:43     
variable shape and color so we have two vectors one for shape one for color then     
28:49     
we also need vectors for the values that can be assigned to the variables circle square blue and red so we have uh I     
29:00     
guess six vectors here and we have these vectors that you know have the shape and     
29:05     
color of everything we're going to add to these vectors as we move through the analysis of this object or these     
29:13     
objects the vectors must be distinct their distinctiveness can be quantified     
29:18     
by a property called orthogonality which means to be at right angles so they need to be at right angles to one     
29:24     
another in 3D space there are three vectors that orthogonal to each other     
29:30     
one in the x direction another in the y direction and a third in the z so it creates this 3D     
29:36     
space or at least three spatial dimensions uh so that's a 3D     
29:43     
vector and then if we have a 10,000 vector that's where we have 10,000     
29:49     
mutually orthogonal vectors so we have this highdimensional space which has you know we don't want to put letters on     
29:55     
them anymore we want to just think of them as being all orthogonal to one another but having 10,000 vectors which     
30:02     
is a very crowded space a very highdimensional space something we can't really visualize easily we usually have     
30:09     
to reduce this to three-dimensional space to actually visualize it but those     
30:16     
you know dimensions exist so basically we're in a similar situation that we are     
30:21     
with our parameter space in deep learning or in machine learning where we     
30:26     
have all these parameters we have this highdimensional space and we reduce it down to some     
30:33     
visualization so you know we still have that sort of complexity it's just that we're using vectors     
30:39     
uh to represent the data but if we allow vectors to be nearly orthogonal the     
30:44     
number of such distinct vectors in highdimensional space explodes so when a 10,000 dimensional space are millions of     
30:51     
nearly orthogonal vectors but now let's create distinct     
30:57     
vectors to represent shape color circle square blue and red     
31:05     
so we want to create these distinct vectors to represent these six features or these six things that we're     
31:12     
interested in because there are so many possible nearly orthogonal vectors you can assign     
31:19     
just assign six random vectors to represent the six items they're almost guaranteed to be nearly orthogonal so in     
31:26     
this case we're kind of forcing the orthogonality     
31:33     
um by I guess just assigning random vectors to     
31:38     
represent these items ease of making nearly orthogonal vectors is a major reason for using hyperdimensional     
31:46     
representation um and this is in a a 2009 paper um this is     
31:54     
uh Penty Canerva who's a researcher at the Redwood Institute uh I don't I might     
32:01     
have the paper down below um the paper built was built upon work     
32:07     
done in the mid 1990s by Canerva and Tony Plate at the time a doctoral student of Jeff Hinton at the University     
32:13     
of Toronto so the two independently developed the algebra for manipulating hyper vectors and hinted at its     
32:20     
usefulness for highdimensional computing given our hyper vectors for     
32:25     
shapes and colors the system developed by Canavan plate shows us how to manipulate them using certain     
32:32     
mathematical operations those actions correspond to ways of symbolically manipulating     
32:38     
concepts so the first operation is multiplication this is a way of combining ideas for example multiplying     
32:46     
the vector shape with the vector circle so remember we have these six     
32:53     
vectors they're being assigned randomly and they're orthogonal but then we're going to do     
32:59     
operations on these uh vectors so we're going to do a multiplication     
33:04     
operation we're going to combine ideas we multiply the vector shape with the     
33:10     
vector circle this binds the two into a representation of the idea that shape is     
33:17     
circle so we're building representation from a simple operation on two vectors     
33:22     
that are orthogonal by themselves but we can also then create these     
33:28     
representations this new bound vector is nearly orthogonal to shape and circle     
33:34     
again it guarantees it's orthogonal because it has new information in it and     
33:39     
the individual components are recoverable all an important feature if you want to extract information from     
33:45     
bound vectors so given a bound vector that represents your Volkswagen you can     
33:52     
unbind and retrieve the vector for its color purple so what they're doing is these operations that are reversible you     
33:58     
can extract things out of the representation you can combine things into representations and it doesn't require a     
34:06     
lot more computational power it doesn't require you to encode your orthogonal vectors you're just taking information     
34:12     
out of existing orthogonal vectors and discovering that uh those     
34:19     
representations the second operation which is addition creates a new vector that represents what's called a     
34:25     
superposition of concepts for example you can take two bound vectors shape is     
34:30     
circle and color is red and add them together to create a vector that represents a circular shape that is red     
34:37     
in color again the suppose vector can be decomposed into its constituents and     
34:44     
this new representation is adding something to the model namely it's not     
34:50     
only adding this semantic property but it's also adding in like maybe like the     
34:55     
creativity aspect so it's creating new things it's kind of reasoning it's doing     
35:02     
what you might call induction perhaps um you're able to basically create um a     
35:09     
shape you know a certain shape that has a certain color and that's then that     
35:15     
representation is reversible so it's interpretable but also um you know it's     
35:21     
it's not adding a whole new representation to the model     
35:27     
the third oper operation is permutation which involves rearranging the individual elements of the vectors     
35:34     
for example if you have a three-dimensional vector with values labeled X Y and Z so we have this     
35:40     
threedimensional vector permutation might move the value of X to Y Y to Z     
35:46     
and Z to X so you're moving things to different dimensions basically it's like taking a cube and turning it in space     
35:55     
rotating it and having those values and end up in those different     
36:00     
positions and you know so this is just a way to kind of understand what you have     
36:06     
uh in the article Perva says permutation allows you to build structure it allows     
36:12     
you to deal with sequences things that happen one after the other okay so you     
36:17     
you it's like taking an object and turning it simulating it seeing what it     
36:23     
does in time with function     
36:28     
etc consider two events represented by the hyper vectors A and B we can     
36:34     
superimpose them into one vector but that would destroy information about the order of     
36:39     
events okay so we could like take two vectors and just kind of you know     
36:46     
uh reduce their dimensionality and have a summary statistic um that would be     
36:52     
fine except that you would destroy information about the order of certain events you destroy context and you     
36:59     
probably destroy a semantic value as well combining addition with permutation     
37:05     
preserves the order the and the events can be retrieved in order by reversing the operations much as you might do with     
37:12     
a math problem where you have certain a certain order of operations and getting an answer and that if you change that     
37:19     
order of operations you get a different answer but the key is like the way in which you execute this and it's     
37:26     
reversible because you can just back up and you know use the reverse     
37:31     
operations to retrieve the information so it's a lossless type of     
37:37     
approach meaning you don't lose information you're just you know kind of     
37:43     
compressing information or better yet you have information encoded in a better     
37:49     
data structure together these three operations proved enough to create a     
37:54     
formal algebra of hyper vectors that allowed for symbolic reasoning but many     
37:59     
researchers were slow to grasp the potential of hyperdimensional computing     
38:05     
and so then this led to uh 2015 study by Eric Weiss who demonstrated one aspect     
38:12     
of hyperdimensional computing's unique abilities we figured out how to represent a complex image is a single     
38:20     
single hyperdimensional vector that contains information about all the objects in the image including their     
38:26     
properties such as colors positions and sizes so this this helped those shows and     
38:33     
conceptualize how this worked uh so they've been developing these hyperdimensional     
38:40     
algorithms replicate simple tasks that deep neural networks have began tackling about two decades before such as     
38:46     
classifying images so this is of course the imageet stuff     
38:52     
um and so they walk through how this algorithm works and     
38:59     
um so this is just kind of the beginning of how to apply this method the     
39:04     
strengths of hyperdimensional computing line the ability to compose and decompose hyper vectors from reasoning     
39:11     
the latest demonstration of this came in March when Abaserini and colleagues at IBM research in in Zurich used     
39:19     
hyperdimensional computing with neural networks to solve a classic problem in abstract visual reasoning a significant     
39:26     
challenge for typical artificial neural networks and even some humans known as     
39:32     
Raven's progressive matrices the problem presents images of geometric objects and     
39:37     
see a 3x3 grid one position in the grid is blank the subject must choose from a     
39:43     
set of candidate images the image that best fits the book we said this is really the killer     
39:50     
example for visual abstract reasoning so that's why they chose that problem and so they wanted to create     
39:57     
this hyperdimensional computing representation of this problem the team first created a     
40:03     
dictionary of hypervectors to represent the objects in each image each hyper vector in the dictionary     
40:10     
represents an object and then some combination of its attributes the team then trained a     
40:15     
neural network to examine an image and generate a bipolar hyper vector where an     
40:20     
element can be either plus one or negative one so it has this sort of um     
40:26     
polarity to it and so this is how they represent superposition which is a concept from     
40:34     
quantum computing and quantum physics but they're using it in this model and     
40:41     
they're doing it in a way that's not you know uh it doesn't involve quantum computations but it does involve this     
40:49     
representation uh the generated hypervector thus contains information about all the objects and their     
40:56     
attributes of the image you guide the neural network to a meaningful conceptual space that's basically the     
41:03     
goal so you want to have these vectors you do these operations on them you have this encoding and you try to find     
41:10     
different concepts in the space once the network has generated hyper vectors for each of the context images and for each     
41:17     
candidate for the blank slot another algorithm analyzes the hyper vectors to     
41:22     
create probability distributions for the number of objects in each image their size and other characteristics     
41:30     
so then you have these probability distributions which speak to the likely characteristics of both the content and     
41:36     
candidate images and how those can be transformed into hyper vectors allowing     
41:41     
the use of algebra predict the most likely candidate images to fill the vacant     
41:46     
slot their approach was nearly 88% accurate on one set of problems whereas     
41:52     
neural networks or neural network only solutions were less than 61% accurate so     
41:58     
this is where we're adding this hyper vector approach to a neural network as     
42:04     
opposed to just using the neural network and it's its representation of the problem so with neural network only we     
42:12     
have 61% accuracy with the hypervector approach using with neural networks we     
42:18     
get this 88% accuracy so we get this increase in accuracy and so you know not only do we     
42:25     
have the sort of semantic representation or this potential for semantic representation we just get more accurate     
42:34     
models the team also showed that for 3x3 grids their system is almost 250 times     
42:40     
faster than a traditional method that uses rules of symbolic logic to reason     
42:45     
so this is what we were talking about with the application to go where you know they were using symbolic logic they     
42:52     
were using these types of methods where you have this great computational overhead of encoding rules encoding you     
43:01     
know uh trees and things like that that give you this symbolic     
43:06     
logic and so they were able to show that it's superior to that approach as well and of course the reason why that     
43:13     
is is because with symbolic logic the method must search through an enormous     
43:18     
rule book to determine the correct next step so a lot of times if you were like trying to get a machine to play chess     
43:27     
you know you can use the sort of deep learning approach that uh different teams have used to be human     
43:34     
experts where you have all these moves you analyze the moves you can have these outputs for the next move or you have     
43:42     
these huge symbolic trees where you try to analyze the moves and you know give the next move or     
43:51     
you have this approach which is faster than it it combines and recombines things using these     
43:58     
operations so they haven't done anything with chess but I'm I'm kind of uh you     
44:05     
know sort of teasing a potential application domain in the future um so     
44:11     
this is a promising start uh there's some issues with performance and     
44:17     
problems with how to apply this uh there are a lot of error correcting mechanisms     
44:23     
that give that are of high cost uh it's a fairly tolerant method for error     
44:30     
things like that um and so you know this is something that is an emerging     
44:36     
approach but you know it's something also that has you know we we we have to figure out     
44:43     
kind of how to apply it the problems domains in which it can be applied and     
44:48     
uh you know it we have to see where we can apply it maybe it's not uh     
44:56     
universally applicable but I think it's a promising approach     
45:02     
And it kind of reminds me of the things we've been doing     
45:07     
with contextual geometric structures and you know this is a different kind of     
45:13     
concern that that's trying to achieve but deals in the same area and there have been a number of other approaches     
45:20     
that have been kind of parallel to this so from my perspective I think it's     
45:25     
actually getting approaching the problem in the right way     
45:33     
okay do we have any questions or     
45:47     
comments okay so I don't know if Jesse's ready to give an update but we had a     
45:54     
question from VD or a comment um yeah just like minimax or alpha beta algorithms     
46:03     
yeah I said like right now when you mention about chess and then the 3 + 3 grid and then how we have the minus one     
46:08     
0 and plus one so I just like yeah it's like related to it's not related to it but that's how mini maps and even alpha     
46:16     
beta algorithms work so yeah I just wanted to say that okay that's good     
46:21     
thank you you there Jesse     
46:27     
yes hi um so we had our first meeting yesterday     
46:35     
it was it was actually I I always look forward to the start of the season but     
46:40     
then um we got to go into a lot of introduction material but it's that     
46:46     
important part of like sorting out what you want to do um and getting things going and probably can say more about     
46:52     
that or not but in in in the meeting um it was fun because what what I got to     
46:58     
say or what I'm sharing or or championing of some form is we've had     
47:06     
for for many many years we've had a development of uh what actually happens     
47:12     
during our meetings and typically they're Friday meetings that are these Google Summer of Code     
47:19     
opensource open source and now sort of it's     
47:24     
professional development component to all of them and it's it's     
47:29     
um it was nice because I think we have a nice breakdown now of um you know so     
47:36     
like the the the specific content that the contributors will be working on will     
47:43     
be in their home meeting which has DVO graph like all the detailed The     
47:49     
questions will be in those Monday meetings some of the ones that are for open source will probably be more in     
47:54     
this meeting but well the open source sustainability project I should say for     
48:00     
open source at large and the Google Summer code project at large and our our     
48:06     
whole like what has now become the cohorts are all going to be in these Friday meetings and we had the first one yesterday     
48:13     
so it's I I kind of feel like okay like we're starting to sort of evolve um in a     
48:20     
nice way of having those things uh segmented but then     
48:26     
also for for years which sounds like forever and it feels like it but it's     
48:32     
it's not that many years but it is years you know Bradley and I have been talking     
48:37     
about um we we would have we would have we     
48:43     
would just have discussions in the meetings and they they were good and they'd be important things we mentioned tw mentioned um a lot of like project     
48:50     
management stuff yesterday barely had the own course on uh open source project management we presented at active     
48:57     
inference who presented at a few different events and conference over the years about like what do you do in in     
49:02     
the space and on a personal note it's it's very a     
49:08     
rewarding time because I am finally being able to crystallize some of these efforts     
49:15     
into different projects for me too um I have finished my graduate program in     
49:22     
data science and part of the capstone work there um and some of the course work there has led me to kind of these     
49:27     
two new projects that are uh Jerro um basically projects within Jerro they     
49:34     
they pro they they're still part of is probably both mostly under the um society ethics     
49:41     
technology working group that came up here was established in uh orthogonal     
49:47     
lab still exists still going strong has been doing a lot of things um but these     
49:52     
are like projects a little bit more specific than applied like uh these two I think are are very applied in ways     
49:58     
that I haven't really done in the past or that we haven't focused on most recently I should say so the two     
50:05     
projects are from here to there um from here to there strategy and mentorship     
50:11     
for innovators which is essentially going to be a lot of commentary and interviews and discussions and how to uh     
50:18     
sort of like theory and application for project management um but     
50:25     
also this is probably a good time as any what I really want to do with it is offer a much more um much more holistic     
50:33     
take on a lot of these a lot of what happened because I find a lot of discussion around these things is a bit     
50:39     
expert laden and a bit siloed so what I want to do is from here to there somewhat     
50:45     
is have the three sort of major categories in the same room like you     
50:51     
have your seuite and your high vision abstract how do we pursue a goal or a     
50:58     
target whatever you want to do you have your sort of the people     
51:03     
um building it out this should be oh well yeah     
51:09     
um you have sort of like what is it like to be on a team and to lead a team to be a project lead to be to be in between um     
51:18     
the highest level in an organization and and and the people on the teams building     
51:24     
products like what is in the intermediary space then you have things for people who are either early career or just joining the team at at at that     
51:31     
level um there's obviously a lot of gray and overlap in these spaces but what I     
51:38     
really wanted to do is to have almost     
51:43     
a a space where almost like being a bit of a mediator um but having these     
51:49     
discussions where you know um in in one     
51:54     
in you know in one in one post I'll focus like a lot of a lot of the posts that currently exist for example on here     
52:01     
are like first I'm on a panel applying the Google Summer of Code right that are are much more early career oriented and     
52:10     
that's great and and and I was it was it was so nice because I feel like we had a really really natural dovetail um in the     
52:17     
Google Summer code meeting yesterday where we're saying "Hey we're gonna talk about um where you're at now and where     
52:24     
you're at is great but we're also going to mention some things like we're gonna we're going to mention um when you're     
52:31     
presenting at your uh vent like what's what's what was this event like where     
52:37     
these people this is a a graduate course on building an AI venture and you're     
52:43     
presenting to people who've sold 23 AI companies in their careers like like     
52:49     
this that's so it's kind of like starter town versus final boss in terms of in     
52:54     
terms of uh you know putting something into in in industry or in in a market     
53:01     
you know and making money off of it in that sense and that's not everybody's final boss obviously and doesn't need to     
53:07     
be but for the sake of the whole spectrum being able to represent what those things are and to give to give to     
53:15     
give people a sense of when you're at this stage here's here's what you should be doing and and things like that um I     
53:22     
was just it's just nice to kind of have more there because for for folks who don't know um this this these kind of     
53:31     
were this conversation and they're like "Oh I should write about this or I'll write a little bit about about that or     
53:36     
let's write kind of a post something to the medium page and and talk about it." But now it's now it's a bit more than     
53:43     
that and and I'm very thankful i don't know if my uh one of my collaborators     
53:49     
might be able to to join me soon um but     
53:55     
um like they might pop into this meeting but I'm very thankful to sort of have     
54:02     
this infrastructure in place this is one of the projects that's sort of a spin-off from finally finishing my my     
54:09     
grad work the capstone my time in this lab my time in a lot of the spaces here i'm I'm based     
54:15     
in Boston currently and doing a lot of things and um the innovation space is here and also I spent the last four     
54:22     
years um but sort of being a     
54:28     
strategic administrative assistant but like dealing with strategy dealing with     
54:34     
um talking to vendors in a health tech space like I' I've been on the machine     
54:39     
learning teams uh I've been uh I've been with the hardware team i wasn't I wasn't     
54:47     
an engineer in either one of those things but I've been in the room with those people trying to make decisions about how to build up at that level um     
54:55     
and then you know it it's just it's just a more holistic perspective that I'm really trying to pursue and I'm really     
55:01     
excited to be able to do that here and so we'll seed a little bit of     
55:06     
um that into the into the open source Friday meetings and I'm I'm excited about that in general um hold on this     
55:15     
here some questions okay yeah um anyway I uh what     
55:26     
else do we talk about i will I'll dip into the AI ventures a little bit and     
55:31     
the other one the other project is essentially um this one uh data and direction which doesn't have as much     
55:37     
post yet but I actually am doing um I'm I'm having interviews I think starting     
55:44     
next week um about about working on this project which is really cool and uh it's sort of     
55:50     
like it's sort of like a we robot related stuff it'll be about data     
55:56     
science but also So these sort of tools like um the data nutrition labels you     
56:02     
mentioned before uh I was able to go to this event which is very very very informative this is actually last week     
56:08     
at MIT um the kind of these sort of year end uh you know showcases they're doing     
56:15     
this this is one for the ethics and computing research symposium one     
56:20     
um but it's just been it's been fun and it's been nice to kind of build out these things to we're going to do     
56:27     
projects we're going to do talking about it and I'm I'm hoping to get uh I have interviews lined up i just have to sort     
56:34     
out some of my hardware about things and go from there um okay um let me stop sharing all this     
56:44     
stuff for a second and turn this off and try to     
56:51     
um yeah try to message     
56:57     
my collaborator so they can join in uh but before I will take a brief pause and     
57:04     
then talk about the the event I attended two days ago the specific ventures thing a few things from that um but any     
57:11     
questions or comments in the meantime like be a minute before I     
57:18     
proceed nothing yet     
57:24     
okay and V feel free to like if you need to leave you can leave     
57:30     
yeah um I think that he's been here long after now but like these meetings can can be long and there's you know you can     
57:38     
come and go as you need to um and I say that for some of the uh the new people     
57:44     
joining the lab or looking at the lab or anything like that or coming along for Google software code like this is this     
57:50     
is just a big a big uh say party of     
57:56     
sorts and you don't have to stay the whole time um okay so     
58:05     
uh moving on I will go back to sharing my     
58:13     
screen he said okay um so yeah     
58:21     
um I've been trying to as as a side note I've been trying to sort of post um     
58:27     
in-person meetups when I time because I'm going to be doing more traveling this year and stuff like that uh this     
58:33     
was this was I was trying to it was it wasn't I'm still getting used to it     
58:38     
let's say but I tried to host a meetup around the the event i happened to have the fortune of being invited to this     
58:46     
event i ended up being kind of a judge or catalyst person i was by far the     
58:55     
um I have my qualifications and you know I'm proud of who I am but I I acknowledge that I was not the master in     
59:02     
the room of the the judges or the uh the the people that were there who have uh     
59:10     
basically been in the business probably much longer than I've been alive and and and just done a whole bunch of things so     
59:16     
being being in the room and being able to be around the the um the judges or     
59:21     
the senior people the folk folks that were there uh was very very     
59:28     
um very fun and and very uh engaging um     
59:34     
I I had a I     
59:42     
had Yeah um I had a good time i basically was was     
59:47     
a judge i was a what what what was the actual context for it um this is it     
59:53     
there there's sort of a a course it's called AI for impact solving societal scale problems     
1:00:01     
and it's it's a it's an intense course i don't know if they they've updated their website just recently but     
1:00:08     
um basically you you get a lot of highlevel help or mentoring on a topic     
1:00:16     
and you you start your um you start your     
1:00:23     
[Music] um sorry I'm so There we go this is the     
1:00:30     
actual main page now I think yeah yeah and they've been running it looks like for a couple years and it's sort of the     
1:00:37     
end of the year course work you know they had their their final um demo day today and it was a lot very     
1:00:46     
interesting take in terms of the m the MIT demo or DASA uh yeah here we go okay     
1:00:52     
so you can kind of see it started in February they had their meet and greet they've done this um midterm or whatever     
1:01:00     
and at the end of the at the end of it you have your final class and a social event so they had their final demos uh     
1:01:06     
during that day and it was it was a number of you know grad students from across many different disciplines and     
1:01:13     
the goal was you know um teams to produce endtoend functioning     
1:01:21     
prototypes and customer traction for their startup idea will teach students write of technical frameworks for     
1:01:26     
prototyping with AI uh lowcost geni tools um hands-on practical course high     
1:01:33     
impact real world uh learn technical fundamentals modern AI stack uh lectures     
1:01:39     
from AI scientists CEOs VCs all that stuff um and yeah like it it was it you     
1:01:46     
know I think one of the lines from the conference was like we're we're going to teach you how to you know do this stuff     
1:01:52     
and not just rearrange a poweroint point or um minutia about     
1:01:59     
about things that sort of might generically be covered this is very hands-on and what I really took away     
1:02:05     
from it overall and I'm I'll do some kind of a ramp about this or whatever um     
1:02:11     
it was an event it was uh it was the event itself was was um     
1:02:17     
like MCED and and hosted by John Wernner who does a lot of things in space he he     
1:02:24     
writes for Forbes he does the imagination action stuff he's he's a basically a super connector and and very     
1:02:30     
good at um what happened and I I' I've been reflecting a lot on you know     
1:02:37     
essentially come back here yeah on essentially um what you know just a few really quick     
1:02:44     
points from the whole event um I I've never really been at an event before     
1:02:50     
that was [Music] um Oops this isn't working i never     
1:02:57     
really been in an event before that was here     
1:03:05     
um conducted quite the same way and I've been to a few John Warren events but I think this is mostly this is a bit of     
1:03:13     
you know most the people there are very very very experienced and kind of know the drill about how to do this kind of     
1:03:18     
stuff but also a lot of a really a really good pacing everything was very     
1:03:24     
fast and fun like it it's it's always fun when you're when the bullets aren't flying at you and you kind of just get to sit back and relax and and enjoy the     
1:03:30     
show which really what I what I was doing um as opposed to being the high     
1:03:35     
pressure you know high stakes things for the students trying to pitch their things here and at their final project     
1:03:42     
but it was very fast it was moving well it was it was it it was kept engaging     
1:03:48     
and kept kept at a very nice pace and it kind of conveyed an implicit sense that     
1:03:55     
everybody's time uh was important and I'm I'm learning how to incorporate that     
1:04:00     
in other things that I want to do because it was there was just a lot going on there um John would also spend     
1:04:07     
a lot of time to just recognize whoever is in the room like what's going on like someone would walk in or he'd often pull     
1:04:13     
people that were someone was going I think Rosland Picard from MIT was like     
1:04:19     
going to lunch break and like hey you know who this is like you know know who this person is and a good job of just     
1:04:24     
like taking people out like know who's in the room here's somebody here you might want to know a lot of uh from a mentorship standpoint from a a     
1:04:32     
a making it making it accessible it was this really interesting balance between     
1:04:37     
keeping this train steadily moving forward taking like appropriate pit stops to     
1:04:43     
identify a key idea or a person or an opportunity and then making things work     
1:04:49     
for both the the teams and then keeping it moving for for the judges and sort of     
1:04:56     
the the VIP folks that you're trying that you're asking to do favors to give     
1:05:01     
time and care about what you're doing so it was it's interesting dynamic that way     
1:05:06     
um and and occasionally dropping in wisdom and perspective which was nice     
1:05:11     
like the the props that were used today were um the uh uh the Newton does any     
1:05:18     
like you might know the Newton Bradley but I remember Yeah I remember what it is it's a little palm Yeah handheld     
1:05:26     
device and it was it was the props were basically this um an old MIT yearbook uh     
1:05:34     
and also the Star Trek uh triquarter or the the medical communicator thing that they had like like you know a fictional     
1:05:40     
version of that and there was this nice narrative of basically saying you know     
1:05:45     
um like the United States has kind of had you know 250 years of of stuff     
1:05:53     
um the the the the future the Star Trek future is supposedly 250 years away     
1:05:58     
where are we now um a lot of you know I don't I I don't I'm not going to go into     
1:06:04     
this and you can you can guess all if you want but given that we're at MIT and innovation and and we're basically     
1:06:11     
training the this classes for training not entirely early career folks because     
1:06:16     
not everybody was early career in the class but some of some of them were undergrads a few few like undergraduate     
1:06:22     
types but a lot of graduate students from very different backgrounds from medical stuff from uh more social     
1:06:29     
science sciences like like all these different collaborations to make ventures we have everybody in the space and they're thinking about okay like     
1:06:35     
where is AI where is that going and all that stuff but the Apple Newton prop was     
1:06:40     
this sort of failed um writing device I guess and I don't I     
1:06:46     
never really used one I don't know if you want to talk about it at all but basically it's an example of a a product     
1:06:51     
that was a really good idea but for various reasons it didn't it didn't take off in the form that it came out to be     
1:06:58     
um and and it it was a a it became a     
1:07:04     
source of mockery I guess is a way to put it here um but also like it wasn't     
1:07:10     
meant in a derisive way in the discussion it was more just understand where um you know where things can go     
1:07:16     
and yeah like like basically there was a full semester term but I think they only really working on their projects fully     
1:07:23     
for six weeks and and there's something to be said one of the things as as a caveat uh for later     
1:07:30     
um you know I think I think this graph comes up     
1:07:36     
a lot because when you say for six weeks it's like yeah but like if you can actually start your ideas much earlier     
1:07:44     
the six weeks from here to here is a lot different from the six weeks from here to here so like depending on where you     
1:07:51     
start in this and what what people see and what effort says now if you've been cooking up your idea for two years and     
1:07:57     
get into this course and they have a whole bunch of uh advanced level mentoring that six week is going to be a     
1:08:03     
lot different than you come up with an idea out of totally out of nowhere and and and thinking about it for the first     
1:08:09     
time and I think that was one of the differences in the projects too um but uh like like the criteria for     
1:08:17     
judging was um impact uh which which is oh no I just remember     
1:08:26     
it yeah impact um which which which wasn't really defined and I I think that     
1:08:33     
was the most subjective take on on things but uh my my take on impact     
1:08:38     
probably is different than some others because of what I think should happen where the world will go in certain ways     
1:08:44     
whatever but it was impact it was um uniqueness which is very interesting     
1:08:50     
to think about and then also completeness so again um in kind of mentioning this graph like your sense of     
1:08:58     
visible success or the completeness may not you know linearly come to you or or     
1:09:04     
be visible to other folks but um it's there and so um yeah my my last couple     
1:09:12     
thoughts on the on the on the the event were um I have here it was it was just very     
1:09:21     
fun it was it was it was a very interesting lesson on both managing an event keeping things going and and and     
1:09:28     
giving giving spotlight for for for people some people got a little more encouragement some people got these like     
1:09:35     
some people just presented with very funny like obstacles saying like "Oh hey like here's you know here's an awkward     
1:09:43     
situation or here is a here's a potential rivalry between MIT and Harvard are they going to make it work     
1:09:48     
let's see what happens." like like John would kind of create these opportunities for people to deal with um you know     
1:09:56     
maybe awkward turns or whatever and there was there was there was an implicit kind of coaching to to things     
1:10:02     
and like at a very high level there's a sense of okay like get used to the     
1:10:07     
hustle and bustle get used to presenting and get used to you know when when     
1:10:12     
there's a curveball how do you handle it or a non ideal starting point you're     
1:10:18     
very well rehearsed three minute on the dot speech blah blah blah you know but here you go like like     
1:10:24     
getting used getting used to it at that level was was fun to see and it's like     
1:10:30     
very implicit little teachable moments the whole time so that was good and then     
1:10:35     
finally um like big picture takeaways something that I think everybody here knows but     
1:10:41     
just just to reiterate them like yeah like everything right now is like and granted it's the point of this course as     
1:10:47     
I said this is a of course about agentic and genai stuff right like it's about     
1:10:53     
using that stuff but they're focusing on that because it's super easy now like things that that would take months can     
1:10:59     
happen in weeks in terms of even just the the foundational work of doing the prototyping and and pushing the idea     
1:11:06     
into into things out there one of the one of the speakers it might have been might have been Romesh um who's done a     
1:11:13     
whole lot of things there he said basically you know um when I was in grad school or when     
1:11:20     
when much earlier in his life or career he's like well we just have nice papers you know we just all of our ideas would     
1:11:26     
just be a paper and theoretical and now you know you can have a good portion of the um presenters     
1:11:34     
like demonstrated their app live they demonstrated their functionality or they     
1:11:40     
they had they had something that we know was just uh functional uh but but     
1:11:47     
conveyed the intent and some people already have you know uh customers willing to line up to take it people     
1:11:53     
that are working on their focus groups and everything else so it it was interesting to see that but but the big     
1:11:59     
picture picture takeaway was essentially it's there's kind of a a big rush right     
1:12:05     
now to get an AI agent to get your native AI concept of building from the     
1:12:11     
start AI you know whatever you want to do making it about AI as opposed to just some kind of add-on flimsy wrapper that     
1:12:20     
you're you're adding to it to to you know have a minimal actual impact of making it AI and and get your     
1:12:28     
subject matter experts together create a unique service and then get people to     
1:12:36     
support it and and get it out and and it it's there's a lot of wacky applications     
1:12:42     
for this in the world and a lot of people that are just trying to you know make make something I want     
1:12:50     
to make something out of nothing but it it is the name of the game right now at the level of     
1:12:55     
combining expertise and creating you know through Genai stuff or making these     
1:13:01     
agents or making these like hyper specific um applications and then hoping that you can either connect to other     
1:13:08     
other groups or get it out and and and just be bought up by OpenAI or something like that there were a few mentions of     
1:13:14     
that that happened i don't know like that day of of [Music] um uh someone got bought by Open AI     
1:13:22     
whatever not at the event because there's like a few week cooling off period uh but you know people were     
1:13:28     
already at the event ready to invest in some of the projects there cool right but that's sort of the gold rush moment     
1:13:35     
right now is people trying to tenibly use AI stuff and get into the space and     
1:13:41     
and do it and have something come out and see what happens um and the other point or the flip side of the coin is     
1:13:46     
like yeah like just because you know it it is it is it is a course it was a six week course and and or six six weeks of     
1:13:54     
of being able to to um really work on the project so it     
1:14:00     
wasn't you're not going to have a complete product by then in in a general sense but um you know it was a sense     
1:14:07     
that the challenges are still there like not even not even people who have all this training all this back and all this     
1:14:13     
funding their pitches weren't not every pitch was perfect not every there were still classic you know there were mostly     
1:14:20     
avoided and I I think they did a commendable job of it but there were a few just technical errors where you know     
1:14:27     
you everything was moving really really really well but then occasionally there was like oh this video didn't load um     
1:14:35     
and there some of the pitches weren't weren't fully complete they weren't fully developed there there were a lot     
1:14:40     
of a lot of the questions about a lot of often very common questions like okay who who are you really going to sell this to from from the very experienced     
1:14:48     
VCs from the very experienced founders and stuff like that um but it it's just     
1:14:53     
it's just good to see the the challenge of the space um so     
1:14:59     
um that was all of my takeaways from that event i think did I hear yeah I     
1:15:06     
don't know that's a slight I might uh depending on the timing of things Bradley I might say a little bit more     
1:15:12     
about the blog post um but also I think Sylvia is here so I don't know if Sylvia     
1:15:19     
wants to say I think Sylvia is someone who's been helping out with some JoPro stuff and uh just stopped by the meeting     
1:15:25     
because she had time today i don't know if she wants to say hi or not     
1:15:31     
uh yeah I'm just um here to see how these meetings usually go and     
1:15:37     
get some like context for oral and rep     
1:15:44     
welcome yeah um yeah     
1:15:49     
um do you have is there like five more minutes Bradley or do you want to Yeah go ahead go ahead and go over the blog     
1:15:56     
post at the Okay yeah uh and I just has been very particular about sharing my     
1:16:02     
screen but oh well um so yeah this     
1:16:09     
is this is sort of the the most recent one     
1:16:14     
um and this is a very old concept i I think this would be worth a much a much     
1:16:21     
more in-depth discussion than what I'm going to get into but as I note here like this is something that I'm pulling     
1:16:26     
this right out of um years of discussions here and Bradley would often make a remark that you know momentum can     
1:16:33     
be more important than than progress or visible progress how do you keep momentum how do you keep showing up     
1:16:39     
another way to say is basically iteration beats stagnation uh but they're kind of they're they're not both     
1:16:45     
the same thing a lot of a lot of what I get into here is a very high level     
1:16:52     
um kind of team lead focused take on how do you you know lead people through this     
1:16:59     
and navigating the um navigating what what what may sort of be     
1:17:06     
the initial mis misconception about things     
1:17:12     
uh that is a very nonlinear relationship um and nondirect relationship     
1:17:18     
uh between visible success um and how that manages to what your     
1:17:27     
effort might be over time uh and so I mean I what what I want     
1:17:35     
to get to also at at the conclusion and is some other things that we're will eventually um building out i really like     
1:17:43     
this graph i just do a preview of it here but basically you know what do you do with different projects and how do     
1:17:48     
you navigate the space of like importance and then duration of of of stalling about things like that how do     
1:17:55     
you um how do you manage at the level of being on teammate which I think a lot of this a lot of our audience here or     
1:18:02     
first-time folks here will be okay I'm I'm just joining a team how do I manage     
1:18:07     
uh my role in that and that's going to be a a whole separate topic so we will get to that but this is a little bit     
1:18:13     
more for um almost like I don't want to say cognitive uh     
1:18:22     
training but more like perception and awareness or what is it like when you're trying to lead people through this space     
1:18:29     
or on this journey of you know I I always I couch all this in innovation     
1:18:34     
when when you are when you are doing new things um when yeah when when you're     
1:18:40     
when you're not just duplicating something that happened before and you're actually trying to find new questions and new problems and new     
1:18:45     
solutions and you can say you know all manner of doing business activities is innovation yeah but like there's huge     
1:18:52     
there's huge gaps in if if you're if you're in a a research lab that     
1:18:58     
has very high financial pressure in a deadline because of a certain grant um     
1:19:04     
or if you're in a more open-ended space that doesn't have those pressures or if you're or if you have a very specific     
1:19:09     
market and very specific uh funding and expertise that you're trying to use in an industry setting like those are all     
1:19:16     
very different um spaces and I think one of the the nice     
1:19:22     
things that come out of this is this analogy of the the role of the leader it     
1:19:29     
could be projectly it doesn't really it doesn't matter in a startup or in a smaller shop you're wearing a bunch of pants Anyways but from this perspective     
1:19:35     
of between the project team and the destination the this leadership role is     
1:19:41     
acting as sort of an ambassador to communicate between the two uh the team is sort of navigating these uncharted     
1:19:50     
spaces the destination is sort of allegedly somewhere but it may change a lot and so it's like you have to kind of     
1:19:56     
keep everybody in step and even like communicate uh with the destination like     
1:20:02     
hey are you still there have you changed or like is is is the is the light going to be on when we get there kind of a     
1:20:08     
thing so it's like how do you how do you deal with that and while at the same time dealing with the fundamental     
1:20:15     
tension of time and attention and the ability like how much people are     
1:20:20     
invested in in really trying to do the thing you're asking them to do um like     
1:20:25     
you have to bet to balance to balance all of that um the you know the challenge here     
1:20:35     
is when you're striving too much for perfection um and you you really try to     
1:20:41     
add a lot of polish um you may you may inhibit     
1:20:48     
yourself um uh you you may be kind of focusing on having things be all wrapped     
1:20:54     
up and and really nicely done but you aren't you haven't really connected all the dots yet that's you know a very     
1:21:00     
common um pitfall so how do you keep the team moving forward and and then from a     
1:21:06     
teammate standpoint you know how do you show up and and I'm going to be writing more about this specifically in this     
1:21:13     
there's a lot of there's a lot more things here this is really quite a a broad uh almost background primer     
1:21:19     
article for for a lot of the more specific topics but yeah how do you keep showing up and find ways to do what you     
1:21:25     
want to do and and a lot of a lot of my personal a lot of what the lab and has     
1:21:34     
sort of offered me was a space to keep showing up and Bradley's been a very good um enabler of hey let's talk about     
1:21:43     
this let's let's show up and and giving giving sort of the right amount of constructive push and then also space to     
1:21:50     
just to grow and to fail to learn make mistakes and realize this this is doesn't work and and all of those things     
1:21:56     
are important in different ways um uh chasing progress is a fixed ideal um     
1:22:03     
I kind of already covered this um some general discussions here about about     
1:22:08     
what that is um there's one of the things I really     
1:22:15     
would would enjoy talking about and will write about 100% sure is is sort of the     
1:22:21     
the use of updates um and and also even project management i have a I have a a     
1:22:27     
very classic story um that I'll just refer to about the chief operations     
1:22:33     
officer of of a group saying yeah I think project all project management is a waste of time and and why it makes     
1:22:40     
sense for his perspective but also why it didn't uh it that approach did not     
1:22:46     
serve them well when they did something else uh so to be continued about that     
1:22:51     
but I but I think you know especially for for certain groups um and and when     
1:22:59     
you're when you're when you're getting new people who are new to the space of problem or topic you you need to balance     
1:23:05     
between this compelling you know that quote the architecture quote about make     
1:23:10     
no small plans they don't have the power to stir a man's soul right but you need     
1:23:16     
to balance between that wonderful vision and the tenable steps at hand um you you     
1:23:24     
you you have to keep the hope alive but then also not expend your hope capital     
1:23:31     
and have people think oh well tomorrow we're going to have this great product no it might take several iterations it     
1:23:36     
might take it might take showing up it might take showing up in the dark um before you can figure out where you know     
1:23:42     
the matches are to get the candle to light up the way to see the path better and you're going to have to just navigate in that space for a while so     
1:23:49     
how do you do all that that that's kind of what we're setting the stage to talk more about here um in this post I don't     
1:23:57     
I don't I don't talk about scrums i don't talk about agile at all but I just I just I just mentioned it's like yes     
1:24:02     
that's important but also like what we're trying to do is     
1:24:09     
um understanding I guess I guess in one sense it's it's sort of how do you     
1:24:14     
understand what I'm currently calling like your organizational literacy or like how do you how do you understand     
1:24:22     
where you are in these processes and what can you do um yeah moving along just to to kind of     
1:24:30     
quickly get get through this um when you're sort of in the leadership     
1:24:37     
or leading a team or or at the level of trying to execute a broader strategy     
1:24:43     
with a selective people that are building stuff um yeah how can you find the small wins um how can you get sort     
1:24:51     
of releases or like establish the iterations how can you     
1:24:57     
um this is a I don't I'm I know what this means but I don't know if I like     
1:25:02     
the phrasing somewhere but like you have velocity over idea purity essentially what I probably should is like be okay     
1:25:09     
with killing your darlings the phrase of you have really great ideas but in the     
1:25:14     
process of building stuff normalize as much as you can that it will you know um     
1:25:21     
evolve the pedals the beautiful pedals will fall off eventually and that's okay     
1:25:28     
um documentation uh what's the next thing we can try test or publish there's really good language     
1:25:34     
in here pat myself on the back about um yeah like identifying critical decision     
1:25:40     
spaces like like you really need to find out what that is this I'll get to that for a second this chart is sort of about     
1:25:48     
like when you're directing people's attention you can try to put them towards these different topics it's just     
1:25:54     
a simple chart here but if people need to maintain momentum maybe you give them     
1:26:00     
easier things to work on or or whatever you always want to avoid like thankless     
1:26:05     
tasks especially people already are low on momentum you don't want to put them into these just big waste of time and     
1:26:11     
money but maybe they need a break from high intensity high effort things     
1:26:16     
uh to to something easier or or whatever and it's this this challenge of     
1:26:22     
orchestrating the attention that way um and and keeping them and going when you     
1:26:28     
can but the main the main quest line is always about you know the more you can     
1:26:34     
demarcate the decisions you need to make what are the problem space and then you     
1:26:40     
can actually try to invest in determining what those decisions are the decisions aren't necessarily the same     
1:26:45     
thing as doing or building or doing the coding or making the product but the decisions are sort of the ultimate like     
1:26:52     
you need to know what you want to do so it's kind of about how do you try to     
1:26:58     
keep things moving so you in a in a Gibsonian information sense you continue to get the movement so you get the more     
1:27:04     
information and I make a few other cognitive science references here too which is my my preferred lens um but you     
1:27:13     
know that's that's me um but how do you keep things moving how do you get to     
1:27:19     
um directing the context of the teams properly and then finally um for for for     
1:27:25     
teammates for the people who are on the team with the project leader what do you do um I think ultimately you know the     
1:27:34     
the the the better and more experienced or maybe just easier your problem space     
1:27:40     
is the more a manager may help you to navigate this when that's that that is a thing and and having buy in none of this     
1:27:48     
really matters if if you're especially if you're in an organization where you have people dictating what you have to do like you need buy in from the top     
1:27:54     
down because if you don't have if you don't if if the CEO is changing every month what your priority is then you can     
1:28:02     
you can you can do all this stuff and it won't you just keep going in circles and and you know acknowledging that that's     
1:28:08     
part of it too but let's say you have stability there have you have a team leader that's doing their best okay     
1:28:18     
um what do you do in an individual level like how do     
1:28:23     
you show up how do you be a part of the team how do you     
1:28:29     
um kind of participate in this and this kind of there's a lot here in terms of a sort of demo or die or presenting or um     
1:28:37     
keeping momentum at that level um and eventually uh in a in a forthcoming     
1:28:43     
thing we'll talk about this sort of decision matrix or this you know there's sort of a trajectory of like as as as     
1:28:50     
things go here is as as time progresses are you are you moving up and down here     
1:28:56     
um what is what is the role of like from a a a who is causing the stalling is it     
1:29:04     
the um the team lead or the people sort of setting the vision are they being     
1:29:11     
unclear about it and are they are they um oops are they kind of bottlenecking     
1:29:17     
you in the process moving forward or is it something you know what what is it when it when when the task is clear um     
1:29:26     
and or or when I think like a good example like for for Google summar code     
1:29:32     
the task is relatively clear right now at least in theory but probably most of the people haven't     
1:29:38     
um haven't really made what they're attempting to make before they're not just re reproducing it so how do you     
1:29:44     
navigate um different kinds of stagnation how do     
1:29:49     
you navigate How do you show up how do you um you know okay I'm going to I'm     
1:29:55     
going to make the most of the community period i'm going to make the most of um you know this time to to talk to a     
1:30:01     
former mentor i'm gonna you know get used to presenting my incomplete ideas and have a very simple presentation and     
1:30:09     
find a way to do that or and in a very in a very classic sense um you may not     
1:30:15     
even have things to show every week but how do you show up and as I think it was     
1:30:20     
uh Nahu said yesterday like the importance and the value of showing up     
1:30:25     
to meetings and and he said specifically like yeah I didn't always show up to all the meetings but I kind of wish I did     
1:30:30     
because it really helped me it helped me to realize the value of stuff and then when I'm getting the job in the real     
1:30:36     
world like showing up to the meetings and and and knowing how to be active and meaning like be a meaningful contributor     
1:30:43     
to those meetings um for your for your team it does matter so more on this     
1:30:48     
ahead um my my you know uh moral of the story is is trying     
1:30:56     
to imbue in in the culture like     
1:31:01     
um respect for the process of maintaining momentum and then trying to     
1:31:07     
get decision makers or leaders like here's how you do it like here's how you     
1:31:12     
don't get in the way and try to give people the space to do it and then for the people that are trying to do the     
1:31:18     
building and the hard work and heavy lifting of of directly manifesting the things or or innovating or building what     
1:31:24     
has not yet to be built how do you understand that dynamic and do the best     
1:31:31     
of what you can a little bit of well I'm following orders here but then what beyond that like what can you do um     
1:31:38     
to to keep the momentum going and try to contribute to as best as you can to the     
1:31:46     
the team's overall momentum to focusing on the project so yeah um and thank you     
1:31:52     
Sylvia for helping with the design here um and some of the editorial things but     
1:31:57     
like this is blank right now and maybe a little technical and I I talking about it i was like I might need to change     
1:32:03     
what this says um the bottom subcaption some more to be a little more clear but     
1:32:09     
um I really like this this image and I think it'll be a great a great reference point for a lot of other things I want     
1:32:15     
to talk about in this space so uh that's my overview of the article and and     
1:32:21     
there's many more things to say um on these topics and I'd love to continue to talk about them and I kind of want to     
1:32:28     
invite Bradley and some other folks like hey let's sit down and like actually rap about like what does it mean you know to     
1:32:34     
to be you know like right here like like what does it mean when when someone's     
1:32:40     
expectations are off or what does it mean what does it mean when you know we're having a lot of     
1:32:47     
um you know we're not really focused on on releasing anything and how do we do that how do we do that in a space like     
1:32:55     
you know um like this versus a different organization and so on so     
1:33:02     
um yeah that's what's on my mind about all that stuff and uh many many more things ahead     
1:33:10     
yeah that's great it's a great set of updates i like this post that you did it looks like you could probably write a     
1:33:18     
book on this well that's that's sort of where I want to go with it like one it's     
1:33:23     
it's been there's certainly a book to be written and then also like     
1:33:29     
um there there's like a book to be written but then also like I think I'm realizing both the     
1:33:38     
conversation that I want to have and then also the ways in which     
1:33:44     
conversations happen that that maybe haven't been the best in terms of the holistic take on it what I really     
1:33:52     
would like to do is is make it less I find a lot of these discussions are sort of esoteric or um like you don't     
1:34:00     
actually put like the seauite person in the same general conversation as the     
1:34:05     
repeat teammate and I don't I don't I'm not like oh yeah anti- hierarchy and and     
1:34:12     
let's just do it let's just do it for generic holistic reasons like that's nice but a lot of through uh like     
1:34:20     
Nickwick the innovation panel and the career panels a lot of a lot of the realization for me was just     
1:34:27     
like a core factor especially for early career folks and I would say yeah like     
1:34:33     
even more so in innovation spaces like in corporate spaces pretty hard to get like literacy at organizational scale     
1:34:40     
that's like yes but in innovation spaces there's more less things are defined     
1:34:46     
often so how do you how do you navigate that how do you get a sense of oh I     
1:34:53     
should probably be nudging my manager here to give me feedback and clarity     
1:34:58     
because they have to make a choice that I can't make for them and and     
1:35:04     
and a lot of my earlier years were like okay like I'm doing this thing but I     
1:35:10     
didn't really know how to sort of cross reference what the bigger decision makers were trying to do in the     
1:35:15     
situation and like how do you understand that dynamic while you're trying to build it's like it's it's really it's a     
1:35:23     
I I'm drawn to it because one I think it's critical and I know it affects people and affects projects but two it     
1:35:29     
can be such a messy space that's not um well defined and and how like I find a     
1:35:35     
lot of people I find I'm encouraging people to go do stuff or like do generic instead of conventional mentoring like     
1:35:41     
oh we're going to go build this thing let's build this project and then there's this whole set of skills that are just not     
1:35:48     
um not really communicated about and people just run up and hit a wall and like oh what happened here it's like     
1:35:54     
well there's a there's a curriculum and a literacy and models and artifacts they     
1:35:59     
built to talk about this stuff So that's where I'm going with it and um for anyone who's really been in the lab for     
1:36:05     
a few years we we talk about these things all the time and so this is me sort of trying to start crystallizing things we put together so um more ahead     
1:36:13     
on that and and appreciate the ability to discuss it here yeah no problem yeah     
1:36:19     
that's great and uh again welcome Sylvia hope you find well find this     
1:36:25     
useful but like the meeting in general um I have a point well a lot of points     
1:36:31     
I'd like to expl I'm going to read over the article but in uh my project     
1:36:37     
management course we've been kind of hitting on this issue of u I guess you could call it performative     
1:36:44     
progress but it's basically where you build road mapaps and documentation especially demos and updates and how     
1:36:52     
especially demos and updates can be performative or how you can perform to the to object so it's like if I give an     
1:37:00     
update I don't it doesn't necessarily have much substance we just go through this ritual of giving updates and you     
1:37:07     
know it's like okay well that's nice but like you know what is the what is the     
1:37:12     
actual progress being made are we making the pro are we making the progress we'd like or are we just kind of going     
1:37:18     
through the motions the same thing with demos you can make a really good demo and um you know it works out but     
1:37:26     
then it's just a demo it's just like a proof of concept to actually make the thing that you want to make that goes     
1:37:33     
beyond the demo because the demo is just a way to like explain to people how something works and um you know give people an     
1:37:41     
idea let them engage with whatever it is but you know if you want to build     
1:37:47     
something like a release or product then you have to go beyond the demo and getting beyond the demo is a bit uh for     
1:37:54     
a lot of teams and even in like re u engineering research moving beyond the     
1:37:59     
proof of concept is really hard because you build a proof of concept you publish a conference paper say and it's great     
1:38:07     
and then you go to make you know where's the use case where's all this and um you     
1:38:14     
It's a different ball of wax so yeah yeah exactly     
1:38:20     
and it's it's it's tough because you need to do these     
1:38:26     
acts to get feedback from other people and try to iterate but     
1:38:34     
then it's not the same thing it's not it's not the final avenue of of of the     
1:38:42     
the of the victory or success it it it's it's sort of it's it's     
1:38:49     
so and that that that kind of speaks to some of the tension that I'm I'm really trying to talk about for sure because     
1:38:54     
it's like you need there's another a related article that and I actually wanted to talk to you about this specifically like there's sort of a you     
1:39:02     
need to give people stuff to do like you like especially initial you have to say what do I do okay I'm I'm showing up for     
1:39:08     
work today what do you do and it's like okay well you know you want to have them     
1:39:13     
moment you want to get them momentum opportunities to maintain momentum interest then if it's like okay make a     
1:39:19     
bunch of pointless demos that are really nice and speak to an audience but don't don't further the ultimate goal it's     
1:39:24     
it's a tough it's very tough set of choices and there's um that I think the     
1:39:30     
more people can appreciate the and get literacy about why those choices are what they are the     
1:39:36     
better especially for people that want to build new things     
1:39:41     
because it's there there's often not really a right answer and it's kind of trying     
1:39:47     
to determine and course correct as you go um so yeah please go on um     
1:39:58     
oh yeah well yeah I think this is great and again these matrices that you show that the     
1:40:03     
um when we're showing importance versus duration and uh impact versus effort I     
1:40:10     
think those are useful visual yeah and like they're kind of I don't think I did     
1:40:15     
the best setup for them to be fair and I talked to Sylvia about this before i kind of feel like oh like Sylvia got like the one I really wanted to say and     
1:40:21     
then I didn't I didn't quite my my pitch my pitch wasn't perfect here but the the     
1:40:27     
the matrices are kind of like given where you are for for the momentum and and like stagnation one     
1:40:34     
depending on where you are in in that space like your options change and     
1:40:40     
sometimes like I don't think I don't think it's on this one but like when you're in the long stagnation and the     
1:40:45     
importance is kind of trickling down it's like okay like should you formally sunset this project should you do you     
1:40:51     
formally have the documentation you need to park to park it can can you set it in a place where you can come back to it     
1:40:58     
later or is this like nope we're going to really you know what do you do at those spaces or if you're a team lead     
1:41:04     
who's seeing something trending in that direction okay like I need to energize this here or what is the flow and can we     
1:41:12     
pivot or not like is this mission critical or not and it's just it's I I find those conversations to be     
1:41:20     
um really important and and I'm learning how to to formalize discussion about     
1:41:26     
them like there's some books and some talking but I don't I don't I don't find them to be tailored enough to what I     
1:41:33     
really uh want to get at so yeah like um I think that's a really unique thing     
1:41:38     
that we get to talk about here and you've done all this coursework and you've been in this game for a while so I'm excited to keep that up and and yes     
1:41:45     
apply it to Google somewhere code to kind of little little bits there this is this is a much more extended discussion     
1:41:50     
i know we'll have like 20 minute discussions every Friday about this but um for people that do want to talk about     
1:41:56     
it more we can and there's opportunities to both like if people want to write an     
1:42:04     
article or do an interview about this i'm I've got I've got them cooking so I     
1:42:09     
just need to get them out there i think it's an important space i'm looking forward to it so     
1:42:15     
yeah um definitely on the Friday meetings I think would be good to help a     
1:42:21     
series so I want to get in one last article here for today actually I wanted to mention that um so Paola Deio who's     
1:42:30     
been in the group um and she's doing some really interesting research she has     
1:42:36     
a an active inference guest stream that happened recently so this I think May     
1:42:42     
2nd was the date so it's on the active inference     
1:42:47     
institute YouTube channel and this is her work that she's been doing on I     
1:42:53     
guess uh system psychology is a good way to put it uh it's called system systemic     
1:43:00     
deviation or SD from systemic failures to systemic aberration     
1:43:06     
and I think it probably has a lot to do with like systems theory and complexity theory but also like you know     
1:43:13     
psychological causes of things and it's really interesting uh work so yeah if     
1:43:20     
you want to check that out I would recommend it just to see what she's up to and and the active inference guest     
1:43:28     
streams are always good because they like give a presentation they answer questions and all that so it's pretty     
1:43:34     
good congratulations to Paulo now I'd like to talk about this paper     
1:43:40     
here uh this is a I guess a newish paper in nature it's come out in the past     
1:43:47     
month [Music] and it's a on world models so we've been     
1:43:53     
talking about world models i talked about world models in the first article we talked about today     
1:43:59     
um this is a a good paper from uh I guess     
1:44:05     
uh a couple people here Hafner Paconus     
1:44:11     
Battlecraft and they're uh talking about mastering diverse control tasks the     
1:44:18     
world models so they're talking about world models they're talking about control     
1:44:23     
tasks they're talking about reinforcement let's get into the abstract     
1:44:29     
um so developing a general algorithm that learns to solve tasks across the     
1:44:35     
wide range of applications has been a fundamental challenge in AI although     
1:44:41     
current reinforcement learning algorithms can be readily applied to tasks similar to what they've been     
1:44:47     
developed for in other words like you can you basically craft a reinforcement learning     
1:44:53     
algorithm for specific tasks you apply it it finds the best policy you know but     
1:44:59     
then if you want to generalize reinforcement learning algorithms it's a little harder to do and you know kind of     
1:45:06     
synthesizing uh new contexts and reasoning in new     
1:45:12     
contexts is hard so that's that's where they're going with this     
1:45:17     
um and so although current reinforcement learning algorithms can be readily     
1:45:24     
applied to tasks similar configuring them for new application domains require     
1:45:29     
substantial human expertise and experimentation um so this is where we     
1:45:34     
have these uh we talked about I think RHF which is     
1:45:40     
um you know basically where humans guide the reinforcement learning algorithm to     
1:45:46     
these new contexts and um give it this reasoning capability but we had a whole     
1:45:52     
series of features in previous meetings this year on the topic here we present     
1:45:59     
the third generation of dreamer a general algorithm that outperforms specialized methods across 150 diverse     
1:46:07     
tasks with a single configuration so this is where they're kind of building this world model generalized     
1:46:14     
algorithm uh you know that generalizes across all these different tasks and you don't have     
1:46:21     
to spend time training it or helping it generalize dreamer learns a model of the     
1:46:27     
environment and improves its behavior by imagining future scenarios     
1:46:33     
so again this is a world model they call it dreamer because it's trying to model     
1:46:38     
future scenarios and it learns from a general model of the robustness techniques based on     
1:46:47     
normalization balancing and transformations enable stable learning across domains so they use a sort of a     
1:46:55     
robustness approach apply it out of the box dreamer is to our knowledge the first algorithm     
1:47:02     
to collect diamonds in Minecraft from scratch without human data or curriculum     
1:47:08     
learning so this is where you know we don't have to train it necessarily     
1:47:15     
on telling it basically what to do or giving it a curriculum it can learn from     
1:47:21     
the data it can learn from playing the game this achievement has been posed as a     
1:47:27     
substantial challenge in artificial intelligence it requires exploring far-sighted strategies and pixels and     
1:47:34     
sparse rewards in an open world our work allows solving challenging control     
1:47:39     
problems without extensive experimentation making reinforcement learning broadly applicable     
1:47:47     
so they talk about again reinforcement learning is good at playing games it can     
1:47:55     
play uh games like Go or Dota and it can surpass human performance on those is     
1:48:02     
also a key component for improving large language models beyond what is demonstrated in the pre-training guide     
1:48:09     
uh although the proximal policy optimization or PO algorithm has become a standard     
1:48:16     
algorithm in the field of reinforcement learning more specialized algorithms are often used to achieve higher     
1:48:22     
performance so you we have this sort of generalized algorithm proximal policy optimization     
1:48:30     
algorithm that you know works to some extent usually want to use specialized     
1:48:35     
algorithms to get to sort of on on harder tasks to achieve performance but     
1:48:42     
the problem of course is that they're very it's it's very brittle and you know     
1:48:47     
when you have a specialized algorithm you can achieve higher performance at the expense of this sort of robustness     
1:48:54     
that you want in you know maybe in in a real world task where you're changing your context changing your domain     
1:49:04     
these specialized algorithms target the unique challenges posed by different application domains such as continuous     
1:49:10     
control discrete actions sparse rewards image inputs spatial environments and     
1:49:17     
board games so basically you know context where you have continuous control that is hard to predict or hard     
1:49:25     
to always predict discrete actions which require response given some     
1:49:31     
stimulus sparse rewards where the reward structure isn't very well     
1:49:37     
specified uh spatial environments where you're navigating to different places and of course that spatial environment     
1:49:44     
is heterogeneous and then board games where you have like you need to deploy strategies in different contexts so it's     
1:49:51     
like context heterogeneity predictability those are the things where this robustness comes     
1:49:59     
in handy and the brittleleness helps the     
1:50:04     
system fail or it basically um initiates system failure     
1:50:11     
however applying reinforcement learning algorithms to sufficiently new tasks such as moving from video games to     
1:50:17     
robotics tasks requires substantial effort expertise and computational     
1:50:23     
resources for tweaking the hyperparameters of the algorithm this brittleleness poses a bottleneck in     
1:50:30     
applying reinforcement learning to new problems and also limits the applicability of reinforcement learning     
1:50:36     
to computationally expensive models or tests where tuning is prohibitive so you know as brittleleness     
1:50:44     
it's acceptable for very narrow problem domains but when you get to these     
1:50:50     
broader problem domains it's really hard you know it just basically poses this     
1:50:55     
bottleneck and needs to be overcome but also you know we have this problem where     
1:51:01     
if we want to tune the model um in some cases we can't necessarily do that like     
1:51:07     
in real time behavior continuous behavior where we don't want     
1:51:12     
they have to jump in and tune the parameters constantly uh sometimes it's not even possible because the parameters     
1:51:19     
need to be tuned continuously so creating a general algorithm that learns to master new     
1:51:25     
domains without having to be reconfigured has been a central challenge in artificial intelligence     
1:51:31     
would open up reinforcement learning to a wide range of practical applications so then they introduced this uh I guess     
1:51:38     
you could call it a world model called dreamer this is a general algorithm it's based     
1:51:45     
on the idea of learning a world a world model that equips the agent with rich     
1:51:50     
perception and the ability to imagine the future so you have perceptual information coming in from these     
1:51:57     
different contexts you have this component that's like this mental modeling component where it can simulate     
1:52:04     
different outcomes of the future as shown in figure one the world model     
1:52:09     
predicts the outcomes of potential actions then a critic neural network judges the value of each outcome and an     
1:52:17     
actor neural network chooses actions to reach the best output so these actor critic model this is an approach where     
1:52:25     
you know it's like the actor and the critic the actor does something the critic tells what what it did wrong the     
1:52:31     
actor tries to improve its behavior the critic uh criticizes the the improvement     
1:52:37     
and so on and so forth although intuitively appealing robustly learning and leveraging world     
1:52:43     
models to achieve strong task performance has been an open problem not     
1:52:48     
sure what that sentence means but basically world models are easier said than achieved and so you know we try     
1:52:56     
these different methods we try actor critic models we try different types of     
1:53:01     
uh we could even try like computational schema and they're all kind of like you     
1:53:06     
know no one knows which one is the best approach um dreamer overcomes this     
1:53:12     
challenge through a range of robustness techniques based on normalization balancing and transformations     
1:53:19     
these are like technical uh you know techniques that people use     
1:53:25     
normalization of course is normalizing data normalizing the context balancing     
1:53:31     
is like making sure that you have well represented cases and then transformations     
1:53:37     
uh you know ways to transform the representation of the world to the     
1:53:43     
representation of other contexts so basically you can use these technical um     
1:53:49     
approaches to sort of uh fill in the gaps of what we have in the challenges     
1:53:54     
that we have to uh you know wide ranging reinforcement generalized     
1:54:03     
reinforcement and so they give their uh performance uh but obviously this method     
1:54:09     
performs very well notably larger models not only achieve higher scores but also require less interaction to solve a task     
1:54:17     
offering practitioners a predictable way to increase performance and data     
1:54:23     
efficiency so what they do to try to test this out is they put this in     
1:54:28     
Minecraft environment um and Minecraft is is useful because     
1:54:34     
it's been used by a lot of researchers to benchmark your algorithms because it offers this sort of open-ended world     
1:54:41     
where you can simulate things in Minecraft and have avatars that you can then u measure their performance in real     
1:54:49     
time so they move around this Minecraft environment and they have this u these     
1:54:54     
different uh you know behaviors that are not reprogrammed they have to interact     
1:55:00     
with the world as it happens not you know in a very controlled task so uh actually it's interesting     
1:55:08     
because there are these international competitions that uh are hosted and the     
1:55:14     
objective of those competitions is to get agents to autonomously learn to     
1:55:20     
collect diamonds in Minecraft that means that they can't be trained by humans to do this task they have to figure it out     
1:55:26     
on their own so this is a problem that you know has been a long long-term problem in     
1:55:33     
artificial intelligence and in reinforcement learning and you know we have to kind of figure out how to how to     
1:55:40     
to solve this open world game so we have this procedural diversity these longtime     
1:55:48     
horizons and this exploration difficulty in addition in the reinforcement     
1:55:53     
learning context there being sparse rewards in other words you don't get immediate rewards you just have to keep     
1:56:01     
going and collecting diamonds and then that's the reward but it's a longer term thing that the algorithm may or may not     
1:56:08     
recognize as valuable and so um a lot of the previous     
1:56:14     
approaches needed to use a lot of human expert data like RHF and domain specific curricula which     
1:56:21     
is curriculum learning which is basically teaching the model how to do     
1:56:27     
things of very specific instructions and then you know it's like a a class where I teach you things and then you apply     
1:56:34     
what you've learned but that's again this human training that we kind of want to avoid when we want to implement these     
1:56:42     
algorithms in real time so um this is figure one this is     
1:56:49     
the training process of dreamer so this is world model learning here on the left and actor critic     
1:56:55     
learning on the right the world model learning um involves     
1:57:02     
encoding sensory inputs XT which are these X's down     
1:57:07     
here and then we have this in these encoders which are here so we have     
1:57:14     
inputs as vectors we have them put it to an encoder then they go to these     
1:57:19     
discrete representations Z which are these checkerboards and then there's this     
1:57:25     
decoder which of course can decode it to from X1 to X hat one so it's decoding it     
1:57:32     
to a sequence model and then you have these recurrent     
1:57:38     
states HT given actions A so you have this action coming in you have this recurrent     
1:57:46     
state it's incorporated into this discrete representation of what's going on in the world the inputs uh the action     
1:57:55     
inputs then we have the sensory inputs coming in here and we have an encoder     
1:58:00     
that encodes that into this discrete representation and then we decode the     
1:58:05     
discrete representation at each time step and transform that from H1 or from     
1:58:12     
X1 to Xhat one so that's how this works and then it works over time so you have     
1:58:19     
X1 X2 X3 different sensory inputs a1 and     
1:58:24     
A2 are the different action inputs and they contribute to this     
1:58:29     
evolving representation where you encode features of action encode features of the sensory     
1:58:36     
world the center hole being things in uh features of the Minecraft environment     
1:58:42     
encode those into features encode that into this discrete representation at each time step and     
1:58:49     
then decode it as this uh new uh sensory     
1:58:56     
output xhat or xhat 2 or xhat okay so this is a reconstructed     
1:59:04     
uh sensory input with action this helps to shape the rep the final     
1:59:11     
representations and then we have the and so that's the world world learning world model learning you're learning aspects     
1:59:18     
of the world you're learning the actions on those uh sensory features and you're     
1:59:24     
doing this over time then we have our actor and critic learning model so the actor and critic     
1:59:31     
which are the uh so we have these actions     
1:59:37     
A and we have the actor doing those things and then we have values     
1:59:42     
B which are things that kind of go out so we have the actor doing things and     
1:59:49     
then the critic doing things and so we have the basic structure that we had before we have     
1:59:56     
this encoding this becomes part of a discrete representation then this is something     
2:00:03     
that the actor acts upon and then the critic in the next time step     
2:00:09     
criticizes that action and then the actor improves their performance the critic keeps doing that so we end up     
2:00:16     
with these this great representations which are Z1 and then Z hat 2 and Z hat     
2:00:23     
3 so now we have these different reconstructions of the discrete     
2:00:29     
representation that uh go over time so when we have we acquire the first     
2:00:34     
discrete representation from um from sensory inputs and from action     
2:00:40     
and then the actor critic model takes over we have the actions in subsequent     
2:00:46     
time steps and the critic uh corrections in subsequent time steps and we keep     
2:00:52     
going so then they get into world model     
2:00:59     
learning so the world model learns compact representations of sensory inputs for     
2:01:05     
autoenccoding and enables planning by predicted future representations and rewards for potential actions we     
2:01:12     
implement the world model as a recurrent statebased model shown in figure one     
2:01:17     
that's what we sh we just saw so this is the technical term recurrent state base model     
2:01:22     
so they describe this whole process and they provide these different     
2:01:28     
uh equations for the different components of a world model so they have a sequence     
2:01:33     
model HT an encoder which is ZT which is     
2:01:38     
equivalent to this equation here it's conditional probability a dynamics     
2:01:44     
predictor which is Z hat T so you have an encoder and then this reconstruction which is the dynamics predictor so it's     
2:01:51     
predicting this trajectory and so that's what we do in our uh actor credit model our actor     
2:01:58     
credit model is trying to extrapolate out from each of these states so I guess in this sense Z1 is just one possibility     
2:02:06     
we could do this for Z2 and Z3 and we could generate uh these these uh sort of     
2:02:14     
reconstructions of the discrete representation for these future time     
2:02:20     
steps we're just extrapolating a trajectory out of this first time step in this example     
2:02:28     
so we have the encoder the dynamics predictor predicting the dynamics of like a     
2:02:34     
certain initial state then we have a reward predictor which predicts the reward for certain scenarios certain     
2:02:41     
dynamics certain trajectories that's rh hat then continue     
2:02:47     
predictor which is chat hat t which is I guess where you you know predict how     
2:02:52     
valuable it is for you to continue down this path and then the decoder here which is xhat t which we talked about     
2:02:59     
this model here this is where you decode things from each sensory     
2:03:05     
moment given actions and so forth     
2:03:11     
okay uh so actually the tilda here is represents random variable sampled     
2:03:18     
from their corresponding distribution so each of these represent this distribution here or the sample     
2:03:25     
distribution for its conditional probability that you have here okay so     
2:03:31     
that's that's a a note on that uh figure three visualizes long-term video     
2:03:36     
predictions of the world model uh so they in the figure three they talk about     
2:03:42     
that um the encoder and decoder use con use use convolutional neural networks     
2:03:47     
for image inputs and multi-layer perceptrons for vector inputs so the     
2:03:53     
dynamics reward and continue predictors are also these uh multi-layer     
2:04:00     
perceptrons representations are sampled from a vector of softmax distributions we take straight through gradients     
2:04:06     
through the sample stuff so they basically have a lot of technical detail     
2:04:13     
here and kind of talking about how to get this world model up and running and     
2:04:18     
a lot of the tools used to make that happen okay um previous world models required     
2:04:25     
scaling the representation less differently based on the visual complexity in the environment complex     
2:04:31     
scenes contain details unnecessary for control must prompt a stronger regularizer to simplify the     
2:04:38     
representations and make them easier we find that combining three bits     
2:04:44     
with small representation loss scale resolves this dilemma allowing for fixed     
2:04:50     
hyperparameters across domains moreover transforming vector observations using     
2:04:56     
the simlong function described later prevents large inputs and large reconstruction gradients further     
2:05:02     
stabilizing the trade-off with the representations so again they're overcoming some of these problems of     
2:05:08     
previous world models technical aspects so this is figure two diverse     
2:05:14     
visual domains used in the experiments they have uh these different visual     
2:05:19     
domains um there's a control suite which is like this robotic control program     
2:05:26     
that models these uh point mass robots uh different uh like spiders and legs     
2:05:34     
and runners and quadripeds and and things like that kind of training on     
2:05:40     
visual motion uh then we have Atari games so we have this this suite of     
2:05:46     
strategy games where they learn some strategy we have procedural generation     
2:05:52     
which are uh games that are procedurally generated so it's training in a kind of encountering the unknown so it's like     
2:05:59     
trying to to figure out the value of these different trajectories um and then DM lab uh which     
2:06:07     
it requires spatial and temporal reasoning and then Minecraft which is     
2:06:13     
the domain the complex and infinite domain they want to implement the     
2:06:19     
algorithm so they do all these they have all these different training domains that they use they're not all the same     
2:06:25     
qualitatively they have they emphasize different skills they allow the world model to acquire different types of     
2:06:32     
skills and attributes to generalize them in     
2:06:38     
mind we go to figure three this is uh video predictions of world model so we     
2:06:44     
have this procedural maze and we have this quadriped robot so the quadriped     
2:06:49     
robot is going to respond to this procedural maze these are these images at the top so we have the context input     
2:06:57     
and then open loop prediction and then we have this true movement that's supposed to be     
2:07:03     
generated here and then the model down here what the model does the output of     
2:07:09     
so we have a procedural maze in the quadripedal robot given five context     
2:07:14     
images in the full action sequences of an unseen video dreamer predicts 45     
2:07:20     
frames into the future without access to intermediate images so this is interesting because we're using this     
2:07:27     
actor critic model to model these trajectories into the future given this context given the scene what should the     
2:07:34     
behavior be down the road you don't have intermediate information about what will     
2:07:39     
happen in the world the world model simply has to predict out to that point and then produce behavior it's a bit     
2:07:46     
like if I asked you to predict what would happen if you you know if you     
2:07:53     
encountered the certain scenario of driving and you had to give me an answer and in humans we can do this because     
2:07:59     
we're trained to drive we learn how to drive gain expertise at driving and it comes becomes natural to us to respond     
2:08:06     
to a hypothetical with an reasonable answer but with the world model we can't     
2:08:12     
assume that the hypothetical is something that the world model has to be trained on it has to be able to produce     
2:08:19     
these uh you know these these trajectories these scenarios for the future and then draw from the correct     
2:08:25     
one to produce the correct output so actually in this sense dreamer does a     
2:08:30     
pretty good job it is able to go 45 frames into the future and just kind of     
2:08:36     
extrapolate from the hypothetical to to pick the right behavior and so this is this is all done     
2:08:43     
from just training on this context input and then making these open loop     
2:08:50     
predictions okay so I think yeah and then there are     
2:08:55     
these benchmark scores so we have uh B Suite Proprio Control Visual Control     
2:09:03     
Atari 100K EML Lab Procgen Atari and Minecraft     
2:09:08     
and these are just tasks um that they they have for benchmarking this and     
2:09:14     
dreamer outperforms or performs similarly to other models this is PO     
2:09:20     
which we mentioned at the beginning this is the generalized reinforcement learning approach that's kind of     
2:09:25     
standard it you know that is sometimes uh lags     
2:09:30     
well behind dreamer sometimes it's comparable with dreamer so for buite ppo is similar to dreamer performance but     
2:09:38     
for proprio control visual control atari Minecraft     
2:09:45     
uh and dm lab it's it it lags well behind dreamer and then procgen maybe a little bit closer to dreamer in terms of     
2:09:52     
of performance but the point is is that you have these competing algorithms and     
2:09:58     
dreamer pretty much does a superior job okay so um I think that's all for that     
2:10:07     
paper all right well um so a last word about that paper uh I     
2:10:14     
think it's important to view that in the context of some of the world model discussions we've had in past     
2:10:22     
several meetings if you go back to the beginning of the year we start talking about reasoning in models reinforcing learning     
2:10:30     
models large language models and then kind of how world models can help us     
2:10:35     
overcome some of these reasoning difficulties and then we've talked about     
2:10:40     
kind of how to build these world models themselves we talked about this in our     
2:10:46     
contribution of the special issue on uh improving machine     
2:10:52     
learning while large language and reinforcement learning models in terms of how they can interact with the     
2:10:59     
world world models of course can help a model generalize but it also provides     
2:11:05     
context and so I think this is a nice example of a model that and and how this     
2:11:11     
works with you know technically how the technical parts can be put together to     
2:11:17     
form a world model into you know this this is just for     
2:11:22     
reinforcement learning so the large language models might be different for other types of machine learning models     
2:11:29     
might be different but I think this provides an interesting example of under the hood of what world models actually     
2:11:35     
consist of okay so that's all for     
2:11:42     
today thanks for attending see you next week
