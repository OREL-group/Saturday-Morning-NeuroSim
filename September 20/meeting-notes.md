## Meeting Recording

[YouTube link](https://youtu.be/pHR2kac1sak)

## Mastodon thread

[link](https://neuromatch.social/@OREL/115240307803374359)

## Feature Videos

[Not Machines All the Way Down (discussion of Bongard and Levin)](https://youtu.be/RcGti05gLto)

[Braitenberg Vehicles: biocybernetic models using memristive circuits](https://youtu.be/8rQshy3382A)

[The Utility of Vibe Coding in Neuroscience](https://youtu.be/q8LhTNwWbyM)

## NOTES
Invite someone for ActInf. Yarrick — never open-source people. 

Turing Way community manager?

OpenLifeSci: community that trains new researchers.

coding is not the purpose of the project —> what re the greater goals?


Fireside Chat: Bongard and Levin —> discuss their work.

* biomimetic/biohybrid design.

* “Machines all the way Down”.

* “Plenty of Room in the Middle.

* Agential Materials, traditional computational robotics program.

* computer sim of robotics class. Anthrobot simulations.


Inequality tool for coding: knowledge provides greater productivity, wheres no knowledge or expertise leads to less productivity.

* event on vibe coding, what should people know to use effectively?

* Jesse --> dealing eith vibe coding, immense ease of conceptual exploration.

* parallelizing code, run on GPU (CUDA). Democratize fMRI analysis.


What can Vidhi do moving forward?

* build out SustainHub, connmect to computational agents work.

* what are your specific areas of interest? What is your time horizon?

* what's going on in 2025? Can we do a short video series?

* a lot of code is sitting around. Needs to be connected and utlized.

* more empirical work around ekkolapto. Meta-brains and the role of language (symbolic level).  


Motility Prediction: add axle/wheels to basic robotic form.

* build with parts -- not machines, moves like a centipede.

* Poldrack -- better code, better science. Chris Grewlowski: Posts chapters of the book -> uses Claude for book chapters.


* "parts list" paper using Bongard's platform -- CompuCell3D.


Doing events with NeuroTechX: do a predictive coding response.

* hard to give example code, in this case, we can take it apart.

* Simon Williston, Allen Institute open scope program.

* noticed a lot more quality code generated by LLMs in repos.


Alternative computational frameworks: meta-robotics --> natural vs. Artificial Intelligence.

* bodies, learning, adapting, regeneration, controlling versus artificial approximations.

* Cybernetic Psychology lab. Animal Behavior, Unconventional Computing people.

* Language coordination, teleonomy as coordination.

* vanZant --> role for symbolic things.

* Mind/Body/Language problem --- fun, what is the forward movement?


MIT/Frontier Tower connections. need an implementation of consciousness ideas to resolve ambiguities.

* vibration/polycomputation. Multiple frequencies in EEG. Earl Miller/Luis Pessoa. Analogue computing.


Futures Center -- Simple Website, landing page.

* Admin (1/3), Scholastic (1/3), Logistics (1/3).

Tools that facilitate narrative (Levin, Plot Twisters).

* Autoethnographic, discipline spaces?

* there are not proto-cars: parts that are inert, whole is living. No, but there are intermediate forms.

* soft robotics with finite element modeling.


NeuroData Hack --> DANDI archive --> Ben Dichter.

* open-source software sustainability.

* Frontier Tower: people in the cult of vibe coding.

* done best by a swarm (multi-agent problem). Agents with defined roles.


Vidhi Rohira
Vidhi Rohira says:
hi, how have yall been..how were the past 2 weeks 
9:45

Jes (JOPRO)
Jes (JOPRO) says:
9:46

Morgan Hough (he/him)
Morgan Hough (he/him) says:
https://miccai.org/
10:04

Jes (JOPRO)
Jes (JOPRO) says:
https://x.com/soniajoseph_ 
10:38

Morgan Hough (he/him)
Morgan Hough (he/him) says:
Join me at Reading Group #21:  "Where Minds Come From", Michael Levin lecture 
https://meetu.ps/e/Ptz8m/zhpDz/i
10:45

Morgan Hough (he/him) says:
https://thoughtforms.life/symposium-on-the-platonic-space/

## TRANSCRIPT 
0:00   
Hello. Hey there. How are you?   
0:06   
Yeah, best. Just uh still haven't haven't quite had my   
0:12   
breakfast yet. Had to get up very the the capstone   
0:19   
projects for the the students is like, you know, 5 5:20 a.m.   
0:28   
Oh, okay. Yeah. Like   
0:33   
do you have to go somewhere or is that on on Zoom or something like that? Yeah, I know.   
0:39   
Okay. I think I think some Yeah, they have   
0:46   
they have a local site in Nigeria.   
0:52   
Okay. Inos. Yeah. Uh   
0:57   
but I I just got my my students um   
1:02   
uh uh kind of um report and um   
1:09   
so my students are all from Ghana. Okay.   
1:14   
Different different universities in Ghana.   
1:20   
Right. So yeah, we had uh one meeting this week that was the D.VAR meeting and   
1:26   
uh that was uh I think just Susan and I were there and and maybe Morgan I think   
1:31   
was there as well for a while and uh we we talked about a paper where they used   
1:38   
to model this process in uh development called invagination. So it was they were   
1:45   
modeling the cell sheet in a ball and they were modeling it folding inward and   
1:51   
they used and we went through the mathematics of that um and what they were doing and Susan of course has been   
1:59   
working on this um 10segrity project and so she tried using comsol for that and   
2:05   
it didn't work very well. So I wanted to go over the sort of how they implement a model in   
2:11   
console for developmental biology because usually console is an engineering tool they use for you know   
2:18   
building mechanical systems or um you know other types of   
2:24   
physical systems that aren't biological. So it was interesting to see how they   
2:29   
did that. Uh and then we talked about this paper about um uh phase transitions and sort   
2:38   
of information processing in cells or in um in migration. It was actually uh cell   
2:45   
migration and development. So we had uh little discussion around that as well.   
2:52   
So that was a good meeting. Um and that's on the divor YouTube channel.   
3:00   
Uh didn't have any other meetings this week. Um a little bit of discussion about   
3:06   
following up on things from you know meetings past and and Jesse's of course   
3:13   
going to talk about his um he he did a couple of things this   
3:18   
week we'll have to talk about a couple plans going forward. Yeah. And then I we've been working on   
3:25   
this active inference institute uh symposium   
3:30   
and that's coming up in the middle of November around November 13th or 14th   
3:36   
and um I've been working on some submissions for that. Um, and we still have   
3:45   
so I'm kind of on the uh scientific advisory board. So I'm doing a lot of work with uh Daniel, you know, preparing   
3:53   
for things and uh so one well I guess there's a plan to do uh   
4:01   
one talk that's kind of related to the last year's talk and then another talk   
4:07   
on the open source sustainability stuff. So that's and I don't know if we want to   
4:14   
invite someone to give a talk like we did last year because last year what we did was we had the main the cybernetics   
4:22   
talk the open access open science talk and then we invited someone.   
4:28   
So if we want to invite someone we can do   
4:34   
that. Um I can set it up what we can do. Yeah. I mean I I   
4:41   
Yeah, I've got a lot of emails that I need to get out and um   
4:47   
uh you know, I I don't know if um   
4:55   
well, I mean, I think a couple of months in advance is is is   
5:00   
good enough uh to see if Yar is interested. You know, he can say   
5:07   
so much about open source. Yeah. Uh I'm trying to trying to think about other   
5:12   
other people though. I mean in the sense that like you know   
5:18   
um who are the who are the new open source   
5:24   
I mean as well as like the open source sustainability is is such an interesting   
5:30   
um it's such an interesting project   
5:36   
uh that is is kind of more than open source itself right or   
5:43   
Um yeah, just trying to think about who   
5:53   
you know if it's worth connecting with kind of like a   
6:02   
a person who's thinking about um Yeah, maybe like   
6:16   
Maybe somebody like um like the Turnway community manager or   
6:23   
something like that like somebody was thinking about   
6:31   
kind of like   
6:37   
this Turn the Turnway community. No, no, no. It's a the Turing way like   
6:42   
like Allan Turing. Yeah. Yeah. Yeah. So, it's it's the it's the British um data   
6:50   
science institute. Yeah. Okay. Well, well, you know, this is the Turing   
6:56   
Institute, right? The turning way is a project that was started there.   
7:03   
That's an opensource book, right? Yeah.   
7:09   
Um but it's an open source book of best practices   
7:14   
and has become kind of a community of community builders,   
7:21   
right? So, and I and I'm pretty sure that they spawned,   
7:26   
you know, of the many things that kind of like this community of community   
7:31   
builders built. Uh, uh, open   
7:38   
open life I think is is a community   
7:44   
that they built, um, that trains   
7:52   
new life science researchers um   
7:58   
you know I mean and they've definitely got like a software carpentry model   
8:03   
um in terms of you know the trainees become trainers kind of graduate   
8:09   
right and um anyway like like   
8:16   
I don't know maybe maybe Yaric is just kind of you tired of always being the the the the   
8:23   
voice of the open source community. Yeah. Uh uh and and you know I mean I I I've   
8:33   
um as well as like the the project is also   
8:39   
uh you know well I mean I'm kind of curious like how again like you talk about the   
8:47   
project as as being more than like   
8:53   
a software ware coding multi- aent coding system.   
8:59   
Right. Right. Because that's not that's not the purpose of the project. Right.   
9:04   
Right. And and so   
9:11   
in kind of in getting a speaker, you know, I think you'd want to be   
9:17   
kind of like more aligned with the   
9:22   
the project's kind of greater goals. Yeah.   
9:27   
Uh which, you know, again, not to say that that's not Yar   
9:34   
like again, he's he's he's my uh he was my inspiration in terms of open source   
9:43   
project management and kind of community development. For sure. Yeah.   
9:51   
Yeah. Yeah. I think that would be good. Um because yeah the the greater goals   
9:57   
are kind of like you know it's like giving a talk about the different technical pieces that have been put into   
10:03   
place the last couple years because you know we've kind of built upon the reinforcement learning aspect. We've had   
10:10   
probably good three years of development on that. Last year we did large language models and that's interesting but you   
10:18   
know it's kind of another piece. And then there was the uh back in 2022 if you remember Brian Mccoral's work on   
10:24   
active inference and how he did some of that. And then those are all pieces.   
10:41   
Yeah. Where is where is Brown now? Uh well I I I guess he's doing his art and   
10:47   
and doing other things. Making music. Yeah. Yeah. Making music. Yeah.   
10:53   
Um you know working I guess. Um you know. Yeah. But anyways, and you know,   
10:59   
having and those are technically interesting, but having the overarching goals and then of course having someone   
11:06   
speak to that outside of the that project like what's the greater   
11:11   
utility of this? Yeah,   
11:17   
I'm just going to put on my camera for just a second and have a bagel. Okay.   
11:24   
All right. Um All right. So Jesse sent me this uh I think this is like a   
11:30   
I don't know what this is if it's a draft that he's working on about or maybe he's doing a post on this. This is   
11:37   
living machine living things are not machines. So this is this paper that we reviewed I think in a cybernetics   
11:45   
meeting and it was this uh with Josh Bongard and um Michael Leven and this is   
11:54   
well this is the foresight neuroch seminar where they reviewed this paper   
11:59   
and they didn't they didn't really review the paper they just they they brought it   
12:05   
up and in the the It was a fireside chat that started um I   
12:13   
forget the host's name, but uh um   
12:19   
he's kind of asking them to speak on on their work, especially their their work   
12:24   
together. And um and you know uh I I think it was   
12:32   
Josh though who mentioned the um um   
12:40   
well I can't remember but but that that um that it's machines all the way down.   
12:47   
Okay. Yeah, I remember that to to to get Yeah. Yeah. you know,   
12:53   
um, uh, um, playing playing on two two lines, right? So, the,   
13:00   
you know, some somewhat the turtles all the way down, but, um, but also I think   
13:06   
it's from that paper. Um, there's plenty of room in the middle, I think, is   
13:12   
there, right? Their that that plays on the the Fineman. Um,   
13:18   
right. Yeah. Yeah. But it it was more it was   
13:23   
you know as opposed to like covering paper it was more just speaking to those that that particular a aential   
13:29   
multiscale agential material. Yeah. Yeah.   
13:35   
So yeah, this is uh kind of I guess he's   
13:40   
doing or Jesse's doing a post on this, you know, kind of digesting some of what   
13:46   
was mentioned in that event and then reflecting on, you know, the paper   
13:51   
itself. So I think it's interesting um you know   
13:56   
when he comes by today he will probably talk about that amongst other things. We'll see.   
14:04   
Yeah, for sure. Excuse me. Um the um No, it was good. Um   
14:15   
they were both speaking very high level about their work. Yeah. Uh   
14:21   
and um but I did get to I mean it's just like my my one goal was to ask well and   
14:30   
then Michael left um at a certain point.   
14:37   
I I I wasn't actually looking at the clock, but you know, like half an hour in something like that, Mike left and   
14:45   
Josh was Josh remained. Um, so I did get to ask Josh, uh,   
14:54   
you know, my question was where does or um, how   
15:02   
can we bring more biology into the kind of computational simulations that uh,   
15:10   
that they use for their xenobot and anthrobot   
15:15   
kinds of predictions. you know, um because, you know, uh I mean I love   
15:23   
his uh I love his evolutionary robotics course.   
15:29   
Yeah. And you know and they they he he brings you through   
15:35   
let's not say a traditional robotics program but but certainly a traditional   
15:42   
computational robotics program in the sense of he he he starts you very   
15:48   
very early with you know doing doing   
15:53   
computer simulations of robots. Right. Right. And and so it it's it is almost a   
16:01   
computer simulation of robotics class, but then once you get um   
16:11   
once you get to some sophistication with that,   
16:17   
he he does kind of talk about an adv advanced applications and one of those   
16:24   
is just the but Uh the the Anthrobot simulations   
16:30   
are they're they're very, you know,   
16:39   
they're very crude u biological simulation,   
16:45   
right? I mean, you know, it's like it's   
16:54   
Yeah. I mean, there's a reason that you kind of only get the motility prediction   
17:00   
because that's that's   
17:06   
the the simulation environment that you're working with kind of only does that,   
17:14   
you know? Yeah. I mean, it's it's this is this is an   
17:19   
environment where, you know, you start the class by like like   
17:24   
How how do I add an axle and wheels, you know, to to a a basic robotic form?   
17:32   
Right. Right. Um uh   
17:39   
yeah, I I I think it' be anyway. I mean, I shouldn't say I I only   
17:46   
think I got into like the the 20th lecture or something like that.   
17:53   
uh of of this year's course but I I don't know how much we get into you know   
18:00   
his answer to my question was was talking about more biomimetic   
18:06   
simulations and biohybrid designs you know which which again somewhat speaks   
18:13   
to a very   
18:19   
to some extent traditional robotics like   
18:24   
traditional robotics like work, right? Where it's just like, you know, like like you're building, you're still   
18:31   
building with parts, not machines. building with parts and and you're   
18:37   
making some but you're making something that perhaps moves like a centipede or   
18:45   
you know like like you know you're b making machine machine robots   
18:53   
that are insect like or something like that, right? Yeah.   
18:59   
Uh [Music] well anyway I mean that that you know   
19:05   
again it's it's well suited for the for the simulation environment yet   
19:10   
and and you know   
19:16   
I I want to see more because I know some of some of uh uh Michael Leven's   
19:22   
software projects. It's like I wanted, you know, basically I wanted to see, yeah, we're we're also   
19:30   
thinking about conc.   
19:36   
But those would honestly be more more Michael Evans in terms of, you know,   
19:42   
people familiar with with biology um to to actually   
19:52   
be working with those tools or or thinking about how to utilize those   
19:57   
tools or, you know, um   
20:03   
I I I forget if he even gets into kind soft robotics with like finite ele   
20:21   
but even even then I mean well that that would certainly be one way to bring in you know physics in a in an appropriate   
20:29   
fashion but you know in terms of making predictions   
20:36   
about the anthrobot behavior. Um   
20:43   
it it still doesn't seem that there's any good model, you know,   
20:49   
right?   
20:55   
But it was it was definitely a nice discuss or you know it was nice to to have them for briefly   
21:02   
answering questions.   
21:18   
All right. Um, why don't we move on to   
21:23   
paper? Um, for I want to move on to this item here.   
21:32   
So, yeah, I want to move on to this item here. Um this is something Yeah. from   
21:37   
the transmitter. This is um Ben Benictor. Yeah. Yeah.   
21:44   
And it's called should neuroscientists vibe code which is if you're familiar   
21:50   
with VI coding it's basically where you go and you lean on a large language   
21:55   
model to generate code and then kind of put it together and try to get it to   
22:02   
work which is kind of like you know how we do things in um   
22:09   
you know with with Stack Overflow just kind of putting together code and a lot of times that's considered bad practice.   
22:16   
And of course um you know using a large language model is sort of similar just generating code   
22:23   
you know to sort of you as long as you pose the problem well you know you   
22:28   
theoretically should be able to get code that works pretty well and then putting it together. Uh so it's it's not at   
22:36   
let's just say it's not at the pinnacle of software engineering good practice   
22:41   
but it's you know if it's effective and useful especially for neuroscientists who don't spend enough time on   
22:50   
uh software development in the first place that you know might be something that's acceptable. And we've talked   
22:57   
about how you know neuroscientists can use uh software engineering to improve some   
23:05   
of the software projects that are used in neuroscience. So like you know they're uh research software engineers   
23:12   
who you know can improve a lot of the academic software because a lot of the   
23:19   
academic software isn't very um you know doesn't have a very good robustness to   
23:25   
it. In any case, uh that's that's kind of the the frame here of what this is.   
23:31   
And of course, thinking about vibe coding more generally. Um it's I I talk   
23:38   
about this in a class that I teach and one thing that people point out is that   
23:43   
you don't really learn anything from vibe coding. In other words, if I vibe code and I query a large language model   
23:50   
for code, or if I just kind of get code from other places and stick it together in a in a in a program that does   
23:59   
something, um, I've not only created a piece of software that isn't really maintainable   
24:05   
in the long term or it's probably not maintainable, but it's also um, I never   
24:11   
learn like how thing, you know, I never learn how to program I never learn sort   
24:17   
of how to use better data structures. I just use the data structures I'm given. So it can be especially for people who   
24:24   
aren't computer scientists who maybe need to learn some things about coding   
24:30   
um or experts in that language. It can be um somewhat problematic. But anyways,   
24:39   
that sets up this whole like sort of debate that they have here, which is should neuroscientists buy food? And so,   
24:48   
um, researchers are developing software entirely through natural language conversations with advanced large   
24:55   
language models. The trend is transforming how research gets done, but it also presents new challenges for   
25:01   
evaluating the outcomes. So that's the uh point they're trying to make. So um   
25:08   
this other quote here, every line of code in a research project, whether written by humans or AI, must be   
25:15   
attributable to a specific person who can defend its logic. This is what I was talking about with respect to education   
25:23   
and um you know in auditability of the code that like if I put together   
25:29   
something through vibe coding I don't necessarily know how it works and um you   
25:34   
know I can't really say oh yeah I know why this isn't working or you know if someone says this is uh not processing   
25:41   
the data correctly and this happens a lot in you know academic labs where you   
25:46   
try to do an analysis and you have something doesn't you know   
25:52   
it might work for a couple of uh data points or data sets but then when you   
25:58   
try to apply it again it doesn't work because it hits some exception in the data file or something and and then you   
26:04   
try you spend a lot of time trying to find a solution to it. So uh you know   
26:10   
this is a problem. Um you want to be able to defend the logic of the program. You want to be able to go through line   
26:16   
by line and explain what's going on. You want to be able to validate the assumptions made by the by the program   
26:24   
it's generated. So you know in a lot of uh you know statistical tests for   
26:29   
example we have assumptions about the the data that go into it. If you query   
26:35   
um um you know a large language model or even go on to Stack Overflow and ask you   
26:42   
know uh generate this code to do this thing it doesn't necessarily care about   
26:49   
the assumptions of say fMRI or EEG and what those data you know what's what's   
26:55   
underlying those data points is it a time series what are how are we binning things all   
27:02   
those things about measurements uh don't really hold. And then of course   
27:07   
you have to explain this to reviewers. So if reviewers point out that your code is not doing what it's supposed to do,   
27:13   
then you have to be able to respond to that. So um so there's been this debate uh   
27:21   
about using AI to write essays, but of course we're also applying it to   
27:27   
research and there's this whole other set of uh sort of standards that we need to develop. So you know like journals   
27:33   
like nature have developed uh guidelines for using AI to write research papers   
27:39   
but not necessarily for working with data or generating research code. Um and   
27:44   
so that's that's kind of a problem that we have to kind of uh solve as a as a   
27:49   
research community. Vibe coding is a rather new thing. It was uh coined by   
27:56   
OpenAI co-founder Andre Kaparthy and you know it's just basically   
28:01   
interacting with an a large language model and trying to generate code and   
28:06   
then use it in I I guess high stakes situations. Um because you know you're   
28:13   
you're you're doing the same thing you're doing with uh software development. You're just kind of like   
28:18   
cutting out the part where you actually do the analysis and thinking. I guess   
28:24   
you do thinking in the queries that you you how you query the language model, but you don't have you don't have to   
28:30   
think about like the data structures that you're using and the pros and cons of that and all of that.   
28:36   
So it does offer opportunities for people who aren't like you know uh   
28:42   
professional software developers and so uh you know that's that's the advantage   
28:48   
of using and so this is this person says u the implications became clear through   
28:55   
my own work I collaborate with a small team to build AI interfaces for the dandy and open neuroarchchives   
29:03   
extending standard agent tools to search data repositories and directly access open data sets. The results surprised   
29:10   
us. The system could reproduce key findings such as orientation tuning in the visual cortex, directional   
29:17   
selectivity of motor cortex, and place field properties in the hippocampus   
29:23   
at the level of a competent first year neuroscience graduate student. Whether it can discover genu genuinely   
29:30   
new phenomena remains uncertain but its ability to rapidly validate established   
29:35   
results is already transformative. So this is um you know kind of a sort of   
29:41   
a victory for uh this method but also you know there   
29:46   
are of course some challenges um but but they're going to talk about   
29:52   
sort of the victories first. So it can reproduce things. It can reproduce results.   
29:58   
Uh the democratization extends far beyond reproducing textbook findings. Spike sorting which traditionally   
30:06   
required deep experience in signal processing can now be accomplished by any researcher who can describe their   
30:12   
experimental setup. Building biologically realistic neural network models once the domain of specialist   
30:19   
programmers might soon be accessible to anyone who can articulate their theoretical framework. So as long as you   
30:25   
can articulate this in in natural language or you can you can query a AI   
30:32   
model in some way then this becomes uh possible.   
30:38   
um you know it opens up uh doors instead of creating barriers.   
30:44   
Um the technical barriers that eliminated many neuroscientists to descriptive statistics are dissolving.   
30:51   
But this newfound power comes with serious risks that our field hasn't adequately addressed. So this is an   
30:57   
interesting point and it's kind of goes beyond live coding to kind of you know   
31:02   
using tools that allow you to do things like dynamical systems analysis.   
31:08   
or other types you know uh just basically getting a hold of a lot of data sets and of course he works for I   
31:15   
guess dandy so it's you know you have that other added aspect of you know does   
31:21   
neuroscience change when you have access to a lot of data because there are all sorts of issues around data set um sort   
31:28   
of reconciling data sets and all this other stuff that is um you know you   
31:34   
don't really learn in a classroom Um and they do have some classes and computational neuroscience isn't about   
31:41   
this. It's about computational models of the brain. Are there classes where you can learn about using computation   
31:49   
in research and that so that's a problem because maybe not a lot of uh neuroscience students get that   
31:55   
education. Usually you're busy learning all sorts of things about the brain and you know things that maybe about like   
32:02   
computational methods and then other things that you need to know and biology and in psychology and in computer you   
32:09   
know you're learning all these other things that are important for uh being a practicing neuroscientist. Is there room   
32:16   
for a class like this? And do people get that exposure given how central it's becoming?   
32:24   
So um that's and then of course this question is uh so should neuroscientists   
32:30   
vibe code and then the author says the answer is a qualified yes proceed only with the right approach.   
32:37   
Okay so then kind of goes through some of the drawbacks of using AI and benefits of using AI. This goes through   
32:45   
a lot of the drawbacks, how uh AI can feed off of pre-existing biases and how   
32:54   
it can be extremely sick of fantic. So it gives you the answer you want instead of the maybe the correct answer if   
33:01   
you're misguided. Um you know it won't tell you that you have to find out the   
33:07   
hard way. Um and so these incidents reveal a troubling pattern. AI systems   
33:14   
fail when we don't understand their training data. Implicit assumptions or decision-making processes. In   
33:20   
neuroscience, where subtle methodological choices can determine whether you find a significant effect,   
33:26   
this lack of transparency becomes especially dangerous. Okay. Um and then of course there are   
33:33   
also reproducibility implications. So he said that you can reproduce research   
33:40   
but um then there's also this other aspect of reproducibility   
33:45   
where there's this sort of human intentionality behind every methodological choice in a normal   
33:51   
setting where you're not using AI. So if you decide to go with a certain   
33:56   
methodological choice that's something you can defend that's something that you understand and is a standard in the   
34:04   
field. So if it's not a standard in the field, you know, gains scrutiny. If you   
34:09   
can't explain it, it gains scrutiny. But if it's generated by AI, you know, we   
34:15   
just have to kind of accept any kind of thing that results from that. So it's   
34:21   
kind of hard to know, you know, what kind of assumptions the model is making.   
34:26   
So consider a concrete example. An AI might choose to apply a particular smoothing kernel to fMRI data based on   
34:34   
patterns that learn from training examples without explicit reasoning about your specific experimental design.   
34:41   
So that means that you could have the situation where it's doing added data   
34:46   
analysis that violate the assumptions of the of the   
34:53   
statistical method or violate the assumptions of the data set.   
34:59   
And so that's a problem. And of course, if you don't know that, you can't defend that choice because you didn't make that   
35:04   
choice. Uh the documentation challenges multiply   
35:09   
when we consider prompt sensitivity. Research has shown that subtle variations in how you phrase requests to   
35:15   
AI systems can dramatically alter outputs. Changing analyze this neural   
35:20   
data for place cells or to identify place cell properties in this data set   
35:25   
might yield different statistical approaches or parameter choices. Unless we maintain detailed logs of every   
35:32   
interaction with AI systems, including failed attempts and refinements, we're left with analysis pipelines. This   
35:39   
provenance is essentially unnable. So this is you know we build analysis pipelines for a reason and it's going to   
35:46   
be undermined in this way. So it seems like it's pretty you know those are some   
35:52   
pretty big qualifications and depending on you know how you build your pipeline.   
35:58   
So, you know, in other words, um you know, if you use something like this, you want to be able to know kind of to   
36:05   
see if you can figure out exactly how the code is generated. And what I mean   
36:12   
by that is if it's doing things that are kind of not you don't really understand   
36:18   
what the logic is, you know, being able to go back and analyze the code post hop   
36:23   
to make sure that it's something that you want and then refining your query. So, you know, sometimes there's this   
36:29   
temptation to um, you know, try to grab the, you know, try to do this in the   
36:35   
quickest way possible, grab the code and run with it. And in fact, what you probably need here is a iterative design   
36:42   
process where you, you know, not only design your kind of code base, but also   
36:48   
design the queries that you're using to get code to add to that code base and   
36:54   
then use that as your analysis. So it might take a lot more work than writing code by hand or it might be a shortcut   
37:02   
but you need to have these you know this this added layer of scrutiny or or   
37:07   
auditing to it. So AI tools can be transformative but   
37:13   
they require the develop development of new forms of literacy.   
37:18   
statistical understanding becomes even more essential because AI can implement any test you request without determining   
37:25   
whether it's appropriate. And so domain expertise matters more than ever because   
37:30   
the quality of AI generated solutions depends heavily on insert specification.   
37:36   
The ability to read and critique code becomes essential for identifying subtle errors that can invalidate entire   
37:42   
studies. Um and so this is where you get into the responsible adoption and the   
37:48   
accountability and uh you know people who embrace this   
37:55   
transition thoughtfully uh will have tremendous advantages in tackling the field's biggest challenges.   
38:02   
And so yeah, that's that's the article. And so I don't know what you had to say. I I'm sure you have a lot to say about   
38:08   
that, Morgan. Yeah. Yeah, for sure. Um, so one,   
38:15   
um, yeah, I got to meet, um, I I got to see Ben at, uh, at the, um,   
38:25   
the Allen Institute, open science education for undergraduates or   
38:31   
undergraduate education, open science for undergraduate education. Um   
38:37   
and you know we we talked some about so like   
38:43   
um if you want an example of of you know   
38:49   
their their work with Dandy Archive in particular um the neuro data rehack   
38:58   
um is all available on um um   
39:03   
it's all available on YouTube. So they just they just did a like a coding   
39:10   
you know kind of a hackathon they it's rehack because it's a it's using dandy   
39:18   
archive data um to do secondary analyses right so um   
39:26   
these are all published data sets but can you can you use these these   
39:32   
published data sets to to have some other conclusion or focus on a   
39:40   
different question or something like that, right? And and it was very much like for grad   
39:46   
students, posttos, right? Uh um so I I I wonder I didn't I   
39:55   
I know I posted the videos on on Maritech XSlack. I'll I'll find a link   
40:02   
in just a second. But um I I wonder if this was a session of that   
40:09   
in the sense that like this was definitely a meeting where I think it would have come up, you know,   
40:19   
uh totally related to that. Hey there.   
40:24   
Um yeah, I mean and and kind of related to   
40:30   
u the software the the open source software sustainability   
40:36   
some of the well I I should also say that at Frontier Tower there's there's a   
40:42   
lot of people who absolutely are you know um in the the cult of vibe   
40:49   
coding Yeah. Um and and   
40:56   
you know like like like a lot of people whose first um whose first   
41:05   
search operation is to ask an aline. Right. Right.   
41:11   
And um and I'm just kind of uh I mean I'm I'm not making fun of that. It's   
41:19   
it's u you know it's just like like there   
41:24   
there's definitely you know a great need to understand   
41:30   
these outputs. Um but but the the bigger the bigger issue   
41:38   
is the uh the bigger issue uh or something that's coming up a lot is that   
41:45   
like Vive coding um   
41:50   
should be done by a a swarm of agents,   
41:55   
you know. Okay. And that that to me reminds me of the open source sustainability at least   
42:01   
you know in terms of treating it like a um   
42:07   
treating it like a multi- aent problem uh where you you   
42:14   
give the system more uh more   
42:21   
different defined roles to to address some of the issues that you that you you mention or Ben   
42:27   
mentioned in terms of you know documentation and kind of um   
42:33   
uh to to some degree testing you know again like   
42:39   
how how to how to well define those rules going in is another question but but   
42:46   
it's it's something that we should talk about the the other thing I I wanted to   
42:52   
mention was um Uh Russ Holddrech, I I think I've   
42:58   
mentioned this before, but Russ Pdre is writing a book right now that is   
43:04   
called something like Better Code Better Science.   
43:10   
Yeah. Um Oh. And he's he's like he he's been posting.   
43:16   
So if you check um uh you know these days I I try to use   
43:23   
LinkedIn more than X um Twitter   
43:28   
uh can't fall into calling it. Um   
43:34   
uh yeah, the he he has posts he posts chapters of   
43:44   
of the um of the book and his um   
43:51   
uh his student Chris Gurowski.   
43:57   
um um I'm not I'm not I'm not saying his name right but uh his or postoc I forget   
44:06   
now now works for anthropic okay so I believe this book is uh using   
44:15   
claude I'm not sure whether we should consider   
44:21   
that an endorsement um but Uh but I'm   
44:27   
sure you all know that this is one of the things that um Anthropic is   
44:33   
definitely trying to trying to market um or trying to differentiate I should say   
44:40   
their their products in terms of um uh code generation.   
44:47   
So, I think I think it would be um I I would love to do a real like   
44:56   
let's let's get his book or like let's get the chapters and and see, you know.   
45:03   
So, it would be nice to get the guy who   
45:08   
started open. Yeah. um who's also writing a book about this   
45:15   
um uh as well as um   
45:20   
that that that when I talked to Ben at this symposium   
45:26   
um he was very down to do events with with Nerchek X or like   
45:35   
we we could do something for undergrad students, you know, to   
45:41   
um I mean I I I would love to show them how to do something like he describes in   
45:49   
terms of take a dandy archive data set and and you know do a rehack where you   
45:57   
demonstrate you know some sort of um predictive coding response you know   
46:05   
like that that that that uh again like showing showing   
46:13   
showing undergrads how to do a kind of first year grad student work uh with   
46:20   
quality would be cool. Yeah. Yeah. I mean, and with with again the   
46:26   
caveat that like you're not asking them to   
46:33   
to keep doing it that way, but but you're both showing them what these   
46:39   
tools will be able to do in terms of augmenting their work   
46:45   
um as well as uh Yeah. Yeah. Just just   
46:50   
how to how to navigate this. how to navigate this new world, right? Yeah.   
46:56   
And um uh I'm sorry, I was gonna say something   
47:03   
about that. So, generating that um   
47:08   
uh I there was there was one more thing   
47:14   
about that. Um   
47:22   
um well hope hopefully it will come to me   
47:27   
but um uh I think it would be really valuable   
47:33   
to you know it's it's it's showing them how well sorry that's that's what I was   
47:39   
just going to say was like like you know it can be hard to to give   
47:48   
students something, you know, example code to look at sometimes. And this is   
47:53   
this is potentially one way where you can generate example code and then actually spend the time where you're   
48:00   
just taking it apart, not um not just kind of blindly using it or treating it   
48:06   
like a black box. um   
48:12   
better better potentially uh as a way to get across concepts. It's it's another   
48:20   
way to get across concepts that's not just kind of starting with the language primitives and and trying to trying to   
48:28   
build up. Um anyway, and yeah, let's   
48:33   
let's you know, let's definitely   
48:39   
have this as as something that uh speaks to kind of like the open source software   
48:47   
sustainability, you know, in terms of its multi- aent   
48:52   
uh as well as like um this um oh oh   
48:59   
sorry and then the um Allen Institute open scope program.   
49:04   
So Jerome Lok was talking about um   
49:13   
he he he says that he's noticed   
49:18   
a lot more quality code showing up in in repositories.   
49:24   
Okay. And and he thinks that it's LLM generated   
49:30   
a lot more quality code. Yes. Huh?   
49:35   
Yes. Yes. Like against against the downward pressure but a lot more like advanced. I   
49:42   
wonder if it's probably like like robust and like I   
49:48   
Yeah. Yeah. So I I I too would like to to know more. I mean, you know, again,   
49:57   
you know, I I hate to just, you know, parrot the the the the statements of of   
50:05   
the, you know, vibe coders. um or the people talking   
50:11   
about vibe coding when I have never touched an   
50:17   
so so I I don't but but I uh   
50:22   
you know I'm thinking about like is it Simon will Williamson   
50:29   
Williston or something like that. Yeah. Yeah. You know what I'm talking about. Yeah. And it's like like and he's simon   
50:35   
Williamson.net net or something like that. Anyway, um   
50:41   
uh um he he like was he like the original WordPress   
50:47   
developer or something? I think so. Um something like that. Anyway,   
50:53   
you know, there there's there's definitely, you know, expert coders who   
51:00   
who can use these tools in to, you know, in productive ways. Right.   
51:06   
Right. And so certainly there's people saying but like this will this is like   
51:12   
you know the the income inequality tool of of coding in the sense that like you   
51:19   
know people people who don't know how to code will will be producing slop and and   
51:25   
people who are um who who are really know when to use it and how to use it   
51:32   
will will be you know making themselves more productive. again that that I feel like I'm paring   
51:40   
people who absolutely believe these are, you know, gamechanging tools, but but I   
51:48   
don't know how much they have experience with them. So, I I I think it would be great to do an event. I think it would   
51:54   
be great to get into um uh um Russ's   
52:00   
book, you know, and like like Russ has always been a a coder scientist, you   
52:07   
know. Um so I'd love to see how he's using them. Um and   
52:14   
uh yeah and and the the other thing is that   
52:20   
um that you know this connection uh   
52:25   
program that I'm doing like like there's there's definitely   
52:32   
there's definitely need for more tools for for teaching in you know and Um,   
52:42   
uh, yeah, like like I've I've got some   
52:47   
issues that I think can be solved technically, but like we're not doing   
52:52   
them when especially with these students that are that are in Africa with with   
52:59   
um, you know, network connectivity problems and and compute resource   
53:04   
problems, right? Yeah. that uh uh I feel like we we've done a   
53:12   
bad job of kind of like adapting tools to to better handle their   
53:19   
needs. Um so I think a lot of opportunities here, you know, and not   
53:25   
just to like replace coding or something like that, but to like think about teaching in new   
53:33   
ways. Can Can I I think I missed it. I'm sorry. What's the connection program that you're doing like like the   
53:41   
That's just why I've I've had to skip a couple meetings. So, um that's teaching   
53:48   
we're teaching um computational modeling of of MRI like   
53:56   
yeah mostly MRI although PET as well uh to students in Africa.   
54:04   
And you know it's been they're they're very distributed too, right? So it's not just   
54:11   
that they're um yeah they're not in a all at the same   
54:18   
institution. They're all at different universities. Like so I just found out   
54:23   
today or last night that like all my students are at different universities in Ghana.   
54:30   
Oh, nice. they're not they're not actually able to all sit in the same room together, you know, and so like   
54:37   
when when we're talking on WhatsApp or Google Meet, like they're having all the   
54:44   
same like like it's it's not just me being really far away, but like they're   
54:50   
getting they're getting laggy results, you know, like hearing it, you know, and and you know, yeah,   
54:59   
I I I would like to connect you with somebody who I I don't I don't I don't know what how   
55:07   
how they how it works right now because they're they're in a slightly different field, but she's from Ghana and I worked   
55:14   
with her in the past about developing educational capacities for   
55:20   
people in Ghana. Okay. might have some insight or like at least   
55:26   
help or like at least at least support or cheer it on or like find something that would benefit you all there. That's   
55:31   
like the OG cause for some things um or um   
55:38   
so I will make a note of that. So please please   
55:43   
Yeah. Go ahead. Sorry. Yeah. No, I was just, you know, and and so Russ is, you know, it's like I I   
55:50   
assume a lot of Russ's code, you know, better code, better science. Uh I I   
55:56   
assume these are going to be neuro imaging related. I I could be wrong.   
56:01   
Um uh but   
56:07   
I have I have a whole bunch to say about and we don't have to I know I don't know where Bradley wants to go with this stuff, but like I've been dealing a   
56:14   
little bit with the LM and V coding. Um, and   
56:21   
it's real interesting. Um, in terms of   
56:28   
develop like I think I think there's like there's two very broad like things happening.   
56:36   
One is like the immense ease of conceptual exploration   
56:41   
and and how like being able to just structure kind   
56:47   
of like like Andrew Andrew Ning like don't don't worry if it doesn't make sense don't worry about don't worry   
56:52   
about code it's like what you're getting at in in the what is happening sense is   
56:57   
very easy in some ways and much it help I I appreciate the rapidity of   
57:04   
that because I and I don't know I haven't really been I'm not I'm not a teacher I'm not a co-p profofessor uh   
57:10   
but like that's fun, but it's very different from what is the code doing,   
57:17   
right? And are you you know how to do any like here's the output and the   
57:22   
output's fine but like are you just trying to get like a where's where how much do you need to go on on the   
57:28   
internal understanding of making the code or the language or reviewing it or   
57:37   
just kind of pressing the easy the easy button of Ellen like I don't know try again try again try again try again try   
57:43   
it again like do this and like I've been there I've been I've been I've been I've I have used LM. I use LM for different   
57:50   
kind of study and everything like that and and you have to be very very very careful and I do think it's for people   
57:56   
that are like their first this search is the LM search. Yeah. So that's a whole I'm very to to   
58:05   
ground this and maybe move on to segue to whatever Ry wants to talk about next. Um I'm very interested in those topics   
58:12   
as well. and would be interested in supporting events around how do you do the code? Um, as I think I've mentioned   
58:18   
before, I'll say it here again. You may not have been here for this, Morgan, but I am I have I have uh answered the call   
58:28   
of um I'm I'm I'm a longtime member of a   
58:34   
particular group that that um puts on some events for um   
58:40   
early career folks. And one of the things that has really came up this   
58:46   
year, there was basically an open call like saying, "Hey, all of our all of our   
58:52   
students and potential students and potential people coming to the event are like, what do we do about Gen AI and and   
58:58   
jobs? Um, and what do we do about the impact on the people that are just coming out of college and early career   
59:05   
stuff to get the entry level stuff?" And this maybe isn't directly related to   
59:11   
that. um in in in in this learning how to do what I understood the events might   
59:17   
be around isn't isn't quite the same as that. But I think uh I think there's a   
59:23   
lot of overlap there. So I'm kind of I'm already doing some a lot of programming   
59:30   
um about this in the sense of kind of knowing what to advise others   
59:38   
early career folks on about it. like I'm I I have my limited experiences and I want to start asking basically everybody   
59:44   
here. Um and and I'm I'm I'm I'm over the course of the next few months I'm   
59:49   
going to try to be understanding like what is you know what to do and what is   
59:56   
advice and what what should people know and and how to prepare as best as possible because   
1:00:02   
um Okay. Yeah. Um yeah. So, more about that later, but um interesting stuff.   
1:00:09   
And it looks like it looks like I came in and we're discussing the article. I don't know if the article was or could   
1:00:16   
be shared here again. The transmitter transmitter   
1:00:21   
and then we had a discussion. So, it's called should neuroscientist vibe code is in the transmitter.   
1:00:27   
Okay. Yeah. So that's this is a yeah an article on kind of a debate about it but   
1:00:33   
it's a one person debate and like just talking about this person's experiences with it   
1:00:42   
and I put in the um Mikai 2025 meeting   
1:00:48   
um just because I was talking or you know like like uh Stephen Alward at   
1:00:57   
who's like a a was like a long time kitwear   
1:01:03   
um principal um moved to Nvidia,   
1:01:11   
right? one of the sweet sweet GPU money. And um uh   
1:01:18   
he was talking about um uh   
1:01:24   
doing doing something doing an event where people try to potentially people   
1:01:31   
try to use LLMs to take previous Mikai   
1:01:37   
conference papers and and code them, you know, using with   
1:01:43   
CUDA. right? Um   
1:01:48   
uh you know and like get get a get a 2024   
1:01:55   
paper working as a as a CUDA   
1:02:00   
um you know so not just implement you know a registration or transform or   
1:02:06   
whatever but like like GPU paralyze it. Um, and you know, which which is a kind   
1:02:15   
of like a a specialized C++ programming, right?   
1:02:22   
Um, and you know, and and my response to that was like, you know, to some degree   
1:02:30   
that's not crazy or that that if you had the right test data   
1:02:37   
set, right? And the right um,   
1:02:42   
you know, the right procedures around it. like you could absolutely be, you   
1:02:50   
know, using using it to generate some of those those um key operations.   
1:02:59   
Um and just thinking about how to, you know, how to have enough test cases to   
1:03:06   
to validate the the the the tool, you know. Um anyway, I I I would like to see   
1:03:14   
it like like a lot of the um a lot of the connection people. So connections   
1:03:20   
just this this program uh um it's it's in a larger group called camera   
1:03:28   
which is really about democratizing MRI in in Africa. And a lot of camera people   
1:03:34   
are definitely going to be at Mai like like the the um the head of the program   
1:03:39   
was talking about seeing seeing people in Korea. Um   
1:03:45   
so I I I would love to I don't know think about that next next weekend. So,   
1:03:51   
it's like the 23rd to the 27th and um and I I you know it I was just   
1:03:57   
thinking about it because like again like Frontier Tower is full of a bunch of vibe coders, right? So, I'm like,   
1:04:04   
"Come, you know, I'd love to do an event where it's just like, okay, come use your prompting skills. Generate me some   
1:04:12   
some uh cuda cuda code um and you know,   
1:04:18   
and let's test it out on you know, medical imaging data sets." Anyway,   
1:04:25   
that would be a cool event. And we might be able to get GPU. We   
1:04:31   
might be able to get Nvidia support in terms of like if I if I said to Stephen   
1:04:37   
that we were doing that like hey can you give us like Nvidia GPU cloud access for   
1:04:43   
you know a day or something. There you go.   
1:04:50   
All right. So uh yeah thanks for that discussion. That was a great discussion. Um, so yeah, I see that when I was doing   
1:04:59   
the article, Jesse and VD showed up. So, welcome. Um, and so I don't know if V   
1:05:04   
had anything any updates she wanted to give before we move on.   
1:05:12   
Hello. Can you hear me? Yes. Hello. Yeah. With my university exams just got over   
1:05:20   
today. So, I mean, I think I can look at other stuff. Maybe go through GitHub, see what's happening the world, what   
1:05:27   
other people are doing, something like that. Yeah.   
1:05:34   
Well, that's great. Yeah. Um and good. Yeah. And like I think I texted you and   
1:05:41   
Jesse before my exam started like um how should I continue and all and like what can I do? What can my goal like what   
1:05:47   
role can I play? Something like that. Yeah. So yeah, congratulation on your   
1:05:55   
exams. Hope you did well. And yeah, as for you know, next steps in in   
1:06:02   
the lab, you know, we're working on a overview of open source sustainability   
1:06:08   
for the active inference uh symposium. So you know, you might want to be involved in that. Um we have other   
1:06:16   
things going on this fall uh different meetings, different things. So just you   
1:06:21   
know we'll we'll uh keep things updated in the Slack or we'll try to do things   
1:06:27   
through the meetings where we kind of try to solicit people's involvement for   
1:06:32   
things that's usually the way it works here. And so um you know if you have any ideas of your own you'd like to pursue   
1:06:38   
if you'd like to you know take your GOC project and do things like you know run some   
1:06:45   
simulations and um you know like we can look at the results of that and maybe   
1:06:51   
you know publish a paper on that or we still have to update the um open source   
1:06:57   
sustainability technical paper because I have that to kind of uh update and it's it hasn't   
1:07:05   
been updated for a while. So, um yeah. So, we have a lot of things we can do   
1:07:11   
and it's just a matter of like getting them uh done.   
1:07:17   
Yeah. So, I was thinking if it's like about my Sorry, you want to say something or can I   
1:07:22   
continue? Go ahead. Go ahead. So, I was thinking if it's about my GOC project, it's about sustainab   
1:07:31   
next year and utilize the summer for that. and like like main I can collect some   
1:07:37   
ideas about how I can extend my project then and then now like if any other help   
1:07:43   
in all if there's any project that are working on any research anything like that so something like that like   
1:07:49   
yeah yeah I think that would be good you can do G-S two years in a row as far   
1:07:54   
as I know you can do it twice we had someone who did it twice um so yeah that's that would beice   
1:08:02   
yeah Yeah. Yeah.   
1:08:08   
I would I would um basically just do a nudge of it's really   
1:08:16   
up to you in terms of if you particularly think focusing on sustain   
1:08:22   
hub is really good for you personally, professionally, or otherwise, just keep   
1:08:28   
working on it all the way through. Like you don't have to wait. It's it's your it's your show. But um if you think   
1:08:36   
there's other things you'd rather be doing, do that. Um you you've been in the lab for a while, you have the   
1:08:43   
ability to um center what you want or make your own   
1:08:49   
projects. Um or like if you want it like again I don't I don't think this is what   
1:08:54   
you want to do, but it's an example. You could make a whole you could build out okay sustain hub is this thing. You   
1:09:00   
could make an adjacent project. You could make you could make a center for this. Then there's even stuff in the lab   
1:09:05   
about like computational modeling and um a lot of a lot of   
1:09:14   
things in the closet, things that are just in the archives of like adjacent stuff. So, what I would suggest I   
1:09:22   
understand you're kind of asking us somewhat um and that's fine to do. I would also suggest tell us some specific   
1:09:31   
like areas of interest that you have because one there's probably   
1:09:38   
excuse me there's probably some connection to those things   
1:09:45   
coughing suddenly there's probably an existing connection to those things or if not we can support   
1:09:52   
you in developing it further. I think it's kind of like you you're um you know   
1:09:57   
the ropes somewhat here and you've demonstrated the capacity and quality to   
1:10:03   
do things. So you have you have the brains to do to do what you want and and outside of outside of this moment like   
1:10:09   
if you want to talk with Bradley or with me or whoever you want to talk with us like hey what let's strategize about for   
1:10:18   
my career or for my personal interests I'm really interested in doing more and blank let's have a talk about what that   
1:10:25   
looks like. I would just say like let's do that. Uh because I think the real   
1:10:30   
question is um you know if if you just want to be told   
1:10:35   
what to do, we can tell you hey work on this. Um but I I I tend to advocate and   
1:10:41   
that's what you get in a lot of places. I tend to advocate for um let's find an   
1:10:47   
alignment of interest and and opportunity and and uh   
1:10:54   
what what's going to matter to you and matter like to your future. That's my two cents on it anyway. So,   
1:11:01   
yeah. Yeah, let's let's like I would I would basically say think about specific   
1:11:06   
topics or targets or things you want to do more of and we can discuss like what   
1:11:13   
what what would be a new project for like this term or like if you wanted if you're on   
1:11:18   
board for like the rest of the year, okay, let's focus on this the rest of the year and and we're happy to um   
1:11:25   
identify that. So yeah. Yeah.   
1:11:31   
And of course I know that. Yeah. Okay. And of course I I did in going through   
1:11:38   
some of these things for the act of influence uh symposium I noticed that you know   
1:11:44   
well I've had this idea for a while but like extending what we're doing in open   
1:11:49   
source sustainability to the things we're doing on computational agents. So   
1:11:54   
we of course we've done a lot of work on like metabrains and brainberg vehicles   
1:12:00   
and you know having kind of you know because we've done a lot of work on   
1:12:06   
reinforcement learning in particular through open source sustainability using that in conjunction more with the uh   
1:12:14   
intelligent agents or the computational agents uh rather than just uh limiting   
1:12:19   
it to open source sustainability. So there's a lot of interesting stuff here I notice with sort of like uh   
1:12:27   
learning and with the stuff with the large language models of course and some   
1:12:33   
of the stuff with reinforcement learning even where we were viewing with like uh   
1:12:38   
you know complex tasks. So it's like you're generating a task, you're defining it and then you're having   
1:12:45   
agents like kind of interact and solve tasks and that sort of thing.   
1:12:50   
And then of course there's always this issue of like the swarm intelligence or the collective behavior. And I think we   
1:12:56   
had someone who had proposed like a couple years ago a GC project where they   
1:13:03   
were going to do like something with collective behavior and open source sustainability.   
1:13:09   
But like of course we were doing the things of multi-agent reinforcement learning. Um and that's sort of another   
1:13:15   
theme in reinforcement learning. And so that area is, you know, that's of course   
1:13:21   
where you have multiple agents doing reinforcement learning tasks and that's that's something that could be developed   
1:13:27   
as well or, you know, we we packaged in a different way. So there are all sorts   
1:13:32   
of opportunities and we have code all over the place basically. So if it's   
1:13:38   
like anything that you find would be useful to research or even just to to   
1:13:43   
like um you know bringing it into new uses I guess is a good way to think   
1:13:49   
about it then that would be welcome.   
1:13:56   
Yeah. So I like Yeah. I think I'll like think   
1:14:01   
about what I want to do. I'll be sure about that and then we can have another discussion.   
1:14:07   
Yeah. And that can that can be it can be in Slack. It can be a private event that's like hey can we just talk like   
1:14:14   
you know for Friday Friday on some some some other time's   
1:14:21   
brother's busy with a bunch of things. I'm busy with things but like we can find a time to just have like a even a 30 minute a 10 a 20 minute discussion of   
1:14:28   
like hey what what interests opportunities here how do they align and let's do something there's a lot of   
1:14:34   
things that are kind of again it these meetings are so tough because we don't   
1:14:39   
we don't really talk about everything that's going in the lab all the time. Uh, so there's actually we might be due   
1:14:47   
for kind of a what's going on in the lab in fall 2025.   
1:14:55   
Um, you know, but that that that's something that that maybe should be written out or   
1:15:01   
a small video on that at some point. But there's a there's a lot going on even even in my own sense my my own self.   
1:15:08   
There's uh one thing I might talk about soon and I don't know what I don't know what you want to talk about the rest of   
1:15:14   
today Bradley but um there's a few updates that I have and a few events that I would talk about too that are   
1:15:19   
kind of all around these same clusters but V like anything you want to say before we move on to other stuff too.   
1:15:26   
You can go ahead and speak up. Yeah, but definitely reach out or like   
1:15:32   
um the message in Slack uh in particular and I'll I'll try to follow up on some   
1:15:38   
things too because I know some stuff might might be relevant, but I really I   
1:15:44   
don't know. My biggest unknown for you is what where does BG want to go? like like I   
1:15:50   
know you I know you have some aspirations for grad school in certain areas but you know what's what what   
1:15:56   
what's your uh you know destinations so um yeah let's follow up on that as   
1:16:02   
far as other stuff um did you want to talk about anything specific Bradley or   
1:16:07   
do you want to there's a few updates that I have for pro stuff and then some of the events that I mentioned this week   
1:16:14   
too. Yeah. So, why don't we segue into Jesse's updates? I had mentioned earlier   
1:16:20   
about like this thing you posted in the Slack about um the Bong Garden 11 talk   
1:16:26   
that or whatever that was. It's like kind of a review of that talk or something.   
1:16:32   
Yes, I have a draft that's I can go over for that and that that'll be fun and relevant to um a lot of stuff. Um, I   
1:16:40   
think I'll go I think I'll I'll get my other junk out of the way and then go to that because I'll be like, "Oh, yeah.   
1:16:45   
Let me talk about this," you know, quite a bit. And and um, a lot of really   
1:16:50   
interesting overlaps there. It was it was it was something that was fun to write and I I was going to do like a   
1:16:56   
three, four paragraph and then I just like I read Leven's update. I was like,   
1:17:01   
"Oh, well, okay. Well, this is cool." like   
1:17:06   
18. It was cool to see him associate here's where I stand relative to theoretical biologists like Montana and   
1:17:13   
Bella and like like oh okay this is like what are you doing relative to machine it's kind of just an update on on the   
1:17:19   
machine stuff. Uh but with my my brief updates are um   
1:17:30   
there's also other event but I don't know how to talk about that as well. I don't know if you were there for that   
1:17:36   
one, Morgan. The one with and   
1:17:43   
uh Will will Will Han the echolop the one from late Wednesday or something. I don't remember.   
1:17:49   
Right. Right. Yeah. So, yeah, we didn't talk about the computational philosophy um meeting. Um   
1:17:55   
Oh, yeah. You were there. Wasn't that at that was at It was in front of your tower. Yeah. Yeah. you were totally there   
1:18:02   
because I it it was it was I to to to save myself from from embarrassment   
1:18:07   
which I don't have any but just to like it's because the first half of the event was like very   
1:18:14   
a specific set of talks and then Elon and Will joined it it was   
1:18:20   
their LM stuff. So yeah, it was um   
1:18:26   
uh uh it was an interesting way to do things,   
1:18:32   
but just just to give you know Bradley and and everyone   
1:18:38   
a a you know sense of the backstory here like um   
1:18:45   
echalapto um prince principal or yeah ai   
1:18:52   
applied to be a member of the tower and um   
1:18:59   
and then Dugan who's the Wolram Institute um um I forget what his   
1:19:06   
position is there but um was in San Francisco and they so they wanted to   
1:19:11   
host an event at the tower and um and this sorry and this was   
1:19:16   
together with Andreas who's the um co-founder of Qualia Institute,   
1:19:23   
Qualia Research Institute. So, CQ RI, right?   
1:19:28   
And um and although um I have   
1:19:35   
some mis misgivings about anybody, you know, who's not very concrete about   
1:19:40   
their consciousness work. Um uh uh   
1:19:46   
there's there's definitely a a thread of qualia research institute work that I I   
1:19:54   
really love in terms of computational modeling of multimodal neuro imaging   
1:20:00   
and this this kind of relates to some of like Robin Khart Harris's work and and   
1:20:07   
um Morton Kringlebach and um Selene Addisoy that that is, you know, top   
1:20:14   
top-notch. Uh, I mean, this this is some of the work that I'll be covering in the   
1:20:20   
second week of October at this neural 2025 meeting. Um   
1:20:28   
they so so Dugan did a presentation on the rulology rulology   
1:20:36   
um you know the the Wolfram Institute work and and then you   
1:20:44   
know there was there was breaks and then then professors were calling in. So   
1:20:49   
basically his advisors at um uh is it University of Florida? Florida Atlantic.   
1:20:56   
Yeah, a lot of them are from FAU. So yeah, FA Yeah, Florida Atlantic University. Um   
1:21:03   
and um yeah, so I I was trying to accommodate them kind of last minute.   
1:21:10   
Um, but I was really happy and and I'm happy that um that Adi's interested in   
1:21:16   
becoming a member and that um so let me just check if I've got a message wrong   
1:21:23   
because uh I was hoping to   
1:21:28   
um yeah anyway unfortunately he's going to have to reapply   
1:21:34   
but um uh uh That was great. I like like they were   
1:21:42   
there, you know, doing doing events until the the late in the evening. So   
1:21:48   
even after uh um William and um is it uh   
1:21:54   
Evan? William Han and Elon Baron Halt. Elon Elon. Yeah. E L an R   
1:22:02   
correct. Um and uh but even after the uh   
1:22:08   
conversational philosophy meeting ended uh Andreas and Dugan went upstairs to an   
1:22:14   
AI meeting where Andreas was continuing to present.   
1:22:19   
So they they didn't leave the tower until like you know in the 9:00 or   
1:22:25   
something like that. Um um so that was that was very cool.   
1:22:31   
really hoping to have them, you know. So talking to AI yesterday like like having   
1:22:38   
a you know multiple um like say twice a week sorry twice a   
1:22:44   
month if not once a week uh recurring meeting that we host at uh at the tower   
1:22:51   
that and and I was super interested to hear that that um Elon and and William   
1:22:58   
are interested in fMRI studies of their work. So just getting to that point of   
1:23:04   
of you know I I'd love to see more computational work I'd love to see more   
1:23:10   
empirical work around around these theories. Yeah. Yeah. That I think that's what um and I   
1:23:18   
think I think it's a mix of I mean exactly like that that that that how would some of that be like instantiated   
1:23:25   
or done or what does it mean? And I, you know, I'm I'm very open to I I think I'm like I'm not I say this as someone who   
1:23:36   
is very um   
1:23:42   
very vested in being aggressive theoretically about   
1:23:48   
what you want to pursue. Uh so that's not a bad thing to me. But yeah, it it   
1:23:53   
it kind of and I think I think there's I think there's a realization of that and a realization of like okay like   
1:24:00   
um there's there's like pre-prints that I know are being being worked on and and   
1:24:06   
and fleshed out. Um I don't know how much they're going to be computationally centered, but yes, exactly. And that's   
1:24:12   
that's sort of where I am too about it in the sense of um   
1:24:18   
I I'm I'm curious like like in in the meeting uh and I think it was that   
1:24:24   
meeting there were so many this week that I'm they're all meshing in my mind right now when I try to talk about them.   
1:24:29   
There were some things at the end of the meeting about what's next for for for everyone. Um, and   
1:24:36   
at at there is a sense one one I'm very   
1:24:42   
interested in. It's so it's so interesting because I feel like I'm I'm kind of balancing the Josh Bondard uh   
1:24:49   
Michael Leaven thing from from earlier this week or from later this week, which   
1:24:54   
is like yesterday. Wow, it's yesterday. and this where Michael Leven's doing   
1:25:01   
he's really trying to do a specific kind of work bringing bringing   
1:25:07   
behavior machine versus non in a direction and a lovely throwback to the   
1:25:12   
behavior purpose teology paper as usual and it's this latest iteration of his work in that space then you have this   
1:25:19   
sort of hopes of like Elon and um will have this sort of hopes about LLM's   
1:25:27   
are identifying this key language.   
1:25:33   
Um, I was going to say to Bradley, it's it's almost like   
1:25:39   
it's almost like a like in our old school metabrain, we have the kind of the the   
1:25:46   
lower functioning relatively thing and then this metacognitive box on   
1:25:52   
top, right? It's almost like they see language as this other layer in the metabrain. Um that   
1:25:59   
that that the LMS have solved the the like the I don't want to say topology   
1:26:05   
space because I think it's a little bit more I that's more me than anything they're saying like they like they've solved some way of navigating what this   
1:26:12   
layer of contextualization is. um or re the re revealed a   
1:26:20   
the it's it's so tough and I do want I I do want to see more like stuff from them   
1:26:25   
like really really I want to see some some really juxtaposed clarifications because when I'm trying to do it here   
1:26:31   
live I I don't know if it's me inserting my stuff or not and that's and I don't   
1:26:36   
want to do it injustice because that is to totally steel man the effort I see it as okay do I I personally I'm My   
1:26:45   
personal bias, just to declare it, I don't see LMS as   
1:26:51   
being really smart. Um, I see LM as   
1:26:57   
being excellent at extracting statistical   
1:27:05   
coordination of things. My what what I actually wanted to as aside I I'm very   
1:27:11   
interested in basically writing something about my my phrase is teological coordination. That's that's   
1:27:17   
what I've developed from it. And there's the a lot of a few months ago a lot of the language and the echolopta stuff was   
1:27:23   
like language as coordination. And it's like okay yeah yeah like I'm in like coordination and it's like I'm kind of   
1:27:28   
in between like the Leaven's very very open to like uh   
1:27:35   
behavior purpose theology reference that kind of stuff and like yeah like what you're trying to do is coordinate at   
1:27:42   
this level and I don't know if the same level that Elon and company want to talk about what they're doing. So to step   
1:27:49   
back, I I I'm I'm let's say agnostic about what LM do and and I'm sympathetic   
1:27:56   
to I'll I'll even be say I'll take I'll put on the blacklisted um stance of I'm   
1:28:04   
sympathetic to some of what Gary Marcus says about   
1:28:09   
structures of things. And it's so interesting because there's m the disagreement. Dan Dan Vanzant uh who is   
1:28:16   
a do uh PhD student of Elon's um is a   
1:28:21   
little more like well maybe there should be some symbolic stuff here. Maybe maybe it's not just this thing. So   
1:28:28   
interesting. I'm I would love to have an extended discussion with like all of them in a in a in I don't really want to   
1:28:36   
do this but it would be fascinating to have basically me Bradley and Morgan you two and and Dan and and Elon as like   
1:28:45   
almost like a round table or and then someone else someone else like I don't   
1:28:51   
know who but someone to be like the other juxtaposed point of what that what   
1:28:58   
not debating about what LM do, but like what   
1:29:03   
what is what is the uh uh like ping like what's being pinged   
1:29:10   
around in terms of what's the inputs outputs of it like what what is happening and how does it relate to   
1:29:15   
everything else we want to be studying right that's all um oh I have to reply   
1:29:20   
to this person I just saw I just saw he to reply to right uh   
1:29:28   
That's so funny. I look the corner of my eye, I see somebody's face like, "Oh, I didn't reply to that person." Anyway, um   
1:29:36   
yeah, what what's happened there? So to to to condense um   
1:29:44   
I'm really I think there is an insight that Elon has that is useful and I I   
1:29:51   
like the framing of whose pro whose problem is the mind body problem it's language's problem like there's a fun   
1:29:58   
there's something fun there but uh and and and I want to wield something   
1:30:05   
like that to revolutionize cognitive science science, AI, like to do the bigger work at play. Is this thing going   
1:30:13   
to be it? I don't really know cuz I don't know what I don't know enough   
1:30:18   
about what the insight what what what is what is the like movement forward yet. I   
1:30:26   
don't know. I don't know enough detail yet. So, I think there's a little bit of like is it a space that everybody   
1:30:33   
everybody's interested in like talks MIT frontier? we got a lot of people interested in this kind of stuff, but   
1:30:38   
like what the there there's a sort of mountain like what is it going what is it functionally going to do and and and so   
1:30:46   
on. So that's what that's kind of that um and I'm trying to put find what I   
1:30:52   
what I wrote because I wrote a few different notes about these things as I as I usually try to do. Um   
1:31:01   
oh sorry here we go. Um, what do I have here? Also, I I did get   
1:31:08   
an email from Michael Garfield about stuff. Um, well, I've emailed him to confirm it and and you know, we can   
1:31:14   
follow with him about that stuff. Here, here's what I said here. Uh, be curious about I said, yeah, okay. In   
1:31:22   
in this lack I had, it'd be curious about y'all's take on this. And then   
1:31:27   
then I mentioned my Metagin comment. Um,   
1:31:33   
yeah. And you want to see more. And then Morgan said what he said earlier about computational examples and and and the   
1:31:40   
theory. Okay. Um, that's that's kind of all I had to say for that. I don't know if there's anything else you wanted to say about that event before I move on   
1:31:47   
things. Yeah. Yeah. So, so you know, there's still still a lot of ambiguity in the um   
1:31:57   
the conversation around these these topics that that   
1:32:05   
you know the the the others that are working in this field or in these you   
1:32:11   
know similar areas who are doing computational work like it's It's um a   
1:32:19   
lot of those ambiguities disappear when when you see an implementation   
1:32:24   
and and an implementation applied to some sort of of data or some sort of   
1:32:30   
process, you know. Um but but what I wanted to, you know, um just say a bit   
1:32:38   
more about and and also get some some feedback on was the um was the Josh   
1:32:45   
Bongard uh um Michael Lean meeting in terms of two things that um that he   
1:32:53   
mentioned. So one was was vibration   
1:32:59   
and polymputation. Um, so I I hadn't had a chance to go through   
1:33:06   
kind of like um events this week and and upcoming events, but events this week or   
1:33:15   
you know past week one was Earl Miller's presentation at   
1:33:21   
Louis Pesawa. Is that Pesa? Um, entangled   
1:33:28   
brain guy Bradley. I don't know if you know how to pronounce his name. Um, but   
1:33:35   
Earl Miller's got a presentation that I think is super relevant for this kind   
1:33:42   
of poly computation in terms of of   
1:33:47   
redefining or kind of like trying to use the   
1:33:53   
multiple frequencies and oscillations in um, whole brain electrophysiology   
1:33:59   
to come up with a kind analog computing model   
1:34:04   
that that I think is a lot of overlap with the kinds of things that again Josh   
1:34:11   
didn't give me enough detail uh but he gave me some paper suggestions in this   
1:34:16   
regard um to follow up in terms of poly computation and I think I think finding   
1:34:22   
those links between the um what what Earl Miller is talking about who is you   
1:34:29   
know very much in the brain with electrodes.   
1:34:34   
um would be interesting because they're both getting at um they're both getting   
1:34:43   
at alternative computational frameworks that that allow   
1:34:50   
for you know um an incredibly efficient   
1:34:56   
uh incredibly high throughput computational system   
1:35:01   
which does sound like a good description. of of the brain. Um,   
1:35:08   
and then the the other term that that he dropped was this meta robotics and I   
1:35:16   
don't think you know like like I I know you said something about um uh yeah did   
1:35:24   
you did you comment on meta robotics with regards to um meta   
1:35:31   
brains? Yeah. No, basically I maxed that out already.   
1:35:36   
I I Okay. I I I I was in a a very peculiar situation   
1:35:42   
during this meeting and I was really locked into like   
1:35:47   
probably 65% of it overall. And then I was there listening and I all the stuff   
1:35:53   
to do and I was I was in a cafe and all the stuff was going on. Like I really know I know I listened super intently to   
1:36:00   
like a good chunk of when Leven was there. Le For those who don't know, Le was there for basically like 30 minutes   
1:36:05   
or so and he had to dip. Yeah. Um and then the focus shifted slightly   
1:36:13   
um to like Josh's stuff. Um, and   
1:36:19   
I I don't I didn't give up enough of the the meta   
1:36:27   
stuff because it just sounded similar or is that not not similar but like it   
1:36:33   
sounded like okay like this kind of makes sense in in our existing context   
1:36:38   
for it. But I I like I'll defer to you if you have any like actual insights or   
1:36:43   
Well, I've I've you know, so this was where he was responding to I think   
1:36:51   
male's question um if I if I remember that name right,   
1:36:56   
but like like there was someone who was definitely a roboticist who was asking   
1:37:02   
questions and and   
1:37:08   
uh that that you know it seemed like Josh   
1:37:15   
understood the the kind of the greater context of   
1:37:21   
of where these questions were coming from and and this is where he was just   
1:37:27   
like yes this would be you know very meta robotics you know and and it was   
1:37:35   
one of the I think Maybe I was still thinking I was still u turnurning on the   
1:37:43   
connections in the poly computation. I I I think that's that's I think that's   
1:37:49   
actually also a fair way to say. I think I was trying to get myself an out with all this other stuff going on, but like there was just there were some really   
1:37:54   
deep nuggets and I I just hadn't expected to go to as you can see here on on pointing doesn't really matter where   
1:38:01   
I'm pointing as I I wasn't expecting   
1:38:07   
maybe it was foolish of me but I wasn't expecting to go into the living things aren't machines paper that we covered   
1:38:14   
here like we we I don't know if Morgan was around for now but like we went in   
1:38:19   
depth on that paper and thought it was really interesting and then also kind of   
1:38:25   
criticized like okay this is this is really new like this is not fleshed out and then he drops in the comments which   
1:38:30   
is on the screen right I I I'm very cheeky like oh so like new things are   
1:38:36   
machine and then everybody's like yeah that's cool and and lemon's like oh by the way I released an update a few   
1:38:42   
months ago about my thoughts on this and I'm thinking you know so that that's just like oh I was kind of thrown off by   
1:38:48   
all of this stuff and I didn't that happened like a couple times and I didn't like oh I my mind as   
1:38:54   
it goes there I was like I have to consider this now. Yeah. Sorry. I'm just seeing I'm just   
1:38:59   
seeing the the the the link title itself is living things are not machines. Also   
1:39:07   
they totally are. Yeah. Yeah. Also they totally are. And   
1:39:12   
that's like that's that's that's that's funny in a lot of different ways. Okay. That is okay. Okay. You know,   
1:39:19   
I I I when the when the chat came up, all I saw was the was his actual words,   
1:39:26   
right? Like I've now come to think that they're, you know, Yeah. Yeah. So, I I   
1:39:31   
hadn't seen the Yeah. Um Oh, interesting. Yeah. Yeah. But but this is this is   
1:39:39   
cool. Um uh uh so t Tuesday is the 20.   
1:39:45   
Yeah. So, Tuesday evening we're doing uh San Francisco Cognitive Science Reading   
1:39:51   
Group. Oh. And um which there's no virtual component to that, is there?   
1:39:56   
There is there is um uh it is late. I can share the I can   
1:40:04   
share the meetup link. Um uh I will need I I might need to um   
1:40:14   
the uh the guy who runs it.   
1:40:19   
He's a he's a deep mind guy, but I don't actually have his um   
1:40:26   
contact like like he definitely runs a   
1:40:31   
an online piece to this, but I've never actually   
1:40:37   
seen the link, so I don't know how to um anyway, I just dropped that in the um   
1:40:44   
in the chat or, you know, I'll put um let me put it in   
1:40:51   
the slack as well.   
1:40:56   
Octopus. Nice. All right. Um   
1:41:03   
anyway, the um yes, you you you you certainly can join. I mean, we we're   
1:41:12   
we're just covering one of the videos in this in this particular group. Uh um   
1:41:18   
although I'd like to dive into, you know, some some of some of   
1:41:25   
Leven's papers are are, you know, are good, you know, I don't want to say easy reads, but they're not they're not uh   
1:41:33   
they're not necessarily requiring a bunch of biology background or Yeah. like that, you know. And and I I I I can   
1:41:42   
I really I'm I'm hoping to be well   
1:41:48   
I don't know how to speak about this yet. I hope to actually finally get to sit down next to 11 and get a chance to   
1:41:54   
talk to him in October at at an event here in Boston. And   
1:41:59   
um I really like my my $1 million question or billion or   
1:42:06   
however you want to say it these days um is along the lines of that that you   
1:42:11   
probably seen it. I mentioned it many times the part of his research paper the part of his research lab website where the bottom he says like he I I want to   
1:42:19   
just ask him like what is it what is the motivation and psychology around like your advocacy efforts around um   
1:42:27   
getting people ready for the ethics behind what it means to fully understand   
1:42:33   
like the the mind diverse minds and bodies across things that are like we don't even have good frameworks for yet   
1:42:40   
and I feel like that's Like I I I know that's sort of my personal thing, but I   
1:42:46   
just also feel like I feel like   
1:42:51   
I if if if Levan didn't wasn't so ubiquitous and doing a bunch of stuff   
1:42:57   
and I I was a little more put together about some things, I'd be like, let's let's do something very specifically   
1:43:03   
about that because I feel like that that's always an undertone for a lot of things and it's it's very well done because I actually I don't at the same I   
1:43:10   
don't want to rock book because I think the way that he talks about it is there's a very particular like strategic I don't want to say massaging because   
1:43:16   
that sounds a little bit more nefarious than I mean but there's a very particular positioning of some things   
1:43:22   
and I'm like this is great and so I don't want to interrupt what he's doing because I think I think it's done in a   
1:43:28   
way where he has enough clout and respect for certain things that will just bring people to look at stuff in in   
1:43:34   
the ways that it needs to be looked about in some ways but I'm very curious how that goes and to go back to go back   
1:43:39   
to your point like like some of it is very even the things that he's like his blog which I haven't followed everything   
1:43:45   
on but like he's he's he's doing a particular   
1:43:54   
he's he's trying to go to a particular direction for things and I I respect the effort that's kind of separate from just   
1:44:01   
the scholarly work but also like very like I haven't seen anything where he   
1:44:07   
just comments on this you know what I mean like that's like I Like like and this is just where my mind   
1:44:13   
goes about a lot of things like strategically like what are you trying to like and you can't you probably won't say this like on the record but like   
1:44:19   
strategically what are you what are you what are you aiming for and how are you trying to make your how are you trying   
1:44:26   
to advocate or enable certain things that you want to see happen. So yeah. Um and yeah, you just posted in chat the   
1:44:32   
platonic space and I I actually mentioned um I mentioned this to Addie. I don't know if you're in the other   
1:44:37   
Discord. I mentioned this to Addy after you shared it because I was like, "Hey Addy, like yeah, you know, they're trying to do stuff   
1:44:42   
with the computational philosophy club is this new thing that they're working on." Yeah. And it's like, "Hey, like check this   
1:44:49   
out." Like like we can pull stuff from there to get speakers and ideas from. There's a lot there.   
1:44:55   
Yeah. Yeah. I I I you know he he asked me about it and and I said you know I I   
1:45:01   
I loved you know I think I loved it even more to be for Frontier Tower to be   
1:45:08   
hosting the computational philosophy than necessarily Echolto um just because that's just so well   
1:45:14   
aligned with with my own background. Um so uh yeah I thought I thought this   
1:45:22   
was interesting. I I was trying to remember um I don't know if Bradley's still here, but um the   
1:45:30   
there was a meeting like um a couple years ago. It was based at   
1:45:38   
UCLA. Um Michael Lean was one of like 25   
1:45:43   
speakers, but it had this like incredibly eclectic mix of speakers.   
1:45:50   
um this this uh and it had a a very it was   
1:45:57   
a very unique meeting. Um uh   
1:46:05   
I I I I did not know the the organizer well, you know, but after this meeting,   
1:46:13   
you know, I I should have memorized their name because it was like such a great collection of people like like a   
1:46:22   
lot of, you know, an animal um   
1:46:28   
animal behavior people, a lot of um unconventional computing people,   
1:46:36   
a lot of um anyway, sorry, I'll   
1:46:42   
um I'm not putting my finger on it right now, but I'm I'll I'll do a dived. But   
1:46:50   
yeah, anyway, there was there was a lot in this this meeting that would be good to   
1:46:55   
follow up on. Um, and uh, and I I really   
1:47:00   
do, you know, like if they're really interested in in, you know, getting more   
1:47:07   
uh, empirical and getting more um, uh, comput, you know, like like   
1:47:13   
implementations of computational uh, you know, would love to to really   
1:47:20   
help support that and try and try and make that happen because again, like he's a he's a great meeting organizer,   
1:47:28   
you know, um they've got a really interesting network, really uh eclectic   
1:47:34   
network of of people already. And the the AUG Lab people have moved to San   
1:47:41   
Francisco, too. So, um I'm working with the same guy, Pedro, the same guy who   
1:47:47   
helped organize the human augmentation summit. like, you know, I I would love   
1:47:53   
to have similar people, the kinds of, you know, BCI work that they were doing, the kinds of, you know, projects they   
1:48:00   
were doing. Um, I've I've already had a visit from one of the new PhD students   
1:48:06   
at the cyborg um cybernetic psychology lab at at the MIT Media Lab.   
1:48:13   
Yeah. Pat Pat's group. Yeah. Yeah. So, um I think it was Claudia   
1:48:19   
Alrech Okay. Anyway, I'll check, but I don't want to.   
1:48:26   
Um, Bradley, you've got some papers, too, to cover, right?   
1:48:33   
Um, well, I mean, we don't have to do that. We could I mean, I can present one paper if you'd like, but   
1:48:41   
always like paper. Well, yeah. Yeah. Uh to to that end I'll say yeah   
1:48:49   
I'm really interested in that also like I may be helping out um local labs all   
1:48:55   
lab stuff for next year here um because yeah a lot of the people just   
1:49:00   
jumped coast but there are some folks trying to do stuff next year and all con   
1:49:05   
stands constands all   
1:49:11   
um yeah okay um Yeah. And I like I know it's kind of   
1:49:17   
the top of the hour, Bradley. Um I might just do like a just a verbal brief update on the front   
1:49:23   
the future center and then we can talk to the papers. Okay, that's good. Um   
1:49:30   
really briefly, uh we made progress on the future center. I'm I'm establishing sort of this futures center of sorts at   
1:49:37   
JoeRo and I'm I'm doing a lot of work on the foundational sort of materials and context and framing and the theory of   
1:49:44   
change and what we want to do and had very nice conversation with Bradley recently about like mission what you   
1:49:50   
want to do and then also like mission creep what you don't want to do and making it um coherent um and aiming to   
1:49:57   
be rigorous in this and and and so on and so that work has been happening. I   
1:50:02   
basically have a I have I have a very simple website landing page up for it. Um I have a   
1:50:09   
um a a a pretty structured set of things I want to do both like administratively   
1:50:15   
I'm kind of there sort of I'm breaking it down into kind of thirds right now as sort of   
1:50:21   
what are my goals like the founding founding person of this particular center is like one third is sort of   
1:50:26   
administrative one third is sort of actually um   
1:50:31   
you could say scholastic or or doing some of of of the uh   
1:50:38   
I don't know about research but but the academic framing of what we're trying to   
1:50:44   
do and then another third sort of um   
1:50:50   
I don't know logistics and and and and and the kind of boring   
1:50:58   
stuff uh and dealing with dealing with other people and trying to get get make it make it happen and people that are   
1:51:04   
interested in helping out in is formed which is nice but it's really much keeping it keeping it going forward and   
1:51:09   
beyond beyond that work um in in the in essence of of staying brief   
1:51:17   
um I had a number of conversations this week with people it's been very interesting sort of the sort of   
1:51:22   
intellectual scholarly talk that that Morgan's been a part of these other two meetings and now here in orthogonal and   
1:51:28   
there's this other subthe that's that's been significantly um   
1:51:36   
on the nose of of really looking at   
1:51:45   
I think I I believe some I believe this week or the week before in this lab I we   
1:51:51   
talked about the uh I think it was like an Atlantic or a Time article written by a high schooler   
1:51:57   
saying um the the discipline the the advent LM has sapped the   
1:52:04   
discipline of doing things in a set time because you can just wait until the very end and throw it at the machine and something comes out. Did we talk about   
1:52:10   
that barely? I don't remember. Um, but I I won't I won't go into it again either way. And suffice suffice suffice it to   
1:52:18   
be it's led to a number of interesting conversations with some of the interns that I have doing work on AI education   
1:52:24   
and equality. um which kind of goes back to the LM conversation earlier today, but also um   
1:52:32   
the the essence of discipline itself and how do we do that? I think we talked about that. I'm remembering a little bit   
1:52:38   
more. I think we talked about that some like like can you do it in terms of aspirational building way. So, a lot of   
1:52:44   
the conversations that I've had this week with with people in different fields, one of them is is someone who's   
1:52:50   
um yes, social workers and things like that, but also um people doing uh   
1:52:57   
academic research, people looking at system behavior change and systemic change and people trying to like even   
1:53:03   
some folks from like the plot twist community who are trying invested in building, you know, tools of various kinds that   
1:53:11   
facilitate this sense of um we could say agency around one's narrative and that   
1:53:17   
will be my that'll be my slight dovetail back into Leaven. One of the things that I don't know how to capture and and   
1:53:23   
desperately desperately desperately want the video from the foresight institute this week is the way Lean spoke about   
1:53:30   
narrative felt so broadly applicable to like plot   
1:53:35   
twisters and other things that that I'm in the space of. And I feel like   
1:53:42   
both controlling like his his take on narrative was sort of cybernetically like control sort of almost like macro   
1:53:49   
like you can see you can see the the chart with all the parentheses and like negative feedback goal directed behavior   
1:53:55   
prediction like like like you like narrative like across that is sort of I   
1:54:01   
I know that's sort of what he's kind of getting at but plasters is narrativity is much more you know uh almost um   
1:54:09   
autoeththnographic phenomenological internal narrative um which is not really what they're   
1:54:16   
focusing on but like those are the arenas and so I feel like there's   
1:54:22   
something between the narrative between the internally external and the sort of   
1:54:29   
identifying problem spaces like the discipline space in terms of how do you build and do things in that space and   
1:54:34   
its relation to how do you how do you have aspir operations that require   
1:54:40   
uh skills like discipline but also um   
1:54:46   
related to the narrativity of it all. I'll put it that way. So that um that's super brief and super like teasy. Um but   
1:54:54   
but there's been a tremendous amount of like really nice um   
1:55:00   
there's a lot of there's a lot there's a lot that's cooking right now and and I I feel like my goal is just to stay the   
1:55:07   
course and materialize it. Um, we have this on on the screen that I'm still   
1:55:14   
sharing you like there's this this this blog post was really supposed this post was just originally like a capturing of   
1:55:21   
things and then I like when you look more at at some of the quotes from Lebanon about um   
1:55:28   
like he he really like what's so what's so cool about this paper he really juxaposes himself to Francisco and   
1:55:35   
Hberto Materana like um and and and   
1:55:40   
getting at this stuff about, you know, he he brings up this again and and just   
1:55:46   
where's he going with this? Also, Thomas Fuches's mention was really cool. I mentioned Thomas Fuches and Josh Bongard. I'm just seeing this now.   
1:55:52   
Bongard was like, "Oh, yeah." Like he he reacted to it or something. Actually, I think I mentioned it and he was he was   
1:55:57   
like he like liked it and was probably engaging or writing something and someone else like physically asked him   
1:56:04   
directly a question verbally and he was distracted because he was replying to this. I thought it was a cool moment.   
1:56:09   
Not not because I, you know, cool for me, but like I would love to have sit down and talk with Josh Bungard more   
1:56:15   
about like futes and organization level stuff, you know, f is kind of like doing the whole like well it's at the level of   
1:56:21   
the organism, you know, and and and how does that fit with what they're doing and maybe bringing rigger where where   
1:56:27   
fuse is kind of trying to kind of outline where to go, but but maybe   
1:56:32   
didn't didn't do too much about that. Um, also this this book, the old book,   
1:56:37   
just because I'm here, uh, this is a book he he was asked sort of how do you, you know, what what does someone get in   
1:56:44   
this field look at? And he's like, well, I wrote a book a long time ago that's kind of outdated in some ways, but some of the core still there. So, his how the   
1:56:50   
body shapes the way we think with him and his former advisor Ralph Feifer. Um,   
1:56:57   
and then also mentioning little bots again. And that's actually um more about that later. But yeah, that   
1:57:04   
that's fine. I don't want to ramble too much more. So um thank you for uh brief updates and more I'll I'll   
1:57:11   
publish this and I'll publish um I have more things to publish and share about uh the future center um at the start of   
1:57:18   
next week. I'll I'll throw the mic back and run   
1:57:23   
away after that. All right, that sounds great. Thank you,   
1:57:30   
Jesse. I think it was a good conversation uh about this stuff. Um yeah, being uh   
1:57:37   
definitely submit that post to the um medium and we'll put that up and I look   
1:57:43   
forward to reading the final version and you know we can uh go from there. you know, we can look at like what   
1:57:51   
what the final version has, what what kinds of threads it pulls on and so forth.   
1:57:58   
Yeah, I I kind of didn't expect to be thrust back into Eleven's 2025 take on his   
1:58:06   
conclusion, which was in the chat. I don't know if you got to read it. Like he his his conclusion was like he he   
1:58:12   
wrote in chat and it kind of confused me at first and I I don't know if this is what was was Morgan's reaction. It was confusing because all all you saw when   
1:58:20   
even when I read it after after prompting it by mentioning the original the 2021 paper Lean said I now think   
1:58:27   
that almost nothing is a machine even machines. I'm like what? And so he kind   
1:58:34   
of elaborates that in in the post which I'm still processing. So maybe listening to to I would love to maybe prepare   
1:58:41   
something for that and talk about it more next time and sort of this cognition futures uh revisiting of it.   
1:58:48   
Um but but yeah, there's a lot of like um things to pull out there and maybe   
1:58:55   
you know I don't I don't know if this is really V's um alignment or not but like   
1:59:00   
there's there's a definite dovetail of like things happening in that direction or for other folks who want to do   
1:59:05   
something maybe watching the video and joining live too. Yeah. Yeah. So the takeaway is that it's   
1:59:12   
machines all the way down but nothing is machines not even machines. That's the   
1:59:17   
Well, there was this Yeah. And there was this wonderful comment and I I took partial notes of it. Maybe Morgan can remember it, but it was this really nice   
1:59:23   
and I don't know if it was Lean or Bard trying to explain something because it was explained. It was a very interesting   
1:59:29   
comment and it was like when you're taking apart like a physical being   
1:59:37   
there's more it sells. It sells all the way this recursive not   
1:59:43   
there. It's kind of the same thing even if it's differentiated out like like the   
1:59:48   
stem cells coming up through a cell cell. So, but when you're taking apart like a car like it's not smaller cars,   
1:59:55   
it's it's not it's it's these components of you have a an objective in a thing,   
2:00:02   
but like it's not like there's protoc the the thing.   
2:00:08   
I mean, yeah, please say it better because I can't I couldn't He he he was this was   
2:00:14   
kind of his you know it's machines all the way down but but a machine if you   
2:00:21   
zoom in you eventually get to like a tire and it's just rubber you know and   
2:00:28   
or you know like like the parts are inert and   
2:00:33   
that's that that's you know I mean he went for this kind of like it's   
2:00:39   
machines all the way down. I I'd always liked the agential matter, you know,   
2:00:45   
where it's just like it's, you know, like that that says it all, right? Like   
2:00:52   
Yeah. Is that falling out of vogue now? Because I haven't heard that as much recently, but like I don't I don't you know, like like um   
2:00:59   
Yeah, the these certainly Michael Lean seems like someone who's awfully online.   
2:01:06   
Yeah. And I and I wonder what that does to his thinking and   
2:01:12   
speaking um you know. Yeah.   
2:01:17   
All right. Well, why don't we move on? Um so, as requested, we'll do a paper. So, let's do this paper. This is an   
2:01:23   
interesting paper because it's uh it's actually from 2020,   
2:01:29   
but it is from uh a Chinese group and they're doing this work with Braenberg   
2:01:34   
vehicles. And the interesting thing about this is that they're basing a Bradenberg vehicle on memoristic   
2:01:41   
neuromorphic circuits. So, you know, we think about the brainberg vehicle as a toy model and how it's a very simple   
2:01:50   
sort of connection between the sensor and a factor or the maybe the light   
2:01:55   
sensors or something like that in a wheel. So if we have like two light   
2:02:01   
sensors on the front of a vehicle and two wheels on the back, there's a mapping between that sensor and a   
2:02:07   
factor. It could be like a cross connection. It could be a ipssolateral connection. It could be um you know   
2:02:14   
something more complex. And so that's the way we think about we almost think about it as a connect very simple   
2:02:20   
conneto. And so but in this paper what they're doing is they are trying to use a simple   
2:02:27   
memoristic neuromorphic circuit because they want to apply uh this to   
2:02:33   
engineering applications. So um again you know we went back to Brightenberg's   
2:02:41   
work on neuroanatomy. This was this last summer. There were there's several uh   
2:02:46   
features that I did on this where we went through his thinking from like being a neuroanatomist in insect   
2:02:54   
physiology to thinking about how you would simulate a nervous system. And so   
2:02:59   
it was like a progression from his work in the 50s and 60s to this um you know   
2:03:05   
this this artificial sort of biocybernetic approach that he took   
2:03:10   
leading up to his 1984 book and beyond. So this is kind of u you know where he   
2:03:18   
was coming from. In this case, what they're trying to do is they're trying to develop this memor that can um do   
2:03:25   
basically the same thing that is respond to stimuli adaptively generate behaviors   
2:03:32   
and provide this mapping from sensor toector. So let's start with the abstract. Um the brainberg vehicle is a   
2:03:39   
simple conceptual model to characterize the response behaviors of animals or insects under a stimulus is widely used   
2:03:47   
to develop autonomous vehicles able to adapt to the varying environments   
2:03:53   
that you see in maybe the world. I mean, you know, in brainberg vehicles is a very um uh stereotype sorts of stimula,   
2:04:02   
but you can have all sorts of complex stimuli and that, you know, of course would result in even more complex   
2:04:09   
behaviors than we see in Brainberg's vehicles as demonstrated in the book.   
2:04:15   
Considerable effort has been devoted to building the neuromorphic processors with the software in the vehicles.   
2:04:21   
However, there has been no demonstration of brainberg vehicles with neuromorphic hardware so far. So, people have   
2:04:28   
actually tried to use or to build neuromorphic processors with software,   
2:04:34   
but they haven't demonstrated it with hardware. So, here in a Braenberg vehicle with simple memoristic   
2:04:40   
memoristic neuromorphic circuits is built for the first time. This vehicle   
2:04:45   
exhibits adaptive behaviors in the supervised learning process and is eventually trained to conduct the task   
2:04:52   
of tracking paths. So basically it's trying to train the vehic they're trying to train the vehicles to follow or do   
2:04:59   
path following basically following a stimulus following that gradient outward   
2:05:05   
and u you know building a path. Uh moreover the memoristic circuit in the   
2:05:11   
vehicle demonstrates a very short response latency and they estimate that   
2:05:16   
at about 56 nanose to input sensory information.   
2:05:21   
Herein an alternative promising solution is to build self- adaptive robots and   
2:05:26   
pave the way for realization of autonomous robots based on memoristic neuromorphic search. Uh the introduction   
2:05:33   
is that you know they kind of go over these self they review self- adaptive behaviors which are of crucial   
2:05:40   
importance in you know varying environments and it helps animals or insects avoid   
2:05:46   
obstacles. And so you know they talk about the Bradenberg vehicle being this thought   
2:05:52   
experiment and this toy model and then they kind of describe that   
2:05:58   
in spite of much success in achieving autonomous robots based on this vehicle model the processors of the smart robots   
2:06:05   
are still based on vonoyman architectures. What they mean I guess is when people   
2:06:10   
implement brainberg vehicles as robots they generally use a vonoyman architecture to do so. So usually if you   
2:06:17   
have a Bradenberg uh a robot that's a Bradenberg vehicle instead of a computer simulation   
2:06:24   
u you're using a uh bonan architecture to simulate this sensor factor mapping.   
2:06:30   
So this is limiting of course in the sense that it's you know maybe not biologically inspired and it just   
2:06:37   
behaves maybe like any other robot that's come up. So what you know what's the point of using the brain vehicle? Uh   
2:06:45   
so far the well-known Brightenberg vehicle model has never been implemented on neuromorphic hardware and so   
2:06:51   
neuromorphic architectures allow for the implementation of dynamic neural control   
2:06:57   
through physical computation. On this architecture information is transmitted and processed in the analog   
2:07:04   
domain enabling low power consumption and low latency. Previously works have   
2:07:10   
shown that various neural networks can be mapped on the memoristic crossbar arrays for self- adaptive learning   
2:07:17   
for the memoristic architecture the nonvolatile property and processing   
2:07:22   
in memory improve the energy efficiency which arises from the ions migration the   
2:07:30   
advantage of meristive architectures is not limited to energy efficiency avoiding the conversion between analog   
2:07:36   
and digital consider considerably reduces time delay in information transmission and processing. So there's   
2:07:42   
this analog aspect of the stimulus and it has to convert in the monolamin architecture. It has to convert it to a   
2:07:49   
digital signal and then convert it back out to an analog behavior. In the   
2:07:54   
meristive uh case you don't have that conversion. So it reduces the time   
2:08:00   
delay. This is why they uh they cited the very short response latency in the   
2:08:05   
abstract because it's basically not doing that step of converting the signal. Considering the affformentioned   
2:08:12   
advantages, it is interesting to build the brainberg vehicle with memoristic neuromorphic circuits.   
2:08:19   
And so here for the first time they build a brainberg vehicle based on a very simple memoristic neuromorphic   
2:08:26   
circuit which is two grayscale sensors, a memoristic neuromor neuromorphic   
2:08:32   
circuit in the middle and then motors which drive the wheels. With a   
2:08:37   
supervised learning rule, vehicle can be trained to track a path. Furthermore, a   
2:08:42   
very short response latency is achievable for the memoristic circuit of the vehicle. And so this is where   
2:08:50   
they're kind of very into the technical aspects of a memoristive circuit.   
2:08:56   
But this of course are their we'll go through their figures and that gives a little bit more context here. So   
2:09:04   
this is an example of course of an insect nervous system where you have the uh compound eyes, you have the brain,   
2:09:12   
you have the locomotive system and there's a you know basically things are coming into the eyes being processed by   
2:09:19   
the nervous system and then being mapped out as movements in the limbs. So you   
2:09:24   
can see that here. And so they're behaving and that was of course the inspiration for bring vehicles uh which   
2:09:30   
you see an example of here. And so here they have uh so an A they have of course   
2:09:36   
the ant uh and do engaging in obstacle avoidance. So this ant is moving around   
2:09:43   
the stock here and it's doing so through this system that I just described. So   
2:09:49   
it's doing this path following. it's able to develop an adaptive path through   
2:09:55   
an cluttered environment. Uh image B is um an electron microscopy   
2:10:02   
image of a 1x6 memory or crossbar array. So that's here. So this is the hardware   
2:10:07   
that they're using. C is continu uh continuous conductance   
2:10:12   
tuning performance on these memory under the stimulus of electric pulse. And this   
2:10:18   
is the chemistry here TA TA 205. So this is the the sort of the   
2:10:25   
deposition of the layers the metal layer 80 nanometers of TA TA 205 which is 10   
2:10:32   
nanometers another metal layer and then the substrate and then we have in D continuous oh   
2:10:39   
that's the D um actually the schematic array was here and then this is the   
2:10:44   
performance in terms of conductance in D. So they're you know given the pulse   
2:10:49   
number what is the conductance um and then E is model a braenberg   
2:10:56   
vehicle including grayscale sensors memorist of neural processors and steering control systems. So this is the   
2:11:03   
setup here is diagram. So the grayscale sensors are here at the bottom you have   
2:11:09   
the steering control. You have the bio inpired processor and it's going forward   
2:11:15   
in this direction. rail scale sensors are kind of back here and it's picking up the information and it's moving and   
2:11:21   
following the path. Um F is the top view of this assembled   
2:11:27   
greatenberg vehicle. So there here's the vehicle here. The sensors are down here. The wheels are here. This is the steer   
2:11:34   
or this is the uh processor. The steering control is down here. This is a   
2:11:39   
top view. And then G, demonstration of obstacle avoidance behavior that the   
2:11:45   
vehicle exhibits. So if you can see here and compare with what we saw with the ants, we have this uh you know cluttered   
2:11:54   
environment where you have obstacles and the vehicle is able to get around those obstacles much like we see with this ant   
2:12:02   
avoiding this star. Okay. So they go through uh the training of the brainberg   
2:12:07   
vehicle for path tracking. Um they say that the locomotion mechanism of the   
2:12:12   
brainberg vehicle is determined by neuron interconnections by changing the   
2:12:18   
connections. The brainberg vehicle exhibits different and complex behaviors under the same stimulus.   
2:12:24   
Therefore the capability of learning and adapting to the varying environment is crucial for the practical application of   
2:12:31   
this. So in figure two they show a flowchart to illustrate how a supervised learning process   
2:12:37   
um is performed in the memory of neuromor neuromorphic circuits.   
2:12:42   
Um the weight in the artificial neural network would be updated according to the punishment or reward feedback   
2:12:50   
instructed by the supervisor which is based on different response behaviors of the vehicle to input signals.   
2:12:57   
After a few iterations of the feedback loop, a new mapping relationship between the input signals and the output signals   
2:13:03   
will be established which indicates that the vehicle acquires a new skill. So they have this whole training regimen   
2:13:10   
where there's this supervise or the supervisor and it's giving the sort of   
2:13:15   
reinforcement learning approach to um stimuli and to you know encountering   
2:13:21   
stimula. So when you encounter a stimula, the supervisor looks at the weights. It gives feedback. The feedback   
2:13:28   
is either positive or negative. The negative is punishment. The positive is reward. And then this allows us to have   
2:13:36   
this map these different mapping relationships over time that change the behavior. So it can follow this path.   
2:13:45   
Traditionally weight update process of the memory or neuro neural network is controlled by the software in a digital   
2:13:52   
controller such as a personal computer or microcontroller. So we have this um you know we have this   
2:13:59   
weight update process that's it's going on um kind of separately from the   
2:14:05   
navigation and it's just kind of giving feedback. uh note that we have implemented   
2:14:10   
neuromorphic neural networks in the vehicles uh using memory of crossbar arrays. On this neuromorphic hardware,   
2:14:16   
we update the weights in the artificial neural network through a simplified method without using the traditional   
2:14:22   
digital controller. So they describe this process in a vonoyman architecture   
2:14:27   
but then they describe it in the neuromorphic architecture. So they go through the weights here and   
2:14:34   
and kind of how this is done all the methods here. So this is uh figure two.   
2:14:39   
Uh so A is a flowchart of this process. We go from the environment. Information   
2:14:45   
from the environment is captured by the sensors. The sensors then pass this to the   
2:14:50   
bioinspired processor where you have this simplified neural network where you have apherent neurons.   
2:14:57   
This memoristic array for synapses which just map the apherent neurons to epherent neurons. The apherent neurons   
2:15:04   
take in information from the sensors. The effort neurons are the output layer that map that to the motor control of   
2:15:12   
the vehicle. And so the uh the WIJ matrix is just the mapping between   
2:15:17   
those. And those weights then of those connections are um uh sort of given   
2:15:23   
feedback by the supervisor. When the weights are positive, they give you know uh positive feedback. When they're   
2:15:30   
negative, they give negative feedback. Negative means basically you're headed towards an obstacle. positive means   
2:15:36   
you're on a path that avoids an obstacle and so then that leads to motor control.   
2:15:42   
Uh now B is figure 2B is the detailed circuit diagram of the brainwork vehicle. So this just describes this as   
2:15:49   
a circuit. So we have grayscale sensors, two grayscale sensors. We have the   
2:15:54   
battery, a driving engine and the pulse generator. The grayscale sensor is mapped to this   
2:16:00   
internal supervisor. So this is where you have this sort of um much more   
2:16:06   
coarse grain map that we can follow that basically gives the feedback signal. So   
2:16:11   
it's either positive or negative. That's why we use this brace this uh two big grayscale sensor. Um and then we have   
2:16:19   
the pulse generator which generates information from the environment. This   
2:16:25   
goes into this network. the supervisor uh evaluates the network and provides   
2:16:31   
feedback. We have the reward feedback and the punishment feedback. So we have   
2:16:37   
uh you know that's a binary value that goes into this network. The device selector is learning mode one and   
2:16:44   
working mode zero. So it's either going without learning or it's actively   
2:16:49   
learning and you can switch between the two. And then there's the steering engine and a differential amplifier. So   
2:16:56   
once this network is supervised and given the proper feedback then it goes through this differential amplifier.   
2:17:03   
This oscillator is added to the generator and then this is giving the steering engine which gives you the   
2:17:08   
motor output. So that's basically how that's structured.   
2:17:14   
Um this is figure three. This is a demonstration of learning process. Again, uh this is where this graph in a   
2:17:21   
is where we go over time and we have the normalized weights of each connection.   
2:17:27   
Uh one positive, one negative, two positive, two negative. And this just shows the normalized weight of that. And   
2:17:36   
this is I guess normalized by uh I don't know from   
2:17:43   
one to zero I guess or zero to one. Um and then so our iterations here we see   
2:17:50   
that over time we get these uh weighted or these normalized weights. So the   
2:17:55   
positive is positive feedback, the negative is negative feedback. And so we have these these uh these graphs here   
2:18:03   
which show over time that it's learning from the environment and then we see the behavior of the   
2:18:10   
vehicle. So in iteration zero, the vehicle travels in a straight line. Even though it's supposed to make this curve,   
2:18:17   
it doesn't make the curve successfully. In iteration 24, it's learning how to make a curve, but it doesn't make a   
2:18:23   
curve successfully or at least two curves successfully. It kind of makes a curve and then goes off on a tangent.   
2:18:30   
And then finally by iteration 37 is able to learn in this course where it actually needs to make um   
2:18:38   
five or six curves I think uh to make it all the way around the circuit. So to   
2:18:43   
recap iteration zero it learns nothing. It's just operating on input output. In   
2:18:49   
iteration 24 it's learn partially learned how to make curves. How to make turns but it only knows how to make the   
2:18:55   
one or actually two turns. It only knows how to make that curve. And that's it.   
2:19:00   
And then by the iteration 37, which isn't that much time from iteration 24,   
2:19:06   
it manages to leverage that knowledge of curves or that ability to curve into making multiple curves to follow the   
2:19:13   
path. And so then this is just the gray value at the left sensor, gray value at the   
2:19:19   
right sensor. So the differential learning between left and right. And you see that there's this difference over   
2:19:26   
time where you get this iteration zero, it's basically random. Iteration 24,   
2:19:32   
it's kind of figuring out a gradient. And then in iteration 37, there's this   
2:19:39   
sharper gradient which allows it to do this sort of behavior.   
2:19:45   
And so then yeah they kind of give this overview of the memoristive circuit and   
2:19:50   
the different inputs and out or the different input values and and that sort of thing. Remember this is a an analog   
2:19:58   
system not a digital system. Uh and then of course they show the difference   
2:20:03   
between the memorative neuromorphic circuit and a digital vonoyman circuit.   
2:20:08   
The analog domain is where the environment is. And when you use a vonoman circuit, you need to do some   
2:20:15   
sort of analog to digital conversion and then process things and then go digital   
2:20:21   
to analog for the response behavior. But in a neuromorphic circuit, you'd use   
2:20:26   
parallel processing, not serial processing, and you keep things in the analog domain. So there are two benefits   
2:20:32   
to that. Okay, so that's all there is for that paper. I thought that was an interesting paper in terms of like the   
2:20:38   
technical aspects but also sort of the larger aspects of when we were talking   
2:20:43   
about uh analog sort of simulations of the nervous system and that's kind of   
2:20:50   
one example of how you might do that. Yeah. Actually   
2:20:56   
trying to add neurons. Yeah. Yeah. Yeah.   
2:21:03   
All right. Thank you. Uh that's that's a great paper. Um all right. So uh I think   
2:21:09   
we can end for today. Um thanks for the conversations and let's follow up and   
2:21:16   
see you next week. Let's follow up on Slack. All right. Thank you. Bye. Take care.   
2:21:21   
Take care.
