## Meeting Recording

[YouTube link](https://youtu.be/NJZDKj4H44g)

## Mastodon thread

[link](https://neuromatch.social/@OREL/115679636216170643)

## Feature Videos

[Best Paper and Sejnowski-Hinton Award at NeurIPS 2025](https://youtu.be/NnYKaD1q2TI)

[Feedback Alignment in Neural Networks](https://youtu.be/OivOjpivr-4)

[JoPro Organizational Update](https://youtu.be/FODqsLfipZQ)

## NOTES
Hive Mind — Santa Fe Institute —> different data sources of each model. Is this Simon DeDeo’s work?

everyone uses the same benchmarks.

Foundation Models in Brain and Behavior (EEG, EPhys).


Morgan: looked at EES —> proximate, ultimate causation.

 “What is Intelligence” book, popgen view of ALife.

development —> proximate, evolution —> ultimate.

evo-devo—> proximate/ultimate causation.


Variational —> different paths between genotype and phenotype.

simulated basis for discussion — don’t think about the diversity of genomes enough.

genomic version of Streidter book, Paul Cisek reading group.

Cognitive Virology.


G-P map (GECCO and Gunter Wagner) and Intelligence. 

where does symbiosis come in? Computational Symbiogenesis.

what would an ekkolapto, Frontier Tower, OREL collaboration look like?

get a better sense of Barinholtz’s work.

LLM-Language. Variational nature of a mutational map. Multiple paths to a phenotype, multiple paths from a genotype.


Update from Jesse: DigiNest (Digital Narratives and Emerging Story technology).

momentum, progress, merge with things in OREL —> Plot Twisters.

Avery —> Sociocultural and Technology; Jen Jiang —> Social Work spotlight.

calculating empires (.net) —> nice Frontier Map —> style visualization.

what would we like to center in next year?


Investigate PM digital work. XR, VR, AR —> demo style.

experiments —> Bayesian (slow), Fitness (slow), Backdrop (not slow), Feedback as error correction.

move the problem space in a certain direction.

Nicole Rust “Elusive Cures”, Tom Insel @ Google —> can we tech our way out of this? 


## TRANSCRIPT
0:01   
Hello. How are you? Not bad. Not bad. Just just getting   
0:08   
getting together here. Oh, yeah. All right.   
0:14   
So, yeah. Great. Um, so welcome to the meeting. Um this week, uh we had another   
0:22   
evilware meeting and um   
0:29   
so that was a pretty good meeting. Um   
0:35   
we actually covered a paper on there's a new paper on sea elegance. It was on the   
0:42   
Nobel prizes that were awarded the sea elegance over the years. So actually segans has been focus of four Nobel   
0:49   
prizes um over the years ranging from discovery of GFP   
0:56   
to uh you know things like microRNAs   
1:01   
and other types of scientific discoveries. So both tools and scientific discoveries and then the   
1:08   
paper also talked about some of the uh databases that the community runs. So   
1:15   
the community runs databases um such as Wormbbase and Worm Atlas and some other tools that   
1:23   
are indispensable really to doing C elegance experimental research. So that   
1:29   
was a good paper. We went over that   
1:35   
and that was our divor. Um, I'm about to publish the uh, Evoorm   
1:42   
Group summary for the year. I have to give a report every year to open one and   
1:48   
so I'm about to post that annual update and I just cover some of the things we've talked about this year. So, um, be   
1:57   
on the lookout for that on the Evilm YouTube channel.   
2:03   
Okay. Um the other thing happening of course this week was Nurips and I did not attend that but I saw that there was   
2:09   
a lot of interesting stuff going on there. Um last week I gave an overview   
2:16   
of the Nurups conference went through the um   
2:23   
went through the uh   
2:28   
the schedule and everything and you know didn't get to go, but it looked like it   
2:34   
was very interesting. And so this week, I want to follow up with some things from their blog about their uh best   
2:42   
papers of the conference and things like that. Hello V, how are you?   
2:49   
Hi, how are you? I'm good. I'm good, too. Yeah, it's nice.   
2:56   
How was last week apart from all this? Oh, pretty good. Yeah. Yeah, that's   
3:03   
Did you have any updates for us or um No, not updates actually. I've just   
3:10   
been caught up with exams and they'll be going on for like 10 more days. Yeah.   
3:17   
I thought I could present something this week, but then I've just been so caught up with exams that I couldn't prepare   
3:23   
anything. So, probably later on. Okay. Well, that's all right. Yeah.   
3:30   
Yeah. All right. Thank you.   
3:35   
Now, this is a blog post from uh from Nurips and this is announcing the   
3:42   
Nurips's 2025 best paper awards. So, this is again um kind of an overview of   
3:50   
u some of these things that I just mentioned. So, um   
3:58   
let's let's read this article. The best paper award committee members were nominated by the program chairs and the   
4:04   
database and benchmark track chairs who selected leading researchers across machine learning topics. These   
4:11   
nominations were approved by the general chairs and next generation accessibility chairs. The best paper award committees   
4:18   
were tasked with selecting a handful of highly impactful papers from the main track and the data sets and benchmark   
4:25   
track of the conference. With that, we are excited to share the news that the best and runner of paper   
4:32   
awards this year go to seven groundbreaking papers, including four best papers, one of which is from the   
4:40   
data sets and benchmark track, and three runners up. The seven papers highlight   
4:45   
advances in diffusion model theory, self-supervised reinforcement learning, attention mechanisms for large language   
4:52   
models, reasoning capabilities, and large language models, online learning theory, neural scaling laws and   
5:00   
benchmarking methodologies for language model diversity. So here are the winners. So the first one is artificial   
5:07   
hive mind, the open-ended homogeneity of language models and beyond.   
5:12   
Um, and this is where, you know, we're talking about how all of the outputs of   
5:18   
the current frontier models are convergent. So, the abstract reads, uh, large   
5:25   
language models often struggle to generate diverse humanlike creative content, raising concerns about the   
5:32   
long-term homogenization of human thought through repeated exposure to similar outputs. Yet scalable methods   
5:39   
for evaluating language model output diversity remains limited, especially   
5:44   
beyond narrow tasks such as random number or name generation or beyond   
5:50   
repeated sampling from a single model. To address this gap, we introduce Infinity Chat, a large scale data set of   
5:58   
26,000 diverse real world open-ended user queries that admit a wide range of   
6:04   
plausible answers with no single ground truth. We introduced the first comprehensive taxonomy for   
6:10   
characterizing the full spectrum of open prompts posted to language models   
6:16   
comprising six top level categories. And so that the examples include   
6:22   
creative content generation, brainstorm and ideiation that further breaks down   
6:27   
to 17 subcategories. Using infinity chat, we present a large scale study of mode collapse in language   
6:35   
models, revealing a pronounced artificial hive mind effect, an open-ended generation of language models   
6:42   
characterized by a few things. The first is intramodel repetition where a single   
6:48   
model consistently generates similar responses and then more so number two which is   
6:54   
intramodel homogeneity where different models produce strikingly similar outputs.   
7:01   
Infinity Chat also includes 31,250 human annotations across absolute   
7:08   
ratings and paras preferences with 25 independent human annotations. For   
7:13   
example, this enables studying collective and individual specific human preferences   
7:20   
in response to open-ended queries. Our findings show that state-of-the-art   
7:25   
language models, reward models, and language model judges are less well   
7:31   
calibrated to human ratings on model generations that elicit differing idiosyncratic annotator preferences   
7:38   
despite maintaining comparable overall quality. So, Infinity Chat presents the   
7:44   
first large scale resource for systematically studying real world open-ended queries to language models,   
7:50   
revealing critical insights to guide future research for mitigating long-term AI safety risks posed by the artificial   
7:57   
hive mind. So, this is just kind of reflections from the selection committee. So this   
8:04   
paper made a substantial and timely contribution to the understanding of diversity, pluralism and societal impact   
8:10   
in modern language models. The authors introduced infinity chat which is this   
8:17   
model that we talked about. Beyond releasing a valuable data set, this paper provided deep analytical insights   
8:24   
through the first comprehensive taxonomy of open-ended prompts and an extensive   
8:29   
empirical study across more than 70 models revealing the artificial hive   
8:34   
mind effect which is pronounced intra and intermodel hom homogenization   
8:41   
that raises serious concerns about long-term risks to human creativity, value plurality, and independent   
8:47   
thinking. The findings expose critical miscalibration between current reward   
8:53   
models, automated judges, and diverse human preferences, highlighting the tension between alignment and diversity   
9:00   
and establishing the foundation for future work on preserving heterogeneity in AI systems. Overall, this work sets a   
9:09   
new standard for data sets and benchmarks that advance scientific understanding and address pressing   
9:15   
societal changes rather than solely improving technical performance. Okay,   
9:20   
so that's the first one. Uh the second paper is gated attention for large language models, nonlinearity, sparity   
9:29   
and attention sync free. So this is another paper where you know they're   
9:34   
thinking about um these uh post transformer architectures or at least improving the   
9:42   
attention mechanism in transformers as they stand today. So   
9:48   
the abstract reads, gating mechanisms have been widely utilized from early   
9:53   
models like LSTMs and highway networks to recent state space models, linear   
9:59   
attention and also softmax attention. Yet existing literature rarely examines   
10:05   
the specific effects of gating. In this work, we conduct comprehensive experiments to systematically   
10:11   
investigate gating automated softmax attention variance. Specifically, we   
10:16   
perform a comprehensive comparison over 30 variants of 15B mixture of expert   
10:23   
models, 15 billion mixture of expert models and 1.7 billion dense models trained on the 3.5 trillion token data   
10:30   
set. Our central finding is that a simple modification applying a headsp specific   
10:36   
sigmoid gate after the scale dot product attention or SDPA   
10:42   
consistently improves performance. This modification also enhances training stability, tolerates larger learning   
10:49   
rates, and improves scaling properties by comparing various gating gating   
10:54   
positions and computational variance. We attribute this effectiveness to two key   
10:59   
factors. So the first is introducing nonlinearity upon the low rank mapping of the softmax   
11:06   
attention and the second is applying query dependent sparse gating scores to   
11:11   
modulate the sdpa output. Notably we find the sparse gating mechanism mitigates massive activation   
11:19   
attention sync and enhances long tech context extrapolation performance. We   
11:25   
also relate release related code which are in these GitHub repositories here   
11:32   
and models which are in hugging face here to facilitate future research.   
11:37   
Furthermore, the most effective SDPA output gating is used in the Q3 next   
11:42   
models and these are al also hosted on hugging face. So this is where they're   
11:49   
using this Q3 next model. They're introducing this gated attention   
11:54   
mechanism and it's available in open source.   
12:01   
So the selection committee what they had to say was that the main finding of this paper is that performance of large   
12:07   
language models using the softmax attention can be consistently improved by introducing headsp specific sigmoid   
12:14   
gating scale dot product uh attention operator   
12:20   
operation in both dense and mixture of experts transformer models. This finding is backed up by more than   
12:26   
30 experiments on different variants of variants of gated softmax attention.   
12:32   
This paper also includes careful analysis showing that the introduction of the author's recommend gating   
12:38   
improves the training stability of large language models reduces the attention sync phenomena that has been widely   
12:45   
reported in attention models and enhances the performance of content context length extension. The main   
12:52   
recommendation of this paper is easily implemented and given the extensive evidence   
12:57   
provided in the paper for this modification large language model architecture, we   
13:03   
expect this idea to be widely adopted. And so this paper represents a substantial amount of work that is   
13:09   
possible only with access to industrial scale computing resources and the author's sharing of of the results of   
13:16   
their work which will advance the community's understanding intention of large language models.   
13:22   
Um, and so this is a breath of fresh air apparently from a lot of the models   
13:27   
where the code is proprietary not open source. So they they make a point to   
13:32   
talk about how they appreciate this being open sourced.   
13:38   
The next pair paper is 10,00 layer networks for self-supervised reinforcement learning scaling depth can   
13:45   
enable new goal reaching capabilities. So this is now going moving to   
13:51   
reinforcement learning. So the abstract reads scaling of self-supervised   
13:56   
learning has driven breakthroughs in language and vision yet comparable progress has remained elusive and   
14:02   
reinforcement. In this paper we study building blocks for self-supervised reinforcement   
14:07   
learning that unlock substantial improvements in scalability with network depth serving as a critical factor.   
14:15   
Whereas most reinforcement learning papers in recent years and shallow architectures of around two to five   
14:21   
layers. Uh we demonstrate that increasing the depth to up to 1,024   
14:27   
layers can significantly boost performance. Our experiments are conducted in unsupervised goal condition   
14:34   
setting where no demonstrations or rewards are provided. So an agent must   
14:39   
explore from scratch and learn how to maximize the likelihood of reaching commanded goals   
14:45   
evaluated on simulated locomotion manipulation tasks. Our approach increases performance on the   
14:52   
self-supervised contrastive reinforcement learning algorithm by outperforming other goal condition   
14:58   
baselines. Increasing the model depth not only increases success rates but also   
15:03   
qualitatively changes the behaviors learned. So this is uh reflections from the   
15:10   
selection committee. Again this paper challenges the conventional assumption that the information provided by   
15:16   
reinforcement learning is insufficient to effectively guide the numerous parameters of deep neural networks.   
15:22   
Hence suggesting that large AI systems be predominantly trained through self-s supervision   
15:28   
with reinforcement learning reserve solely for fine-tuning. The work introduces a novel and easy to   
15:34   
implement reinforcement learning paradigm for the effect of training of very deep neural networks employing   
15:41   
self-supervised and contrastive reinforcement. The accompanying analysis demonstrates   
15:47   
that reinforcement learning can scale efficiently with increasing network depth leading to the emergence of more   
15:53   
sophisticated capabilities. In addition to presenting compelling results, the study includes several   
16:00   
useful analyses. For example, for highlighting the important role of batch size scaling for   
16:06   
deeper networks within contrastive reinforcement. So that is an example of contrastive   
16:13   
reinforcement learning and how that is implemented. Um and so then that and then we go to   
16:20   
diffusion models. So we're moving from large language models to reinforcement learning the diffusion models.   
16:28   
So this one is why diffusion models don't memorize role of implicit dynamical regularization in training.   
16:36   
And so this abstract reads diffusion models have achieved remarkable success across a wide range of generative tasks.   
16:44   
Key challenge is understanding the mechanisms that prevent the memorization of training data and allow   
16:49   
generalization. In this work, we investigate the role of the training dynamics in the transition   
16:55   
from generalization to memorization. For extension of experiments and theoretical analysis, we identify two   
17:03   
distinct time scales. The first is an early time at which models begin to generate high quality samples and the   
17:11   
second is a later time beyond which memorization emerges. We have these two different time scales that the model   
17:17   
operates on. So it's this generative part that's early and then this memorization of   
17:25   
later time. Crucially we find that increases that increases linearly with the training set   
17:32   
size while remaining constant. uh this creates a growing window of   
17:37   
training times where models generalize effectively despite showing strong memorization of training continues   
17:42   
beyond it. It is only when it becomes larger than a model dependent threshold that overfitting disappears at infinite   
17:49   
training times. These findings reveal that a form of implicit dynamical regularization the training dynamics   
17:56   
which allows to avoid memorization even in highly overparameterized settings. Our results are supported by numerical   
18:03   
experiments with standard UNET architectures on realistic and synthetic data sets by a theoretical analysis   
18:11   
using attractable random features model studied in highdimensional way.   
18:18   
Uh so the selection committee uh said this paper presents foundational work on   
18:24   
the implicit regularization dynamics of diffusion models delivering a powerful result by unifying empirical observation   
18:32   
with formal theory. The critical finding is that quantitative identification of two distinct predictable time scales. An   
18:40   
early data set independent generalization phase followed by a linear data set size dependent   
18:46   
memorization phase. So it's it's data set independent versus data set dependent.   
18:52   
This demonstration of an expanding window for effective generalization is not merely an empirical finding, but is   
18:59   
rigorously explained by dering the spectral properties of the random features model using random matrix   
19:05   
theory. By linking the practical success of diffusion models directly to approvable dynamical property, the   
19:13   
implicit postponement of overfitting, this paper provides fundamental actionable insight into the mechanisms   
19:20   
governing modern generative AI setting a new standard for analytical depth in the   
19:26   
study of generalization. Okay, so those are the winners of this.   
19:32   
It's best paper award. uh because it's a big conference, you have to have four of them. Uh so there are a bunch of runners   
19:39   
up as well. Um so the first one is does reinforcement learning really   
19:44   
incentivize reasoning capacity in large language models beyond the base model?   
19:50   
And so they're doing this method called reinforcement learning with verifiable rewards or RLVR   
19:56   
has recently demonstrated notable success in enhancing reasoning performance of large language models   
20:03   
particularly mathematics and programming tasks. It is widely believed that similar to how traditional reinforcement   
20:09   
learning helps agents to explore and learn new strategies, RLVR enables large language models continue to continuously   
20:17   
self-improve, thus acquiring novel reasoning abilities that exceed the capacity of the corresponding base   
20:23   
models. Um, in this study, we take a critical look at the current state of   
20:28   
RLVR by systematically probing the reasoning capability boundaries of RLVR   
20:34   
train large language models across diverse model families, reinforcement   
20:39   
learning algorithms and math/coding visual reasoning benchmarks.   
20:45   
um using um large val at large values as the evaluation metric with RLVR improves   
20:52   
sampling efficiency towards a correct path. We surprisingly find that the current training does not elicit   
20:59   
fundamental reasoning patterns. We observe that while RLVR trained models outperform their base models at smaller   
21:05   
values, base models achieve higher uh scores when it is large. Moreover, we   
21:12   
observe that reasoning capability by large language models often narrows as RLBR training progresses. Further   
21:19   
coverage in complexity analysis shows that the reasoning paths generated by RLBR models are already included in the   
21:27   
base model sampling distribution suggesting that their reasoning abilities originate from are bounded by   
21:34   
the base model. From this perspective, treating the base model as an upper bound, our quantitative analysis shows   
21:40   
that six popular RLBR algorithms perform similarly and remain far from optimal   
21:46   
and fully leveraging the potential of the base model. In contrast, we find that distillation can introduce new   
21:53   
reasoning patterns in the teacher and genuinely expand the model's reasoning capabilities. Taken together, our   
22:01   
findings suggest that the current ROVR methods do not fully realize the potential reinforcement learning to   
22:07   
elicit genuinely novel reasoning ability for models. This underscores the need   
22:12   
for improved reinforcement learning paradigms such as continual scaling and multi-turn agent environment interaction   
22:20   
to unlock this potential. So, RLVR sounds like an interesting area and   
22:26   
they're kind of tying in other types of agent learning into this.   
22:33   
So the selection committee says this paper delivers a masterfully executed and critically important negative   
22:40   
finding on a widely accepted foundational assumption in large language model research   
22:46   
that reinforcement learning with verifiable rewards elicits genuinely new reasoning capabilities.   
22:52   
The paper shows that RLVR training across various model families, tasks and   
22:57   
algorithms enhances sampling efficiency without expanding reason capac reason   
23:02   
reasoning capacity already present in base models. Reinforcement learning narrows exploration. Rewarded   
23:09   
trajectories are amplified but the broader solution space shrinks revealing that RLBR optimizes within rather than   
23:17   
beyond the base distribution. This is an important finding which will hopefully incentivize fundamentally new   
23:23   
reinforcement learning paradigms that will then navigate the vast action space and genu genuinely expand our language   
23:31   
model these new capabilities. So that's interesting that you know they   
23:37   
kind of have these sort of they work out these sort of dynamics for reinforcement learning uh with application.   
23:49   
Okay. Um, this next one is optimal mistake bounds for transductive online   
23:54   
learning. So, this abstract uh says, "We resolve a   
24:00   
30-year-old open problem concerning the power of unle data and online learning   
24:05   
by tightly quantifying the gap between transductive and standard online. We   
24:11   
prove that for every concept class with a little stone dimension, the transductive mistake bound is at least   
24:18   
But there are some formatting problems with this blog post. This establishes an exponential   
24:25   
improvement over previous lower bounds of and respectively due to uh this   
24:30   
citation here and this other citation. So the first is Ben David uh Bushelovitz   
24:36   
and Mansour 1995 1997 and Henaran and Shaver 2023.   
24:42   
We also show that our bound is tight for every uh supposed to be a symbol there. There   
24:49   
exists a class of little stone dimension with transductive to state bound. Her upper bound also improves the previous   
24:55   
best known upper bound from Ben David. Uh these results demonstrate a quadratic   
25:01   
gap between the transductive and standard online learning whereby highlighting the benefit of advanced   
25:07   
access with the unlabelled instant sequence. This stands in stark contrast to the pack setting where transductive   
25:14   
and standard learning exhibits simple sample complexities. So this is uh   
25:22   
so the selection committee says this paper presents a breakthrough in learning theory deserving the NERP's   
25:29   
best paper runnerup award for its elegant comprehensive and definitive resolution of a 30-year-old open   
25:35   
problem. The author has not only precisely quantified the optimal mistake bound for transductive online learning   
25:42   
um but they've also achieved a tight match with the upper bound. Uh this establishes a quadratic gap between   
25:49   
transductive and standard online learning. A result that represents an exponential leap beyond all previous   
25:56   
logarithmic lower bounds and dramatically highlights a theoretical value of unlabelled data in this   
26:01   
setting. A crucial insight distinct from the more limited role in PAC learning.   
26:09   
So what does this mean? I'm not really sure. Um this is largely a proof. So   
26:14   
it's it's an open problem in the field. I'm not really familiar with this problem. Um this is really just thinking   
26:22   
about you know how you can do online learning without labels. Um and it's just an example of how this is kind of   
26:29   
worked out mathematically. Um   
26:37   
so some of the insights here um for the lower bound the adversary employs a   
26:44   
sophisticated strategy that balances forcing mistakes with carefully managing the shrinking of the version space   
26:51   
levering the concept of paths and trees is a fundamental underlying structure.   
26:56   
The upper bound demonstrating a learnability within these mistakes introduces an inhibitive hypothesis   
27:03   
class construction that embeds a sparse coding for off path nodes. A probabilistic design where most off path   
27:10   
labels are zero but the rare ones carry immense information. The winner strategy to exploit this   
27:16   
class is equally brilliant. Integrating several non-standard sophisticated techniques. For example, danger zone   
27:22   
minimization to control the instant sequence presented by the adversary.   
27:28   
Splitting experts via multiplicative weights approach to handle uncertainty about a node's on path status and a   
27:36   
strategic transition to having once sufficient information is gathered from the sparsely encoded off path labels.   
27:43   
This intricate interplay between a cleverly constructed hypothesis class and a highly adaptive learning algorithm   
27:51   
showcases a master class in theoretical analysis and design. So that's that's a good paper there. Um   
27:59   
this next paper superposition yields robust neural scaling. This is um   
28:07   
though the success of today's large language models depends on the observation that larger models perform   
28:13   
better. However, the origin of this neural scaling law the that loss decreases as a   
28:20   
power law with model size remains unclear. We propose that representation   
28:25   
superposition, meaning that large language models represent more features than they have   
28:30   
dimensions, can be a key contributor to loss and cause neural scaling.   
28:37   
Based on anthropics toy model, we used weight decay to control the degree of superp position, allowing us to   
28:43   
systematically study how loss scales of model size. When superposition is weak,   
28:48   
the loss follows a power law only if data feature frequencies or power law distributed. In contrast, under strong   
28:55   
superposition, the loss generically scales inversely with model dimension across a broad class of frequency   
29:01   
distributions due to geometric overlaps between representation vectors. We   
29:07   
confirm that open source large language models operate in the strong superposition regime and have loss   
29:14   
scaling inversely with model dimension. and that uh chinchilla scaling laws are   
29:19   
also consistent with this behavior. Our results identify representation superposition as a c central driver of   
29:27   
neural scaling laws providing insights into questions like when neural scaling   
29:32   
laws can be improved and when they will break down. And so the selection committee says this   
29:39   
paper moves beyond observations of neural scaling laws. The empirically established phenomena in which model   
29:45   
loss exhibits a power law decrease as model size data set size or   
29:50   
computational resources are increased that demonstrate that representation superposition constitutes the primary   
29:57   
mechanism governing results. Authors introduce a control toy model to examine   
30:03   
how superp position and data structure affect the scaling of loss with model   
30:08   
size and demonstrate that under strong superposition the features are overlapping the loss scales consistently   
30:15   
as an inverse power law with respect to the model dimension. The core findings are supported by a series of carefully   
30:22   
designed experiments and offer fresh insights into an important research area. So this these are their papers   
30:29   
that they've given awards to for this year. Um and that is   
30:36   
all we have. Okay. The other thing that we should   
30:43   
probably go over is the 2025 Sajjinowski Hinton Prize. So the NERIPS organizing   
30:50   
committee is pleased to announce the winner of the 2025 Sajinowski Hinton Prize. And this is Tim Lilly crap,   
30:57   
Daniel Cen Douglas Tweet and Colin Acriman for their groundbreaking 2016 paper random synaptic feedback weights   
31:05   
support error back propagation for deep learning. This was published in nature communications is as is also available   
31:14   
on the archive. Um so this is I guess a paper like the   
31:19   
best paper of all time that they kind of pick and uh kind of bring it back into   
31:26   
relevance today. So um this is the topic of this paper is feedback and we'll talk   
31:32   
about that paper later but I wanted to kind of go over this blog post and see   
31:38   
what they have to say about it. So uh theories of the brain have long   
31:43   
sought to explain how neural circuits learn efficiently using only local information. And so this is you know an   
31:50   
example. This is how synapse adjusts based on signals available at each connection rather than some through some   
31:58   
explicit global error propagation. So you're correcting things locally.   
32:03   
You're processing information locally. And this happens at every synapse. Um,   
32:09   
you know, you can assume some sort of global error propagation, but that's not really the way the network works.   
32:16   
Inspired by this challenge, researchers have explored ways to train artificial neural networks that perform gradient   
32:22   
descent using local learning. This paper is recognized for its contribution to that pursuit with the   
32:28   
discovery of feedback alone. The authors demonstrated that multi-layer networks can learn effectively when fixed using   
32:36   
fixed random feedback weights rather than requiring exact backwards weight   
32:41   
symmetry as in back propagation. So you have these sort of random feedback   
32:46   
weights that come from the local interactions of those synapses. Uh,   
32:52   
remarkably, the network the network's forwarded weights naturally aligned with these random feedback signals over the   
32:58   
course of learning, yielding a biased yet useful estimate of the loss rate.   
33:03   
This insight provided the first concrete biologically grounded solution to the long-standing weight transport problem   
33:11   
question of how real neurons follow loss gradients without non-local information transfer.   
33:17   
And so this work had significant impact helping to establish a new sub field of biologically plausible learning rules in   
33:24   
the near community of be. So basically the Sajjunowski Hinton   
33:30   
prize is awarded annually to a paper published within the past 10 years that   
33:35   
has made major contributions to computational theories of the brain especially drawing insights from   
33:41   
artificial intelligence and has had a significant impact on the IPS community.   
33:47   
All right. Um any questions about that? That was a lot of material. Yeah,   
33:56   
I mean I'm sure a lot of this stuff is not like easily accessible. Um, you   
34:01   
know, if you're in that sub field, then you understand exactly what's going on.   
34:06   
Yeah. Yeah. Um it it is it is interesting just to go   
34:13   
return to the kind of beginning topic of um hive mind. Um   
34:20   
and just wondering how much that is driven by I'm trying to think of the the   
34:26   
researcher who covered I think it was it's Santa Fe Institute but covered the   
34:37   
uh the different d sources of of each model.   
34:42   
Okay. I mean, as as as like best you could determine. Yeah.   
34:49   
You know, like like how much does that drive it versus say um   
34:55   
uh it just everybody using the same   
35:01   
benchmarks, you know? Yeah. like like there's definitely um   
35:09   
um what what what do they call that particular um   
35:15   
that particular problem where where everybody's just trying to inch up the same benchmarks?   
35:22   
Um yeah, take care. Yeah, I'm not sure what it would be. Um,   
35:29   
right. Yeah, there's there's there's, you know, there's a   
35:34   
Yeah. Yeah. Yeah. I mean, that's obviously a problem if you want generalization.   
35:41   
The the today is the big foundations, foundation models and brain and   
35:48   
behavior. So this is this is the day where they'll be more   
35:56   
um yeah like a lot a lot of the   
36:01   
presentations that are of interest are are today I mean I should say for kind   
36:08   
of like neuro um   
36:13   
like EEG electrophys models will be talked about today. So luckily   
36:20   
one of the organized reasons is a member of the tower. So plus plus you're going   
36:26   
to be recorded so this will all be what's that? Good. Yeah.   
36:32   
Yeah. Yeah. Yeah. No. Absolutely. Absolutely. So um uh but but I I don't   
36:40   
think live streamed so or I I'll check but you know it won't   
36:46   
be until like 9 something. on west system.   
36:52   
Right. Right. Right. All right. Um yeah, that's great. So,   
37:01   
you know, thinking about this feedback alignment problem. So, this is the nature communications paper they   
37:07   
mentioned in the award uh call. This is   
37:12   
from 2016. This is nature communications. This the title of this paper random   
37:18   
synaptic feedback weights support error back propagation for deep learning. Um   
37:24   
so this is uh they think about deep architectures   
37:32   
and thinking about what's going on in the brain and then thinking about what's going on in models. So the brain   
37:39   
processes information through multiple layers of neurons. This deep architecture is represented powerfully.   
37:46   
It complicates learning because it is difficult to identify the responsible neurons when a mistake is made. This is   
37:53   
this credit assignment problem that they're interested in. So, you know, you have basically a network where there are   
38:01   
these generic signals that are being sent and you'd like to be able to isolate and identify where things are   
38:09   
coming from. that you know in in case you have errors or mistakes you can correct them or figure out where the   
38:16   
errors are coming from. In machine learning the back propagation algorithm assigns blame by multiplying error   
38:24   
signals with all the synaptic weights on each neuron's axon and further downstream.   
38:30   
So this is where they use back they talk about how back propagation in machine learning um can basically sort of   
38:39   
amplifies the error signal and so however thisol involves a precise   
38:45   
symmetric backward connectivity pattern which is thought to be impossible in the brain. So you have this amplification of   
38:52   
the error. So you can identify it in some way. But this of course uh requires   
38:58   
a specific architecture to be in place. this precise symmetric backward connectivity pattern that the brain   
39:05   
doesn't have because the brain has this structure um which is often asymmetrical   
39:11   
or at least not symmetric in its in its um in its structure and it doesn't have   
39:18   
this sort of uh forward uh this this forward and backward ability where you   
39:23   
can trace things back. Here we demonstrate that the strong architectural constraint is not required   
39:30   
for effective error propagation. We present a surprisingly simple mechanism that assigns blame by   
39:36   
multiplying errors by even random synaptic weights. This mechanism can   
39:41   
transmit teaching signals across multiple layers of neurons. It performs as effectively as back propagation on a   
39:48   
variety of tasks. Our results help reopen questions about how the brain could use error signals and dispel long   
39:55   
long-h held assumptions about algorithmic constraints on so it's an interesting paper very   
40:02   
influential. Um going into the article, uh networks in   
40:08   
the brain compute via multiple layers of interconnected neurons. During learning, these neurons are believed to adjust   
40:14   
their synapses so that networks outputs become more appropriate for its tasks.   
40:20   
In many cases, learning is thought to utilize error signals such as those that result from mismatches between expected   
40:27   
and actual perceptions or between intended and realized motor behaviors.   
40:32   
This requires mechanisms that can adjust the weight of synapses earlier in a network. So if you take synapse between   
40:41   
X subi and H subj and they show this in figure one and the basis of downstream   
40:47   
errors and that's shown. So this uh example is figure 1 a x i and hj and   
40:55   
then this other example e also shown in figure one except for the error naive   
41:01   
learning rules could adjust uh synapses deep within a network based on the correlations between a scale or error   
41:08   
signal and the normal activity. However, the performance of such learning rules slows significantly as the size of a   
41:16   
network grows. So as the network gets bigger the performance of these naive learning rules decreases and so this is   
41:23   
just you know obviously because the number of neurons um in network as they increase the   
41:30   
variance in estimates of a neuron's contribution to the error also. So the more neurons you have the more likely it   
41:37   
is that the error could be from a larger number of neurons and thus lowering the   
41:42   
probability of finding any impact. More powerful learning rules could send   
41:49   
specific teaching signals to a neuron based on how that neuron contributed to the error. An artificial intelligence   
41:56   
and algorithm called back propagation of error or backrop is used to assign error   
42:01   
on a neuron by neuron basis. Backrop works well in real world applications,   
42:07   
underlies recent advances in reinforcement and unsupervised learning and can account for cell responses in   
42:13   
some areas of cortex. But for a variety of reasons, it has been difficult to imagine how a learning algorithm such as   
42:20   
backrop could be implemented by neural circuits in the brain. And so one of the   
42:25   
most significant issues is that backrop requires that downstream errors are fed back to upstream neurons by an exact   
42:33   
symmetric copy of the downstream synaptic weight matrix. So this requires sort of this uh symmetric connectivity.   
42:42   
You can't have a lot of structure in the network. You can't have a lot of asymmetric structure.   
42:48   
Specifically, more precisely backrop multiplies error signals E by weight matrix WT which is   
42:55   
the transpose of the forward synaptic connect a set of synaptic connections W.   
43:01   
This issue was described in detail by Gberg who named it the weight transport problem. Uh the name arises from the   
43:08   
fact that for each neuron information about downstream synaptic weights must be transported to make optimal updates   
43:15   
to the neurons's incoming or forward synaptic weights. Back prop requires each neuron hidden deep within the   
43:22   
network to have precise knowledge of all its downstream synapses since the error   
43:27   
signal arriving at a hidden unit must be multiplied by the strength of that neuron's forward synaptic connections to   
43:34   
the source of the error. Late transport was also identified as a major problem by Ziper Rumbleheart and their concerns   
43:41   
were echoed by Crick who noted that when taken at face value, rack prop seems to   
43:47   
require rapid information transfer back along axons from each of its synaptic   
43:52   
outputs. So this is figure one and the uh caption   
43:58   
here is random feedback weights can deliver useful teaching signals. So   
44:03   
we're looking for are teaching signals that assign the location of the error   
44:09   
and train the network to avoid making that error again. And that's what we're   
44:15   
doing here. So in a we have an example. We have X, H, and Y. Those are the three   
44:21   
layers. We have X of Y which is this neuron here in the middle. That's part   
44:28   
of the input. it goes to H subj which is in the J uh layer and that is a feed   
44:35   
forward connection and then H subj then then feeds to each of the three Y   
44:42   
neurons equally and then there's this feedback mechanism where you take the in the   
44:49   
outputs of Y each Y and they feed back to J sub H subj using this uh this error   
44:57   
term here and that gives this signal that says okay you know you've made an   
45:02   
error or you've made a correct choice um you know and this is you know so there's   
45:08   
a feedback mechanism but the idea is to correct the error that's been made   
45:14   
and then of course B we have these layers so we have WO which is the input   
45:20   
to the hidden layer and then W which maps the hidden layer to the output   
45:25   
layer and then the transpose of WWT which maps maps the output layer back to the hidden layer. So you can see that   
45:33   
that's basically how they treat this as a transposition. And then C shows WO which is going from   
45:40   
the input layer to the hidden layer. And then we have W which is the hidden layer to the output layer and B which is sort   
45:47   
of the feedback. And then we have this model of actual   
45:54   
biological synapses on axons. So we see HJ which is this hypothetical neuron   
46:01   
with axons and the axons have synapses over here. These synapses here are   
46:08   
imagined as this matrix uh WO which is these uh these J connections. So you   
46:15   
have all these different connections here going into HJ and then you have this error here which is uh this this uh   
46:24   
neuron here B. And so you have this uh synaptic connection here between HJ and   
46:31   
B and that's what you see here which is this feedback mechanism. So basically   
46:37   
the idea is to trace back the error to a specific source use that error to learn   
46:44   
not to make that error again and then improves the performance of the network.   
46:50   
Okay. So then a number of studies have suggested potential solutions to the weight transport problem. Indeed,   
46:56   
encouraged by initial empirical observations, several theoretical studies examined the possibility that   
47:02   
back prop might in fact be implemented via the retrograde transmission of information along axons. And that's   
47:09   
shown here in D. However, further empirical work has shown that retrograde transport operates   
47:16   
on time scales that are orders of magnitude slower than forward propagating neural activity, making it   
47:22   
fundamentally unable to support back like as an alternative to sending error   
47:28   
information anadromatically or anodrammically. It has been suggested   
47:33   
that errors could instead be fed back through a second network. However, most of these approaches either   
47:40   
assume that forward and feedback connections are symmetric but they propose more intricate learning rules   
47:46   
for the backwards weights that maintain precise symmetry. These approaches to   
47:51   
the weight transport problem have helped to perpetuate the view that to achieve back proplike learning performance, the   
47:58   
brain would have to exhibit precise symmetric information and does so despite achieving only a modest symmetry   
48:04   
and reciprocal cognitivity. Of course, these observations are compatible with the possibility that the   
48:11   
brain makes use of more intricate architectures or more complex algorithms. Our results also leave open   
48:18   
many open questions about how the brain might implement fast error-driven learning. Importantly however they   
48:25   
reveal much more architectural constraints and what is required for effective error propagation across   
48:32   
multiple layers of neurons. So that is the uh basis of their paper   
48:37   
and they give these results which are that random feedback weights can deliver useful teaching signals. So they have   
48:45   
this matrix of random feedback weights and they can use that to as a as a tutoring mechanism.   
48:52   
Um and then they call this feedback alignment and this matches backrop in terms of its performance. So you have   
48:59   
back prop in this black uh function here and feedback alignment in the green function and they're pretty much very   
49:07   
similar. Uh feedback alignment learns under a variety of conditions. of this means it   
49:13   
generalizes well and that these signals um can serve to correct the network   
49:20   
under a variety of conditions. And so this is an example here of how feedback   
49:26   
alignment works in multi-layer networks comprised of nonlinear neurons. Again   
49:31   
comparing backdrop and then uh mapping this out in a network a three layer   
49:38   
network and a four layer network. So we saw the three-layer network in figure one and figure three you see the four layer   
49:46   
uh then figure four feedback alignment operates in larger networks more complex dynamics. So using the mnest data set as   
49:54   
input we have the signal of the hidden units we have then the signal of the   
49:59   
output units and we get these patterns here and so it's able to feedback   
50:06   
alignment is able to deal with this network and its input. Instead of the   
50:12   
discussion, the most effective forms of learning emerge networks of neurons rely on mechanisms that adjust synaptic   
50:18   
weights according to errors that are detected further downstream. In examining the conditions under which   
50:25   
neural networks can exhibit such forms of deep learning, we have identified a new algorithm that we call feedback   
50:31   
alignment. We show that in its simplest form, feedback alignment is able to make   
50:36   
use of a fixed random connectivity pattern to update synaptic weights   
50:41   
throughout a network. To our surprise, even with such minimal constraints on connectivity patterns, feedback   
50:48   
alignment can achieve learning performances that are comparable to the back propagation of your algorithm.   
50:55   
Critically, this demonstrates that the kind of precise synaptic connectivity between layers of neurons as required by   
51:01   
backdrop is not essential to achieve effective transmission of error across layers. In characterizing the   
51:08   
performance of feedback alignment, we first demonstrated that the algorithms are effective in using error signals to   
51:15   
update synaptic weights in simple linear and nominal networks. We then showed that feedback alignment   
51:21   
is also effective in larger networks that incorporate multiple hidden layers and in networks that exhibit sparse   
51:28   
connectivity or impose more realistic constraints on how activity is represented.   
51:34   
Finally, our investigations into how feedback alignment works suggest that the algorithm's power relies on the fact   
51:41   
the weight matrices of the forward going synapses evolve to align approximately with those   
51:47   
in the feedback. Taken together, our study reveals much lower architectural constraints. What is   
51:54   
required for error propagation across layers of neurons and this provides insights into how neural networks might   
52:00   
support fast learning in large deep networks. Feedback alignment offers a surprising   
52:06   
and simple solution to the problem of synaptic weight transport. As with many forms of learning that have been   
52:12   
proposed to occur in the brain, it makes use of the idea that teaching signals could be carried by reciprocal   
52:18   
connections and there are a whole host of references on that. However, in the   
52:24   
case of feedback alignment, we have shown that this does not depend on detailed symmetric reciprocal   
52:29   
connectivity and yet it is still able to train large networks quickly.   
52:34   
Um there are of course many outstanding questions regarding how the brain could utilize learning processes that rely on   
52:41   
error propagation or draft upstream synaptic connections in the network.   
52:46   
This includes how exactly the brain computes represents errors and how the   
52:51   
feed forward and feedback pathways might interact with one another.   
52:56   
So we need to figure this out to sort of understand supervised learning and um we it's not unique to any one   
53:04   
algorithm. This is a problem that is uh sort of an artifact of taking sort of   
53:13   
an a brain inspired model extracting it down to the type of system we have in   
53:20   
layer deep networks where we have connections. We have weight matrices but   
53:26   
we don't have the rest of the mechanisms in the brain that you know biologically   
53:31   
this is handled with ease. So this is   
53:37   
kind of going through um how this relates to um supervised learning. So a   
53:44   
keen insight that it um that has been that rather than requiring an external   
53:49   
teacher, errors can result from mismatches between expected and actual perceptions or between intended and   
53:56   
realized motive consequences. So this is of course um an insight of course that   
54:01   
you see in active inference as well whereas there's this mismatch between uh   
54:07   
a prior distribution or a prior experience and a current experience and   
54:13   
that contributes to a posterior distribution that's constantly updated.   
54:18   
So this is very similar in that way to active inference and of course this is   
54:24   
in contrast to having this tutor or having the supervisor or supervised   
54:30   
learning mechanism. So for example it is possible to derive   
54:35   
teaching signals from sensory input by trying to predict one modality from another by trying to predict the next   
54:42   
term in a temporal sequence or by trying to encode and reconstruct sensory information. These processes can be   
54:49   
thought of as supervised tasks with the sensory activity itself playing the role of the teacher. Indeed, experimental   
54:56   
data from a range of systems has shown that normal populations represent prediction mismatch and motor errors in   
55:02   
their activity. So this is again common in motor control and in some other areas   
55:08   
of neuroscience where you're looking for the mismatch and of course in in   
55:13   
cybernetics too where we deal with um these kind of uh systems that have good   
55:19   
regulation and so it's not so much about supervision it's about learning from the   
55:25   
error learning from the mismatch and then continuing to do that over time.   
55:32   
So as with other forms of hierarchical learning, an important question is how feed forward and feedback pathways   
55:39   
interact with one another in the brain. It is well established that there are extensive feedback pathways that carry   
55:45   
information from higher areas to lower sensory areas and these connections have   
55:50   
been shown to modulate the tuning properties and therefore the activity of neurons and other areas. Therefore, it   
55:56   
seems likely or perhaps inevitable that this top down modulation of normal activity will impact the learning that   
56:03   
goes on in the lower area of neuron synapses. Indeed, recent work has demonstrated   
56:09   
that learning sensory motor tasks alters representations of early cortical areas   
56:15   
for higher layers to deliver error information that could enable lower layers to make useful changes to their   
56:21   
synaptic weights. neurons in the lower layer should at least in part be able to   
56:26   
differentiate a top down error signal from activity originating in a forward pathway.   
56:33   
Thus a prediction is is that one of the functions of backward pathways is to ultimately modulate plasticity processes   
56:39   
of the synapses of a neuron in the forward pathway. This regarded as interesting that   
56:45   
experimental evidence is shown that various third factors can modulate the   
56:50   
magnitude and sign of synaptic plasticity mechanisms. And again this is an artifact of the representation the   
56:58   
high level of abstraction from the brain we use in deep learning networks or in   
57:03   
layer neural networks that of you know you don't you only have the weight of   
57:08   
the connection. we don't have multiple synapses that are, you know, kind of   
57:13   
maybe average those out or kind of figure out what the mean value is. We   
57:19   
don't really model those in any meaningful way. And so this is of course going to remove   
57:27   
some of the sort of the mechanisms that may may not know about that occur in the brain.   
57:34   
So this these third factors of course result in part from some of the neurohysiology.   
57:40   
They could also be um other types of things that that result from emergence simply   
57:47   
depolarizing inputs arriving at specific times in or subcellular compartments   
57:52   
neurom modulators different types of synapse and all regulate plasticity   
57:58   
resulting from the pairing of pre and post synaptic activity. So uh one   
58:04   
example of this is that heavy and learning protocols that result in long-term potentiation at neoportical   
58:10   
synapses can be altered to result in long-term depression if they occur simultaneously with local sub threshold   
58:17   
depolarizing inputs into the post synaptic dendrite. And of course then there's this other   
58:23   
finding where an empirically grounded learning mechanism has been proposed in which forward and teaching signals are   
58:30   
delivered concurrently in the dendritic and somatic compartments respectively.   
58:35   
So there are a lot of ways to model this and of course you know we're not really interested in this paper in terms of   
58:42   
brain modeling or neural modeling. We're interested in optimizing the performance   
58:47   
of neural networks. So of course there is this difference in in in the two.   
58:54   
These observations suggest that there are a variety of plasticity mechanisms that would enable feed forward and   
59:01   
feedback pathways to interact during work. Indeed any testdriven learning will require mechanisms that serve to   
59:07   
modulate ongoing plasticity. So for example, reinforcement learning   
59:12   
requires the delivery of a global signal that can be thought of as a widespread third factor for regulating ongoing   
59:19   
synaptic plasticity. So this is interesting. They kind of bring up the global signal that results in   
59:25   
reinforcement learning. At the other end of the spectrum, a learning algorithms such as back prop work require a much   
59:32   
more highly orchestrated computation and delivery of third factors the individual   
59:37   
neurons in the hidden. By contrast, feedback alignment representing a surprising middle ground and that it has   
59:44   
many of the performance advantages of back problem, but it marketkedly reduces the complexity of the machinery for   
59:50   
computing and delivering third factors, which are these modulatory signals and feedback alignment that can be delivered   
59:58   
by random connections by one or many neurons in the backward pathway to one   
1:00:04   
of or many neurons in the hidden layer. and the modulatory signals themselves are computed on the basis of random   
1:00:10   
connections in the backward pathway. So if I'm understanding this correctly,   
1:00:16   
we're using uh stochasticity to sort of augment the system and and   
1:00:24   
correct errors. Um and this this sort of represents a middle ground between   
1:00:30   
backrop and then you know trying to build in all these complex mechanisms and third   
1:00:38   
factors. So even something like reinforcement learning would be hard to sort of add into the network but having   
1:00:44   
sort of a neural modeling paradigm also slow down our computations quite a bit.   
1:00:49   
So using, you know, stochasticity to sort of paper over that or at least serve as a a way to simulate that is is   
1:00:57   
kind of what they're suggesting, which is interesting because if you   
1:01:02   
you know, you kind of think about it, you can do a lot of things with randomness and and this this true in   
1:01:09   
biology but also true in simulation. So it's an interesting point uh you know   
1:01:16   
can you reduce all these mechanisms to sort of random matrix um I guess it works here um and so yeah   
1:01:25   
this just kind of goes through um some more insights   
1:01:30   
and think that's enough for that paper. So,   
1:01:35   
um, so that was the, uh, award winner for   
1:01:42   
this year, the Sinowski prize.   
1:01:48   
Um, any comments or questions? A well, a well named and deserved prize.   
1:01:55   
Yeah, I'm trying to think where I just saw his   
1:02:01   
name recently, but um anyway,   
1:02:10   
looks like Jesse's here. Jesse had an update or   
1:02:17   
Hi. Hi. Yeah. Um, I'll I can say more in maybe like I don't know five or 10 minutes,   
1:02:24   
but I I just got in and I appreciate papers. Um, but I have a few things to   
1:02:30   
say. Yes. Um, in in a couple minutes. Okay.   
1:02:36   
All right. Um, why don't we go over this paper way quickly? This is more of a philosophical   
1:02:44   
paper, something called variational propensities. Um, this is uh I don't know. I've been   
1:02:52   
waiting to kind of talk about this paper because I'm not really sure where it fits into what we're all we're talking   
1:02:57   
especially today. But I did want to go through and um kind of see what it was   
1:03:03   
about and you know maybe think about it in terms of not so much today but like some of the   
1:03:10   
things we've talked about in the last year. So this is from Cynthis which is a   
1:03:17   
philosophical journal. This is um called variational   
1:03:23   
propensities development and ultimate causes. This is by Christina Bayas.   
1:03:29   
Um and so this is you know we talk about variational   
1:03:34   
models in active inference variational bays and other types of things. And so   
1:03:40   
this is kind of relevant to that. Um, but it's it's phil it's a philosophy   
1:03:45   
paper, so it's maybe going to have a lot of like field specific arguments that   
1:03:52   
maybe we're not familiar with. So uh the abstract reads this paper   
1:03:58   
applies philosophical tools from the causalist statisticalist debate to the evo devo   
1:04:05   
idea of variational tendencies as propensities biasing phenotypic change.   
1:04:11   
It contends that variational properties are present in the statistical sense in   
1:04:17   
some populations dynamics models particularly quantitative genetic ones   
1:04:23   
providing ultimate variational explanations. It further argues that these properties   
1:04:28   
contrary to some recent views cannot be subsumed under natural selection.   
1:04:34   
Finally, it advocates for a causalist interpretation of these explanations where variational statistical properties   
1:04:41   
indirectly are referred to Evo Divo's variational propensities. So this has a lot to do with sort of   
1:04:48   
evolution of development and the philosophy of biology and you know from   
1:04:53   
the abstract it's a little hard to unpack but they unpack it in the introduction here.   
1:05:00   
So in the last 20 years a considerable amount of work in the philosophy of biology has been devoted to the   
1:05:07   
so-called causalist statistical debate which is discusses whether evolutionary   
1:05:12   
theory explanations as exemplified in the mathematical apparatus of population   
1:05:17   
dynamics models refers to the causes of evolution or something else. So this is uh   
1:05:26   
reviewed in this article here. Natural selection and its relation to fitness and drift is the main point of   
1:05:33   
divergence for uh contendants. So the whole argument is based on this   
1:05:39   
view of you know what population dynamic what what are the important features of population dynamics models   
1:05:46   
um you know is are we dealing with um natural selection and it's rel relation   
1:05:52   
to fitness and drift. how we'll be thinking about that. Causalists defend that natural selection is a cause of   
1:05:58   
evolutionary changes whereas statisticalists argue that it is an explanatory statistical aggregate of   
1:06:04   
causes acting at a different level. The bottom line is that there is some   
1:06:09   
causal story that relates to these population level explanations and that philosophers disagree about   
1:06:16   
whether the explanations represent the story which is embodied in causalism or   
1:06:21   
abstract away from it which is the uh story of statisticalism in order to   
1:06:27   
predict how the next chapter goes. It is not coincidental that population   
1:06:32   
dynamics models have captured so much attention from philosophers. These models are at the core of the   
1:06:38   
modern synthesis view of evolution constituting the main tool for explaining and predicting   
1:06:44   
microevolutionary changes on the basis of fitness differences between traits in a population. And when they say the   
1:06:52   
population dynamics models, they mean population genetics and the kind of population genetics   
1:06:58   
models um you might find uh where you know we we have Hardy Weinberg   
1:07:04   
equilibrium when we look at things like selection and drift and those where it's   
1:07:09   
a population level uh phenomena. And so we're looking at a population of   
1:07:17   
organisms as they're evolving. We're looking at their frequencies of alals   
1:07:22   
and how those change with natural selection or sometimes with drift   
1:07:28   
and you know this is kind of the basis for the modern synthesis of of bio of   
1:07:34   
evolution. So this is kind of the debate they're having. So, it's down in the weeds, but I wanted to give a little bit   
1:07:40   
larger context to it. Determining whether these models can accurately capture the causal components of this   
1:07:47   
evolutionary process and especially the role of natural selection within it is a vital aspect of how evolutionary biology   
1:07:55   
has achieved its ability to provide explanations and predictions. Despite this prominent position, however, the   
1:08:02   
bait debate has barely been applied outside its own limits. The causal or non-causal nature of selection and drift   
1:08:09   
in population dynamics models is usually taken as an isolated philosophical   
1:08:14   
discussion over what types of explanation evolutionary theory can provide. But contemporary evolutionary   
1:08:22   
biology is a multidisciplinary area where population dynamics models are only part of the story. The historically   
1:08:29   
received ideas that these models play a privileged role in the explanation of evolution is nowadays questioned by   
1:08:36   
conceptual approaches coming from very diverse domains within evolutionary biology. So you have paleontology,   
1:08:43   
epigenetics, ectology or evo. And then they kind of talk about the extended evolutionary synthesis which is   
1:08:51   
of course a number of different um you know perspectives that are kind of put   
1:08:56   
together in this extended evolutionary synthesis which purports to explain   
1:09:02   
things beyond the level of population genetics models.   
1:09:07   
And these kinds of uh models in in the extended evolutionary synthesis discuss   
1:09:12   
the scope of classical approaches to evolution particularly as exemplified by   
1:09:18   
populations dynamics models in light of these other research agendas.   
1:09:24   
So from a philosophical perspective many of the puzzles posed by the EES debate   
1:09:29   
eventually lead to scrutinizing what constitutes a cause of evolution. how to   
1:09:34   
classify evolutionary causes and instinct types and how these different types relate to one another.   
1:09:41   
So one one part of this is this discussion about reciprocal causation   
1:09:48   
and the ultimate approximate distinction in biology. So reciprocal causation is   
1:09:54   
where one thing causes another and that other thing feeds back to the to the original thing and there's this   
1:10:01   
reciprocal nature of causation. hardcape. There's also this issue of ultimate   
1:10:07   
proximate distinction. So what is the ultimate cause and what is the proximate cause? And often times those things are   
1:10:14   
not the same thing. And so you know these are these are things that people   
1:10:19   
have struggled with throughout the history of of biology, the philosophy of   
1:10:24   
biology and so forth. Ernst Mer famously divided the realm of biological causes   
1:10:31   
into those pertaining to the lifespan of organisms which he labeled proximate causes and those acting at the level of   
1:10:38   
populations and changing their composition through evolution which he labeled ultimate causes. So this is from   
1:10:45   
mayor in 1961. Accordingly, evolutionary biology was associated with the study of ultimate   
1:10:51   
causes while organismal causal processes were considered mostly irrelevant for   
1:10:56   
evolutionary explanations. So um this is where you know we have things that   
1:11:02   
happen in organisms and those things are you know we have say plasticity in organisms and those   
1:11:09   
result in changes in the organism but then it's a separate question as to whether that contributes to heritability   
1:11:17   
and the inheritance of those sorts of changes in plasticity or other things   
1:11:22   
that are going on within the organism. So you know there's this difference the   
1:11:28   
sort of approximate causality, you know, what might uh impact plasticity within   
1:11:35   
an organism versus this ultimate causation. What impacts plasticity   
1:11:40   
within a lineage? So those are two separate questions, two separate causes.   
1:11:46   
uh accordingly evolutionary bios associated with the study of ultimate causes or organismal cause causal   
1:11:53   
processes were considered mostly irrelevant for evolutionary explanations. However, some non-class evolutionary   
1:12:00   
areas emphasize the impact of organismal level processes in determining evolutionary phenomena in turn   
1:12:07   
challenging the meaningfulness of such a separation in organismal and evolutionary process.   
1:12:14   
Um, interestingly, despite a lack of overlap in the discussions, this is   
1:12:19   
precisely what is at stake in the causalist statisticalist debate with respect to selection, fitness, and   
1:12:25   
drift. Those denying a causal nature nature to selection and population dynamics explanations, we would end the   
1:12:33   
basis of an alleged failure to relate the real ecological causes determining differential survival and reproduction.   
1:12:40   
In other words, statisticalists believe that evolutionary changes are not caused by selection and drift as in population   
1:12:47   
dynamics models, but by the ecological and developmental organismal processes   
1:12:52   
underly. But in terms that are more familiar to the EES debate, statisticalism considers   
1:12:58   
that evolution only has proximate causes, even if one can build good ultimate non-causal explanations of the   
1:13:06   
evolutionary process through population dynamics. Causalists on the other hand believe   
1:13:13   
that evolutionary causation can also be depicted at the population level and   
1:13:18   
therefore that notions such as selection and drift represent genuine ultimate causes either autonomous or grounded on   
1:13:26   
individual level causes. So these are distinctions that are made in the philosophical literature. And um   
1:13:34   
you know it's kind of one of these deep in the weeds arguments. It's hard to sort of disentangle but basically um you   
1:13:41   
know it's it's not really easy to sort of say what the right answer is but um   
1:13:47   
it is definitely this sort of debate that can inform other things. So she gets into evolutionary developmental   
1:13:54   
biology and kind of thinking about how th that field sort of brings together   
1:14:01   
these two forms of causation, the proximate and the ultimate. So you see in development you see proximal   
1:14:09   
causality. You see causality within the developmental process, how it unfolds,   
1:14:14   
how it's buffered, how it exhibits this sort of generative capacity. And then   
1:14:20   
you see evolution which is this ultimate causation which uh does things to   
1:14:26   
influence uh development and so forth. So there's this nice interaction in   
1:14:32   
evolutionary developmental biology that we don't see in other areas and it can maybe bridge the gap of this argu or   
1:14:39   
this this debate. Um, and so in a nutshell, the received   
1:14:45   
picture of evolution assumes that genotypic variation is random and left aside the emergence of phenotypic   
1:14:51   
variance, focusing on how natural selection and drift shape the relative frequency of extent ones and assuming   
1:14:58   
that mutational impacts have negligible or at least undirected effects on this process. How such a frequency based view   
1:15:06   
of evolution can account for the emergence of phenotypic changes is known as the problem of variation.   
1:15:12   
So what they're talking about here is that in your population genetics models oftent times what we're looking at is   
1:15:18   
the frequency of variance or the frequency of alals and that doesn't really explain what's going on with the   
1:15:26   
generation of phenotypic variants which are often the products of many alals and   
1:15:32   
the frequency of those variants uh don't necessarily map to the frequ frequency   
1:15:37   
of alals and so we need to have this um you know this This is a problem of   
1:15:43   
variation or how do we interpret all this variation in the model and then we're dealing with two   
1:15:49   
different levels of causality on top of it. One main contribution of evo to   
1:15:54   
evolutionary biology is a study of developmental biases and phenotypic variation explaining the origin and   
1:16:02   
nature of phenotypic changes in turn contributing to solving such a problem.   
1:16:08   
Uh while recent works have indeed explored the connections between selection as an ultimate cause and its   
1:16:14   
approximate lower level determinance, the problem of developmental biases and phenotypic variation remains unexplored   
1:16:21   
from this perspective. So developmental biases are these changes in in phenotype   
1:16:28   
over development and how uh you know the same set of alals can result in   
1:16:34   
different phenotypes based on developmental processes. So in this paper I filled in part of   
1:16:41   
this gap by applying some aspects of the causal statistical debate to the EES   
1:16:46   
discussion on developmental biases and phenotypic variation. I first review the   
1:16:52   
main aspects of the statisticalist debate and situate the problem of developmental biases with respect to it.   
1:16:59   
Then I show that ultimate explanations make reference to developmental biases with a quantitative genetics idea of a   
1:17:06   
phenotypic response to selection. Finally, I discuss the implications of this for a causal understanding of   
1:17:13   
evolutionary models and argue that it makes sense to speak of developmental ultimate causes, a distinctive   
1:17:20   
contribution of quantitative genetics in Evodo to the conceptual foundations of   
1:17:25   
evolution that have not been acknowledged so far. So that's really interesting that you know in this model   
1:17:33   
ultimately where she's going with this is to talk about developmental ultimate causes and to frame this sort of   
1:17:40   
approximate ultimate causal uh framework in in terms of evo and then thinking   
1:17:47   
about the statisticalist versus causalist debate. thinking about sort of   
1:17:53   
the standard population dynamics model maybe is not simply a statistical   
1:17:59   
construct but as a causal construct. And of course we know the difference between sort of statistical   
1:18:05   
uh models and causal models is that statistical models especially ones that   
1:18:12   
are models of correlation aren't necessarily causal. They don't necessarily tell you the cause of   
1:18:17   
something. just simply tell you what the structure of something is. Pausal models are quite something else and you know   
1:18:24   
they usually involve some set of interventions or something like that.   
1:18:30   
So this is kind of um you know kind of talking about this   
1:18:35   
debate. Um and so this is kind of uh   
1:18:42   
Elliot Sober um basically uh took natural selection,   
1:18:48   
migration, mutations and genetic drift as forces of evolution acting on   
1:18:54   
populations and defined these as source laws of evolutionary change. And so you   
1:19:00   
see source laws all the time in theoretical ecology which explains the ecological interactions giving rise to   
1:19:06   
natural selection and drift uh which you can also have the laws of genetic transmission   
1:19:13   
uh explaining the occurrence and inheritance of mutations. In this picture, the models of population   
1:19:18   
dynamics or consequence laws or those that describe the system and forces are applied to it predicting the dynamics of   
1:19:26   
populations once ecological inheritable factors are considered. Although it is not the main current   
1:19:32   
causalist position, the forces analogy first made explicit the idea that population dynamics models represent the   
1:19:40   
causes of evolution. This is what this causalist statistical debate has considered for more than 20 years now.   
1:19:47   
How much of actual causes of evolutionary change or source laws in sober's terms are in the theoretical   
1:19:54   
framework sustaining evolutionary predictive models? So consequences from   
1:20:00   
the point of view of the uh extended evolutionary synthesis debate the dispute concerns whether there are   
1:20:06   
ultimate causes that population models refer to. So this is kind of the argument and then   
1:20:14   
she talks a lot about sort of these causalist arguments in the framework of population dynamics and how they can   
1:20:21   
sort of maybe improve our model of population dynamics.   
1:20:29   
And so going through and so there are a lot of threads in this paper and you know if you're not familiar with the   
1:20:35   
area I'm sure it's hard to follow but um you know there is a lot of stuff here   
1:20:40   
it's really interesting especially if you follow these debates uh where you're looking at   
1:20:47   
you know uh sort of the sources and causes of evolution.   
1:20:53   
Um one point here uh she starts talking about genotype to phenotype maps and   
1:21:00   
this is an important tool for looking at the relationship between genes and phenotype   
1:21:06   
and the way she views genotype phenotype maps or as an abstraction of   
1:21:11   
developmental processes. It associates phenotypes to genotypes accounting for   
1:21:16   
the way phenotypes change over genotypic changes and thus for developmental biases. These maps are modeling tools   
1:21:24   
that abstract away from the specificities of the developmental mechanisms actually connecting genes and   
1:21:29   
phenotypes and thus allow for explanations with a different scope than lineage explanations. So this whole   
1:21:36   
section basically summarizes the sort of formal tool that you can use to look at   
1:21:44   
causality from these statistical distributions of al frequencies. So if   
1:21:50   
you have a genotype where you have a bunch of alil frequencies and they're constantly changing due to selection or   
1:21:56   
drift um you know that doesn't tell you a lot about the phenotype in of itself.   
1:22:02   
Um but you can have this genotype to phenotype map where you say okay there's   
1:22:07   
this relationship between the state of these alals and what's happening in the phenotype and this process all you know   
1:22:16   
when a change in some set of alle frequencies will result in a change in the phenotype or the way the phenotype   
1:22:23   
is presented. And so this is something that um is you know a tool we can use to   
1:22:29   
sort of uh take go from that purely statistical interpretation of population   
1:22:35   
dynamics and move towards a more causalist view of populations.   
1:22:42   
Um what's also interesting here is that she starts to get into um you know   
1:22:49   
thinking about the emergence of variance. So these explanations also account for the emergence of variance   
1:22:56   
but they do so by studying the biases development imposes on the production of phenotypes in populations. And so what   
1:23:03   
tends to happen in genotype to phenotype maps is you get these variational   
1:23:08   
tendencies. So the idea is that one can use these genotype to phenotype maps to   
1:23:14   
study how likely a certain phenotypic change will be given the developmental   
1:23:20   
structure of a trait and the mutational environmental inputs it may receive.   
1:23:26   
And so developmental systems differ in the way they can generate phenotypic variation under such inputs and their   
1:23:32   
tendencies can be associated with general properties of the genotype to phenotype maps represented. Some systems   
1:23:40   
tend to retain their phenotype under mutational perturbations represented in a mutationally robust genotype to   
1:23:46   
phenotype map that maps many genotypic variants of the same phenotypic outcome.   
1:23:52   
So you have this phenotypic buffering that you see in development where multiple genotypes can represent the   
1:23:58   
same phenotype. Contrarily other maps are very variable associating different phenotypic   
1:24:05   
variants to genotypic changes. So you have these you know clear relationships   
1:24:11   
between the frequency of alals and changes in the phenotype. There's no buffering. It's just maybe like a   
1:24:18   
statistical purely statistical mapping to the phenotype. The idea though here is that there's a   
1:24:24   
lot of variation in that. So you get these variational paths from genotype to phenotype. And that's kind of what she's   
1:24:32   
getting at here is that you can build these variational structures   
1:24:37   
as a from a consequence of having these genotype to phenotype maps and   
1:24:43   
furthermore as a consequence of viewing um developmental biology as being both   
1:24:49   
approximate and ultimate in terms of its causation.   
1:24:55   
So that is all for that paper. Um a little tough maybe to through, but I   
1:25:00   
think maybe there's some lessons learned. Okay. So, um I don't know. Did Morgan   
1:25:07   
have anything you wanted to add to say?   
1:25:15   
Um it's it's been a long time since I've   
1:25:21   
I've looked at um   
1:25:28   
EES material. Um   
1:25:34   
I I definitely you know this um this what is intelligence book uh that   
1:25:46   
you know has has a lot of interesting   
1:25:53   
uh I mean again it's it's it's a life but it's very   
1:26:00   
Um it's very population genetics.   
1:26:06   
Yeah. As well. It's a very population genetics view of of artificial.   
1:26:11   
Okay. Yeah. Yeah. So like like you know I I I think a very   
1:26:19   
um a very reasonable uh title for for their paper was is   
1:26:27   
computational life. Right. Right. Like that's the Yeah. Um so   
1:26:35   
you know certainly familiar with with some of that debate.   
1:26:40   
Um I I I I really like   
1:26:47   
u I I want to see models. Yeah.   
1:26:54   
you know, like like, you know, it's like, okay,   
1:27:00   
uh these   
1:27:06   
Yeah. I I want to see models. I I I I fear I fear um causes.   
1:27:15   
Yeah. Or like like I I I Yeah. It's been so   
1:27:22   
long. I I can't even remember what an ultimate cause is.   
1:27:29   
Do we ever deal with ultimate causes? Well, I guess the idea of ultimate cause   
1:27:34   
is like if you see something that happens over and it's it's relative to   
1:27:39   
the approximate cause, right? So if you have something that happens in a lifetime and something that happens over   
1:27:46   
like a thousand generations, the ultimate cause is what happens after a thousand generations. Whereas   
1:27:52   
approximate cause might be happening in a single generation or in a single period of evolution. like   
1:27:58   
you might have some burst of uh diversity that occurs in nature like you   
1:28:05   
know like the dinosaurs and then over a long period of time they're sort of inconsequential to the tree of life.   
1:28:12   
It's kind of like an offshoot of the tree of life. So like you know that's that they're two different things there.   
1:28:19   
Um, no. Sure, sure, sure. It's one of those things where it's just like or you know,   
1:28:26   
you can always pause at a a more ultimate cause. Yeah. Yeah. you know. So, yeah.   
1:28:34   
But uh uh that that's that's my main you know like I really   
1:28:41   
I mean one of one of the bits that I like about this this book or you know   
1:28:49   
which again is kind of a summary of of either his researcher or others   
1:28:57   
is the is the   
1:29:03   
It's the simulated basis you know um for the for the discussion you know   
1:29:11   
and um   
1:29:16   
as well as like you know or certainly another thing that I I was   
1:29:23   
trying to get across in the the first reading group about it was like you know   
1:29:30   
if you if you only think of to to some degree, you know,   
1:29:38   
we don't think about the diversity of of genomes   
1:29:43   
enough as well, right? Yeah. And and you know, in in the same way   
1:29:52   
that it's interesting to go what's the um   
1:29:58   
what was the Paul Cizzic um book that or like remember the reading group they did   
1:30:04   
a couple years ago. Yeah. And what was the book reading that like   
1:30:09   
you know anyway it was like cross species nice charts evolutionary right   
1:30:15   
and um we should be thinking about the genomic   
1:30:20   
version of it. Right. Right. And it and it should include plants. Right.   
1:30:26   
Single cell organisms and plants. Right. Right. Because because even though we   
1:30:32   
just thinking about you know uh uh anatomical form   
1:30:40   
uh what what ESS I mean sorry EES   
1:30:46   
is getting at is is is much more kind of fundamental right and   
1:30:55   
you know again it's like trying to get at all the mechanisms that are that are   
1:31:01   
at play there, you know, and just like how much duplication and and other   
1:31:06   
things where it's just like, you know, I I'd still really love to come back. I I think I might need to ask   
1:31:12   
you for a paper on cognitive viology.   
1:31:19   
Okay. um you know getting it at um again like you   
1:31:25   
know we've got all this genomic material that's that's viral and and um and yet   
1:31:32   
like like super you know it's viral but it's it's   
1:31:39   
anatomical manifestation or its phenotype   
1:31:44   
but like like super specific like like either function   
1:31:50   
or like like structures, you know, and and you know that that wasn't like Yeah.   
1:31:55   
Anyway, it's just very remarkable and very hard to um to map with language,   
1:32:02   
right? And it's just like I I just want to see I want to see more of his computation.   
1:32:08   
Yeah. you know, because he's got this I I haven't seen how   
1:32:16   
I mean I I'm I'm sure I'm trying to think what's the big what's the big EES   
1:32:21   
tome. Um uh   
1:32:28   
I mean there's a couple people that that are widely cited when you kind of you   
1:32:33   
want to add a reference. Right. Right. Well, I think they've had book collections and then there are other   
1:32:39   
books and they definitely had like books that have like a chapter from everybody. Okay.   
1:32:44   
Um but like you know where does where does um   
1:32:51   
uh symbiosis come in or you know how is that particularly discussed?   
1:32:59   
And and again in the um   
1:33:07   
yeah so I I you know you know me I just I want to see more of the Gecko papers   
1:33:14   
like you know like or you know I don't even know if gecko is the other you know   
1:33:20   
is um   
1:33:26   
you know gecko might be too You know, like too conversational and not enough. Yeah.   
1:33:32   
Not enough a life. Yeah. Too applied. Yeah. Gecko is usually for developing genetic   
1:33:37   
algorithms, you know. It's it's you know, whereas a life is still   
1:33:45   
like it isn't isn't focused on isn't focused on evolutionary theory enough.   
1:33:52   
Right. Right. You know what I mean? Like   
1:33:57   
Anyway, but you know, like like really interesting. Um, and um, you know, I I   
1:34:07   
I'm on two minds with with Dennis Noble right now, but you know, he he he was   
1:34:14   
just um he just spoke on um Michael Evans channel   
1:34:21   
or you know, which is part of the um   
1:34:27   
I forget what he's calling his platonic platonic symposium thing or whatever.   
1:34:32   
Yeah, but it's like it's like platonic spaces or like like it is, you know, it's like   
1:34:40   
platonic something symposium, I think. Anyway, um you know, he he he had no   
1:34:49   
speaking, you know, just the the I think um   
1:34:55   
Professor Dave explains does a pretty good tear down of of a lot of a lot of noble   
1:35:03   
stuff. Um, but if it's like, you know, like with   
1:35:09   
nobles, this is like, you know, he he he brings out some good criticisms   
1:35:15   
but doesn't necessarily Okay. There it is. Yeah. Um,   
1:35:23   
he he he doesn't do enough commentation. Yeah. Yeah. That's always the problem   
1:35:28   
with like philosophy and and getting into some of these debates is I know there's like computational   
1:35:34   
philosophy but it's not uh and then people the people do a lot of the computation don't think about the phil   
1:35:40   
philosophical issues and it's really kind of hard to bridge the two and get it published somewhere where people can   
1:35:46   
see it. So yeah. Yeah. I I I've been I've been um   
1:35:55   
I I've I've definitely been warming to this what is intelligence book.   
1:36:00   
Yeah. And and he's one of he's one of the speakers too, right?   
1:36:05   
Yeah. Yeah.   
1:36:11   
I just I just I certainly just saw the book. Yeah. Where's that one?   
1:36:17   
Yeah. Yeah. Yeah. Yeah. What's it called? Okay. Yeah. Yeah. Yeah.   
1:36:24   
Yeah. Yeah. Yeah. How long is this? It looks really thick.   
1:36:32   
It It is, but it's not um   
1:36:40   
but it's small pages. Okay. Well, yeah. And um   
1:36:46   
so uh yeah I I I don't have its its actual stats but you know the other   
1:36:54   
thing being that like a lot of it is is really   
1:37:00   
you know it's sum summarization of of research which you know I I would say   
1:37:08   
we've we've probably covered some of this in more depth   
1:37:16   
uh you know especially especially when he's going through um this kind of genetic   
1:37:24   
phenotype and and yeah but it's it's got a big um   
1:37:32   
well still I got I got to finish it before the 18th.   
1:37:38   
Oh it's a library book. Well, we're doing the second second part.   
1:37:44   
Okay. But just getting into the kind of, you know, consciousness as a as a   
1:37:53   
reflective self-prediction. Is the 18th when the the the next event   
1:37:58   
is or? Yeah. Yeah. For the for Lemon's thing or the other one? No, no, no. Our ours.   
1:38:06   
Yeah. Yeah. Yeah. I mean, it's like in person. Well, it's it's hybrid. It's hybrid. Um, but we will be we will be   
1:38:14   
it's um Tom um graciously moved the the   
1:38:20   
the in-person meetings at the tower. Nice. So   
1:38:27   
that's uh it will it would be fun to host. Yeah.   
1:38:32   
And uh trying to think if there was anything else. I feel like there's something there for like an eventual   
1:38:39   
computational philosophy club semi-echapto big group. Like I'd like to see all like I'd like to see everybody   
1:38:47   
like even like a Frontier Tower and then that crew and then and then us here as a   
1:38:53   
as like a big a big something like that's a little bit because I'm in the mode of trying to organize such things   
1:39:00   
and like doing reading groups but then also like you know we talk about the more like synthetic time or the the   
1:39:06   
whatnot. I think that would be fun. I'm I'm open to it. I don't have anything to suggest, but like this sticks out to me.   
1:39:15   
Yeah. Yeah. Yeah. Absolutely. Absolutely. I mean, I I you know, I want to get a   
1:39:22   
better sense of um Baron Holtz's   
1:39:28   
work, you know, like like I I I've I've just never done um   
1:39:34   
I think he's putting out more stuff slowly like recently and I haven't gotten to like watch it or or look at   
1:39:41   
it, but yeah, like the same thing about like computation. It's one of these things where it's just like I I need um   
1:39:49   
I need to see some papers. Yeah, exactly. Like like and and you know again   
1:39:58   
computational philosophy. Um I'm going to lean on that word computational,   
1:40:04   
right? And I think I think between that and I know I know Addie who's   
1:40:11   
has a lot of plans to do things in a um   
1:40:18   
biologically grounded in like like pushing certain parts of biology in a in   
1:40:23   
a particular direction relative to his interest. Um Baron Baron Holtz with was   
1:40:28   
with is is with the LLM stuff and language and I think Addie Addie is trying to also   
1:40:35   
I think he's really trying especially in the the next few months and the year ahead I think he's trying to go into a sense of like let's talk about biology.   
1:40:42   
So, a lot of the things that came up here about like like like like some of the oh a Paul Kais like paper on this   
1:40:49   
and heard of that. I don't know if he's quite that deep into it yet, but I could   
1:40:54   
see that being like a good a good thing that may have some energy around that.   
1:41:00   
Um, so I gotta say is is um Google Scholar is   
1:41:06   
not um is not what I would have imagined. Who's   
1:41:12   
uh Ellen Baron Holtz? Oh, like what is his Google Scholar?   
1:41:18   
I mean um you know I'm seeing like visual fixations during processing of timecompressed audiovisisual   
1:41:24   
presentations. Um mice recognize 3D objects from   
1:41:29   
recalled 2D pictures. Uh   
1:41:34   
let's see. Um   
1:41:40   
the role of bio inpired modularity in general learning.   
1:41:46   
Um um   
1:41:51   
that's kind of interesting. A controlled investigation of behaviorally cloned deep neural network behaviors in an   
1:41:57   
autonomous steering task. A lot of a lot of visual cognition.   
1:42:02   
Yeah. I mean, do you mean that relative to like the LM focus or like   
1:42:08   
Yeah. it it's been with the LM, you know, being very   
1:42:14   
focused on the the uh kind of recursiveness.   
1:42:20   
Um, it's been interesting to kind of see that because it's sort of like it's almost like a different an inversion or   
1:42:27   
because I I don't I don't really like using this phrase, but it just came in my mind so much from other things   
1:42:33   
recently like an uno reverse card in terms of like Gary Marcus and LM's are,   
1:42:40   
you know, no good. And now I think he's really trying to use his LM structure to   
1:42:50   
more so get at language and and it's been interesting that he's a part of what his take on I get I get sort of   
1:42:56   
philosophically some of the language like okay let's just look at lang interesting way to think about his work   
1:43:01   
is like language whose problem is the mind body problem and it's like oh it's language's problem in the sense of   
1:43:08   
language is sort of doing its own thing in the rules language are not necessarily the same as like, you know,   
1:43:16   
biology or whatnot. And I kind of get that and I do I want I want to see more where he's going with that. But yeah,   
1:43:21   
it's sort of like where where where are you kind of drawing the lines about   
1:43:27   
like embodiment and competition and everything else. And like I I I don't   
1:43:32   
know some of those. I don't know where his like uh I get a sense of the direction he's   
1:43:38   
trying to go in still, but I don't I don't know like where he's drawn the lines and some stuff. So, we'll have to to wait and see.   
1:43:45   
Yeah. Yeah. I mean, that's that's just what what's needed to be able to   
1:43:51   
have a a good discussion with them about it, right? Um and uh   
1:43:58   
hope hopefully these things exist. um um or you know like like but but then there   
1:44:05   
are also texts like these like like like um blazes which are   
1:44:14   
you know a very large synopsis   
1:44:20   
of of a lot of work you know which gives us a lot of material to discuss. I mean   
1:44:25   
like like we could be going much slower through this book and still have very fruitful conversations.   
1:44:31   
Yeah. And is this a rating group is that what the book the rating group is about right now or has been   
1:44:37   
it it is it is you know like like historically   
1:44:42   
we've done um a book and a paper a book and a paper. Um but this one um you know   
1:44:52   
it is such an overview of such a large amount of material. Yeah. Plus plus I think there's some really I   
1:44:58   
think there really are some great if it is hybrid. When is that one?   
1:45:05   
So so December December 18th um it would be 10 o'clock your time.   
1:45:15   
That's fine. Okay. But very happy to add you. I mean know like   
1:45:20   
Yeah. Oh yeah, please do. Even if I can't make the whole thing, I'll try like I will try to do it. I feel like I   
1:45:26   
feel like I've just stepped into and I'll I'll if we have time, I'll try to I'll say a few things soon about my end   
1:45:31   
of stuff. I feel like it's it's an era of like, oh, like I'm I'm I'm finally   
1:45:38   
functioning and then the year's ending and a lot of stuff, but then all like these these reading groups and these other smaller like things in between   
1:45:47   
full events and nothing are popping up more that I can do and that I'm I'm h   
1:45:53   
like I'm kind of coming out of that and doing that even though something's already this year. So, I'm very happy to to do that.   
1:46:02   
Yeah. Yeah. Yeah. Um I don't want to   
1:46:08   
if we have more to say about that, we can. But I I know this. Did you want to sing Bradley or how much did you want to   
1:46:14   
split up the time that we have left? Um well, I think probably we can finish up with an update from Jesse.   
1:46:22   
Um you'd like to Okay. Talk about what you've been up to and Yeah. Um okay. So, I will I will do   
1:46:30   
that. And I know we we only have like I don't know 10 15 minutes or so at most.   
1:46:36   
Um I'm trying to figure out where to begin.   
1:46:41   
Um because I can show some things and I don't I can't I don't have like a good visual for other things. Basically, I'll   
1:46:48   
I'll I'll start with some uh general GoPro stuff. Um   
1:46:56   
the the newest thing is basically this which is a reading group. Um and I hope   
1:47:02   
to compress some papers and also maybe a little bit of what I what I'd like to do   
1:47:08   
and sort of do here. Um uh part of how this came about is um   
1:47:17   
Avery Avery is sort of venturing out into the realm of of doing   
1:47:23   
things a bit more and and which is I'm very happy for and I wanted to support   
1:47:28   
that. But also there's this overlap with things. Avery's interests are kind of in   
1:47:35   
some game development, some simulation, a lot of the personal um narrativity and   
1:47:40   
and that stuff and plot twist type things. That's that's one thing. Um,   
1:47:48   
in Plot Twisters Proper, we've been having some regular meetings and building up some steam and very much a a   
1:47:55   
nod to the the classic Bradley line of um momentum versus progress or progress   
1:48:01   
can be more, you know, sometimes momentum and maintaining it is is is   
1:48:07   
just vital. Um, even though progress may look like this or that along the way. Um   
1:48:13   
and we've maintained momentum through the summer. Um and some really interesting things that come out from   
1:48:18   
that. Uh and the the sort of the unified piece here which I'll very briefly   
1:48:24   
mention is this paper uh which is out of MIT out of the fluid interfaces lab at   
1:48:30   
MIT media lab. And this paper has sort of come up in   
1:48:35   
threeish different different spaces now. Um,   
1:48:42   
but I'll get back to that in a moment. This this this group and I kind of want to put ethics   
1:48:49   
in here or something after our first we had a a very a very brief preliminary well a very preliminary meeting. It   
1:48:56   
wasn't brief, but it was me, Avery, and another person named Molly Hugh uh kind   
1:49:02   
of went over our ideas about what to we want to cover in this group. We have, this isn't really a great outline   
1:49:08   
because it's not updated. But we we basically wanted to talk about you know some papers our background motivation.   
1:49:16   
We talked about the RAF paper which we'll talk about soon and and some different interests and we'll kind of cover papers in this space. Avery's   
1:49:24   
maybe a bit more um interest in game development and like   
1:49:29   
implementing some things. Mali is a bit more um   
1:49:34   
I don't want to say ethics focused but like what does it what what do these technologies mean even for like studying   
1:49:40   
elements of like uh cognition like like like co I don't want to say cognition   
1:49:47   
and consciousness but how these technologies relate to our internal   
1:49:53   
um structure and functioning so kind of almost a deeper phenomenological   
1:49:59   
plus human computer interface and she has a background in like some human computer interface things and and how   
1:50:06   
machines and and trust relate and stuff like that. Um, so this is happening like this is this   
1:50:12   
is kind of getting off the ground and I kind of I inherently see it as sort of a part of like you know um society as a   
1:50:21   
technology group and then I wanted to open it up here and kind of you know now that we kind of have a little bit more   
1:50:27   
sense about what's going on just you know um I want it to   
1:50:34   
be an open thing that if if we want to merge merge it with anything in orthogonal lab or say hey you know I I   
1:50:42   
would like to invite other people to that if they want to do that as sort of a natural um it's basically society   
1:50:49   
ethics technology reading group with a little bit of gamedev and a little bit of ethics focus on this like the the the   
1:50:55   
dig digital a digital the experience of certain digital things   
1:51:01   
like it it can tie into VR stuff as well um it's not really it's not really not   
1:51:07   
specific to a particular hardware instantiation of it. Um, but all of   
1:51:13   
those things are covered. So I kind of see it as a natural Joe orthogonal lab and I even I even   
1:51:19   
kind of because some of the stuff has come up already in plot twisters. I kind of want it I would ideally like it to be   
1:51:26   
sort of a a Joe Pro orthogonal lab plot twisters combined reading group session   
1:51:32   
thing particularly led by Avery and myself. And and honestly, if I can center Molly to I feel like Molly's this   
1:51:39   
like actually great counterweight to things that we well we and and some of   
1:51:45   
the philosophy and some of the phenomenology um are interested in too. Uh so I kind   
1:51:50   
of would like to have that be sort of the main if you will co-hosts of the discussion   
1:51:57   
um and go from there. Uh but but but we'll see. It's not I'm not entirely   
1:52:03   
we're just getting it started. But I wanted to do it um more ahead and particularly for Orthogonal too. Like I'   
1:52:09   
I've ga mentioned like hey like Avery is just getting you know kind of coming out of a period of not doing a lot but   
1:52:17   
there's they are interested in some of the they're they're experimenting with some of their own   
1:52:22   
game development stuff and their own theories and and and implementing into into those spaces. So I'm like hey like   
1:52:28   
we have some experience with some of the simulation work here. So like let's try to overlap that as much as possible. So   
1:52:35   
that's that's one thing that's happening. Um I'll go into some of the specifics here   
1:52:42   
um about this. Um it it it   
1:52:50   
sort of came about uh you know Avery said this is a quote that I captured. I'm passionate about   
1:52:57   
ways that digital narratives can be used to enable flourishing a lot. reminded me of the invasing humans with   
1:53:04   
AI pat flourishing but I don't think they knew that at the time as part of this I'm   
1:53:10   
interested in exploring both the socioultural considerations behind technology did as well as the creation of site models on aging and the   
1:53:17   
effective implementation towards technology at end okay nice um oh also   
1:53:23   
like um I don't know it's um if Jen will be a part of the meeting's   
1:53:30   
proper her all the time, but I I've kind of made a social work kind of spotlight uh because J's a social work student and   
1:53:37   
I I I wanted to bring her into this because one of the things that's um coming up all the time and and this is   
1:53:43   
can be a conversation for a different time, but it's like in in the training of   
1:53:49   
someone learning to be a clinical social worker or whatever. It's a very interesting use case of someone who is thrust upon both people dealing with   
1:53:56   
these AI relationships and in the training of of of someone in the   
1:54:02   
graduate program. interesting situation where as a m as a master student you're   
1:54:09   
kind of proh prohibited from using AI to make your stuff but there's also an   
1:54:16   
instance of uh grading through AI is is is you're told   
1:54:24   
the TAs are using AI to grade your papers and give you feedback and um you   
1:54:31   
in a mandatory course uh which you cannot get out of and you cannot opt out   
1:54:37   
of the pilot program. You are exposed to a pilot program for a a GTP like agent   
1:54:43   
that's used to use for your training as a developing professional   
1:54:48   
uh with with a particular you know early stages model of GTP based agents uh that   
1:54:56   
that you're supposed to interact with and learn from how to to do your vocation on other other people on our   
1:55:01   
Hebrew beings. So, so sort of like you're on the business end of of the AI,   
1:55:06   
uh, but you're not going with any knowledge about it. Um, and that's something that we we we talked about that today and it's an ongoing   
1:55:12   
conversation, but I feel like it's a fun it's a fun mix here because we have um   
1:55:19   
Avery who's very interested in this, you know, theory and art and game development and and meaning and Molly   
1:55:26   
who has this this background in like doing   
1:55:31   
doing technology and being part of like government implications and and different different different SEC   
1:55:38   
different people dealing with the impact of technology. Then you have Jenna who's doing like the social work both like and   
1:55:45   
is a current master student who's learning to deal with people that are   
1:55:50   
having to deal with technology and then and using herself like this is a really interesting mix in that space and I and   
1:55:57   
I I kind of wanted to keep keep elements of that in the group over time.   
1:56:03   
Um and obviously you all know my interests um and my you know eccentricities.   
1:56:09   
Uh so just a few things to to mention out of this. Um the first thing we're   
1:56:15   
going to cover is is messed it up here. um this paper. Um and   
1:56:24   
also also a slight note ironically u before I get on this paper uh this this   
1:56:30   
came up um one one person from platish is is at the Oxford internet institute   
1:56:36   
still and um this is a separate reading group. This is the this is the games and   
1:56:42   
technologies interest group uh which has kind of been on hiatus for a little bit. like totally unrelated to me making this   
1:56:49   
on the group like oh hey by the way I might be starting this up again in the next year so the next few months this might come out uh which is very much   
1:56:56   
even more uh exploring uh games industry XR VR all those things um and we might   
1:57:03   
have sort of an invite to to attend some of that um a lot of you know cool people Amanda Curs's plat and and many other   
1:57:11   
cool people here um but but that may be sort about another related thing that   
1:57:17   
hopefully we you know interact with somewhat maybe crosspollinate with a little bit. Um, I mentioned this, um,   
1:57:25   
very briefly. I'll mention this is actually a really interesting discussion between Bnee Brown, um, who's, you know,   
1:57:32   
kind of I almost pops like, but but not really like she actually I've kind of been not followed her at all for a   
1:57:38   
while. And I actually, this is actually a really really really really interesting discussion between Bnee   
1:57:44   
Brown and Kate Crawford, uh, who like Atlas of AI and all this other stuff. also like the this amazing website. Um   
1:58:01   
Empires uh for map lovers. This is just a cool a cool a cool thing like across   
1:58:06   
eras timeline and it's sort of like different communications and education   
1:58:13   
and stuff. um very like you know frontier map like all the cool stuff. Um   
1:58:20   
it's a nice effort. It's imperfect but it's a nice like you know collection for the last 500 years or so. So shout out   
1:58:27   
to Kate Crawford for that. But this discussion was actually quite interesting um and quite relevant and   
1:58:33   
and um more about that some other time. Um, this paper came up a little bit in   
1:58:40   
in the discussion group and with Jen about like divorces and this sort of like these advanced things about like AI   
1:58:46   
relationships, both chat bots and all the other stuff and how they're affecting real people and these   
1:58:51   
pressures on all this stuff. More some of the time. But the center point for right now what I'll conclude on it is   
1:58:58   
this paper um which is I think it might be easy to do this too   
1:59:05   
just for some like where does this paper come from? This paper comes from uh   
1:59:11   
oh wait it's not showing up here. Um well   
1:59:19   
yeah you guys probably know enough anyway but but I I I I showed this paper   
1:59:25   
to someone like oh yeah this is really nice like it's a nice paper because it has some grounding in and different   
1:59:30   
stuff and I'm like yeah well Rosalyn Picard is sort of you know the captain   
1:59:36   
of effective computing in that way and Patty Mays has been a long you know a long time person at fluid interfaces at   
1:59:43   
MIT lab and Mel Kim like is doing a lot of really cool stuff also had a paper at   
1:59:48   
Nurip about like interpreting EEG data in a certain way which is pretty cool   
1:59:54   
but this paper is very much this um what's cool about it I'm just going to   
1:59:59   
jump into it reflective agency for empirical framework for AI mediated self   
2:00:05   
systems and I'm not I'm not going to go through it I mean jump in and just get some of the parts we're interested in   
2:00:11   
here or like related stuff and they do try to ground it in philos philosophy in a nice way uh mediated selfhood uh   
2:00:19   
phenomenology they situate phenomenology here with H highiger stuff and uh indies   
2:00:26   
I think um yeah Ed and uh they go this   
2:00:32   
they get a little bit of you know Aristotle virtue ethics stuff they get these principles of of sort of what's   
2:00:39   
what's going on um and they try to develop this framework that's around um   
2:00:46   
the principles Then also these tensions like they they try to mitigate these tensions about or not to try to address   
2:00:54   
or or identify these tensions about like user between user autonomy and systemic guidance and and and try to put that out   
2:01:01   
like what is someone's experience doing and how it impacts on you know things like phenomenology and overall the sense   
2:01:06   
of how someone's narrative is being developed. the kind of the rough rough   
2:01:12   
one or two sentence versions of the paper is um and they they do a number of these case studies on like common um   
2:01:22   
uh two-part empirical case studies first systemic analysis of six they use AI   
2:01:29   
journaling applications um and then an exploration of perception   
2:01:34   
responses to these types of principles so they're using things like replica I think wave and and some other like   
2:01:40   
popular things that are these AI journals or mediators or the like this advanced basically these chat bots that   
2:01:47   
are purpose for different programs and they're looking at how does this affect how someone's drawing a conclusion or   
2:01:53   
how someone is is reflecting and they look at the different pressures on all this you know on the journaling process   
2:02:01   
and why why this paper is sort of interesting and I originally presented   
2:02:06   
it to some folks from plers is that in in essence This paper I think justifies everything plot has been doing from the   
2:02:13   
start which is to say most AI right now pushes people towards very uh towards   
2:02:19   
conclusions or as Bnee Brown said very nicely in this talk um the seduction of it is a certainty it's a certainty   
2:02:27   
making machine like you're going to get certainty even if it's hogwash even if it's a hallucination or hallucation   
2:02:34   
making up making up references to justify itself you're presented with   
2:02:39   
this veneer, this appearance of certainty um in in in its language in   
2:02:45   
general. And we're saying even in the in the journaling component or this supposed the interactive component where you're finding something is supposed to   
2:02:51   
you know relate to you or whatever the pressure is on this sort of arbitrary   
2:02:58   
uh reduction of nuance or reduction of um all these other things and putting it   
2:03:04   
into well here's here's something that's going to kind of undermine the agency of   
2:03:10   
of your reflection process of your selfnarrative of of your comprehension of the situation. And it's kind of a call for um we   
2:03:19   
envision AI not as a guide but as a quiet companion helping individuals stay connected with their evolving sense of   
2:03:24   
self and remain the primary agents in their self-discover discovery thereby preserving what we define as the   
2:03:30   
reflective agency. We urge designers and researchers to adopt and extend our   
2:03:36   
framework to ensure future technologies genuinely support autonomy, meaningful self-discovery and a digital well-being,   
2:03:41   
which is like that's basically what plot sources has been founded on. So, it's a   
2:03:48   
sort of interesting paper for ploters that that justifies uh with some research and some some   
2:03:54   
analysis um what ploters is doing there. And that's cool for plotwers, but it's   
2:04:00   
also interesting in the digest sense for like game design and in some of our other senses for you   
2:04:07   
know teasing apart some of their take on phenomenology some of their take on this   
2:04:14   
human computer interaction part of things and and and so on so um I will I   
2:04:20   
will pause there for any questions um I   
2:04:26   
we we're going to go over the paper um I think is be our first major paper   
2:04:31   
in the digest reading group, although it's kind of already come up in some other other places before, but we might   
2:04:37   
kind of send her some discussion about that the group next week. We actually met Friday night, which probably isn't a   
2:04:42   
popular time for most people, but Avery and Molly and myself were like, "Okay,   
2:04:47   
well, this is an okay time to do it." So, we might meet at Friday night at 700 p.m. Eastern time again next week. uh   
2:04:54   
which probably it won't go, but we are making them async, recording them and eventually get them out. Um but but   
2:05:02   
that's sort of where we're going to go with that and and a lot of other things ahead. So I'll pause for any um comments   
2:05:09   
or question for for now.   
2:05:14   
All right. Yeah, I'm it looks pretty good. I'm glad to see that you're doing a reading group and kind of get it. you   
2:05:22   
know, this is how you tease out ideas and kind of work through them is is do these collective groups and   
2:05:29   
figure out. I I'm I'm very much interested in like   
2:05:35   
in some ways on a personal level, this reading group is a   
2:05:42   
I don't want to say harboring, maybe not foreshadow, but I I do want to get I'   
2:05:48   
I've kind of been warming up myself on a personal note. I' I've been complet like between October and like most of   
2:05:54   
November I've just I've just not been able to to be like present for a lot of   
2:06:00   
things. Um and I want to have like we we've had   
2:06:05   
many things about oh with let's like in within oral we've had discussions of like let's have a discussion around   
2:06:10   
project management stuff or a specific series about that. I'm like 100% more   
2:06:17   
now ready to do that on many fronts. So this is one one thing and a very nice   
2:06:22   
niche space but for things like um I I think I might do one on philosophy of history or sort of things that are   
2:06:29   
around sort of the map and spacem contextualization but then also a more pragmatic one in terms of project   
2:06:35   
management and many things we talked about here. So, um I'm I would like to talk not not right now uh but maybe in   
2:06:43   
Slack or whatever about what what things would we like to center in the next you know if we're going to be making perhaps   
2:06:51   
a rendered reading group but also kind of like even like structured lectures or just like structured discussions about   
2:06:56   
things that aren't just kind of hey what's this paper say but more like we're going to investigate uh you know project management digital   
2:07:04   
project management or something or or we're investigating being um like I   
2:07:09   
found the Peter Godwin Smith book about like theory versus reality like like a book I liked talked about like last year   
2:07:15   
or something in terms of philosophy history science type stuff like like being a little bit more structured   
2:07:21   
because what I'll conclude with a bit of a soap box uh comment from before but I'll make it very quick here is I'm   
2:07:28   
pretty discontent with a lot of education and educational materials   
2:07:33   
about things that I care about and I'm kind of on the war path of like just gonna start building about it and doing   
2:07:38   
it and talking about it myself uh because a lot of things don't cover the context that I want and I want to see   
2:07:44   
them in the world. So that that's sort of a teaser to where I'm going in the year ahead with things. So anything   
2:07:50   
about those topics that we might want to make discussions structured discussions some education discussions lecture   
2:07:56   
series around um think think of me and and let's talk about that   
2:08:02   
the end. I'm done with that. Well that sounds great. Yeah. Yeah, we should think about the next   
2:08:09   
year. I'm going to do a overview of the lab progress for this year. I'm going to   
2:08:14   
put it up on the YouTube channel and then we'll u maybe have like a maybe we   
2:08:19   
should have a admin meeting at some point soon like uh maybe for the first   
2:08:25   
year that Yeah. Yeah. Um   
2:08:32   
whenever you start um Whenever   
2:08:38   
stories come up, I I always think of the computational story lab, but I know   
2:08:44   
that's not exactly what their their   
2:08:50   
focus is. Uh it's super interesting and um   
2:08:57   
uh if they do get started, if they do restart that group in Oxford, let me   
2:09:02   
know because Oh, the uh connect them to some people. Yeah. Yeah. Yeah. Yeah. think that would be   
2:09:08   
interesting to connect to some of the the um the the new Oxford Neurotex   
2:09:16   
Society people too because they're they're also very interested if you're if they're covering VR XR kind of stuff   
2:09:24   
too. Um yeah. Um I I've heard about them and then I know I like I know like we Amanda   
2:09:30   
Curtis is a plot twist's co-founder. So like she's she's in house for that   
2:09:36   
group and she's she was doing she's like the main person behind the small hassles court um those play testing things I met   
2:09:44   
mentioned a few weeks ago. Um, so, so she she's doing stuff there and and I   
2:09:50   
don't know a lot of details yet about it, but I I have a sense that she's definitely someone who can get things done. Uh, so as it starts up through her   
2:09:58   
stuff, um, I'll definitely mention it here. I think I think it's a fun it's such an interesting uh wave of   
2:10:07   
stuff as plas kind of I don't know ascending from a certain slumber and   
2:10:13   
then there's this adjacent stuff too uh with some of the game dev stuff. I'm really curious what's going to happen   
2:10:18   
there. Yeah. Yeah. Yeah. And then um the other thing I I thought of or you know um so   
2:10:28   
had a woman from from MIT Media Lab visit um   
2:10:35   
from Yeah. from the um   
2:10:41   
it's definitely cybernetic. It's like um cybernetic psychology.   
2:10:47   
Cyborg psychology from P maybe that's the newest one. If it's really new, it's that   
2:10:52   
um and um uh I think so. And so she was she just   
2:11:01   
had a paper on um or you know she's she's a co-author on a   
2:11:06   
paper on um   
2:11:14   
like like it relates to to chat bots, but it's like chat bots for um   
2:11:23   
like like sexual partners, you know, or like   
2:11:29   
could be critical matter too, you know, human AI interactions um with   
2:11:36   
with this this kind of um romantic relationships.   
2:11:43   
and and you know somebody Yeah. Constance Yeah.   
2:11:50   
And um uh she well this comes up a lot   
2:11:57   
right which sort of relates to you know the the more broadly   
2:12:05   
defined um um computational psychiatry but but where it's just like like are   
2:12:13   
LLMs able to do Guma just just covered this in a kind of pop or kind of like a   
2:12:21   
news interview, you know, because like people keep proposing in Frontier Tower   
2:12:26   
like LLM is going to solve the loneliness crisis and it's just like you   
2:12:32   
know, oh like you guys you guys I don't I'm not a fan of like the debate stuff but   
2:12:37   
like I I and I I I I I'm   
2:12:45   
uh I don't want it to be debate. I want it to be a a steel man in the problem space thing that I'm working on for like   
2:12:51   
Joe for like I'm tired I'm tired of the debate stuff. Yeah. But I mean like like get those people   
2:12:58   
need to be in a room with the social workers who are dealing with people with those problems. Like if like like you   
2:13:06   
come on guys like you can't you can't you you're all playing you you're all you're all fooling you're there's so   
2:13:11   
much of this like you got to move past this like oh yeahah it's like no you you sit in a   
2:13:18   
room talking to people that are dealing with the exhaust from the system that they have to deal with for their   
2:13:23   
jobs they're trained in otherwise like but no like and that's that's not I would say you're not going   
2:13:28   
to be that hard in the pain when you're talking to people in frontier chair about that like we want them you know what I mean   
2:13:34   
you people people are throwing out things. I mean, you know, it's like it's like it's always it's always difficult   
2:13:40   
when somebody's just dropping something in, you know, in chat where they're   
2:13:46   
like, wouldn't these just be great to solve belonging those graces? Like, how much is this person really invested in   
2:13:52   
this particular thought? Right. Right. And but to your point, you know,   
2:13:57   
like, you know, something like do you think that that's the equivalent of, you   
2:14:03   
know, actually having a a a group support group, you know, I mean, in the   
2:14:08   
sense of like, you know, uh there's a thousand things that come from from   
2:14:13   
actually having people in a in a room together that that is is, you know, is not even   
2:14:21   
attempted to be replicated by an and I think it's so important to like   
2:14:26   
it's not I'm not even out I'm I'm a critical of things but I also feel like it's not I don't think it's the problem   
2:14:32   
that there's the technologies like we need to just take it beyond the initial so much of   
2:14:38   
this the new new AI stuff is I think I I find it to be surprisingly um not   
2:14:44   
surprising but like there's so much of it is just oh like like I like I've been saying um   
2:14:52   
can I easily pull it up here I don't Uh my thing about silver bullet is in the dark. Like everybody's just very   
2:14:58   
very very excited about like a solution to one oneoff thing. It's like no guys   
2:15:04   
we got to get to a different level of like engaging problem where it's like sure LM can do this and look at the   
2:15:10   
whole problem space and like move it in that direction as opposed to oh I have an idea I can buy code it up and get get   
2:15:16   
something out there. Like I think that's that's the shift that I'm interested in particular as you guys know and again it's not   
2:15:21   
Yeah. It it's it's you know I mean and you know me I I love to find the the   
2:15:29   
complexity in things and and you know so uh I think there's   
2:15:36   
some interesting things just around you know LLM's that that that cyborg group   
2:15:43   
is cyborg psychology group is looking at um LLMs as as relates to you know what I   
2:15:52   
would call real computational psychiatry. Um, where you know like how   
2:15:58   
if you if you try to weaponize LLMs for   
2:16:07   
for for interacting with sick people, you know,   
2:16:13   
how how well can they respond and and adapt and control   
2:16:20   
themselves? like like are all they're all interesting problems. Definitely don't   
2:16:25   
suggest using them. Um but there's a there's a I'll drop a link in the uh in   
2:16:33   
conversational psychiatry about this. Um, yes. But then just wanted to to end with um   
2:16:41   
the uh the paper or um Nicole Rust came   
2:16:46   
to speak at Stanford this week and and I gotta say um it was it was   
2:16:55   
both I mean it was great and it was also just like oh okay. Yeah. like like her,   
2:17:02   
you know, the synopsis of her elusive cures are a lot of things that that   
2:17:09   
you've heard me cover in terms of just um the   
2:17:14   
issues in psychiatry, but like but such a great such a great overview and um uh   
2:17:22   
I'm still waiting to see what comes from her embedding with Ya Niv. Um   
2:17:31   
uh you know in terms of like what what what will come from her time in a in a   
2:17:39   
you know conversational psychiatry group like y'all's   
2:17:44   
uh I think will be interesting. Yeah. And and you know still   
2:17:52   
Yeah. So, I I don't know if I'm I'm uh I don't know if I can get our our   
2:17:59   
reading group to do um Elucid Cures as a   
2:18:05   
as a as a reading group. Is that her latest book or is that   
2:18:10   
That's her That's her latest book. That's Yeah. Yeah. And it it's it's it's it gets at all the kind of, you know,   
2:18:18   
she covers all the, you know, the the the what's what's been   
2:18:24   
going on, you know. So she's like taking kind of like the best bits of kind of the history of psychiatry together with   
2:18:31   
you know like like what what happened with Tom Insul joining Google and you   
2:18:39   
know the kind of um are we going to be able to tech our way out of this   
2:18:47   
and Yeah. Yeah. So, and I think I think   
2:18:53   
there's also I can try and find um I believe they're going to do some videos.   
2:18:59   
She's she's definitely doing a tour, but you know, it's not just like a typical   
2:19:04   
um I mean I'd be interesting to see the Benet Brown too because I think   
2:19:10   
sometimes she can be very very well grounded in the literature and as well   
2:19:16   
as like really understanding um like like you like you're saying like   
2:19:24   
the power of of you know group therapy and being vulnerable and things like   
2:19:30   
things like that. I I I have a complete confession and we can go I to wrap this up   
2:19:36   
and my confession is like I kind of was like Bnee Brown out because I saw her stuff everywhere and I'm like it's become like live love of psychology.   
2:19:44   
Yeah. Yeah. And I listened to her talk and I was like, "Holy moly." Like, like, "No, she's really getting at some hard   
2:19:49   
stuff." And like even like I looked at a research page on her website about like her art theory research and what she's trying to do. And it's like, okay, like   
2:19:55   
I relate to that. Like you're trying to like you have to you're trying to get at things in a different way. Like I've   
2:20:00   
just, you know, a little bit of, if you will, game recognizes game about like   
2:20:06   
the struggle of what what she's trying to do and then her ability to make it very popular like accessible to people   
2:20:12   
sports analogies. which is important too, right? Like like I mean, you know, to to some degree, you know, it's like   
2:20:21   
um when a new Michael Le video comes out, I kind of have to to   
2:20:27   
check ahead and be like, dude, is there anything, right? You know, like, but at the same time,   
2:20:35   
you know, if you're out there trying to move public opinion, right, like you're gonna repeat   
2:20:42   
yourself. I mean, you know, like like politicians politicians know this better   
2:20:47   
than anyone. That that's like a whole like I would love to have a dis like a discussion   
2:20:52   
about not just science communication but like modern day field building work because that's   
2:21:00   
that's like so key. So let's let's like I'm gonna note that and come back to that later.   
2:21:05   
So, so defin definitely check out more Nicole Rusk because she's the one who's   
2:21:10   
been who's been pushing for more scientists to engage in science   
2:21:16   
communication um both for public opinion reasons as   
2:21:22   
well as like for better science. So definitely definitely good stuff.   
2:21:30   
Yeah. Okay. Yeah. Thanks for this robust discussion and uh thanks for your   
2:21:37   
updates Jesse and hopefully this this meeting I think we covered a lot of   
2:21:42   
ground and um so let's keep up the discussion um you know and maybe we'll   
2:21:48   
come back to some of those next week. Uh our schedule for the rest meeting next week   
2:21:53   
uh yes the schedule for the rest of this year is we'll maybe do two more meetings at least one I plan to meet next week   
2:22:00   
maybe we'll do one on the 20th as well. So, um but you know,   
2:22:06   
and then we want to have an admin meeting maybe after the first of the year so we can talk about what for sure.   
2:22:13   
Yeah. Um and I have like I have things that I'll send in Slack or emails to just   
2:22:18   
like update all this stuff. But sounds great. This is very nice and thank you for for hosting. Good to see you.   
2:22:23   
All right. Yeah. Good to see you, too. Bye. Take care. See you. Bye. Bye.   
