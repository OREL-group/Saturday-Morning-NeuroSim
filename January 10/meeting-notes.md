## Meeting Recording

[YouTube link](https://youtu.be/F_mZ7thKlqY)

## Mastodon thread

[link](https://neuromatch.social/@OREL/115874988565647830)

## Feature Videos

[Sensorimotor Loops and Cybernetics](https://youtu.be/_T7xBaTf0I0)


## NOTES


## TRANSCRIPT
Transcript


Search in video
0:00
Hello. Morning. Yeah. Welcome to the new year.
0:08
Thank you. Thank you. Happy New Year. Happy New Year. All right.
0:14
Is there any new uh New Year's resolutions or anything for you or
0:22
No, just uh make it to 2027.
0:27
Yeah. That would be
0:37
All right. Yeah. Oh, go ahead. I was just saying I've I've been up
0:45
early working on that abstract. So Oh, okay. What is it for? Like uh
0:51
it's a it's a Alzheimer's conference. Okay.
0:59
So yeah, welcome to the new year. Um, you know, this is uh last year I think
1:07
we did a pretty good job of uh doing Saturday morning neurosim uh
1:14
content and and you know kind of figuring out things from that. We got to review a lot of papers. We got to talk
1:22
about a lot of topics and I think we have this nice set of things that we switch back and forth between.
1:29
And if you haven't seen it yet, go to our YouTube channel and you'll see the
1:35
uh annual report which I gave um I posted I think at the end of last week
1:42
right around January 1st uh talking about what we did last year
1:49
uh what will you know uh maybe things that are going to lead into the new year uh different research themes different
1:56
topical themes different typ of outach each. Um and
2:01
then we also talked about some of the sort of the relationships between the
2:07
different components. So we have sort of a core set of collaborators and then we have these uh
2:15
sources of sort of consumptive resources. So I showed this figure in
2:22
the slack. Um, this was over the holiday and I don't know if
2:28
everyone saw it or not, but we'll look at it um and I'll explain what it is and Jesse saw it and he was pretty excited
2:34
about it um just from an administrative standpoint. So, this is um our sort of
2:41
our collaborator graphic. So, we have these interactive sort of collaborators.
2:48
Uh we have Open Worm of course which we've been collaborating with for a long time. Uh
2:55
Jo, which is Jesse's organization. Neuro Tech X which is of course what Morgan's
3:02
involved in. Uh Neuromatch or Neuromatch Academy where of course we've worked
3:09
with since 2020. uh active inference institute which of
3:14
course we've worked with um you know for several years and I'm on one of the
3:21
committees there uh the University of Illinois or Vana Champagne and then INCF
3:27
who sponsors our uh Google summer of code activities so those are you know
3:33
our interactive we we do special things with them we talk about them a lot that
3:38
sort of thing um yeah they may or may not provide support but we're kind of
3:45
integrated in different ways. Then we have our collaborations. So our collaborations are of course the
3:52
tower uh embodied intelligence conference uh bea which is the biologically
3:59
inspired cognitive architectures group which they have their conference every year. We usually present a paper there.
4:06
And then plot twisters, which is something that Jesse works on with collaborators.
4:13
Then we finally have our consumptive resources. And I like this because, you
4:18
know, when we do these meetings or we do anything in the group, we're usually um
4:24
drawing from different areas, drawing from different resources. and we like to make sure that we uh attribute them but
4:32
also know kind of where our food is coming from. And so that we have the um
4:39
international society for artificial life, copy cell 3D,
4:44
um the Santa Fe Institute, the brain inspired podcast,
4:50
the uh augmentation lab at MIT, the Echolopto group, and then this work and
4:57
I'm just kind of loosely defining a community of people doing organoid work
5:02
and um neuronal cell culture and all that the things you talk about when we
5:08
talk about like dish brain or some of the work on uh microelerode arrays and
5:15
other types of neuroche like that. So that's kind of the diagram and then of
5:20
course these resources can move can change from year to year or you know
5:26
depending on what we're working on and so that's you know and of course we
5:31
collaborate with groups but we also consume what they're producing. So that's all kind of in that mix. So I
5:38
think this is a useful sort of diagram for showing kind of where we're getting
5:43
our influences from, who we're working with kind of as a you know contributing
5:48
to what they're doing and then where we have these more interactive relationships. And so if you know we
5:54
think about an organization we want to sort of maybe draw from or collaborate
5:59
with or you know have a joint program with we can think about it in this way
6:05
and it's uh useful.
6:11
Okay. So yeah that's one thing that I talked about over the
6:16
uh over the break. Um, and of course the annual report which I present in full
6:24
and that's on our YouTube channel.
6:29
So the other thing is that this last Monday we started up again with D.VARM.
6:35
So we're going to be doing uh D.VAR in 2026.
6:40
um did the first meeting on Monday and that meeting was um kind of a
6:47
welcome back bringing people back into the new year. U this is our D.VARMM
6:54
YouTube channel. So we have of course I did an AI summary of our meetings for
7:00
the second half of 2025. those those AI that AI summary is
7:06
available on the um channel. I also did the annual report for D.VARMM which was
7:13
at the annual meeting for D.Aworm. That was actually kind of at the beginning of the break. Um and we had a good I think
7:21
we had a good um annual meeting. We chatted a bit about you know different
7:28
things. We always have people attend the meetings. We have our scientific advisory board. We have our people doing
7:35
work, our senior contributors. And then we have people who are visitors. And the
7:41
visitors are people maybe interested in contributing or something like that.
7:46
And so that's uh that was a good meeting. Um and I presented on behalf of
7:51
Divaworm. Um and we only get a little window of time during the main meeting.
7:57
So I decided that you know uh I wanted to give a longer um report and so that's
8:05
what this report is. It's a 41 minute video uh going over what we did in Debor
8:10
last year. So we didn't really publish any papers in Dbor last year but we did do um different you know Google summer
8:19
of code projects. We also had different sort of longer term projects where we
8:24
were building in those areas. So you know that meeting will or that annual
8:30
report will tell you more about that. So yeah we we last year in divorm we had
8:36
42 meetings. Uh the AI summaries I think are useful for kind of summarizing all
8:42
that activity. So that's a lot of activity. It's like 25 hours of content or something like that. Um, and then
8:49
trying to figure out what the main themes are there is really challenging. So the AI summaries kind of talk about
8:56
this this one, you know, every time you do it in Notebook LM, it gives you like
9:01
um a report and it gives you kind of a title and every time you generate a new
9:07
one, it changes the title. But basically, it's trying to summarize everything. In this case, for the last
9:14
half of 2025, it was the uncrack of a worm. And I'm trying to remember what the uh
9:20
one for 2025.1 was. If I can find it. Um that's this
9:28
one. Um well, I don't have it in the title, but um you can see that some of
9:35
the Let's see if I can find some other Okay, so for 2022.2, which was the last
9:42
half of 2022. It was decoding development. For the first half of 2023, it was
9:47
Life's great construction project. For the first half of 2022, it was the brainless architects.
9:54
For the second half of 2023, it was how life builds itself.
10:00
So, it hooks onto this theme of like when we're talking about uh the
10:05
self-organization of life. We're talking about some of these things having to do
10:10
with reverse engineering development um architectures,
10:16
construction, and then you know cracking the worm. And it's just picking up on you know words
10:23
that we've said in the meeting. So maybe we mentioned sort of the aims of open worm or some of the things you know
10:31
larger sort of broader perspective things we're talking about in diva worm and so it's
10:37
using those things to help us understand those things better those meetings better. Um I've also played around with
10:44
the slide generation uh function in notebook LM but so far I
10:50
haven't really found those greatly enlightening. So we'll just leave it at the videos and I think you know if you
10:56
go through you'll see it just does you know kind of pick up on some themes and
11:01
then you can go back to the videos and and get more detail there.
11:06
So in 2026 number one was uh where I talked actually we did do some short
11:13
updates then I talked about uh this concept of neutral theory in
11:19
evolutionary biology and then some of the what they call the function concepts. So in biology of course
11:27
function is a very important concept but it's also can be a pre-scientific
11:33
concept sometimes or sometimes you can define function in ways which are or are
11:39
not warranted. So for example you know if you think about a gene do doing
11:44
something uh in bi in the biology of an organism what is that thing that's
11:50
doing? Is it contributing to a trait? Is it producing an enzyme? Is it doing
11:56
nothing? Um, a stretch of DNA might be sort of junk or it might be like functional or
12:03
it might be multifunctional. It might contribute to a larger complex trait or it might just have a very
12:10
simple function. So all these things are kind of you know we want to be very
12:15
careful when we talk about function and neutral theory is interesting because it
12:21
suggests that a lot of evolutionary change is actually not the product of natural selection but the product of
12:28
molecular changes and sort of the functioning of the molecular millu which
12:36
is where you have all these molecular constituents interacting and shifting their frequency due to you
12:44
know subsampling the populations and things like that. So an interesting kind
12:50
of review of a paper and revisiting some things from the past. We also talked
12:56
about multifysics and material. So uh you know we're talking about 10 segreities in the group Susan Crawford
13:04
Young is really interested in that and um so you know we're we're kind of
13:10
visiting this idea of super stability or tenseity structures
13:15
and uh one of those things of course is to talk about materials and to talk about the multifysics of materials. So
13:22
in development we want to be able to talk about multifysics not just biohysics but biomultifysics.
13:29
So when you have a process a developmental process you have physics going on. Well you don't have just one
13:36
type of physics. So for example you don't just have um cell migration or you
13:43
don't just have adhesion. You have these sorts of mechanical things going on. you
13:49
have these sorts of bioelectric things going on. You have these other types of physics operating
13:55
um at the same time and you need to be able to model all these different types of physics.
14:01
Now there is software to model multifysics. The problem that we're finding is it's not really specialized
14:08
for biology and it's not really specialized for dynamic structures. So
14:13
we have um you know models that model buildings well or or software that
14:20
models buildings well it models mechanical systems well but it doesn't model biological systems. It doesn't
14:27
model open-ended systems. It doesn't model these sort of systems with uh
14:33
causal closure. So all these things are challenges in doing this work. And so I
14:40
talked a little bit about that as well. Okay, so one of the other things I did over the break was I was playing around
14:46
with this program for Mac OS. It's called Draw Things. And Draw Things
14:53
actually draws from the uh stable diffusion community or the
14:58
the sort of the remnants of the stable diffusion community. So I think Morgan
15:04
mentioned this is that when stable diffusion was very hot a couple years ago they had a bunch of forks a bunch of
15:12
communities and then there was a group that branched off from stable diffusion and started developing their own
15:18
software. Now as I understand it draw things is sort of a fork of that
15:23
original project and they've done other things here and they've built this software where you can do generative AI
15:32
image generation uh in an interface. You know, it's local
15:37
on your machine. So, you can install it on your machine. Uh you need quite a bit of uh RAM to do that. So, you know, if
15:44
you're using Max uh if you're using Mac silicon and maybe you have 16 gigs of
15:50
RAM, this works okay. It doesn't run every model well, but it runs enough of
15:55
the models well to be able to do some interesting things. So, I was playing around with it. I
16:01
don't have any images right now. I'm kind of embarrassed about what I was generating because it wasn't very good.
16:08
But, uh, you know, you you basically add a bunch of prompts and then you can also
16:14
add negative prompts so that you can give it sort of a way to latch on to different terms. You might give it
16:21
negative prompts to get it away from certain things and then you can generate different images
16:27
and there the So the advantage of this type of interface is it's relatively
16:33
easy to kind of use locally. So you don't have to go to a cloud server to do
16:38
this. You can do this all on your own machine. You have a number of models you can draw
16:44
from. And then you have these different ways to tune the image. So you can use Laura
16:50
as a post-processing step. You can use control. There are other models you can control different aspects of the image.
16:58
Um you can do you know use random seeds and set the image size and all that. And
17:04
then of course you can generate these on your local machine and you know you can start a project where you prompt a
17:11
certain image like an astronaut on a horse and then you can refine it through
17:16
subsequent prompts. So it kind of improves upon what you're doing. I was
17:22
trying to develop um in sort of a visualization of DVORM
17:29
um and see what it did and it was doing some things that were I don't know every
17:34
time I ask generative AI image uh generation software to generate
17:40
something. It's always like some science fiction worm that looks like it's something out of the Matrix.
17:47
Yeah, it's not it's not the best. uh but you know you can keep playing with it
17:52
and that's what I want to do with that. So uh really accessible software here
17:58
that's out and you know this is something that I I don't know what the uses exactly but
18:05
you know do we have any updates from Morgan or any other comments from
18:10
Morgan? I mean, for sure. Um, I'd certainly love
18:17
to throw um throw throw biopunk on your list there,
18:23
you know, just in terms of the organoid development. Oh, okay.
18:29
Um so yeah I mean I think the big um are you
18:37
know we got a number of things happening um exciting things this year. Um but
18:45
first is is just next week. So in San Francisco, um
18:53
the second largest conference that the city hosts is is called JPM Healthcare.
19:01
So we're doing doing some events that are for that. This is this is actually
19:06
more kind of the this is more kind of like neurotic and
19:12
Frontier Tower in the sense of um doing things with companies. Uh so you know
19:19
this is like the kernel headset which is a a near infrared high density
19:26
like whole head near infrared system. So what that allows you to capture is is a
19:33
signal that is um very similar to fMRI
19:38
in the sense that what you're actually looking at is changes in oxygen
19:44
oxygenation deoxxygenation of hemoglobin. Um so it's it's an indirect measure. It
19:53
has some um you know it has some some some compounds
20:00
that are due to blood flow and other other physiological changes like
20:06
that you know it's it's not a direct um electrical metric like high density BG
20:13
or something um and um yeah so that's
20:18
that's gonna be really interesting. I mean, it's it's nice to work with them.
20:24
Um they are they're one of these companies that's got deep pockets because of a you know um
20:34
rich let's let's call them eccentric uh uh funer
20:43
and but you know it's it's hard to it's hard to find a a neuroch startup that is
20:50
not backed by a single individual. that that has some sort of um story with
20:57
them. Um I guess that's just our our day and age
21:03
in this um but uh
21:08
yeah it's like not the age of innocence
21:14
is is our our income inequality time periods. Let's see what what do we call
21:22
it? just switch it over. Okay.
21:27
Um uh um
21:33
so that that's interesting because you know like like again it is it is
21:38
actually um it's an interesting engineering
21:45
um in the sense that like you know a lot of a lot of what we do develop doesn't
21:51
have that kind of backing. Um, so they've got like developed, you know,
21:57
custom AS6 and things like that to do to really miniaturaturize a lot of the hardware. Um, and you know, the other
22:05
the other big push that we've made this or you know like
22:13
right before the holidays is is to fully utilize like GPUs the way that um all
22:20
the the kids are doing this these days. and and that seems to be part of what
22:25
they're doing, too. So, they're they're bringing they're using um the the
22:32
Jets and Thor. So, it's it's it's interesting because they're they're basically using a platform that I see
22:40
the robotics for using, right? simple. It's it's
22:47
you know like you just can't get away from the
22:54
utility of of you know GPU which is you know like GPU is really just code for
23:01
massively multiparallel right and and
23:07
um yeah so so it's it's nice again just
23:13
being in the tower to see what the other the other floors
23:20
and you know the other kind of um frontier areas are using in terms of tech. So you know like like again like
23:28
robotics and AI obviously you know the kinds of methods that they're using kind
23:34
of simulations they're using there's all sorts of overlap with with work that is
23:40
very much you know orthogonal. Um but uh the GPU as well right I mean just
23:49
in terms of like how it's it's become uh an essential part of you know like of
23:56
the full stack in the sense of like IoT to you know to data center right as as
24:04
some use. So you know the the kinds of things people are doing with just the Jetson um is kind of like you know do
24:12
you need it for your Raspberry Pi? Um, as well as like how they're trying to
24:18
do, you know, what what kind of accommodations they make for robotics, right? So, it's like they're
24:26
it's it's a somewhat hardened device. It's a it's a device where you're thinking about power because you're not
24:35
um plugged into the grid. You're potentially carrying your battery with you, right? So that's one of the things
24:41
that the robot has to you know so it's just like you can't have you know essentially any weight of battery
24:50
because you you propel that you know you've also got to lift it right so um
24:56
so like interesting accommodations on that and and you know
25:01
sorry this is a bit rambling but but it that's interesting too in the sense of like you know when you talk to the brain
25:08
implant companies And because I always get asked, you
25:14
know, just in terms of, you know, how to how to break into one of these companies in terms of, you know, getting getting a
25:21
job. And, you know, one of the things that they one of the jokes is it's like,
25:27
well, do you work on batteries? Do you work on power? You know, are you
25:33
a double E that works on power efficiency? Right? because
25:39
it th those those are kind of their greatest
25:44
challenges, right? It's like like we want to put a we want
25:49
to put a smart device into you, but then we have to power, right? And and so, you know, it's it's
25:59
um thinking about just the Apple Watch, right? So the the the
26:08
Fitbit people like uh I knew a lot of wearable people and you know when the
26:14
Apple Watch came out it was just like they they thought it was a joke because they were like wait you got to charge it
26:20
every day you know like like the the the wearables
26:27
people were like you know you you wear you know wear it and forget it and it's
26:33
just collecting data. Um anyway, so uh
26:41
yeah, so I've been been working with DGx Spark,
26:46
which is the you know, so the Jetson Thor is is Nvidia's kind of robotics
26:52
platform. DGX Spark is basically a dev platform for data center compute, right? So
27:00
actually um when So, Be and I met
27:05
uh I forget like the last Yeah, like I guess it was the the new year. um and uh
27:12
last Saturday and we just kind of talked about some some tech and um uh
27:21
this was this was one of them where it's just like you know it's an ARM CPU with a with a
27:29
latest genu and how to yeah like and kind of like
27:36
how your uh development stack needs change for that. But it's been really interesting
27:42
like a lot of the projects. So I've been with the um camera which is the
27:47
democratization in Africa of MRI. Um uh
27:53
working with those guys, those students um you know having having something that
28:00
computes really fast is actually really helpful if your if your network is unstable.
28:07
So So That's been interesting looking at some,
28:12
you know, been using neuro imaging uh projects uh porting neuro imaging
28:18
projects to this and um kind of testing out their um the speed up.
28:26
So that that's been that's been uh interesting. We'll be doing another
28:31
event. Um so that that like Nvidia is part of or like we're demonstrating a
28:36
lot of stuff with with Colonel to do to do diffuse optical tomography you know
28:43
to to do kind of some of the stuff that um that Hussein's talking about you know
28:49
like um GPUs can be really really helpful and
28:55
uh yeah so so and then Thursday we'll be
29:02
doing another event which is just highlighting a lot of the startups that are coming through the tower. Um the
29:09
neuroch student clubs are all uh talking to each other about doing regional and
29:17
international hackathons which I think is awesome. Um I'm just really happy
29:22
that they're talking to each other at all. Um, and you know, it's going to be
29:28
it's gonna be really interesting to see what comes of this. Um, you know,
29:36
yeah. So, I'm looking forward to this year them taking some more ambitious
29:44
project goals, taking on some more ambitious project goals, which which is would be possible if they're talking and
29:50
collaborating, you know. um uh and really hoping to to help them
29:57
with that. And um
30:02
yeah, and then you know, Brain Hack Toronto is the is the the week after.
30:10
Um and uh yeah, so John Griffith is one of
30:17
the incoming Neuritech X board members. Um he does whole brain
30:23
electrophysiological modeling. Uh he's a he's a great comp neuro
30:29
neuroscientist and uh uh you know works has his own software
30:37
projects that that I've been looking at porting as well on the GPU
30:43
but uh really interesting work in terms of neuro stimulation together with with
30:50
recording. So closed closed loop TMS EGG which is really it's an interesting
30:56
concept. So I'm yeah really looking forward to you know neurom modulation
31:02
neuro imaging uh coupled work this year
31:09
got a lot of got you know I'm not sure where the focused ultrasound is going this year but we will be we will be
31:16
doing something. Yeah. and and you know last last night was
31:21
another was a like a pre GPM event and uh so got the the student clubs from UC
31:29
Santa Cruz that is has been or will be organizing our regional um neuroch
31:36
hackathon and you know I was saying to him so he he knows Kate of of the brain
31:44
engineers and you know so he's like, you know, hopefully you can get uh Kate and
31:51
her her co-founder Spencer to move to San Francisco,
31:57
you know, so if if I can make that happen, certainly what I want to do, you know, he he thinks that there's a
32:04
lowcost midbrain organoid protocol
32:10
that would be easy to get running and um yep, that's that's that's our goal.
32:17
We I was saying with him that I think if we did some sort of neurobiotech
32:25
hackathon uh or you know project that you know like like the mind in vitro
32:32
that that would be really valuable in terms of
32:39
making the the neuroch groups more like a robotics inense of
32:47
like like pulling off a you know some something that requires maybe you know a
32:52
year of practice before you can can contribute but that that would be you
32:59
know that kind of multico organization I think would be really valuable to to narc students
33:07
I've I've also been trying AI coding AI assistance
33:12
I'm I'm learning from Russ Bulra's better better code better science.
33:18
Oh yeah. Yeah. So that's one of the things that came up at the open room meeting is that
33:25
like you can use uh it's not really vibe coding but you can use
33:31
um assistance to kind of refactor code basically. And so that's what they're
33:37
doing with some of the open worm tools because they're, you know, aging and so
33:42
you want to be able to update things um keep them running which is good because you know we always have that maintainer
33:48
problem at open source where we can't always get enough labor or attention to
33:54
things. Um, yeah. So then that's that's that's interesting, but I don't know.
34:01
Um, you know, I think there's of course there's like vibe coding which
34:06
we I think we've talked about in the context of like research software and how you can over rely on that. Uh, but
34:14
that's not to say it doesn't have a lot of uses. Yeah. Yeah. But, you know, I mean,
34:20
better good, better science is, you know, recognizes what,
34:27
you know, doesn't doesn't lose sight of what the goals are with with scientific software. Right. Right.
34:33
Um and certainly where I'm starting you know some somebody was asking um
34:40
yeah like like so you know are you automating your like they they saw that
34:47
I was looking at MRI data so you know are you automating how it runs this guey
34:54
or something like that I was like why would I do that yeah
34:59
like I don't I don't understand the Right. So, you know what I was saying was that
35:06
like like I've started with with basically just the the neurophedora work
35:13
where it's just like you know so with RPM packaging all you do is is you know you write a a
35:20
basically a a small shell script that takes a takes a software project right
35:27
and makes an RPM right makes a package and installs it in a kind of uniform way
35:34
with these these rules and you have a very clear
35:40
um goal, right? Like like I want it to compile. I want it to, you know, I want
35:49
to install it. I want to follow all these rules and I've got a I've got a lint tool that that checks the package,
35:56
you know, in a bunch of ways. Um, you know, I've got a bunch of guidelines. You know, the compilers, you know, the
36:03
compiler tool set, um, you know, your build tools already actually are
36:09
performing a bunch of of tests and and analyses, right? So, um, that's already
36:18
been really interesting because, you know, as someone and this is
36:23
something Russ talks about too, is that like most scientists are amateur coders,
36:29
right? In the sense that like we've we've had no professional training, right? Like like I mean, if I've had any, it was
36:36
because I worked as a software manager for a medical device company, right?
36:42
wick. But like even then it was was like I kind of read professional books myself
36:48
because I felt like I should I should do that. Um
36:54
uh you know software Yeah. software training is a strange
37:01
beast you know which is not Yeah. Anyway, um
37:10
but I got to say, you know, for for someone who's who's
37:15
like who's dealing with a number of projects that are not mine that are having
37:22
compiler or other hardware issues that are super low level like the AI systems
37:28
is remarkably effective. Yeah. And you know, because it's just like you just can't beat it, it's it the
37:36
breadth of its knowledge about low-level detail
37:41
and as well as like how that somewhat intersects with the the packaging and
37:47
and other, you know, software guidelines. Yeah.
37:53
Anyway, it's like it's made me incredibly productive. I I think I'm
37:59
going to make, you know, Fedora. Like, so I' I've packaged all these tools that
38:05
have previously kind of baffled me and I just, you know,
38:10
I kept it. I I'm I want to learn how to do it at the command line, you know, with with cloud code because it's just
38:17
like like I'm getting the response directly from the
38:23
uh you know, I try to build the project and then that error output is like should be fed straight into the right
38:32
and and that is that that those are the examples that I see that that you know
38:38
cloud code examples that that everybody is is touting about right now. These are
38:44
the things. Um so I'm I'm looking at cloud code versus Jules which is
38:49
Google's asynchronous agent. But it has
38:54
been interesting. I mean in the back of my mind I am thinking about the software
39:01
sustainability project just in terms of multi- aent
39:07
multi- aent work right and just how
39:13
I see I see these companies developing what
39:20
looks like the strategy in the software sustainable in the sense that like like they're
39:25
they're they're all moving to multi- aent. They're they're moving to multi- aent where the the the agents
39:34
necessarily they they need the agents to write text files first that say what
39:41
they want like like they're talking about planning. They're talking about uh
39:47
about how to do multi- aent communication in a reliable way, you
39:53
know, and So, they're talking about sending text messages to each other. Yeah.
39:58
And I'm like, you mean like emails or Yeah.
40:04
It's all all they're coming up with is basically the the kinds of
40:10
multi-person communication that you have with the software team
40:16
where everybody's got these roles, right? Is they're just they're just redeveloping that, right?
40:24
So it is it is
40:29
yeah it's interesting to watch but you know and and it's it's again it's this problem like software engineering is not
40:38
a science. Yeah. So yeah
40:45
I think it's going to be a good year for the for the software sustainability project. Yeah.
40:54
Yeah. So, we're looking, I guess, to write up some proposals for Gog project.
41:01
So, I mean, you know, we could do some keep that in mind for that. Well, so, so, so, so here's the thing,
41:09
and it's really funny. Um uh
41:15
so so I I've been you know working with this coding agent to to package you know
41:24
for Fedora and I asked it you know what
41:30
do you think is the the big project that's missing and and you know what's what's the hole
41:37
here and and looking across like using Neurophedora's, you know,
41:44
database of not just projects but also projects that have been proposed.
41:49
Okay. And they're like, well, the the big missing thing is is exactly what I said
41:54
was the ITK. So they're like ITK is the big project
42:00
and and like ITK development has stalled on Fedora. Um uh
42:08
because it's such a big project it like it needs somebody you know.
42:14
Yeah. and and Ana who who you know you know
42:19
runs Nerf Fedora currently you know his focus is really computational
42:25
right and um so you know he has packaged
42:31
it previously anyway I I packaged ITK5 they're like it's like multi-year out of
42:38
date now right so I I still think there's a great case to
42:45
be made for the the what I what I said before was
42:50
just like like you know you you unlock all these other tools if you can get ITK
42:56
work ITK BTK and um but it is very much like a
43:03
looking at a couple professors that are kind of special they specialize in medical software development and and
43:11
medical um machine learning and like what you know how how they
43:18
think about things, how they think about you know software development and and um
43:25
you know reliability. Um and you know that kind of like
43:30
provenence in terms of um software updates and things like that.
43:37
Anyway, I I I Yeah, I'd still love to push that. I I feel
43:43
like I would still need some some, you know, better better mentors for the
43:52
for anybody involved. But but I I still I I also want to ask,
43:57
you know, Fedora team, you know, so I I know at least one of the Fedora
44:02
council that just got elected. Um, so he's actually a former programmer for
44:10
biochemical, you know, like he's like a like a systems biology markup language
44:16
kind of kind of guy, you know, like like the OE for those kinds of models,
44:24
done a lot of, you know, um, chemometrics kind of stuff,
44:29
right? And anyway, he he would get involved when we were doing nerfed
44:35
projects before and he's now on the council. So,
44:42
yeah. Anyway, when when is when is stuff to like you
44:48
you've already put proposals in? Um, well, no, we I think we have
44:53
probably until February 1st or so. So, we're kind of trying to get
45:00
right now we're trying to get sort of, you know, kind of thinking about what they're going to look like
45:05
and uh they won't post them till later. Um, but I, you know, I definitely want
45:12
to do something with open source sustainability in some fashion like you
45:17
know like the ideally kind of move forward on well some of the things we've
45:23
been doing we've you know we've kind of gone in many different directions and if we could kind of pull those back
45:28
together a little bit you know or so you know one of course is the multi-
45:34
aent stuff. I think we've been doing a lot of multi- aent stuff over the past several years. We did uh large language
45:40
model type multi- aent stuff with Sara and she actually did that kind of model where you have multiple agents. They're
45:48
kind of sending each other messages or coordinating themselves around issues and tasks
45:54
and then you know they're kind of developing a project which is interesting but it's you know not kind
46:00
of uh the same thing as we're doing in the other part which was reinforcement learning and then of course we have an
46:07
active inference component that's you know that was something Brian was working on that kind of ties in maybe
46:14
ties together the other two So I I'm not you know we can go in one direction or
46:20
another uh but we have all those strands. So like yeah I mean th those threads are all I
46:28
mean those threads are are absolutely intersecting right right you know like like and and um
46:39
yeah but you can't do all of them and like one person can't do all of them and you
46:45
can't say just I mean because you could have someone pick from all of that but it's like what does the project look like um because you're going to be
46:53
soliciting people's sort of suggestions for what they want to do and they have
46:58
like a certain amount of times it's like how do we focus that a little bit better
47:04
like you know kind of say this is yeah no I hear you I mean I I think the
47:10
the um
47:17
I mean active inference is the
47:23
is what you want to get at. Right. Right. I I you know and and you know so I I I
47:30
think the question is can can you can you address that in the
47:39
um with a project that is
47:45
still you know is already building on multi- aent uh reinforcement learning.
47:53
And to to again I would say to that yes but but like but it it would be
48:00
finding finding the right you know making contributions to the right project in the sense that like or
48:10
like you said like being very careful about the the framing of it like like what aspect you know like you can still
48:17
only kind of focus on one aspect of that in a 10 week period. No. So, um um
48:27
yeah, I I I know. I mean, I still really like um
48:33
um it Andrew Shaw, the the the
48:38
computational psychiatry guy at Exit. I think I was thinking a couple couple references just in terms of like like I
48:46
I like that he does kind of like toy examples.
48:51
Um you know he's got really interesting coding projects that seem very
48:57
digestible, you know, like like they're they're they're
49:03
not big frameworks. there's small small examples to
49:09
demonstrate particular points you know um and um
49:16
yeah I mean of course yeah I'm I'm biased to the computational psych
49:25
I don't know how to necessarily make that into the software development but
49:31
oh yeah well there's a bridge but like basically they're all dealing with collective behavior behavior and the
49:38
active inference aspects of that. So I know this computational psychiatry is focused on like
49:45
you know pathologies but I don't know maybe you could study that and language models and that sort of
49:51
yeah I mean it's it's modeling behavior but but you know the the the what what
49:58
he gets at which is like kind of what you know again like let's not forget that Frista is a psychiatrist
50:05
right yeah yeah so so if anything I think of frist is the the you know he he sort of
50:13
started computational psychiatry. Yeah. And you know like he he is literally a conversational psychiatrist
50:20
and and um uh you know so this kind of
50:26
like having generative models for behavior
50:34
is is what what these were these were the problems
50:40
that he was working on, right? like like and um I mean again like super super
50:48
glad that I traveled to London to just go and sit in his uh analysis meetings
50:55
like going back to like 2000 because it was really just super interesting to see
51:01
him um working you know in the sense of like
51:07
comes into a room there's a bunch of you know neuroscientists
51:13
who've collected behavioral data. Yeah. And and they're, you know, they're
51:19
pitching him their particular problems and issues and so it's like molded from,
51:26
you know, a thousand examples, right? Where you know, um,
51:33
uh, but still, you know, so I wouldn't say it's like it's modeling pathology.
51:40
So like I think it was also like like trying to find these generative models
51:45
that would you know then fit the the behavior they saw whether that was
51:51
pathological or not, right? And and ideally, you know, like like
51:58
like cognitive models would hopefully
52:04
be able to tell you about some something about like how what what the mechanisms are underneath these, right? Like like
52:12
you know um you know like all the all the early work
52:19
in terms of fitting distributions to reaction times. get it. You know that me
52:24
mental chronometry is a is a you know an insight to the
52:29
mechanisms of mind, right? Um
52:40
yeah I I I I you know
52:47
Yeah. So I was I was trying to get at like what is um
52:54
you know like what are what are the essential what's the essential software for a group like y who's you know famous
53:02
conversational psychiatrist at Princeton and um
53:08
and it's basically just probabilistic it's probabilistic programming.
53:13
Yeah. So, so I so I went there GitHub and it's
53:19
it's it's funny because it's like it's like some stuff to connect um it's
53:26
basically like tools for for collecting data from Mechanical Turk. Yeah.
53:33
Tools tools to connect. So So it's like JavaScript frontends for Mechanical Turk
53:39
to to do experiments. uh uh JavaScript connections to to collect EEG data,
53:47
right? So, it's just like like the same same kind of thing, right? And then like the Stan project, right? So, I I don't
53:55
know if you're familiar with Stan, but you know, it's um it's like a
54:07
it's like PMC. I don't know if you know like like these are these are like basian tools I think
54:14
I think it was it was um there was originally a project called bugs so I
54:20
think it came out of Cambridge so this is this this was like the early early
54:26
tools for this like bugs which is like um
54:34
basian uncertainty with gib sampling something like that I'm But the you know and and then and then
54:42
then the successor is Jags which is just another Gibson family.
54:49
Um, so I'm not sure what scan is stands for, but like it can't be a coincidence
54:55
that it's for
55:01
and it's got a very similar, you know, this is this is this totally relates to
55:07
kind of the the Frisman stuff because this is this is basian it's like it's
55:13
about, you know, modeling distributions, variational based, you know, because it's like you're proposing distributions
55:19
to use that are computations tractable, but you're also trying to fit fit data
55:26
with them, right? And um uh
55:35
yeah. Um,
55:41
I I I think the React I mean, have have you thought about using um
55:47
um the React uh
55:53
infer the Julia package from the Netherlands? RX.
56:00
Yeah. Yeah. You know. Yes. Yes. RX infer. Yeah. Yeah. Yeah. Yeah. Right.
56:05
Yeah. I haven't dug into that really. I mean, they they they had some
56:10
they had some um new projects this like
56:17
like over the holidays. Um
56:24
that was interesting. Anyway, all right. Sorry. I'm sure you've got more more
56:30
stuff covered. Well, I'd be interested in hearing about this though.
56:36
Yeah. There was there was something I might let me just check their um
56:44
let me check their LinkedIn feed because there there was something that
56:50
they talking
57:09
Yeah. Lazy dynamics is the company. Oh, okay. Yeah. Yeah. Um
57:19
and so so this is the first thing that I which is not recent seven months ago, but it's
57:26
just it's getting at this issue about about conversational psychiatry, right? So, RX infer can be incredibly powerful
57:34
for robotics, but you need deep probabistic programming knowledge to use it.
57:42
That's exactly, you know, which which is funny because it's like that's, you
57:48
know, like you look at Y's GitHub and that's That's the focus,
57:54
right? It's like, you know, that like there's some stuff with mechanical tur in terms of just like how to get humans to
58:00
actually interact, you know, how how to collect data at scale. Yeah.
58:06
But but the the real key the real key stuff is the the probabistic
58:11
programming. Um so
58:19
like
58:28
okay maybe it was something that they presented
58:36
at nur Um,
58:46
sorry. I I will absolutely follow up.
58:54
Oh, well, you know, so network of LLM agents. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.
59:02
Um, we're about to hit some long flights.
59:10
heading to the states. So, you know what that means? Time to finish those demos.
59:23
Um, so let me see if I can find that just in terms of
59:29
what they were doing. I mean, you know, like like this is what they're looking
59:35
at, right? Right. I mean, um, I would say that they think about their know. So why is it
59:44
called a React framework, right? Because they they want it to be
59:51
um
59:57
you know the the particular kind of functional programming
1:00:03
um is air time. What do you call it? um
1:00:09
that they're using is about this kind of like online, you
1:00:15
know, they they want online tools, right? Yeah. And you know, which which is also
1:00:22
incredibly active. I mean, it's a it's a very active stance
1:00:28
is just like everything about their their project is is very active. Um
1:00:36
uh so
1:00:42
I think there might be something
1:00:48
um that that
1:00:54
actually relates to this problem of of multi- aents in a in a interesting way
1:01:02
but like you know I mean I I think from from that kind of collective problem
1:01:07
what you're looking for is something that you know at its core is simple
1:01:15
but but when you have lots of them interacting it creates a really
1:01:20
interesting structured complexity. Right. Right.
1:01:27
I mean, this this is more stuff. I mean, it's it's it's multi- aent, but they're
1:01:32
they're working on math problems.
1:01:38
Well, it you know, have have we looked at the Sakana
1:01:46
the latest Sakana stuff? No, actually, I don't think we've David Ha stuff.
1:01:52
Yeah, there's a lot of interesting stuff coming out there. I don't think we've talked about it that much.
1:02:00
Yeah. You know, it's um
1:02:12
yeah. Oh, you know, this is something that I
1:02:18
think came out at um at Nurex. So, so I'm trying to find trying to find a next
1:02:24
paper for the Coxai reading group. Okay. And if you've got any thoughts, please let me know.
1:02:29
Okay. Um uh but I'm just seeing that like I think
1:02:37
somebody had mentioned continuous thought machines and I see that that's actually a psychic
1:02:45
like like of course you know um
1:02:54
yeah I mean it like did Did
1:03:00
did you have a chance to to go over like a life and gecko
1:03:06
this year? I mean in terms of just like what were kind of you know
1:03:13
the the breakout projects. Um I don't know about breakout. I did a
1:03:18
review of a life uh but okay I don't know if it was in diva warmer or here
1:03:24
but I haven't like checked out Gecko. Yeah. But okay. Like
1:03:29
Yeah. I don't know what the breakup projects are necessarily. Yeah. Yeah. You know, I mean
1:03:37
Yeah. Yeah. I you know, obviously we we just covered
1:03:45
the big
1:03:51
not what is what is life, what is intelligence book, right? You know, and And the the author
1:03:59
is is is was on the the brain paper that that was like a super interesting a
1:04:07
life project where you know um
1:04:15
is it super interesting a life project that I think was presented. Yeah.
1:04:21
um um you know because it was so evolutionary, right? Like like it it
1:04:26
wasn't so much art. Yeah. It was much more it was much more life than
1:04:33
artificial in the sense of like like it was really kind of modeling DNA
1:04:39
in some compile, you know, much more compiler way. Right. Right. That than say some of the other kind of
1:04:45
you know than I'd say Conway game of life kind of thing. Yeah. Um
1:04:52
uh yeah, but you know it's it's funny though
1:04:59
because you don't really like Sakana stuff doesn't um
1:05:07
uh I mean the AI scientist stuff was is very old for
1:05:14
like like Um,
1:05:20
and I still I mean so like the Sakana stuff that's kind of like multi- aent LLM is is actually 2024.
1:05:29
Okay. you know, um, and I still haven't seen, you know, like
1:05:36
is anybody, um, you know, Future House here, which
1:05:42
is like a project funded by the Schmidt Foundation
1:05:48
and and definitely trying to be, you know, an AI science, you know,
1:05:53
they're trying to develop an AI scientist, right? Um,
1:05:58
it seems like it's more like it's ending up to be more like a
1:06:07
read and digest multiple papers in a in an interesting way,
1:06:13
right? Or, you know, like they they they actually have a paid service called
1:06:18
Edison um that I think is like 200
1:06:27
Ed, Ed Edison science Edison scientific
1:06:35
um uh
1:06:41
but like I don't know if anybody has you know I don't think they can claim
1:06:49
any successes. Um,
1:06:57
and yeah, sorry. I'm I'm not sure I found a good RX for
1:07:04
What else did you want to cover today? Well, I had a couple of little features
1:07:12
to talk about, so we can get on with that, I guess. Um, I just wanted to
1:07:18
mention that Jesse and I had a um sort of a administrative meeting over
1:07:25
the holidays and we talked about a lot of the things that we want to do for 2026.
1:07:31
Um Jesse of course wants to do this uh like meeting or or talk series. Um
1:07:40
and you know kind of following up on that he talked about it before the new year. Um he also you know kind of talked
1:07:47
about some of the new directions or extended directions that we want to take um from his perspective. So that was
1:07:55
interesting. Uh I don't have it summarized in front of me but you know there were some interesting nuggets in
1:08:02
there and you know when he uh attends next we can go over that more. But yeah
1:08:09
I think I think we have a good uh I think we have a good sense of where we want to go.
1:08:15
Um, yeah. So, yeah, that's very interesting stuff. Yeah, please next week maybe bring uh something. I I don't
1:08:23
know. We could maybe cover some of the psycho work or some of the multi-agent work. We can talk about that a little
1:08:29
bit. Yeah, I'm going to try and focus on the RX and Fur and andor like the um
1:08:37
Andrew Shaw. Okay. Like like because he's he's also done some Julia stuff. I mean it it'll be
1:08:43
Julia. Right. Right. Right. So one of the things I wanted to talk
1:08:49
about here um so I don't know if we've talked about this book before. This was of course um you know at one time we
1:08:57
were doing the uh cybernetics meetings almost every week and we're making ties to cognition
1:09:04
and cognition futures and cognitive science and we talked about Hines von
1:09:10
Forester of course who is a cyberneticist who had a lab at the University of
1:09:15
Illinois called the biological um uh
1:09:21
biological systems lab or something like that. And um of course that was closed
1:09:27
in in the 70s sometime and the building it was in is now like um a little quad
1:09:35
um you know in front of the engineering library. But the the inspiration for
1:09:41
that lives on and some of the work that he did. So this is a book that he wrote well after that lab closed. It's called
1:09:49
understanding understanding and um as rhetorical as that seems it's
1:09:56
actually about sort of this higher level cybernetics where we get out to second
1:10:02
order and third order cybernetics we get to observers and all this stuff. So there's some interesting stuff in this
1:10:09
book. Um I want to focus on one chapter here
1:10:16
and that is this chapter 11. It's objects tokens for ien behaviors. So
1:10:23
this book was published like around I think 2003 and it's it's from his work you know in
1:10:29
the past. like it was pretty close to his death and but but the point is is that this is
1:10:37
well before sort of the modern era of large language models and other things like that. So this is the article um
1:10:45
chapter 11 objects tokens for IGEN behaviors and there's a star here I
1:10:50
don't know what it refers to okay this contribution was originally prepared for
1:10:55
and presented at the University of Geneva in 1976 on occasion of Jean PJ's 80th birthday
1:11:03
the French version of this paper appeared in a different volume so Jean PJ's 80th birthday person is a a
1:11:11
developmental person and he of course developed Pijettian methods for looking at development. So that's interesting
1:11:19
that he's kind of connected to that. Um and so this is a seed to last not yet a
1:11:26
flower for Jean PJ to his 80th birthday from Hineson Forester with admiration
1:11:32
and affection. Um and so um so I don't
1:11:37
know if they were roasting Jean PG but basically that's you know it was roasting with papers. Um so I shall talk
1:11:46
about notions that emerge when the organization of sensory motor interactions and also that of central
1:11:52
processes which are these anatomical structures anatomical loops. So you know
1:11:58
there's this this whole idea of sensory motor interactions being the sensory motor loop which is this closed loop
1:12:03
feedback system that includes different structures in the human brain such as the cortical cerebellar spinal system
1:12:11
and the cortical famic spinal system uh is seen as being essentially of circular
1:12:17
or more precisely recursive nature. So whereas we have these closed loop feedback systems where you have sensory
1:12:25
inputs you act upon those sensory inputs you get feedback from the body from the
1:12:32
sensory systems and then you act again and you have this sort of circular
1:12:37
nature circular causality that emerges from that. You also have this recursive
1:12:43
aspect because like some sort of for loop or some sort of other programming
1:12:49
structure, you have things that sort of, you know, processes get kicked off
1:12:54
within these loops and persist and they're regulated by the loop. So they're regulated by past actions and
1:13:02
basically you can reproduce actions and you have this recursive aspect to it.
1:13:08
So he focuses on recursion. Recursion enters these considerations whenever the
1:13:14
changes in a creature's sensations are accounted for by its movements. And so
1:13:19
he proposes SI= SMK which is this idea that the sensations
1:13:26
are linked to movements and movements by sensations MK MSJ. So you have two
1:13:33
functions SMK and MSJ and those lead to SI and MK.
1:13:40
So you have movements and you have sensations and they're interacting. They're coupled terms basically. So you
1:13:46
can see that here. Um when these two accounts are taken together they then form recursive
1:13:53
expressions that is expressions that determine the states movement sensations
1:13:58
of the system. So movements and sensations are different states. So if I have a sensation of touching some
1:14:05
object, I have this maybe the previous experience of looking at the object,
1:14:11
this intention to go touch the object. So I go grab it and touch it and I verify that the object exists and that
1:14:19
gives me more sensory information and so those things are related in this in this
1:14:27
causal feedback system. uh and then expressions that determine the states of the system. The creature
1:14:34
which is just kind of where the system is embodied in terms of these various
1:14:39
states. One point that with more time, effort and space could be made rigorously and
1:14:45
not only suggestively as it has been made here that is what is referred to as
1:14:51
objects. And then he has this term gain stained stad some German term against
1:14:58
standards. and an observer excluded and he has in parentheses linear open epistemology.
1:15:06
So this is where we have this no observer involved um appears in an observer included
1:15:13
circular and closed epistemology as tokens for stable behavior. So this is
1:15:19
where we have this loop which doesn't have an observer and then we add an
1:15:24
observer. So when we have this no observer, it's a linear open system.
1:15:30
When we have an observer, it's a circular enclosed. And then this is like a token for stable
1:15:36
behavior. Um or if the terminology of recurs recursive function theory is used tokens
1:15:42
for igen functions. So he makes this connection between sort
1:15:49
of uh stable behaviors and IGEN functions. Uh and then he's you know using this term tokens which of course
1:15:55
we use in um machine learning all the time in more of the language models and
1:16:02
that's kind of an interesting aspect of this loop is that you have these tokens
1:16:08
that are doing things that are kind of independent units in this in this sort of complex system.
1:16:16
Of the many possible entries into this topic, the most appropriate one for this occasion appears to me the recursive
1:16:23
expression that forms the last line on page 63 of PJ's
1:16:30
equilibrium the structures cogs which is the
1:16:36
equilibrium structures of cognition. Um and then this is the term here.
1:16:44
Observer O leads to observer S leads to coordination S, coordination O, observer
1:16:52
O, etc. So this is a loop starting at observer O going to observer S and then
1:16:58
coordination of S, coordination of O, observer O, and then you continue
1:17:05
through that loop. And so it just loops around. So it's basically observations lead to coordination in these different
1:17:11
aspects of of or different components of cognition.
1:17:16
So I told you this is a roast of PJ basically um for his birthday. Um this
1:17:22
is an observer's account of an interaction between a subject S and an
1:17:27
object or set of objects O. So if you recall that second order
1:17:33
cybernetics is this attempt to add the observer into the loop. So you have the loop the
1:17:39
closed loop system um and then you have the observer it's kind of outside but it's not really
1:17:46
outside. it plays an integral role in integrating this loop so that it's not
1:17:52
sort of self-reerential and doesn't have any sort of uh intelligent correction or whatever you
1:17:59
might call it. So like in the in the in the context of a sensory motor loop, you
1:18:06
might have this closed loop between sensation and movement. And then you have this
1:18:12
sort of online correction mechanism that supervises that loop to make sure that
1:18:18
it doesn't sort of run into um sort of a self-referential
1:18:24
uh uh set of collisions. So, you know, you want to make sure that things don't
1:18:30
collide or become uh
1:18:36
what do you call it? Um that they don't self-contradict.
1:18:42
So, this is uh so we have these objects, we have these subjects. So the in in
1:18:48
this term up here we have an observer object. We have an observer subject. We
1:18:54
coordinate the subject which coordinates the object which then leads to an observation of the object and so on and
1:19:01
so forth. The symbols used in this expression defined on page 59 stand for and then
1:19:08
they refer to figure one which is this which is this curved drawing of uh
1:19:14
observer S observer O coordinate S coordinate O and this is all in French
1:19:20
basically this is a agent with an I and then hand that's about it but it's an
1:19:27
embodied agent which is the subject uh coord coordination which is coordinate S
1:19:34
coordinate O that's the objective of the agent there's this observation of S
1:19:40
which is this hand observation of O which is the object this is the observer
1:19:46
here which then coordinates this whole process and I don't know what this looks like in
1:19:53
terms of a brain circuit but you might imagine that there's like you know the
1:19:59
actual uh feedback loop and then there are other centers that kind of modulate that
1:20:05
and that's what we're dealing with the observer. Now in the paper that we just put out on
1:20:12
the ever regulator theorem we talk about observers and we talk about their role in these closed loop systems. We talk
1:20:19
about system in the world and a model of that system and how that model can
1:20:26
approximate that system. And when you're talking about something like world models, you're talking about a model
1:20:34
that tries to approximate a system, but it has to do so in a way that is
1:20:39
generalizable and um you know it but it has to acquire
1:20:44
that information from the system. So it can't just simply start modeling the system right away. It has to build up to
1:20:51
that. You have to construct a model. And the way you obstruct construct a model
1:20:56
of course is you train it with data. But you can't get all the way there just
1:21:01
by training the model because obviously if we had all the data that we could get
1:21:06
for a specific um system then you know we could basically
1:21:13
we don't even really need to have we don't need to talk about world models. We don't even need to talk about
1:21:20
regulation. We just know that it's you have, you know, this model that approximates the world and if you just
1:21:27
train it with the data, you're done. And and you know, we don't have the problem that we need to that that we have in
1:21:35
modern machine learning, which is we can't necessarily approximate out of distribution events. We can't
1:21:42
approximate rare events, things like that. And so we need to have this system
1:21:48
that generalizes things and that's where the observer comes in. The observer sort of supervises that process. It adds in
1:21:57
context and it does other things. Now I have to say that in our paper we haven't
1:22:02
really dealt with this issue of being specific as to what those components are
1:22:08
only that that's the framework that we need to use. And so you know you might think of the observer or actually you
1:22:14
might think of the object as something in the world like a system in the world. You might have the subject which is
1:22:22
acting upon that information. So the subject is the model. The object is the system in the world. The object is
1:22:29
generating data for the subject to pick up and incorporate into its own internal
1:22:35
model. But that internal model is only going to be based on the things it can observe. If this ball for example uh
1:22:42
behaves in a weird way it's not expecting then it can immediately respond to it.
1:22:49
It has to kind of learn those behaviors but then it still has to
1:22:54
kind of find out where it fits in the scheme of things and that's where your observer is important for online
1:23:01
correction or things like that. So there's this relationship where the
1:23:07
observer might be a symbolic model. It might be some other type of model and
1:23:12
then a model that kind of reinforces these trends on the internal model of
1:23:18
the subject. In any case, um
1:23:24
this is just kind of talking about the different types of things. uh the
1:23:29
observables related to the action of the subject, the observables related to the object, the coordination of actions or
1:23:38
of operations, the coordination of objects and then this etc which is an
1:23:44
important sort of point here. Um and they don't have it in the figure but it's the syntactic injunction to iterate
1:23:51
with no limit specified the sequence of these operations HVF. So there's a lot
1:23:57
of uh undefined jargon in this article. So I'm not going to get into that. But
1:24:03
basically you have this sort of syntact uh syntax
1:24:08
element. You have this sequence of operations element and you have this iteration
1:24:15
function which we don't know what those are. But basically it's kind of thinking ahead in terms of this figure what this
1:24:23
will look like over time. Uh so then for the sake of brevity I
1:24:28
propose to compress the symbolism of before even further compounding all that is observed into a single variable. So
1:24:36
observation of object observation of subject is uh compressed into a single
1:24:42
variable observation and compounding coordinating operations that are performed by the subject.
1:24:50
Coordination of subject, coordination of object into a single operator chord.
1:24:56
Chord which is the single operator now transforms, rearranges, modifies the
1:25:03
forms, arrangements, behaviors observed at one occasion.
1:25:08
So this is where we have this coordination of one time point. And so this is where you can do a lot of things
1:25:16
with this. You can transform it, you can rearrange it, you can modify it. It's almost kind of like maybe like a
1:25:23
recombination operator in a genetic algorithm or something like that. If you're thinking of building a sort of a
1:25:31
genetic algorithm like representation of cognitive processing, you know, this is
1:25:36
where you're sort of transforming the sensory data into different shapes or
1:25:43
forms. You might reverse it. You might randomize it and then teach your model
1:25:49
about that those sorts of transforms, those sorts of deformationations of
1:25:54
data. And you know, then then you have more information about the world than
1:26:00
you otherwise would because you say, well, you're observing in this order, but really it can occur in many
1:26:06
different orders. It can occur randomly or you have to distinguish it from being random or you have to distinguish it
1:26:14
from being backwards or maybe it occurs in a backwards order.
1:26:19
And so you present that to the model. The model knows what that is and it eventually kind of understands that
1:26:26
there's this either this difference or this sort of extension.
1:26:32
So that's an important kind of part of this model as well.
1:26:37
Um so chord transforms things at one occasion into those observed at the next occasion. Express the outcome of this
1:26:45
operation through the equality which is uh this equality here. Observation at
1:26:50
time one coordinates observation at time zero. Okay. So that's basically it. uh this uh
1:27:01
this footnote here one by replacing the arrow whose operational meaning is
1:27:06
essentially to indicate a one-way or semantic connectedness like things like in in linguistic terms
1:27:14
it's things like goes to implies invokes leads to these are expressions that sort
1:27:20
of point towards connectedness that we of course will take things in the world
1:27:27
describe objects or relations to objects in terms of semantic content. So that's
1:27:33
what we're getting at here. Um we're looking at different connectedness between adjacent expressions with the
1:27:40
equality sign providing the basis for our calculus. However, in the order that legitimate use of the sign can be made,
1:27:47
the variables obser observe one must belong to the same domain. The choice of
1:27:54
domain is of course left to the observer who may wish to express as observations in the form of for instance numerical
1:28:01
values of vectors representing arrangements or geometrical configurations
1:28:07
or as observations of behaviors in form of mathematical functions. So these could be things like the equations of
1:28:14
motion or biological propositions um which are things uh one construct is
1:28:22
from mcculla pitts in 1943 they proposed this idea of the temporal propositional
1:28:27
expression or tpe and we're going to go back to mcculla pits later but for right now that's just
1:28:35
something that is putting in this footnote.
1:28:40
While some relational fine structure is clearly lost in this compression gained however may be an easiness uh which by
1:28:48
which the progression of events suggested on the last line of page 62 copied here can now be watched. So this
1:28:55
is just basically the sequence that PJ proposed and then it's just kind of
1:29:01
flipped around or pathways through this uh set of things that happen. So this is
1:29:09
the information processing. Um you have this observation function which moves
1:29:15
the coordination function. Uh so uh the sort of the s function moves observation
1:29:23
of s function moves the coordination of s function. Observation of um o function
1:29:29
can interact with the observ or the coordination of s function and coordination of o is the observation of
1:29:36
o and all these things kind of move to next the next time point. So you have
1:29:42
the observation and coordination of S at time zero uh you know influencing the
1:29:48
observation of S at time 1. The observation of O at time one influences
1:29:53
the observation of S at time one. And so you have these relation you not only have this closed loop system but you
1:29:59
have this temporal evolution which is kind of mediated by this observer.
1:30:06
Um and so this kind of goes through this allow the operator cord to operate on the previous outcome to give uh sort of
1:30:14
this recursive correction or this recursive um recombination
1:30:20
and then this just operates over recursion where we get this complex
1:30:26
system where over enough time we go from observation O we get this coordination
1:30:33
function we have observation. And we can scale this up. So let n grow
1:30:39
without limit. So that we have this limit to infinity of coordination of
1:30:44
different observations leading to observations over infinity.
1:30:50
So, but what they're basically doing here is they're taking the small kernel
1:30:55
of observation and coordination and scaling it up to a bunch of
1:31:03
observations and coordinations of different things over time over
1:31:08
unlimited time. So, it's almost like um just thinking about like how we train AI
1:31:14
models today. If we just trained a model, kept training it and training it and training it, we could get this to
1:31:20
this observation limit of infinity, but we also need to have the observer in the loop to reach this observation of
1:31:28
infinity that actually means something. So, I mean, that's what I'm getting out of this. Basically proposing a lot of
1:31:34
these things kind of way before their time or at least their their uh technical implementation time.
1:31:43
Uh but the point here is that the individual v independent variable OB obs
1:31:50
the primary argument has disappeared which may be taken as a signal that the simple connection between independent
1:31:56
and dependent variables is lost in indefinite recursions and that such
1:32:02
expressions take on different meaning. So one point that um
1:32:08
we brought up in the presentation to the active inference institute I think in 2024
1:32:16
was that if you have a cybernetic system because you have this recursion and if you build a big enough system you
1:32:22
have recursion that becomes very complex especially when you have a lot of
1:32:28
interactions between these loops um is that you lose
1:32:33
uh linear causality. and then it gets swallowed up by this recursive
1:32:38
aspect of the system and that you actually can lose
1:32:44
uh the connection between independent dependent variables. You can also have really unique forms of recursion, unique
1:32:52
forms of causality. So this is really kind of speaking to
1:32:57
that and it's really kind of you know way if you built like a very large cybernetic system not just this first
1:33:03
order clos loop feedback but maybe like a multiple order openloop feedback with
1:33:09
observers in the loop. um that you can have these kinds of uh
1:33:16
variable types of causality and you can have you know interesting
1:33:22
things emerge from those kind of systems. So this just goes on to to continue on
1:33:28
talking about how you build these system ups from a simple closing feedback system to infinity
1:33:35
and this just kind of builds upon that. So note that while in this form of the
1:33:41
expression has disappeared um all the expression and chord are
1:33:46
finite a new feature has emerged namely that the dependent variable observation
1:33:52
infinity is so to say self-depending or self-defining or self-reflecting for the
1:33:58
operator core. So this variable observation infinity which is the sum
1:34:03
total of the entire uh system is dependent on this chord
1:34:10
um fun operator which of course is operating within the loops and it's so
1:34:18
it's being self-defined by the chord operator but the chord operator itself
1:34:24
is dependent on sort of what's going on in these local observations. ations and
1:34:31
so that's kind of and if you think about it it's just merely a time series opposite feedback system court is
1:34:38
operating sort of at each time point the court operator but then the outcome over
1:34:43
a long period of time is dependent on things that are aren't defined until the
1:34:51
initial interaction occurs. So it's just kind of this weird kind of causality that is
1:34:59
hard to disentangle and hard to say do things like audit um the operation of
1:35:05
it. And you know you think about like evolutionary algorithms and you go back to that and you say well you know in
1:35:11
evolutionary algorithms you know we have a mutation operator which changes the initial uh string and it can change the
1:35:20
initial string in a way that so that when you at the end you you know it your
1:35:26
string looks very different than what it started with and to that I say you know we know that like from a lot of
1:35:34
experiments complexity that a lot of these types of operators
1:35:39
and feedbacks are um can fundamentally transform
1:35:45
a system and and affect causality. So, you know, looking at a system at the end
1:35:51
point, it's hard to know what caused something. And you know this is kind of all you
1:35:57
know I'm not going to get into the details here but we've explored down this path in the literature especially
1:36:04
since this paper was written. So it's a very interesting set of observations
1:36:09
from the perspective of this paper because it kind of predicts a lot of those results.
1:36:15
Um should there exist values observation infinity I that satisfy equation seven
1:36:21
these these equations up here. um call these values IGEN values. So now we have
1:36:27
this IGEN value, IGEN function, IGEN operator, IGEN algorithms, IEN
1:36:33
behaviors. And so it's like you know EN values are things you get out of
1:36:39
um uh dimensionality reduction analysis.
1:36:45
You get values for a matrix and there ways to summarize
1:36:51
complex systems. And so this is where he's going with this um where you have
1:36:58
these uh values summarize something you know some complex u vector
1:37:04
space or matrix or system. So what he's trying to do I guess is
1:37:11
extract these en behaviors or IGEN values from these cybernetic loops especially when you have a lot of them
1:37:16
working in parallel where a lot of them working over time.
1:37:22
Um, so this is basically where he's going with this. Um, and I don't want to
1:37:28
get too much into this, but there is this nice uh diagram of the Oraoros
1:37:36
and they have some unintelligible notation next to it. But basically this
1:37:41
is a delta symbol which is
1:37:48
So you basically have this delta symbol which is that changes dependent on this
1:37:55
uh closed loop system that is recursive and then it's hard to disentangle as we
1:38:01
see with the dragon eating its tail or the snake eating its tail. I don't know what this I guess it's a dragon has feet
1:38:09
but this is the point here. Uh I think it summarizes part part of what he's saying. And then there's this other
1:38:15
aspect of this coordination operator uh operating outside of the or basically
1:38:21
the positive feedback system or this coordination operator is coordinating the recursion aspect of it and then you
1:38:30
have this observer or this observation which is a closed loop. So the
1:38:35
observation influences the next observation and this coordination operator is sort of playing the role of
1:38:42
the observer in making sure that those things are internally consistent.
1:38:50
In other words, the coordination of compositions i.e. the whole corresponds to the composition of coordinations.
1:38:57
This is the condition for what may be called the principle of cognitive continuity. Um, so this is where if we have a piece
1:39:04
of chalk and we break it apart, breaking pieces of chalk produces pieces of chalk. So this is where we don't
1:39:13
transform anything by breaking it into pieces. It's sort of a linear view of
1:39:19
cognition where cognition is continuous. You can have like multiple observations
1:39:26
and it doesn't fundamentally change the model. You add on to the model
1:39:32
basically or you decompose the model. You don't fundamentally change the model based on continuous feedback.
1:39:40
This may be contrasted with the principle of cognitive diversity which arises when observer I and the
1:39:46
composition star are not the values of compositions contemplating
1:39:52
or complementing the coordination cord prime which is chord prime which is observer one observer two or
1:39:59
observational observation two. Um and then that's not equal to coordination uh
1:40:06
prime observation one, coordination prime observation two. So you're multiplying these two together. The
1:40:14
combination of them is not equivalent to the multiplic multiplicative
1:40:20
outcome of these or the product of these and which says that the whole is neither
1:40:26
more nor is it less than the sum of its parts. It is different. So this of course then again predicts this paper um
1:40:35
it's more is different um it's sort of a seed paper for the Santa Fe Institute um
1:40:41
by Anderson and this is a paper that talks about emergence
1:40:46
and how you have you know a bunch of different things interacting
1:40:52
and the linear way to describe that would be to add those up and have the
1:40:59
sum of the parts described But emergence is different in that you have a bunch of parts that interact and
1:41:05
then the product of that is more than the sum of the parts. It could be
1:41:10
multiplicative. It could be something else that emerges at the next level of organization.
1:41:16
And so this is different where the sum of the parts is not just the sum of the
1:41:21
parts. There's this transformation that occurs. And this is different than this
1:41:27
uh idea of cognitive continuity where if you just have a bunch of observations
1:41:33
over time that you end up sort of with this we might call it a basian model
1:41:39
because you have this prior distribution of events and you keep updating that prior and it keeps sort of normalizing
1:41:48
your model. In other words, it adds it it sort of gets incorporated as a normal
1:41:54
mode. And so you end up with something that is sort of
1:41:59
approximated down to the proper behavior. So you have you start with
1:42:04
like observations of different things you're trying to put them together and over time you get enough observations so
1:42:11
that you can see the missing components and you get the picture of the whole. Cognitive diversity on the other hand is
1:42:19
sort of this idea that you make a set of observations and as you keep making
1:42:25
observations you don't fill in the entire picture but you get this emergent property that
1:42:32
gives you something different. So in other words you see these parts and then eventually you see this hole. It's it's
1:42:39
kind of like the difference if I had a a jigsaw puzzle where I started putting in
1:42:45
pieces. I might one aspect of it might be that
1:42:50
I want to, you know, I I have an idea of what the pattern is and I'm putting pieces in place from different parts of
1:42:55
the puzzle and I don't know if I have the pattern yet. Um, but my idea is
1:43:01
normative. In other words, and looking at the different parts and I'm seeing how they're connected and they're drawn together by the sort of mean behavior.
1:43:09
And then eventually as I I get the pieces in place and I can see that mean behavior and I can just smooth over
1:43:16
everything else and infer what that is. With cognitive diversity, you have these
1:43:22
pieces in different places and you're putting them together and you have an idea of what this is. But then when you
1:43:28
finally get to the end of the puzzle and get everything in place, you see a totally different pattern. And that's
1:43:34
almost maybe more like a semantic aspect of it because you actually see the meaning in what the pattern is.
1:43:42
In any case, I'll leave that here because you know this is an interesting connection and remember
1:43:48
this predates or is different. So again, this predates all the stuff that we know
1:43:54
now. EN values have been found onlogically to be
1:44:00
discrete, stable, separable and composable while onto genetically to arise as
1:44:07
equilibria that determine themselves through circular processes. Ontologically values and objects and
1:44:14
likewise ontogenetically stable behavior and manifestation of a subject's grasping of an object cannot be
1:44:21
distinguished. In both cases, objects appear to reside exclusively in the subject's own experience of his sensory
1:44:29
motor coordinations. That is, objects appear to be exclusively subjective.
1:44:34
Under which conditions then do objects assume objectivity. this, you know, talks it it not only
1:44:40
talks about um some of the things we talk about in second order cybernetics
1:44:46
with the observer and how objective the observer is, but also he talks about
1:44:52
anttogenetically uh because PJ referred to that and
1:44:57
referred to on anttogeny as this development of this stuff. So you have to remember that from PJ's perspective
1:45:05
all these systems are developing or it there's a developmental aspect to it. So
1:45:11
it's like you know emergence is development the construction of these closed feedback systems are development
1:45:18
we're interested in sensory motor integration as development. So you know sensory motor integration just doesn't
1:45:24
happen at some point and then you know these these these faculties don't just
1:45:29
come online suddenly they develop. So we we have precursor components to these
1:45:35
feedback loops, these closed loop feedback systems, these sensory motor capabilities. So all that, you know,
1:45:41
they doesn't talk about that here, but basically that's what that's the context of what
1:45:48
we're talking about. And again, this is another picture of the uh oraoros
1:45:55
where the snake eats the tail of the other as if it were its own where cognition computes its own cognition
1:46:02
through those of the other. Here is the origin of ethics. So that's the the last
1:46:08
line of the paper. And again, we have this I guess it's a two two wizards. I
1:46:15
don't know if they're snakes, but you have feet. uh but they're eating each other's tails and that's the idea behind
1:46:22
positive feedback is that they're eating each other's tails and it's hard to distinguish between
1:46:28
individual components. So a lot of good stuff on like emergence
1:46:34
and cognition and computing cognition well before this stuff was given a
1:46:41
formal set of terms.
1:46:47
Yes. So, I wanted to Oh, you have some things to say though. First, well, just you know, like
1:46:56
it's it's I think it's perfect as well that that was in celebration of P.
1:47:03
Yeah. you know, um just [Music]
1:47:10
you know, one how Phian
1:47:17
um terminology has also been so durable or
1:47:25
you know so longlasting um in in a good way, right? Like right
1:47:31
like because because it was inside right um
1:47:37
and yeah the the uh
1:47:44
PS and good in a way that freaking bad.
1:47:51
Um and and that yeah I mean and then then adding that
1:47:59
cybernetic you know um having having someone
1:48:09
seeing or you know adding that
1:48:16
kind of mathematical rigor. Well, certainly
1:48:22
formalism, you know, like you know, the compositionality, the recursiveness, you
1:48:28
know, all of that it was just it was it was nice.
1:48:34
Okay. Yeah. And and certainly, you know,
1:48:41
interesting. I mean, you know,
1:48:46
Frank I don't think synchronicity is the the
1:48:52
right word, but the um certainly how interesting it is that
1:48:58
that he happened on terminology that is now super
1:49:07
a coincidence. Yeah. Yes. That's a great great great little
1:49:14
piece in the in the book and there's a lot of other interesting stuff in that book. Yeah. Uh I didn't want to
1:49:20
and I I don't get enough you know I mean you know I I started uh
1:49:28
you know not only um classical liberal arts um but uh it with William Blake and
1:49:39
and writers like him I I have it's been a long time since I caught any
1:49:46
alchemical diodes. Oh, okay. Yeah. Or symbolism, you know, this. So,
1:49:53
it was I wasn't quite sure where he was calling this those figures from, but
1:49:58
those were those were great great additions as Yeah. Yeah.
1:50:03
So, there is this one other thing I wanted to talk about with respect to this. Um,
1:50:11
so this is uh Warren Makoa. So it's not pits on this paper and this is in the
1:50:17
bulletin of mathematical bioysics in 1945. Yeah, you'll have to make that paper.
1:50:26
Okay. Uh yeah. So this is a hierarchy of values determined by the topology of
1:50:32
nervous nets. And we're at Makulla.
1:50:37
He is actually this University of Illinois College of Medicine is now University of Illinois Chicago. So he
1:50:44
was there. He's also a psychiatrist or in the department of psychiatry.
1:50:50
So um you know this is kind of talking about a little bit more now I don't know
1:50:57
if he talks about the term in the 43 paper but he also talks you know very
1:51:02
much in the spirit of uh cybernetics.
1:51:07
So because of the droic character of purpose of activities, the closed circuit sustaining them and their
1:51:14
interaction can be treated topologically. I don't know what dramic means. Do you know
1:51:20
Morgan? Sorry, what was that? What's the word dramicic mean?
1:51:27
I mean um um
1:51:34
No, I'm not. It's not coming to me. Okay. Um,
1:51:39
uh, yeah, I I'll look it up.
1:51:44
All right. Well, anyways, uh, because of the dramic character purpose of the activities, the closed circuit
1:51:50
sustaining them and their interaction create topologically. So he's going to take this topological view of what we
1:51:57
talked about in the in the last paper about um feedback and these circular
1:52:03
systems and these closed circular systems which are you know things that are kind of recursive in nature. It is
1:52:11
found that the value anomaly where A is preferred to B, B to C but C to A. There
1:52:19
corresponds a diadrome or circularity in the net which is not the path of any
1:52:25
drone and which cannot be mapped without a dial on its surface sufficient to map
1:52:31
the drones. So drumic is actually very important term here.
1:52:37
Okay. Okay. So so actually is it is Greek of course.
1:52:43
Yes. Um dramos um meaning race or running.
1:52:49
Um but I think it's I think it is
1:52:54
speaking to the the race course. Yeah. Um being uh circular.
1:53:05
Yeah. Yeah. Yeah, I think that would be um you know and then and then so so once
1:53:13
once I I push through on that then sorry
1:53:18
go back because then it's like doesn't they say by druming
1:53:24
uh yeah yeah yeah so
1:53:29
um no sorry Diadrome diadrome diad drum
1:53:36
you know or or or circularity in
1:53:43
which is not the path of any so I guess what he's saying is that like
1:53:48
if you have a path from A to B to C like a transitive path right you have like A to B which is a path
1:53:55
which is a a course and then B to C is a course and then C to A is a course And
1:54:02
then that's like like you have a competing courses and there's a
1:54:09
circularity that results because you know you have this birectionality
1:54:14
from A to A. You can go outward from A and come inward to A I guess is what
1:54:20
he's saying. Um but then of course this topology is is going to be like you know
1:54:26
if you do do an experiment in the real world you might have like um you know a
1:54:32
choice uh force choice or a choice experiment where you have some subjects
1:54:37
a you know do you choose A or B and then break down your experimental system like
1:54:43
that and then that results in a path of activities
1:54:49
and then that's that's kind of what he's talking about. So he's mapping like uh values in terms of things in the
1:54:56
experimental world to uh some sort of uh
1:55:02
pathway of activities. I that's what I'm getting out of this because I'm trying to think of this in terms of
1:55:07
Yeah. Yeah. Well, then di would be a complete course.
1:55:13
Yeah. Or or oscillation of something. So, so it actually can be used associated with
1:55:20
a pendulum. Oh, okay. Yeah. Interestingly. Yeah. Um,
1:55:27
so so I'm I'm getting those great those great um
1:55:33
dynamical systems images in my head. Yeah. Yeah. of of you know of closed
1:55:40
closed circuits you know closed paths but but being dynam you know
1:55:47
right and again this is all before dynamical
1:55:52
systems was worked out so they don't have the language that we might have today but yeah yeah
1:55:59
I mean well or someone who's just so intimately
1:56:04
familiar with the fundamental math that they're already seeing this.
1:56:09
Yeah. Yeah. Yeah. Um so thus the apparent inconsistency of
1:56:16
a preference is shown to indicate consistency of an order too high to permit construction of a scale of values
1:56:24
but submitting to finite topological analysis based on the finite number of nervous cells in their possible
1:56:31
connections. So this is what he's doing what I can gather. He's taking these
1:56:37
ideas about like if you had a behavioral experiment or if you had some set of
1:56:42
purpose of activities you say I prefer A to B or you know B to C you have this
1:56:48
sort of transitivity where you have a bunch of things and you're making decisions between them and of course
1:56:54
they're related through this sort of uh circularity. So you have you you basically plot everything out
1:57:01
topologically. You figure out what the path of preference is and then you find
1:57:06
that there's this loop. Um and then of course you get you want to map this not
1:57:12
necessarily from behavior to some abstract graph or some abstract
1:57:18
you know representation but you want to map it to a brain circuit or some nervous system circuit. And so that's
1:57:25
what he's thinking about here where we want to, you know, have this topological
1:57:31
analysis of a brain circuit tied to different behaviors because he's
1:57:36
interested in in brains and ultimately in this what thing become connectionism.
1:57:42
So So yeah, sorry. I'm still trying to to parse this this
1:57:50
this language. Uh, sorry. Can you leave the the text up? Yeah,
1:57:55
because it it it's it's okay. So So he's using drone
1:58:02
to be the um the disease.
1:58:09
Uh drum is the sort of the pathway through. So like you have a pathway
1:58:15
through this this graph that he's drawing from these different behaviors or these different
1:58:23
preferences. Um drum is like the path. So it's like
1:58:28
moving from one thing to another. Sorry. The diagram would be circularity
1:58:35
and then he's mapping all this to something of like a nervous system map.
1:58:40
What what's the title of this? uh this is the title is a heterarchy of values
1:58:46
determined by the topology of nervousness. So heterarchy is another term that of course is
1:58:53
uh different from a hierarchy. So heterarchy is something that the cyberneticist used extensively but what
1:59:00
isn't as popular as some of the other terms and it's basically where you have a system of things that if you think of
1:59:08
a hierarchy you might have like say a b and c there's a clear sort of order of
1:59:16
these things. So like a maybe contains b and then b contains c.
1:59:23
So it's a linear hierarchy and that you might think of that as like a you know like where A is a category of all
1:59:29
things, B is a category of like balls and then C is like a baseball. It's
1:59:37
clear hierarchy. A hierarchy is different and it's where you have these
1:59:42
either these non-transitive hierarchies or you have a system where you have
1:59:49
different uh components that do different jobs and they're related through these paths. Uh
1:59:56
so the dramicic aspect is like moving from one path to or one object to
2:00:02
another and then depending on what part of this path you're in those things are
2:00:07
important um at any given time or any given part of the process
2:00:14
um without you know mapping this to any specific thing
2:00:19
and I'm not going to do that because it's you know it take me a while to kind of figure out the example just think of
2:00:24
this as sort of like an alternative to a hierarchy. And then think about these nervous circuits as like the nervous
2:00:32
system isn't hierarchical, it's heterarchical or at least these paths that he's describing.
2:00:38
Okay. Mhm. So what he's trying to get at is the same thing that uh von Forester was
2:00:45
getting at was looking at sensory motor closed sensory motor loops or in this
2:00:51
case reflex arcs which um are this old thing that Sharington discovered and
2:00:57
that you know are kind of the basis for sensory motor closed loop systems. So,
2:01:03
you know, if I hit you on the knee, you have this local reflex arc where your
2:01:09
foot your leg goes up. If I give you a stimulus in a sensory motor loop, there's a little bit more uh control
2:01:15
there, but basically you you give a response, a behavior response. So, this
2:01:21
so the term reflex originally meant a disturbance which initiated by an extra nervous
2:01:27
organ returned by a nervous path to that same organ. So it's like if you have a
2:01:35
you know you you disturb the sort of the equilibrium state by tapping your knee
2:01:41
and then there's a response that comes out of that or I guess in the sense of reflex it's like if I give you a
2:01:48
stimulus you respond to that stimulus that's a reflex
2:01:53
um and then the law of bell magendi that impulses enter the nervous system by
2:01:59
dorsal and emerge by vententral roots which is just the pathways through the
2:02:04
nervous system specified the direction of conduction of these circular disturbances. So again circular
2:02:10
disturbances the reflex arc the sensory motor loops we're just interested in how
2:02:17
we perturb that that closed system sort of semi-closed
2:02:23
um of sort of reference. So if we think about the sensory motor loop that von Forester talked about, you might have
2:02:30
some sensory information coming in. You're acting upon it and that's sort of a self-contained thing. It can become
2:02:39
inconsistent over time. Perhaps you can perturb that by maybe the observer
2:02:45
normalizing things or you can have some external perturbation which maybe disturbs that whole system.
2:02:53
Um and then so he's just thinking about the the sort of the abstract level here
2:02:58
which is where um you know you're thinking about this sort of recursive
2:03:04
system of feedbacks and self- reference and then you're thinking about ways to sort of push that around or to perturb
2:03:13
it or to correct it in some way and it's not spec I mean it could be
2:03:18
specific to anatomy it could just be like a connectionist system which has nodes and connections.
2:03:26
Circular propagation in this direction was called droic in the opposite antidromic. So again droic is very
2:03:32
important with the possible exception of phenomena comparable to that described
2:03:38
by Porter. No response of any facector is ever indicated and antidromic reflex
2:03:43
although conduction in the reverse direction has been demonstrated in both the dorsal and vententral roots. So
2:03:49
droic refers to I guess specifically to this reflex arc and some of it like so
2:03:56
maybe it's a technical term they use in that um so you're propagating something
2:04:02
in a certain direction within the loop and if you're doing if you're going
2:04:08
forward it's droic backwards it's antidroic and you know I don't beyond that I'm not
2:04:14
going to get into that uh what that actually means in terms of what the
2:04:20
outputs of the network are or the loop. The term reflex has laterally been used
2:04:26
of any activity in which one pylon was external regardless of whether or not it
2:04:32
was somatic. Lack of anatomic continuity about the external pylon but uh aftercomers ignore
2:04:39
the essential circularity. All reflexes are drones activities of feedback
2:04:45
mechanisms and consequently their function includes all purpose of activity. So I mean you know this is
2:04:51
really getting deep into kind of jargon and things but um I think the point here
2:04:59
is I wanted to make is to say that these circular systems in the von Forester
2:05:05
paper he formalizes things in terms of cybernetic regulation can map to these sort of nervous nets
2:05:13
and what's going on in the brain and things like reflexes and reflex arcs And
2:05:20
you know and and again you know this is uh this is our guy without the shirt um uh
2:05:28
you know and so he's really interested in building what would then become um
2:05:34
neural networks so or I don't think he knew about neural networks at the time but basically a lot of his work would go
2:05:40
into that. Uh so McCulla um is is really kind of you know thinking about these
2:05:45
kind of system level aspects of the reflex their temporal importance in determining
2:05:51
the formal properties of nervous activity have been previously discussed. This is the null and pits paper 1943
2:05:59
concerning endoderms as well as reflexes. and as well to recall the given feedback circuits may be
2:06:06
regenerative for one temporal combination of excitations and degenerative for another. So these loops
2:06:13
in the brain or in a nervous system or in a simulated or artificial nervous
2:06:19
system uh they they're not persistent necessarily. Sometimes they are
2:06:25
regenerated over time and sometimes they degenerate into nothing. So you get
2:06:30
these loops that maybe are um transitive, you know, transient.
2:06:37
Sometimes they persist over long periods of time and so we don't really know why that is. We just know that that happens.
2:06:45
And so any number of parallel circuits may be utilized by a single drum and these circuits may divide and unite
2:06:51
without the disturbance ceasing to be dramatic. So this is kind of the idea of hierarchy. So you know hierarchical
2:06:58
system would argue that where if we had a hierarchical system here we would have
2:07:04
you know a main circuit and then component subcomponents of the circuit or we might have one circuit that
2:07:11
coordinates all other circuits underneath. In a hierarchy of course we can have these transient loops that kind
2:07:18
of exist in different parts of the network and that sort of contribute to the overall output. So there is no one
2:07:25
driver, there is no one sort of control system. It's just kind of locally
2:07:31
emergent. And this is kind of, you know, again, they don't have the language for this yet, but that's basically what
2:07:37
we're doing here. Um, and so we're interested in disturbances. We're
2:07:42
interested in these directional movements within these in these uh nervous nets and their pathways. And
2:07:50
then we're interested in maybe their persistence and how they're contributing to the overall output of behavior.
2:07:57
So this is a figure here, figure one. It shows again these are just all line
2:08:03
drawings. Um this shows the central nervous system, an excitatory synapse, a
2:08:10
receptor. So we have this loop where we have a syninnapse and a receptor. we
2:08:15
have this continual continuous line or nervous portion of path. So there's this
2:08:20
pro uh pro percession of time and processing over time. We have the
2:08:26
apherent peripheral neuron which is the receptor, the epherent peripheral neuron which is the aector and we have this
2:08:34
broken line which is the nervous somatic or environmental portion of the path. So if we think about this top part of the
2:08:40
diagram, it's basically the inside of the agent. This uh reflex arc or this
2:08:47
sensory motor um processing that happens within the brain or wherever it is
2:08:53
inside the agent. You have the receptor here. So information comes into the agent. It gets processed in some central
2:09:01
nervous system and then it gets uh you know executed as behavior through an
2:09:06
aector and then this broken line which is nervous, somatic or environmental
2:09:12
aspects are you know the the sensory information or in this case importantly
2:09:19
the perturbation that happens with this to trigger this reflex arc. So you have
2:09:24
this information coming in the receptor, but you also have perturbations that affect the output in linear and
2:09:32
nonlinear ways. So I think um
2:09:38
I think that's enough for this paper. Um, yeah, I mean it's it's jargonfilled
2:09:43
and it's maybe unclear to the modern eye, but but basically you're building
2:09:48
this cybernetic case for intelligent behavior from networks and this is all
2:09:55
very important I think to artificial neural networks to thinking about our
2:10:00
modern conception of behavioral feedback and then how this is regulated and maybe
2:10:05
that's useful to neuros systems neuroscience.
2:10:11
Yeah, it's um um
2:10:17
I'm blanking. Is it Grace Lindsay? Yeah. Had the book rec you know like like
2:10:24
covering um you know covering historic
2:10:31
developments like this. Yeah. Like seeing them in their context.
2:10:38
um for you know the remarkable
2:10:43
remarkable achievements they are. Um it would be
2:10:48
it would be interesting. Could an LLM make that paper readable to
2:10:54
a lot? I don't know. Translation problem.
2:10:59
Yeah, translation problem. Well, it might make it worse.
2:11:04
It might make it worse. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Yeah. Or or do you end up with the uh
2:11:11
what's the uh what's the Samuel Mark Twain um you know where he takes the the the
2:11:20
English story translates to French translates it back to English. Oh yeah.
2:11:25
Like like you know but you end up with this like completely different story. Yeah.
2:11:30
Yeah. Um good deal.
2:11:36
Yeah. Um and yeah, some someone who definitely
2:11:43
understood, you know, the the math that um that he was also, you know,
2:11:53
working with at the time. And I didn't I didn't realize UI I mean, yeah, UIC was
2:12:00
kind of like the med school. Yeah. like in the 60s they kind of shifted towards a full university.
2:12:07
I see. I said. Yeah. Yeah.
2:12:12
Um All righty.
2:12:18
All right. Well, next next week. Um I I the I think the
2:12:27
um the RX infer stuff that um I was talking about um is
2:12:38
something that they talk about as the great LLM basian
2:12:45
integration experiment.
2:12:50
So I I will I will try to say more next week.
2:12:56
Okay, sounds good. And you know like just in Yeah, I I I don't know if it's necessarily
2:13:03
where you know it makes sense for like open source
2:13:09
sustainability. Um but but it it would be it would be nice. Um
2:13:17
I think I think we'll have met um
2:13:23
forget what our next SF COGSAI reading group is, but um uh actually one of the
2:13:33
um so one of one of the papers um that I was suggesting for it is is is
2:13:41
actually got um has actually got the name or the
2:13:47
computational model is called Gecko. Oh yeah. like like I tried not to read too much
2:13:57
into that. Yeah. Um anyway, but I might I might talk about
2:14:04
I'm probably gonna bring up both because it's like like it might be too computational
2:14:11
psychiatry for the cog reading group. Yeah. you know, um, uh, I I think we're
2:14:17
gonna end up reading the Tom Griffith paper, that recent paper. Um,
2:14:25
Tom Griffith has a new book, I don't know if you saw this, that'll be, I think, out in February.
2:14:32
Um, and you know, like like this is the algorithms we live by guy.
2:14:39
Yeah. Yeah. Yeah, you know. Um Um
2:14:47
but but I like I like both these paper. I mean I like the the the lazy dynamics
2:14:54
and this this Gecko paper um in terms of just uh like interesting uses of of LLM
2:15:05
agents in um modeling. Not not yeah like like in
2:15:11
the gecko example it's actually proposing it's like you're having an LLM agent
2:15:19
propose the generative models for behavioral data sets.
2:15:25
Oh okay. Yeah. Right. So it's just like it's like anyway and so so so what you're trying
2:15:32
to do is actually have it's kind of like an AI scientist. Yeah. But it's an AI scientist doing
2:15:40
computational psychology. Okay? Because the the data you're modeling is something like reaction times or choices
2:15:47
or things like that. Um, and that actually relates to this lazy dynamics thing because I think I
2:15:54
think some of their examples, you know, this is just like the the non-science world is that
2:16:01
a lot of their examples and the kind of stuff that that actually the the PMC team is paid to do is actually all
2:16:08
marketing data. It's like like like the the the the
2:16:14
commercial probabistic programming companies like all work on marketing problems.
2:16:19
I think it's is actually really funny which by the way is is is kind of
2:16:26
Google's whole business. Yeah. Yeah. Yeah. I mean Yeah.
2:16:31
So um it's kind of a big industry, right? Right. Yeah. Anyway, so next time
2:16:39
Yeah. next time. All right. Have a good week. Thanks. You too. Take care. Take care.
