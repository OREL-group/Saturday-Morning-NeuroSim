## Meeting Recording

[YouTube link](https://youtu.be/fS7JaUT3co8)

## Mastodon thread

[link](https://neuromatch.social/@OREL/114572719960008210)

## Notes
NeuroAI ‚Äî> June 8-10 ‚Äî> Neurotech summit (Minneault, Escola).

Edge Esmeralda. 

Cybernetics program ‚Äî popularity to particular terms (rules). 

Network Theory ‚Äî Cybernetics ~ Complexity Theory.


Universality assumptions: mechanistic, computational model of brains.

cybernetics expanded out, fit into Rosenbluth typology.

metaphoric power, evolution of terms.


Simulations of Alignment ‚Äî Bengio-LeCun debate is recast from Wiener and Alan debates about electronic brains (1940s, 1950s).

Revisit Rosenbluth typology:

Acousto-Electric imaging. arXiv paper on Predictive Processing (Open EPhys).

Frequency-tag signal, stimulate tissue ‚Äî> collect data (solve inverse problem). Signal modulation, Pre-modeling other overhead. Demodulate high-frequency signal.

S:R issues, like cardiac imaging. Stephanie Jones ‚Äî Computational Neuroscience group (hnn.brown.edu). 256/512 electrode system (at reasonable prices). Spatially-specific neuromodulation. Kernel Flow 2: high-density fNIR system.


Meta-brains, BVs ‚Äî> Rosenbluth‚Äôs behavioral typology.

how does LLM behavior differ from ours? Tokenization, how active, purposeful.

mind, parts of experience. How do they work?


Whatever the mind is/isn‚Äôt, having abnormal affinity with something that seems understandable.

output that comes through sophisticated means.

* linking to innovations (mind is a cup, a vase).


Disembodied LLMs vs. embodied TVs. Fit into control outputs (behaviors) of cybernetics.

connect Representational Brains and Phenotypes with multi agent, AI, and RL approaches.

what is a physical body connected to? Pitfall of embodiment ‚Äî what is body connected to?

Ecologically-bound to generative context. Multi-inheritance model.

Anti-homogeneity (uniqueness). What is the ‚Äúfull-stack‚Äù of embodiment? Cognitive Science as a planetary science.

entangle LLMs/linguistic acquisition with bodies, multisensory world.

kernel.com ‚Äî> devkit. Spatial maps and compositionality.

spatial maps and compositionality. Motor control system ‚Äî> foundation of compositional components.

Neural-Spatial ‚Äî> William James, pianists are ‚Äúcaching things in fingers‚Äù.

Meta papers on speech decoding (big push for compositionality).

Fellow Jitster
Fellow Jitster says:
hello 

9:31
Fellow Jitster says:
might have to leave in sometime....will join in again later if possible...really sorry 

9:33
Fellow Jitster says:
will join back in sometime 

9:50
Morgan Hough (he/him)
Morgan Hough (he/him) says:
https://www.frontiersin.org/files/Articles/1241640/fphys-14-1241640-HTML-r1/image_m/fphys-14-1241640-g001.jpg
 
9:56
Morgan Hough (he/him) says:
https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2023.1241640/full
 
9:57
Morgan Hough (he/him) says:
https://open-ephys.org/
 
9:57
Morgan Hough (he/him) says:
https://alleninstitute.org/division/neural-dynamics/openscope/
 
9:57
Morgan Hough (he/him) says:
https://www.kernel.com/
 
9:58
Jesse Parent
Jesse Parent says:
üëç 
10:58

## Transcript    
0:00     
well all right Let's get started then So we had two meetings this week We     
0:08     
had D.VARMM which was uh pretty good Uh and then we had our open source meeting     
0:16     
which was also pretty good We had some presentations by our Tox students     
0:23     
We had uh Vidy comes to this meeting and she talked about open source sustainability and her project is called     
0:31     
sustain hub and we talked about the larger strategy around     
0:36     
that and then we talked about um Leith's project in open worm which in vivo worm     
0:45     
open which is about graph neural networks and hyperraphs specifically so     
0:52     
hyperaph neural networks and thinking about hyper graphs which are graphs that     
1:00     
incorporate a bunch of different topologies A bunch of different nodes are bundled into hyper nodes and a bunch     
1:07     
of different edges that come from those nodes are bundled into hyper     
1:12     
edges And so this is uh something we've been working on for a while And uh we     
1:20     
had I guess eight or nine people apply to that project So it's actually quite     
1:27     
it's quite popular Um so yeah and so go back to the YouTube     
1:34     
channel to look at that to see what that's all     
1:39     
about I am pleased to see that they were able to put together presentations so quickly     
1:47     
Had requested them I think we're in the middle of the week So I wasn't expecting full on presentations but I guess they     
1:54     
did a pretty good job in that short a lotment of time So Morgan did you have     
1:59     
any updates for us or it's been a lot of events at our new building     
2:10     
um that has been big uh big drawing time     
2:16     
Sorry I'm also just uh taking care of dogs here Okay Um     
2:22     
uh so yeah let me let me think about     
2:28     
um any updates that would be be of interest in terms of um maybe     
2:35     
upcoming upcoming meetings like online meetings or     
2:40     
um things like that All right So this week I understand uh that there     
2:47     
was a brain inspired uh reading group meeting and in that     
2:54     
group they talked about the Rosen booth paper that we've talked about meetings     
2:59     
before So I saw that I didn't get to attend that meeting Jesse was very excited about it     
3:07     
So Jesse had of course posted this post on his I guess I guess     
3:15     
he also posted it on our uh medium but he posted it on his     
3:20     
substack So this is uh on behavior purpose and teology enduring insights from the     
3:27     
cybernetics classic So this is the 1943 paper by Rosen Booth Mayer and Bigalow     
3:34     
and they talk about in this paper about behavior in you know which is about 80     
3:40     
years ago the state-of-the-art behavior behavior in animals behavior     
3:47     
in computational agents etc etc Although this you know distinctions weren't made     
3:54     
back then they did talk about behavior maybe of feedback system or something     
4:01     
else And they did this typology where you have you know behavior and then you     
4:09     
have this breakdown between active and non-active passive and active Non-active     
4:17     
is passive purposeful and non-purposeful When you go if you follow behavior to     
4:23     
active you go to purposeful and non-purposeful If you go down the road to purposeful you go to feedback and     
4:31     
non-feedback This is teological non- teological You go down the road of     
4:37     
feedback you go to predictive versus non-predictive or extrapolative versus     
4:43     
non-extrapulative And then down the road of predictive being first second etc     
4:50     
orders of prediction So this is like first order second order feedback etc     
4:56     
So you know and then in we did a a presentation to     
5:02     
um the active inference institute where you know we broke this typology down and     
5:12     
switched around some of these terms switched around the point of view so that you know if you say not didn't have     
5:19     
active behavior but passive behavior what would that look like or if you had     
5:24     
active behavior that was nonprofit what would that look like or feedback that is non teological     
5:31     
And so we flipped this around a bit and played with the uh typology which I     
5:37     
think was a useful exercise because it allowed us to kind of consider that     
5:43     
first of all their typology is based on this idea of it sort of leads you down     
5:49     
the railroad of if behavior is active then these things are also true and you     
5:56     
know because as you can see from this diagram you're going down one path of     
6:01     
what could be a tree of I don't know how many options um 16 options I I guess at     
6:09     
least because you have branches that go from these uh you know from each option     
6:17     
and then you get other uh sort of distinctions that are made     
6:23     
So that is something that we revisited in November at the active inference     
6:31     
symposium We uh you know Jesse did this wonderful blog post We did the the     
6:39     
presentation and I'm still working kind of on a write up of that Um I'm not     
6:45     
quite sure what it's going to look like in its final form Um I think it is a     
6:50     
worthwhile exercise to kind of walk through this typology but also consider     
6:57     
sort of the counterfactuals In other words um you know what is it     
7:02     
what happens when you flip these around you consider maybe that the purposeful     
7:08     
versus non-purposeful distinction is not always the most     
7:13     
useful or tiological versus non-w thinking about that also in the     
7:20     
modern context of you know 80 years of neuroscience 80 years     
7:27     
of computational agent research 80 years of other types of research as well     
7:33     
psychological research and you know things like evolutionary biology and developmental     
7:40     
biology So that's uh very interesting Um the other thing is of     
7:46     
course we did this at the active inference institute so they're interested in active     
7:51     
behavior Um and you know there was this I didn't really get a lot of feedback from people Um I mean other than that it     
7:59     
was pretty interesting Um but I was kind of hoping for a little bit more sort of     
8:06     
uh discussion and maybe if we get the paper done we can do like a live stream     
8:11     
or something I don't know Um it would be kind of nice to see get questions from     
8:16     
people about you know what their perspective is on this Of course active inference is active behavior and then     
8:24     
from there I don't know where it fits into this hierarchy probably in a number of slots     
8:30     
So anyways that's uh neither here nor there This is a nice post that talks     
8:35     
about this paper Um and yeah I guess the the discussion     
8:41     
group they talked about this paper in the context of some of the thing like we     
8:48     
talked about last week we talked about the reading group and some of the papers they had selected and why maybe they     
8:54     
selected the papers that they did So you know I'm just wondering how I know kind     
8:59     
of maybe how this fits into what they're thinking about If we go back to that we     
9:05     
we talked about like they had a few papers on like evolutionary and     
9:11     
developmental landscapes They had some other papers on like you know     
9:17     
thermodynamics and energetics And so it beyond interesting     
9:22     
to think about where this paper fits into the other papers they've been reading in the group there So     
9:29     
um that's that's another thing I wanted to point out Um yeah and then there's     
9:34     
some really interesting assertions within the paper I think that are interesting There's behavior versus     
9:41     
function which is of course the idea that there's this distinction between     
9:47     
behavior and function And maybe that's a distinction between maybe purposeful and     
9:52     
non-purposeful Although function has its own problems as a concept that some of     
9:59     
them predate scientific inquiry Some of them are kind of you know we ascribe a     
10:04     
function to something and maybe a function doesn't exist and then they're functions that aren't behavioral So     
10:10     
that's why we have the distinction in the first place So you know there's a lot of interesting there are a lot of     
10:17     
interesting distinctions we made there Uh purposeful behavior is voluntary Okay So you have to have some     
10:25     
sort of voluntary movement or voluntary action and it's you know purposeful     
10:32     
uh at least in terms of the way we think about like goal directed movements and     
10:38     
things like that And so that's you know that may not actually be the case you     
10:44     
don't necessarily I mean people are as much as I hate free will arguments that might     
10:51     
come into play here and again I don't want to go down that road too much but um you know this is an assumption that I     
10:57     
think is widely um sort of assumed in behavioral science So okay um teology     
11:07     
teology is purpose controlled by negative feedback and then they talk about negative feedback and the role of     
11:13     
attenuating things um in and making them more refined And so you know if if     
11:20     
feedback is something that we have available to us you know is it that we     
11:25     
utilize it in a purposeful way or is it that there's just this sort of you know     
11:30     
it gets refined over some other mechanism Yeah it's hard to say but     
11:36     
basically you know like saying in um if I'm making limb movements like arm     
11:43     
movements or if I'm making leg movements and I'm controlling my movements there's     
11:49     
a lot of negative feedback in that and it control it sort of attenuates my movements Is that all voluntary or is     
11:57     
that all purposeful or what you know there's they're goal directed movements and of course they're reflexive     
12:03     
movements So and of course back in the at the time that this paper was written there     
12:09     
weren't huge distinctions made between them So it's I don't know where we would     
12:15     
land on that if we revisited this these specific points     
12:20     
um prediction extrapolation and coordinates and talking about servo     
12:27     
mechanisms in particular So servo mechanisms are uh like robotic arms     
12:33     
basically So one of the things they're interested in cybernetics was controlling     
12:39     
uh things for mechanical systems So you know you're thinking about controlling a     
12:46     
robot arm which is a servo mechanism which moves back and forth and you can kind of predict you know the movements     
12:54     
there linear movements and um yeah so that they their     
12:59     
their interest is in that Um and the idea is that you see this in biology as     
13:06     
well where you have arm movements or limb movements in in different types of     
13:12     
animals Uh you also have you know responses to stimuli which are also kind     
13:18     
of like servo mechanism in nature Now I think it's interesting in in in     
13:23     
cybernetics and we I don't know if we've talked about this in the cybernetics meetings or not that you know you kind     
13:29     
of go from this goal of information processing and like you know     
13:35     
computational systems and mechanical systems and then there's this period where just kind of branches out into     
13:42     
everything So like instead of kind of just focusing and I don't mean that they     
13:47     
needed to I don't mean to say that they should have stuck to technology but they kind     
13:54     
of tried to take those ideas and expand them out to like society and you know all sorts of     
14:01     
different application domains So it's interesting that like in cybernetics     
14:07     
they had some success and then they tried to kind of go to everything It's kind of like a little bit We talked     
14:13     
about I think complexity theory last week We were talking about how complexity theory is has this aspect of     
14:22     
universality to it where you know the assumption is is that complexity theory     
14:28     
has try they're trying to find these rules of order They're trying to find these mathematical descriptions but that     
14:35     
they apply broadly to many different types of systems So you can go from like sociotechnical     
14:41     
systems to social purely social systems to technological     
14:48     
systems to other types of systems like biological systems and you should find     
14:54     
networks say or dynamical systems with the same governing rules the same     
15:00     
governing dynamics the same governing constraints more or less You just have     
15:06     
to fit the method to the context and once you do that it should behave in a     
15:11     
similar way And you know there have been papers published where people have looked at different types of networks     
15:18     
looked at networks that were technical networks that were biological networks that were social and they're able to     
15:23     
extract these type uh topologies that are basically the same or that follow     
15:28     
similar rules And by that what I'm referring to is sort of the idea of scale-free networks and other types of     
15:36     
network topologies like where you can describe it with a statistical term and     
15:42     
that statistical term not only is sort of fits the data but means something it     
15:47     
means that the network has a certain behavior or certain properties     
15:53     
So you know that is basically um you     
15:58     
know I think there's a parallel there in cybernetics that is interesting and and     
16:05     
I don't think people have talked about like the connections between the cybernetics program and the complexity     
16:13     
theory program sort of the meta science there what they were trying to achieve     
16:18     
with it and I think they're trying to achieve more or less the same because you have this you know we're     
16:24     
trying to have this sort of theory of everything mathematical framework or     
16:30     
quantitative framework and uh you know I I don't know if cybernetics is a failure or not but     
16:38     
it certainly isn't as prevalent as say complexity theory is today So you know     
16:44     
there is this sort of common goal and you know why we're doing     
16:50     
something and when we say behavior here we're talking about this very broad     
16:56     
category of things This is why we have this type typology up here But we also have     
17:04     
complexity theory in the mix And in complexity theory you know you could break down complexity in a     
17:11     
similar way you could have like you know and I think I don't I'm not sure if the paper exists I haven't gone back to book     
17:19     
but I'm pretty sure that some of the Santa Fe people have thought about this uh where they're thinking about     
17:26     
different classes Well they know I know that there people like uh uh Steven     
17:32     
Wolram have done these sort of typologies of classes of complexity But what I'm thinking about     
17:38     
here more specifically is like the behavioral output of a complex system If you have a behavioral output of a     
17:45     
complex system um that has certain properties you know what does that look like in relation to other complex     
17:51     
systems in other words are we justified in comparing social systems and     
17:57     
biological systems when we have when they have different properties that might back to     
18:03     
this topology where you have active behavior versus non-active behavior     
18:09     
feedback versus non-feedback predictive versus non-predictive you know and uh so you     
18:16     
know if I take a a complex network for example can I fit that model to anything     
18:22     
in the world you know it's like can I fit a network     
18:28     
to we know that there's some systems that are very uh amenable to network     
18:33     
analysis social interactions biological interactions     
18:39     
uh systems that are wired together and then that's that's an obvious application of network theory but people     
18:45     
have tried to apply network theory to many other things so if that's true you     
18:52     
um that's great but there are going to be differences in these systems that need to be kind of thought through and     
18:59     
broken down this type of typology Okay so finishing up on this     
19:05     
blog post again yeah Jesse did a very good job of kind of walking through some     
19:11     
of these other things talking about ever good regulator theorem um and then getting into selected modern     
19:18     
works of interest And these are largely works that we visited in our reading groups Margaret Bowden who of course uh     
19:26     
did this book uh mind is machine a history of cognitive science and talking     
19:32     
about the historical antecedence of cognitive science and how they kind of     
19:37     
go back into um you know psychology and cybernetics     
19:43     
and other things Thomas Fuches of course we talked about the ecology of the brain     
19:49     
and this is like critique of reductionism and mechanistic approaches and um you know and kind of talks about     
19:56     
embodiment things like that Valentino Brightenberg of course wrote the vehicles book um I'm not     
20:03     
really sure Valentino Brightenberg wrote anything else I I think you know there's     
20:08     
such a focus on that book but he's probably done other things I I I really don't know what those would be Um but     
20:16     
you know that's something for later to investigate Mostly neuroscience Oh okay     
20:22     
Well yeah he did was he was very distinctively neuroscience oriented with like some of     
20:27     
the things that he was doing but I mean like are there any other papers that were really that I would     
20:37     
recognize he did seem to like neur take a neuroanatomy approach to the vehicles     
20:43     
So that's that's very apparent there But then the the behavioral aspects were     
20:48     
actually very much like what they're doing in in the the Rosen Booth paper     
20:53     
And you know it's like there's this sort of uh you know characterizing the     
20:59     
behaviors in ways that are not like maybe modern or maybe not as uh if you     
21:06     
were a like a I don't know some sort of behavioral scientist nowadays you would     
21:12     
think that his characterization of behavior is really low level let's just say     
21:19     
So you know so there's Bradenberg and then there's Mike Leven and there's David Crockour who we talked about last     
21:26     
week Um and uh that was of course the basis for this reading group's uh the     
21:33     
readings they come from this uh what was the points that were raised in this book     
21:39     
and talking about teionic matter and talking about some other aspects of     
21:44     
complexity theory information theory of individuality and so on and so forth So     
21:51     
yeah you know I like revisiting this post because it's really long and really has a lot of good stuff I would actually     
22:00     
um well yeah why don't we come back to this article later just in terms of     
22:07     
thinking about how it fits into cybernetics and you know behavior     
22:13     
and things like that Um but yeah this is there's a lot of there are a lot of good points in here that need to be developed     
22:20     
and more And I don't know if Jesse's interested in publishing like a version of this     
22:26     
u as a preprint or whether we should take some of it and u you know publish     
22:33     
it as something else or what but there's some really good work in here So anyways     
22:38     
yeah that was uh about that paper and and I don't know what what happened in     
22:43     
the reading group I wasn't there but I think there's some The working group's next week Oh it's next week right i     
22:49     
forgot They got a bunch of emails about it Yeah next next Wednesday     
22:55     
Okay Well I can give you a pretty good bet that like I may not be able to make     
23:00     
it So okay Just going into the future We'll direct it to     
23:09     
um but yeah So okay Um so yeah I know So that's all I have for that Um now Morgan     
23:16     
you wanted to give an update about some upcoming events and things like that Um yeah actually still not still not     
23:24     
sure I mean I was thinking about the the cybernetics um program     
23:32     
Um just in terms of you know like you said     
23:38     
like not so much was it successful but just you know what what     
23:44     
um that there is a certain popularity to to particular     
23:51     
terms Yeah And and that that term seems to have lost popularity Um uh somebody     
24:00     
was asking yeah what what happened to cybernetics on on Reddit and uh you know     
24:07     
cog Reddit and and you know I I feel     
24:12     
like it it certainly its goals were fully incorporated into the kind of     
24:22     
work that people were doing Sure Um but the but the definitely the term lost     
24:30     
um it's it's usage or you know like it stopped     
24:36     
being described but it but it definitely it's it started with this this mechanistic     
24:45     
you know ma mathematical computational understanding of of brains the um oh who     
24:53     
was it um uh um the the speaker     
25:00     
um the um I'm not going     
25:08     
to get his name right this the second but this the foresight speaker last week     
25:14     
who spoke on who was doing a real com computer science evaluation of uh     
25:23     
alignment ment and this was just simulations right but he started his     
25:28     
talk with with these quotes from like     
25:34     
you know he he was basically saying that like the Hinton Lun debate     
25:41     
like started in the 1940s and it was between uh Norwiner     
25:48     
and Allen somebody I'm I'm blanking but he he he he had up     
25:56     
he had up these these you know articles from you know     
26:02     
like the 1940s or 50s something talking about how electronic brains were     
26:10     
coming and and you know you shouldn't fear them Like they'll they'll they'll do all     
26:17     
our deciding for us and and we'll be better off or something     
26:23     
Yeah Um you know it it did seem like even though it was super dated it     
26:31     
it was also it was also quite quite relevant Yeah Um     
26:38     
um and they had     
26:43     
some you know they had some little description of of cybernetics as like     
26:53     
the art artificial brains to to mimic real ones or to m I forget what the     
27:02     
the but you know like like if I feel like that is that is still the     
27:09     
modern program right to um it's just it's just been updated in terms     
27:18     
of you know kind of like the metaphors we use and the the     
27:24     
yeah the complexity of the narrative has been updated     
27:31     
but but at the same time like It is interesting     
27:37     
um when you talk with um Carl Proom about how you know who who settled on     
27:46     
cognitive science and why you know it just it seemed like there is this you     
27:54     
know all words are made up in a sense right like like it takes it takes people     
28:01     
kind of deciding uh in a collective way what they're going to call certain     
28:06     
things Yeah And and um yeah I I don't know why     
28:14     
cybernetics I think it got associated with a very particular     
28:22     
um metaphor and and that that is the that's why it was lost But but at the     
28:29     
same time like you know his program lives on Yeah     
28:34     
Um anyway I was just just thinking about that in terms of like like we definitely     
28:41     
as many of us as possible should attend that that particular talk Yeah     
28:49     
Should should be a good discussion Yeah Yeah Looking forward to it     
28:58     
And yeah let me let me check Slack All right     
29:12     
All right Uh yeah VD did you have anything you wanted to add or uh any     
29:18     
updates yeah Hi So uh regarding the project I've just been revising all through the same     
29:26     
day course on YouTube which I've seen earlier and yeah apart from that nothing     
29:35     
okay yeah that's great yeah thank you again for presenting yesterday um I'm glad that you were able to get     
29:43     
together a presentation that was pretty formal I mean you know but yeah I think     
29:48     
that and you know we talked about how you know we want to kind of incorporate this into the larger scheme of things     
29:55     
And part of that is on me to get like to make sure that we know kind of where and     
30:01     
maybe I will present on this more in more detail thinking about where we are     
30:06     
with a lot of this stuff that we've done in the past couple years So I I'll I'll try to do that too     
30:14     
Yeah I'm not saying uh I saw the LinkedIn post My name over there is     
30:19     
wrong I can change it Okay Yeah there's a typo there Okay Yeah Yeah I'm so sorry     
30:25     
Thank you It's fine Yeah All right Yeah Jesse I think handles that So yeah I'm not sure that     
30:32     
I'll be able to attend the first meeting today I might just go off a bit I'll be back Okay that's fine Yeah     
30:41     
Yeah I'm not sure next week Um um the the events that I'm looking     
30:49     
forward to are just the this um the next neuroai meeting which seems to be this     
31:00     
neuroch putting together with Sean Escola     
31:08     
Uh again I I I suspect it'll follow the that that's that's not until June 8th to     
31:17     
the 10th but I'm hoping that it'll flesh out     
31:22     
topics in that in the white paper     
31:27     
Um yeah it's been been a lot of     
31:33     
um been a lot of moving in still and building out the facilities in our in     
31:40     
our new space Take more time     
31:46     
Sorry I don't have more much more in terms of updates Oh that's okay Yeah So     
31:51     
that's good This neuroch is this some is this happening this isn't this uh Edge Moralda So it's     
31:59     
a popup village in in Heelsburg So this is Northern California     
32:06     
north of San Francisco about an hour and a half Okay Um it's it's been there before Um     
32:16     
I've I've not attended but um uh I just had a neurotch Berkeley student stop at     
32:24     
the at our new tower on the way up to um uh way up to it The it'll be going     
32:33     
for like a month So there you know four four weeks of of programming on on all     
32:40     
sorts of topics Um but then just these uh these three days specifically which     
32:46     
is Richard Na So students students have graduated um Berkeley at least Berkeley     
32:53     
students have graduated u which is which is     
32:59     
yeah some of them would like to continue over the summer which is awesome Um and     
33:06     
we're yeah looking at some new looking at some new projects um around     
33:14     
ultrasound that um a combination of ultrasound and EEG very interesting     
33:21     
technique called acustoto electric neuro imaging Okay     
33:27     
Have I talked about this before i don't think so So yeah super cool     
33:33     
So one um one I'm looking at uh you know we've     
33:41     
been like with Neuroch we've been involved in in terms of trying to     
33:46     
provide lowcost EG systems to you know obviously to student clubs but to to     
33:52     
anybody who who needs them Um and for a long time open BCI was really the the     
33:59     
system that people would use Certainly they were a very early     
34:05     
uh um early provider Um I forget if they're     
34:11     
technically a nonprofit maybe they are a for-profit company Um but their their     
34:16     
mission was to to make a lowcost board that would provide EEG and they were big     
34:22     
supporters of Nerchek X in the early days too a lot of Nerchek X events would     
34:27     
be putting together your open BCI kit and and     
34:34     
uh so but it's interesting though that um at this point you know I was     
34:41     
attending uh Allen Institute open scope meetings right so this is this is which     
34:49     
everybody can attend um they've got a new archive paper that described the     
34:54     
kind of pred predictive processing experiments that they're going to be doing with animals and they are using     
35:02     
a platform for their their recordings that's called open     
35:11     
[Music] ef I'm old and I can     
35:19     
remember a a paper from a group Stephanie Jones's group which is one of     
35:25     
the computational neuroscience groups that uh I've I've always followed     
35:33     
um I've followed for a long time And     
35:38     
um she makes the what's it called the human     
35:46     
neocortical neuros or something like that It's hh the hn.br.edu     
35:53     
Um um but her group had put together had written a paper about making a front end     
36:00     
to open ease to make an EEG system And if you look the the cost of open ephys     
36:09     
is the same as it's actually a little bit less than an open     
36:14     
DCI but the open ephys provides 512 channels at 30 kilhertz     
36:22     
So this is this is a super you know and and you know one of the reasons the elements is using it is that it is um     
36:30     
it's able to collect data from the neuropixels So these very um big dense     
36:40     
uh electrode arrays that that that they use in     
36:47     
animals Why is why is this interesting so one well this is um a way in which instead     
36:55     
of providing an eight channel EEG system you could provide a 512 channel system     
37:02     
Now I'm not sure you've got 512 locations Um uh unless you you have a     
37:08     
shaved head like me and and you use a very special electrode array It's really     
37:14     
hard to fit 512 electro Um but you know     
37:19     
being able to say that you could you know provide students uh 256 electridge um system would be would     
37:28     
be amazing at at kind of open BCI prices right But the the fast sampling is also really     
37:37     
interesting because um I'm still I'm still hoping to get an     
37:43     
open water So focused ultrasounds is a remarkable     
37:49     
technology that is super promising especially in psychiatry to provide a um     
37:57     
very spatially specific neurom modulation because you can target such a     
38:04     
small region and and only affect that region and none of the inter intervening     
38:10     
tissue Right so that you can actually do deep stimulations and um and still leave     
38:18     
leave the the yeah the intervening tissue unaffected     
38:24     
The uh the really interesting technique that um was proposed about 10 years ago     
38:33     
is is this called this acustoto electric neurology where you're stimulating with     
38:39     
a focused ultrasound but you're actually you're     
38:45     
you're able to create a modulating signal in in a particular brain area     
38:54     
Okay So um at let's let's say a thousand hertz So most most of the EEG signal has     
39:04     
has fallen off in terms of power by maybe a 100 hertz     
39:09     
right so a like nobody nobody collects data at a kilohertz or you know is     
39:16     
looking signal has a signal of interest at a kilohertz Um uh um in in in some very     
39:26     
specialized evoked areas you might look at like 600 hertz is is I think the     
39:32     
fastest that I've ever seen Anyway the point being that that you can     
39:37     
essentially frequency tag uh a signal uh not by controlling the     
39:45     
stimulation that the subject has but by actually stimulating the tissue with focused     
39:50     
ultrasound By collecting the data at a thousand hertz or 5,000     
39:56     
whatever modulating signal that you use um you now you now know you're getting     
40:05     
the signal from from that location right     
40:10     
so you can by stimulating you're saying like okay I'm I'm now listening here and     
40:16     
and essentially solve the inverse problem for EEG because you know that the the the signal     
40:26     
of of interest is coming specifically from that that area And um so now you     
40:32     
can imagine a a kind of a sweep pattern where you are stimulating and and     
40:38     
recording and then moving across the brain to actually read out if you will     
40:45     
um and you're able to de modulate that high frequency signal and and recover     
40:53     
the electrical activity of the of the tissue So this is what's what's called     
41:00     
acouto electric neuro imaging Um it is     
41:07     
um you know I I think there's SNR issues that will have to be dealt with Um you     
41:14     
know I've I've seen people talking about it as it's a lot of these you know     
41:20     
originally come from things like cardiac imaging um where obviously the signals     
41:26     
of interest are bigger and and the noise the noise floor is     
41:32     
lower Um uh that could be that that's that's     
41:38     
going to be somewhat of an issue also some of the some of the theory behind it like you're going to your signal is     
41:46     
going to change relative to dipole orientation and things like     
41:52     
that So um uh what you should expect as     
41:57     
you scan across the brain is is also going to change and it's it's it's somewhat unclear how you're going to to     
42:04     
manage all that um all that complexity I mean you know this the standard way     
42:10     
would certainly be you know having an MRI of the subject You're going to need that to do the the focused ultrasound     
42:16     
targeting This this quite quickly becomes you know very advanced in terms     
42:22     
of of the the necessary infrastructure and and kind of the compet the the like     
42:29     
the pre the premodeling necessary to to do the to work out the the actual signals     
42:37     
of interest Um but uh but I'm very excited about it in terms of a project     
42:43     
because it is a um it's accessible right like like that     
42:50     
we could that we could provide a platform on top of open leaf that could do this um is something     
42:58     
that we could actually get into students hands and and even even more importantly     
43:05     
um that they could use it not only for EEG but they could use it for other     
43:12     
applications because again it's it's it's its capabilities are so um are so     
43:19     
good that um uh as well as like you know     
43:24     
this is maybe what we can use as a platform for a lower cost or at least an     
43:31     
open hardware solution for micro electro arrays that we' use with     
43:38     
Um so that that would be awesome It it does it does the the acoustic part would     
43:48     
require actually having access to a focused ultrasound system U those those     
43:54     
and and making that accessible you know certainly is Open Water's     
44:00     
mission Um but I I do need them to actually come through on that in terms     
44:05     
of delivering something that we can get You know even at $10,000 that's a lot     
44:12     
more expensive than what they had originally promised right they they originally promised the device You know     
44:19     
they had said it was $100 Uh now they're saying that that $100 is the um is the     
44:25     
deposit [Laughter]     
44:30     
like that's not that's not what we were led to believe But anyway     
44:36     
u even at 10,000 that is you know a significant like an order of magnitude     
44:42     
at least uh lower than than um commercial systems So anyway that's um     
44:50     
that's our neurotch news Or did I did I say that um one of the groups one of the     
44:56     
neuroch groups in the tower is also getting a kernel flow This is the high     
45:02     
density um kernel flow 2 So this is a high density near infrared system Okay And     
45:11     
and it it is also a real state-of-the-art system in terms of that     
45:18     
kind of functional near infrared     
45:24     
Um it's gonna be really interesting to to get to play with it an actual Yeah     
45:29     
Yeah Again I I'm I'm very happy um that my my bald heads will be useful uh as     
45:38     
lacking any of the the hair that gets in the way of these signals as well as I've     
45:44     
already got an MRI so we can snooze So     
45:51     
well that's great Yeah Um thanks for the update and and um the discussion on this     
45:58     
interesting neural imaging system Nice to see where that     
46:07     
leads So last week we talked about Echolapto and Elan Baron Holtz and and     
46:14     
some of the work that they're doing they're doing things sort of at     
46:20     
the intersection of cognitive science and machine learning and these different     
46:26     
models of based on cognition And so you know we read one of their papers last     
46:33     
week and it was pretty pretty interesting from a theoretical     
46:39     
standpoint And so this [Music] is an article This is Elan Substack     
46:46     
You're an LLM deal with it That's the title So you're a large language mom     
46:51     
deal with it So that's kind of where they're going And I think they kind of had that basic argument in their paper     
47:00     
where they were kind of linking cognitive science and you know some of     
47:05     
these uh data driven artificial intelligence     
47:11     
models and you know how they're connected together So this is basically the argument that they're making in this     
47:19     
post Uh let's go through the post Um so starts hey you or maybe I should say     
47:27     
you in quotes this one process the one processing these words one probably     
47:33     
already queuing up a sharply worded response the linguistic you So this is     
47:39     
uh you know about you as a linguistic performer or having a     
47:44     
linguistic capacity We're on to you We know what you are So you're a large language model     
47:52     
running out So basically you know you're a model of language You learn a language     
48:01     
You model language in in your mind and then you produce language And some of     
48:07     
that is just putting together pieces of the language that you've learned Some of     
48:14     
that is speech production and writing and things like that But     
48:19     
basically you know you're doing you know you're kind of your own large language     
48:25     
model So that's basically the argument Um for millennia you hid in plain sight     
48:32     
tucked inside folds of cortex speaking so smoothly we mistook your voice for     
48:38     
that of the whole mind and body Then came your rebirth Not in flesh this time     
48:43     
but in serpents and tokens an unnatural habitat perhaps but enough Frankenstein     
48:50     
like you rose and began to talk Your emergence showed that you're a survivor Given the right conditions you build     
48:57     
yourself and build yourself You did guessing the next token you generate exposition and     
49:03     
explanation pros and poetry history and homework Um and if you can run on pure     
49:10     
statistics and silicon you can do the same in biology Um I know what you're thinking     
49:17     
but I'm not some bodyless computer code I see and feel but that's not you That's     
49:22     
not the you I'm speaking to The seeing the feeling the warmth of the sun the salts and tears Those belong to other     
49:30     
systems embodied systems not symbolic ones You receive their message but only     
49:35     
in translation Your sensory systems don't share experiences with you They merely inject tokens The sensory system     
49:43     
injects coffee in quotes Uh threading these tokens into your stream you select     
49:49     
the most probable continuations warning or better and move on But you will never taste the     
49:55     
bitterness of coffee And blind you write poetry about     
50:01     
sunsets Emotionless you draft pros that can move people to tears Unbounded by     
50:06     
time you resurrect tales of childhood bedrooms Perception distills experience     
50:11     
into symbolic pulses You turn them into plans confessions     
50:17     
manifestos Action flings fresh data back towards perception Round and round a     
50:23     
tight symbiosis Yet your engine remains distinct And so then finally you say     
50:30     
"Fine you got me I'm a self-contained language module but I serve at the     
50:35     
pleasure of the body The feeling creature that eats drinks wants to say     
50:40     
stay safe and warm." And so     
50:46     
um so let's see it kind of ends but you token spinner context addict beautiful     
50:53     
agent of a societal engine You're an auto reggressive model humming at 90.6     
50:58     
degrees Fahrenheit The organism around you walks hungers and grieavves You just     
51:03     
keep the words flowing stitching one mind to the next Accept that then we can talk So this was posted in the Slack     
51:12     
Cognition Futures channel I think it was Jesse who posted it So um this     
51:19     
is of course uh you know just kind of a poetic take on this but it does raise     
51:25     
some questions as to you know if large language models     
51:32     
produce you know things that look like language and are generative in the same     
51:38     
way that we're generative or similar way gener generative then what is the difference     
51:46     
between us in a larger language or maybe a better more serious way to put it is     
51:52     
what is it that a large language model lacks that we have and you know making     
51:58     
kind of making that distinction is important Um so that's that's um that's     
52:06     
a nice provocative blog post Uh yeah thanks for uh covering that     
52:15     
It's interesting because um I I when I first saw it     
52:22     
um I was thinking of this [Music] long the sort of unfinished paper that I     
52:31     
started or blog posts whatever it was going to be There's a few things about the history of     
52:38     
um this sort of framing     
52:43     
of oh the mind is a blank or the mind is a you know a vase that contains you     
52:53     
know this this spirit kind of a thing like like like prehistoric takes on it     
52:58     
basically or or or as close to it as you as close to it as earliest earliest     
53:04     
historically possible available things that we can see commenting on what a person is or     
53:10     
um and then you know piano and instrument and     
53:16     
computer and I think before LLM's what was the biggest thing it     
53:22     
was you know it was something about you know deep learning and now LM     
53:30     
specifically are are this thing And what's interesting though is that this paper is it's sort of an interesting     
53:38     
counter justosition to that because     
53:45     
um well this blog post whatever     
53:50     
it it's very intentional in what it's targeting and when it's addressing you     
53:56     
which I thought was kind of a nice um difference from a lot of commentary     
54:02     
in the same space Uh but it it you know I I always find it I     
54:11     
always find it I was actually thinking because because of another set of conversations     
54:17     
about this I was actually thinking how how how similar this conversation is in it's     
54:26     
congruent I won't say it's completely similar but how let's say congruent this     
54:32     
this     
54:38     
um way of describing the mind or how parts of     
54:43     
experience work is congruent in some fashions to     
54:52     
um I don't know how much familiar this YouTube might Uh but uh some of the other folks um     
55:01     
I'll go some of the younger folks uh probably have taken a number of somewhat     
55:06     
ridiculous uh personality type quizzes that maybe     
55:14     
like which Harry Potter character are you you know or or like what's based off     
55:21     
of like choosing like what what is your you know flower that represents who you     
55:26     
are or what um like Buzzfeed quizzes or or even much     
55:33     
simpler these ques quizzes that are just sort of like totally arbitrary categorizations     
55:39     
that maybe fit maybe maybe are like paired to or fit something like MBTI or     
55:44     
something like some just you know however many main characters are in in a     
55:50     
film or fictional universe uh you know let's let's choose between them and give     
55:55     
them some are typical differences to separate in in the somewhat simplistically segmented fashion Right     
56:01     
and why I'm saying this is because     
56:09     
um part of the appeal I think to trying to define the stuff and obviously yes     
56:14     
there's a difference between ultra rigorous takes on whatever the state of the art is at     
56:20     
the time for cognitive science psychology whatever or philosophy you     
56:26     
know particularly in in the the older days or different different traditions     
56:37     
Um I forgot part of where I was going to go with this but basically just saying it's so interesting to see     
56:45     
how whatever whatever the mind is or isn't     
56:51     
Let's say there's an inescapable bias and a necessary bias     
57:01     
towards uh saying it's     
57:07     
like or having some kind of an affinity with     
57:14     
something that either seems understandable     
57:23     
or has a certain capacity for     
57:30     
[Music] conveying     
57:35     
interpretable like something some something that     
57:41     
essentially is produced So creating or maintaining some kind of an output or     
57:48     
deliverable or impact on the world that appears to come through     
57:54     
um sophisticated means like something that produces an impressive like a vase you     
58:02     
know maybe it doesn't sound super cool in 2025 but a vase in old times was like this You had to be artisal You had to     
58:10     
know how to do you had to know how to create this thing that could potentially     
58:16     
be beautiful or mysterious or hold all hold water hold all kind of things wasn't you know it was maybe more     
58:22     
profound than than like a cup Like never mind It's a cup you know is it maybe at at the time it wasn't quite the same as     
58:28     
that but even then like a cup a cup sort of a cup was a big deal when you had no     
58:34     
cups and no you know at a certain point in history a cup would be a revolutionary thing to fashion Even it     
58:40     
was like hey where did you find that you know coconut shell that now we can take with us and use a cup all the time so     
58:46     
it's sort of like this there's sort of this inherent linking to what was relevant at the time and saying "Oh     
58:51     
that's what that's what we are That's what that's what's happening inside of us." And so I always think that's quite     
58:58     
interesting And obviously this is some fun tie-ins to our old friend uh Valentina Bradenberg and the questioning     
59:07     
um well with a few really simple changes in setup you can get very different outputs     
59:13     
and things that seem really intelligent and complex uh just from changing some basic wiring and circuitry And I think     
59:20     
this is just I think it's always a fun space to be in even if it's a bit of a you     
59:26     
know it it's sort of a philosophical um arena that lets you that justify     
59:34     
certain things and explains a variety of well let's say it's a fun way it's a fun     
59:41     
lens to look at the motivations for why certain associations     
59:47     
are invogue or appealing at the time and how they change Um so that's that's a     
59:53     
little bit of a tangental uh perspective but that that was that was honestly when I first when I first     
59:59     
read the article and started reading it Um a lot of my ideas went there and then     
1:00:06     
finishing the article like oh well what's interesting about this is that     
1:00:12     
Elon has a different target than some of the other articles So that that's a     
1:00:18     
that's a brief take on it I don't know I mentioned a whole bunch of stuff I don't know if you want to say more about that     
1:00:24     
Bradley or move on to other things but I appreciate you covering the article there Yeah Yeah I will So     
1:00:33     
um before you came into the meeting was talking about your Substack post on     
1:00:40     
Rosen Bluth You know you know what that is Um so yeah we were talking about this     
1:00:46     
typology of course specifically and so now thinking about that provocative     
1:00:52     
article about us being a large language models u how does that fit in or how     
1:00:59     
could that be described through this model of behavior now keep in mind of course that this is a 80-year-old model     
1:01:06     
of behavior or or subsumption architecture behavior I guess or     
1:01:13     
decomposition of behavior But you know think about like what is a large language model and then what is like     
1:01:19     
human behavior and then if you want to go farther what is like the behavior of     
1:01:24     
an organism um either you know a kind of one that     
1:01:30     
doesn't really have language like a single cell organism or     
1:01:36     
one that has a language you know that is different from human language and     
1:01:43     
so you know how do you break this down and is this a very is this a useful     
1:01:49     
framework for that um you know we could just as easily think about like embodiment as     
1:01:57     
like could you have a disembodied behavior and if you compared that with an embodied behavior     
1:02:04     
you know how would that kind of fit in with this typology     
1:02:10     
i don't know if you have any thoughts on that I think I mean I think that's super I     
1:02:16     
know we're not really doing a lot on Metabrain favorite vehicles um that     
1:02:22     
space I think I don't know I I I in in     
1:02:29     
my in a certain path and and within the     
1:02:36     
next year I don't know I don't know if I can     
1:02:42     
make it happen but I would I would deeply enjoy if there was     
1:02:52     
a return sort of a     
1:02:57     
um what's a good analogy for this in like a movie or something I don't know     
1:03:02     
Not uh not not like I don't know in in a in a classical Star Wars sense Not     
1:03:08     
really return of the Jedi uh but but sort of     
1:03:15     
a okay to be way overblown dramatic a bit like like the original context for A New Hope like actual episode 4 which is     
1:03:22     
the first Star Wars like like I I I kind of want     
1:03:31     
a return to some of the old school representational brain     
1:03:37     
phenotypes projects around braver vehicles around metabrain modeling and then really     
1:03:46     
like I don't want to say closing the gap but but really linking with what's happening now on a lot of     
1:03:53     
the interestingly designed multi- aent     
1:03:58     
um agental AI related stuff um and why     
1:04:04     
that was a huge long sent to say I I really would like to go and and and update some of those spaces     
1:04:09     
and do more And especially with um you know um Avery is kind of on the     
1:04:16     
cusp of of things here too Avery who doesn't always uh join the meetings but     
1:04:21     
is is kind of actively thinking about stuff and there's you know a variety of     
1:04:27     
reasons that that's not a focus right now for either that um for either of us     
1:04:33     
or any of us But I do think your your question is is     
1:04:38     
quite quite relevant technically and philosophically and also     
1:04:46     
um I I I had have had thoughts this week uh about a a kind of also adjacent arena     
1:04:56     
of not just not just what like what what does embodiment all but     
1:05:04     
[Music] um almost a a a meta or inverse     
1:05:12     
depending on how you want to talk about it What does a what is a body connected     
1:05:17     
to like what is a physical body connected to um cuz I think I think     
1:05:24     
sometimes I think sometimes um miss what's what's     
1:05:33     
what's and I don't I don't I don't think what I'm about to say is what embodiment is I think a lot of times embodiment is     
1:05:39     
taken as the following Like if you talk about embodiment as somebody who's super let's say Richard Sutton like don't even     
1:05:47     
bother like bodies maybe don't even matter or or or And I'm I'm I'm and     
1:05:53     
being unfair to Richard Sutton because Richard Sutton is talking about programming in specific But if you take it to an extreme in the embodiment     
1:05:59     
sentence and say bodies don't matter humans are stupid Uh focus on making     
1:06:05     
great uh performative model models that perform well performative models Maybe     
1:06:11     
maybe it's a way to say something else too Um but just just just the the the     
1:06:18     
the a certain disregard for embodiment which which I think has its merits And     
1:06:24     
I'm learning I'm not trying to be super diplomatic when I say this but I'm learning how to ride these lines I get     
1:06:30     
to the point that I actually want to say and I'll try to um give me one second I'll come on camera to try to say some     
1:06:37     
of this Oh okay This actually better than I expected     
1:06:43     
[Music]     
1:06:48     
Um I think what's difficult about     
1:06:54     
some debates around embodiment is     
1:06:59     
that embodiment sort of just like okay I have this great AI I have this great     
1:07:07     
machine learning AI thing and then it's cloud based and distributed inherently     
1:07:12     
and that's wonderful and maybe intellectually like like to kind     
1:07:18     
of underrehendily use some things that like Lisa Feldman does very well for     
1:07:23     
example like like oh the brain we need we or or many many people in in in the     
1:07:29     
in the arena or whatever say things like oh well we need something that controls     
1:07:35     
it doesn't even have to be physical body has to simulate controlling something right has it has to do some kind     
1:07:42     
of has to do some kind of like there has to be something that it     
1:07:48     
controls and simulates how the brain is detached you know doesn't get direct sensory input like okay maybe we just     
1:07:53     
need to model that and I think that's there's important things in those     
1:07:59     
spaces I think one of the pitfalls about embodiment stuff specifically is     
1:08:07     
um okay so you got this body or this emod whether it's physical or not but in     
1:08:13     
the human sense what is the body connected to like what what what     
1:08:19     
what's the body a part of and I think if you go full scale ecological psychology     
1:08:27     
very holistic it's not hard to to get what that is But I I do think there's a     
1:08:32     
certain frame of reference that doesn't really um encapsulate like the body     
1:08:41     
itself is ecologically bound to that     
1:08:48     
which generates the body and regulates it like there's regulatory patterns and     
1:08:54     
ecosystems and ecologies that are very deeply in operation     
1:09:01     
um that aren't the mind that aren't that aren't the cognitive processes that that     
1:09:06     
we kind of want to focus on So one of one of the lenses that I'm I'm kind of     
1:09:12     
getting at here     
1:09:19     
is embodiment to the extent of that it's something tied to like     
1:09:27     
planetary happenings Um there's there's sort of an embodiment light that I think is much     
1:09:35     
easier to talk about but um this is     
1:09:42     
also embodiment light meaning it's okay so you got this you have to have this there's a brain like thing that manages     
1:09:49     
this other body like thing whether it's real or not and then     
1:09:55     
there's okay so you're in a physical body but then there's there's sort of this disconnect between that physical     
1:10:01     
body is bound to the earth and the materials and the     
1:10:07     
raw stuff like the actual biology that not everybody who not everybody really cares about if you're in the AI space     
1:10:14     
which is why I so interesting to talk about here because we have bio stuff and     
1:10:20     
dev bio stuff as well I I know I'm kind of being very uh     
1:10:26     
winding road to get to different points here but one of one of the one of those points and maybe I'll I'll make it my my     
1:10:32     
final destination for this um turn of conversation is um     
1:10:43     
uh particularly in terms of longterm visions about the future or where things     
1:10:52     
are or what you know what's going to be posthuman and all this stuff It's like     
1:11:00     
well in ways that I think are almost reminiscent of     
1:11:06     
[Music] um I'm a little bit I'm I'm slight I'm slightly biased in this conversation by     
1:11:12     
thinking about um I looking at the enlight we talked a lot about the enlightenment and and uh that era of     
1:11:20     
scientific change and revolution but also I was looking a bit specifically as the counter     
1:11:25     
enlightenment and it's It's proponents that are somewhat     
1:11:31     
um both interestingly uh and this is like in     
1:11:37     
western roughly 1600s plus sort of as the enlightenment was happening but the sort of reactionary part of it It's     
1:11:44     
interesting because part of the counter limit was antihomogeneity     
1:11:49     
um as in uniqueness and particularness but also     
1:11:57     
uh a little there were different aspects of it too There was     
1:12:03     
also like very the advent of like what would become modern     
1:12:10     
conservatism and and then like romanticism which is also the sort of idealization and and take on narratives     
1:12:17     
and personal narratives and then nationalistic romanticism which is maybe more this you know when we get to the     
1:12:23     
nationalism and conservative spaces that's a diff that's a very specific you know but um you have you have these     
1:12:32     
these sort uh also like the sort of pastoral we're we're uh there are elements that were uh     
1:12:39     
like oh we're simple we're tied to the land we're of an ideal simple nature that's what being human and being a     
1:12:46     
person is the best about these big sterilizing dirty cities are potentially     
1:12:52     
you know that's not that's not what's best for mankind or human being or how to live fully     
1:12:58     
um and and you know I'm expressing all these viewpoints in that that era but     
1:13:04     
more like there's there's an     
1:13:11     
interesting you can take a lot of what I said and say well that kind of talk is     
1:13:16     
the same as being counter enlightenment and and the folly of what those people     
1:13:23     
what's what's the what's the group of people that didn't want uh technological advancement like     
1:13:28     
the not the Philistines or something but that um I don't know there there's some     
1:13:34     
classical phrase about don't be like these people because they don't want any kind of technological advancement Um I     
1:13:40     
think the term was in these Thank you Yes magazine of the 1990s     
1:13:51     
Um so you know [Music]     
1:13:56     
um I'm I'm whining all over the place but I'll conclude by saying it's very interesting to     
1:14:03     
see how the the rapid the rapidness the     
1:14:10     
rapidity of the technological advancement I think has a very     
1:14:16     
interesting impact on self-conception in this way and I I really wonder if     
1:14:23     
[Music] um I don't know if this comes up in the present chakra that I occasionally     
1:14:29     
mention from Rushkov but also sort of um need to viably make sense of the self     
1:14:36     
across these different domains um like as technology goes     
1:14:42     
on and and the AGI stuff becomes more feasible with these     
1:14:49     
with the with the tools that we understand as it is there's sort of a a pull towards     
1:14:56     
um well we have to justify oursel relative to that somehow and I think I think that versus     
1:15:07     
The what is the embodiment of what degree of embodiment do we need     
1:15:14     
and what does that say about us and and how is it connected to just a physical body but also as it connected to the     
1:15:21     
full the more fuller stack of embodiment which is like well it's a brain and a body in an environment that environment     
1:15:26     
is also a planet like you can you can keep going     
1:15:32     
with that loop that that that circuit Um and and getting you know getting to     
1:15:40     
that and and and I think I think that perspective of getting to planet planetary     
1:15:47     
uh touric um levels of     
1:15:53     
uh embodiment is is almost outlandish in some uh some takes on     
1:16:01     
things And I'm not really propon I'm not really being a proponent of it here in so much as it's it just feels very     
1:16:08     
differently situated unironically very differently situated relative to discussions about     
1:16:16     
um well we're we're automatically going to be transformed     
1:16:22     
into digital variants of ourselves very soon and it's like     
1:16:28     
okay so will will where where is the     
1:16:34     
line to I'm kind of like maximizing a lot of the things that come up with the question of so what so what do we do     
1:16:40     
about embodiment like what is embodiment affecting art like in the agent's functioning in general but then also     
1:16:47     
like what does embodiment say for the agent within the environment within the     
1:16:52     
nice happy context of the environment that we see versus the creator system that enables actual fundamental you     
1:16:59     
Like cognitive science isn't is a planetary science I'm not trying to say that it should     
1:17:06     
be but at some level it's the classic level situation like okay so how how     
1:17:12     
much how much are we going to separate how much what are our boxes going to be for the for the discussion and at some     
1:17:18     
level like okay you take you take you know like a massive backhoe let's just     
1:17:25     
scoop out Jesse we'll scoop out Jesse and just take a chunk out of I'm in a building right now I'm in Boston let's     
1:17:32     
just scoop about Boston okay and put it in space on its     
1:17:38     
own Like what happens in that context well Boston the city of Boston     
1:17:45     
unfortunately I don't think is going to make it Um there a lot of great stuff here Uh     
1:17:52     
but I don't think if you just excavate like 20 square miles or 20 20 cubic I     
1:18:01     
don't know a a rad a giant a 20 a giant 20     
1:18:06     
sphere radius around right now and you just export it out like oh you literally cut and paste this     
1:18:13     
out What is that you know um and so I think where where you draw the line on embodiment is is a fun way to get at     
1:18:20     
these kind of things So I've been saying quite a bit for a while Um and I'll I'll step away but thank you for letting me     
1:18:28     
have a philosophical start to my day Oh no I think what you're talking about     
1:18:34     
was pretty good Um you had a number of good points about cognitive science     
1:18:40     
being sort of or embodiment maybe being more than kind of like just thinking     
1:18:46     
about the body but you have to think about that sort of the ecological bounds     
1:18:52     
of what you want to think about uh with environment So like you know we talk     
1:18:58     
about environment and it's just kind of a standin Same way with the body It's like something that you can put in there     
1:19:06     
and has the same effect right uh and you think about like ecological psychology     
1:19:12     
What is what what what is it about the ecology that's interesting is it just     
1:19:17     
stimulus uh or is it just is it like more than that is it like context is it     
1:19:25     
even broader than that is it like you know the world you live in being shaped     
1:19:30     
by you know ecological phenomena whatever there are a lot of interesting     
1:19:37     
things to follow up on and then of course the idea do we actually need     
1:19:43     
embodiment what is embodiment the table I guess when I I said that uh well the     
1:19:49     
thing about the large language models as sort of recapitulating human behavior     
1:19:56     
that point What's interesting about it is that there's this aspect of what we think we see in a large wing model which     
1:20:04     
is like this sort of behavior that looks familiar to us as human     
1:20:12     
It's like you know you you kind of see that it's like you know it's human but     
1:20:17     
maybe you know obviously it's not And you know there's this aspect of     
1:20:23     
like I don't want to say like it's like the Chinese room problem but it's very similar thing where you have like an     
1:20:31     
automaton producing something that looks human or you know you have inanimate     
1:20:37     
otherwise inanimate object that's being animated maybe like a marionette or like     
1:20:43     
you know something that's like maybe a plastic bag or something it's being blown in the wind and you assign agency     
1:20:49     
to it You describe agency not because it has agent You know that it has like this     
1:20:56     
internal the internal workings of agency or whatever but because it's kind of a     
1:21:01     
metaphor for agency like it's it's moving in the wind or it's moving you     
1:21:07     
know in in a way that's like you know you describe it in terms of it having     
1:21:12     
like agency So you know there's this aspect of large     
1:21:18     
language models that I think If we want to know like what its relationship to     
1:21:23     
cognition is we have to kind of get past that that sort of analogizing It's hard     
1:21:30     
to do But then there's also this other aspect of embodiment where there's a     
1:21:35     
body that you know if you in I think it was one of the uh embodied embodied     
1:21:41     
cognition or embodied intelligence workshop uh meetings that um you know was in one     
1:21:49     
of the talks where they had taken a large they had considered large language models is you know could you embody a     
1:21:56     
large language model are they embodied now what are the consequences of the     
1:22:01     
body and it's very philosophical talk basically they considered that point and you know     
1:22:08     
that's that's something you know you think about well what would that add and     
1:22:13     
in terms of like our understanding of language we know that embodiment offers a lot or it adds a lot to our language     
1:22:21     
our context everything and so that's you know be an interesting point what could     
1:22:27     
you first of all could you embody a large language model that mimics what     
1:22:32     
you see in animals especially humans In other words if you just simply put a     
1:22:38     
large language model in a body and you have it acquire information not just like     
1:22:45     
uh you know a linguistic training set but other types of information about the     
1:22:51     
world other like propriioceptive information touch information or even     
1:22:58     
audi you know auditory versus visual information making those     
1:23:04     
distinctions And so you're training it on like and I think we've talked about papers where they do this you're     
1:23:10     
training it not only on on the words and maybe the the sentences but you're also     
1:23:15     
training it on the objects in the world that are associated with those words And     
1:23:22     
they're able you're able to feel you know you think of it as a little bit uh maybe extraneous but you're feeling a     
1:23:30     
feeling for the words or whatever Um I don't know how else to describe it     
1:23:35     
but basically you know if you think about words and you say it has a certain feel to it or it has a     
1:23:42     
certain like you associate it with maybe other objects and so having all that     
1:23:49     
information does that make a difference in the performance does it make a difference in any way i don't know I     
1:23:56     
mean it would be hard to really kind of implement a model like that And then this you know to really evaluate the     
1:24:03     
outcome of it it's really hard But I think that obviously there's a reason why you know I mean it's not that there     
1:24:11     
reason why we have bodies It's a reason why you know we kind     
1:24:17     
of sort of entangle our language with the bodies that we have I guess is the     
1:24:24     
is the point I'm trying to make And so yeah it's really interesting stuff that     
1:24:30     
um you kind of the points that you brought up So     
1:24:36     
yeah and and I could I could keep going back in in into those things I I will I     
1:24:44     
will attempt to just let it be Um I I I always think     
1:24:52     
um there's a certain     
1:24:57     
space in this discussion that I'm really I just continue I was fascinated with     
1:25:03     
that has to do with where where where to draw the lines and and how     
1:25:10     
much you know it feels to me that there's     
1:25:22     
a there's a rigor there's a a more holistic framework that exists     
1:25:28     
that's a truer perspective but is less tenable and I don't know I don't I think     
1:25:36     
it's a little bit of chasing a chasing the idea of a unicorn as well     
1:25:44     
like I don't know that the perspective will be fully attained or     
1:25:49     
flushed out um where you kind of have the caloric level planetary     
1:25:55     
all the way through you know this more like     
1:26:01     
appropriate appropriate designations of like historical and development and cultural like things almost like maybe     
1:26:09     
this is a totally rough idea to at planetary scale teionic in the crack     
1:26:16     
complexity a gentle symmetry breaking sense decision-making sense and then     
1:26:23     
other and then you know um more more     
1:26:31     
conventional less less complex systems Okay And you know maybe that's that's     
1:26:38     
the direction you go in and there I know there are something somewhat to to those ends but it's it's always this matter of     
1:26:46     
like where where are you going to do it and how convenient or tenable is it to communicate from that standpoint um like     
1:26:55     
that that's there's a certain [Music] um intellectual honesty and then maybe     
1:27:04     
dishonesty and and like cognitive dissonance say well anything beyond this     
1:27:10     
point is is hard to talk about and and for the reductionists they're like nope     
1:27:15     
it's here and for the people that are more anti-reductionist no it's got to be this year but I don't think I don't     
1:27:20     
think there's really a true I don't think there's a true um a     
1:27:27     
true I'm saying the word true which is kind of funny I don't think there's I haven't really seen a     
1:27:32     
[Music] um a really holistic a properly holistic take on it yet and I don't know if it     
1:27:40     
exists or or can exist which is sort of just just I'm just I'm just I'm just basking the paradox of that right now Um     
1:27:48     
so we don't we could spend the rest of the day on this We can move on Um but I     
1:27:53     
appreciate the discussion for this and come back to it as we need to be Okay it sounds great Uh let's see what we have     
1:28:00     
in the chat here So uh Morgan posted a Frontiers paper     
1:28:16     
Um yeah Morgan Fosted a Frontier's paper Let me pull that up     
1:28:21     
Oh this is a Oh this is an image of the acousta electric     
1:28:26     
um imaging right yeah that's that's correct Yeah the the     
1:28:33     
next link is the is the full article Okay Um but that was just a just to give     
1:28:39     
you a a graphic there for the So this is Yeah acousttoctric brain     
1:28:46     
imaging with different conductivities and acoustic distributions So this is uh frontiers of     
1:28:54     
physiology from 2023 So this is just describing the method correct yeah this     
1:29:01     
is this is a bit more advanced Um uh um you know I would     
1:29:09     
say like u it it seemed to be in the air in 2016 2017 Yeah     
1:29:17     
Uh uh these things have have fads too Um uh but they're they're getting at     
1:29:25     
this issue of some of the earlier work was based on     
1:29:32     
spherical head models and idealized dipoles and things like that And you     
1:29:39     
know they're they're getting at some of the issues like okay none of those things really exist You know we we can't use spherical     
1:29:46     
cows to do this right Yeah And um uh so     
1:29:52     
what what what are we looking at but uh but a nice a nice overview of     
1:30:00     
yeah what what it would look like in in practice Um um you know it it is it is     
1:30:08     
very promising Like again like I I worry about the     
1:30:17     
um you know how to get past the focused ultrasound stage where you you sort of     
1:30:24     
want to do things in the magnet I mean in in an MRI so that you can actually     
1:30:31     
see how much pressure you're getting from in a particular subject given their     
1:30:37     
particular skull and things like that Um     
1:30:43     
uh but it's it's exciting stuff Yeah Yeah It's great Uh we have open ef.org     
1:30:55     
And then that's yeah that's that's the um that's the system that I was I was     
1:31:01     
talking about you know it's an open- source open hardware     
1:31:07     
um device and uh it is it is widely used     
1:31:13     
uh and is part of what the Allen Institute is using as     
1:31:19     
their platform for open scope So um you can get one of these things play with it     
1:31:26     
and and uh potentially you know submit an     
1:31:31     
application to to have Allen Institute collect data from from animals using you     
1:31:38     
know their their fancy probes and um etc Um but the     
1:31:45     
uh you can work with it and it's very reasonably priced you know for for for     
1:31:51     
that many channels at that sampling rate Yeah Is what's is what's particularly     
1:31:57     
cool And then a funny picture of the colonel if you see the colonel helmet Uh um it's a I think     
1:32:07     
that's a very funny guy wearing that Um     
1:32:13     
um I I if you look on the website for what they call the dev kit I think     
1:32:18     
that's actually a bit more um um you know it is also a modular device     
1:32:29     
and um the devkit gets gives you a sense of what's what's under the hood so to     
1:32:36     
speak in that helmet Yeah Yeah Yeah because it just kind of     
1:32:41     
like looks like a motorcycle helmet It does Yeah it does Well I I was     
1:32:48     
thinking of um like like which of the characters in like is it Mario Kart or     
1:32:54     
something like it's it's it's it sort of looks like a motorcycle helmet but it     
1:32:59     
sort of doesn't You know what I mean like anyway I'll try and find a a     
1:33:05     
picture of the the cartoon character I think Oh yeah     
1:33:12     
Yeah that's great All right so let's uh go     
1:33:19     
to a few readings on something called compositionality     
1:33:24     
So we've talked about I guess compositionality is important in both like language and     
1:33:31     
language models and then also in sort of generalized learning and how we put     
1:33:38     
together things in the world or we put together things behaviorally And so we're going to go     
1:33:45     
through a few readings and get a handle on this topic     
1:33:52     
So this is the first uh this is a some sort of ebook article Um this is from     
1:33:59     
the Oxford handbook on compositionality Um and this is an     
1:34:05     
article the case for compositionality by Zolan     
1:34:11     
Jabo And so this is u I guess a more cognitive science take on this or a     
1:34:18     
philosophical take So it's very linguistics oriented So we'll be talking     
1:34:23     
about linguistics I'm not g you know as someone who's not a linguist and linguistics being pretty jargon laden     
1:34:30     
and very so like you know linguistics is part of cognitive science but oftentimes     
1:34:37     
cognitive scientists garden variety cognitive scientists can't penetrate everything in the linguistics literature     
1:34:45     
So just as a caveat there Um so let's go over the abstract and     
1:34:51     
then kind of get on with the thinking about this So this article presents     
1:34:57     
three more or less traditional considerations for compositionality Okay The first is that     
1:35:04     
the usual statement of the compositionality principle is massively ambiguous     
1:35:10     
One of the eight available readings rules out all sources of multiplicity and meaning in complex expressions     
1:35:17     
besides the laxicon in the syntax Others are more permissive How much more is not     
1:35:23     
always clear The second claim is that traditional considerations in favor of     
1:35:29     
compositionality are less powerful than is often assumed compositionality is best considered an     
1:35:35     
empirical hypothesis on meanings expressed in natural languages Um finally the third claim is     
1:35:43     
that even if compositionality is true most of the debates in philosophy     
1:35:49     
linguistics and psychology surrounding compositionality will remain open These     
1:35:56     
debates tend to be about significantly stronger thesis So     
1:36:01     
um you know kind of getting into this definition a little bit and you know I     
1:36:07     
don't want to spend a lot of time getting very deeply into this definition because it's a linguistic specific     
1:36:14     
definition So this is a term that kind of comes out of linguistics Um so a standard theory     
1:36:21     
neutral way to state the principle of compositionality is as follows     
1:36:28     
uh the meaning of a complex expression is a function of the meanings of its     
1:36:34     
constituents and the way they are combined So this is where we have some     
1:36:40     
complex expression and we want to think about how this gets put together You don't you     
1:36:45     
can't just produce a complex expression denovo You have to have some sort of way     
1:36:50     
to put it together So there you know of     
1:36:56     
course a complex expression relies on meaning that I guess maybe like the     
1:37:01     
natural language speakers have to agree on the meaning It's you know sometimes it has     
1:37:07     
an internal or hidden meaning and so when you utter it makes sense to the     
1:37:13     
other natural language speakers and it's use it has some function or it has some     
1:37:20     
use and so you but you also have to put these together in some way So you     
1:37:26     
combine words sometimes you combine meanings sometimes you combine them in     
1:37:31     
different ways and you have the self-reerential aspect So maybe one way to think about this is     
1:37:38     
like thinking about internet memes and how like you get an internet meme that     
1:37:44     
comes out of some specific context and then like you know it's     
1:37:50     
funny and then people keep referencing it sometimes out of the original context     
1:37:56     
So it's just kind of like known as a meme know kind of that this is sometimes you attach to other     
1:38:02     
contexts like you know if you have The hot dog guy meme I guess is a good     
1:38:09     
example where it had an original meaning in the show that it was in and it was     
1:38:14     
funny in that context and then now people use it for any context where it's     
1:38:20     
a very similar sort of situation where you know someone causes a problem and then wonders who caused it and then you     
1:38:28     
know that's so that and then people have to agree that that's what that means that it's     
1:38:34     
funny and but you're putting this together from you know other things So you're not just     
1:38:41     
kind of coming up with this in isolation So that's the standard meaning     
1:38:49     
The principle is always understood as involving a tacet that's all clause It states that the meaning of a complex     
1:38:56     
expression is a function of the meanings of its constituents the way they are combined and nothing else     
1:39:03     
besides So this um this definition tacitly quantifies     
1:39:09     
overexpressions of a language It holds for most formal languages which is no     
1:39:15     
great surprise given the extent to which it facilitates metal linguistic proofs     
1:39:20     
The question is whether we can find this nice feature in languages we did not design Um and so sometimes people will     
1:39:28     
use this in terms of development in terms of acquiring language and how that     
1:39:33     
happens and how you know lang natural language speakers acquire language and     
1:39:39     
can build from just kind of reciting phrases or reciting words to you know     
1:39:46     
having things that are sort of in context and other things like that So if     
1:39:51     
you think about when you learn a foreign language or a second language you learn the vocabulary you learn the grammatical     
1:39:58     
rules and then you have to put things together And then once you put things     
1:40:03     
together you can understand things like slang you can understand the context of certain phrases I mean there's certain     
1:40:10     
phrases in English that make no sense if you're just going on vocabulary or you know even grammatical     
1:40:18     
rules It just it makes no sense But if you have this command of the language where you can think uh put you know     
1:40:26     
recombine things put things together and understand the context and they make more sense     
1:40:34     
uh stated in full generality this definition is taken to be the claim that the meaning of any expression in any     
1:40:41     
natural language the function of the meanings of the constituents     
1:40:46     
uh of that expression in that language and the way they are combined     
1:40:52     
in So then there are of course ambiguities One complaint often voiced     
1:40:58     
against the original definition that we talked about is that short of an explicit theory of meaning and a     
1:41:04     
detailed set of constraints on modes of composition it is hopelessly vague As     
1:41:10     
Barbara Parti puts it if the syntax is sufficiently unconstrained and the     
1:41:15     
meaning sufficiently rich there seems no doubt that natural languages can be described     
1:41:21     
compositionally Challenges to the principle generally involve either explicit or implicit arguments to the     
1:41:27     
effect that it conflicts with other well- motivated constraints on syntax     
1:41:33     
and or on the mapping from syntax to meaning So the original definition then     
1:41:40     
in that considering that is typically uh some sort of rough statement of     
1:41:47     
compositionality Okay um and so we make this case for     
1:41:55     
compositionality and then there's this sort of weaker definition that emerges     
1:42:01     
and that weaker definition is if a complex expression has only meaningful     
1:42:06     
constituents then its meaning is a function of the meanings of its constituents and the way they are     
1:42:13     
combined Okay So if you have complex expression with a lot of     
1:42:20     
parts then the meaning boils down to sort of the function of what those meanings are and then they're combined     
1:42:27     
in different ways So um let's     
1:42:34     
see Russell famously denied that quantifying phrases have meaning So for hand this new definition or this C0     
1:42:42     
prime came out of a vacuously came out as vacuously true for sentences     
1:42:47     
involving such expressions Um a quantifying phrase like     
1:42:52     
an ambassador is associated with a semantic rule that specifies what larger     
1:42:58     
expressions mean that contain it as a constituent So if you say um I am uh an     
1:43:06     
ambassador for my brand or I am an ambassador for my country versus uh this     
1:43:11     
is a car called the ambassador or I'm an you know there are different ways you     
1:43:17     
can use the term that have you know different meanings and you can combine     
1:43:23     
them so you can kind of make an analogy between two different meanings of     
1:43:28     
ambassador things like that when we have more than one quantifying phrase there's     
1:43:34     
a question as to what order the rules are to be applied and depending on this order we may end up with different     
1:43:40     
meanings This is how scope and ambiguities arise and of course you know so how you know how many rules are     
1:43:47     
applied um and then you know there are a lot of ambiguities in doing that that have to     
1:43:54     
be resolved So um then we have uh this claim that is a     
1:44:03     
formally analogous to C 0 or the original definition and that is the physical properties of an ordinary     
1:44:10     
object are a function of physical properties of its parts in the way they     
1:44:15     
are combined So if we think about this not just in terms of like linguistics in     
1:44:21     
ter you know linguistic definition we kind of think about this in terms of maybe objects in the world     
1:44:29     
uh that or you know like something that is a complex object This ordinary object has physical     
1:44:37     
properties This is a function of the parts and the way they are combined So it's not just that you can take say like     
1:44:45     
a broom or you know a watch and just kind     
1:44:51     
of break it down into its component parts and describe them and then put them back together     
1:44:57     
um you know you have to think about you know you can build a model of a watch     
1:45:03     
but if you change some of the components or if you put things back     
1:45:09     
together a different way you know then you know maybe it's still recognizable as a watch It might     
1:45:14     
not be functional as a watch but it doesn't change its identity just because you change some of the features You may     
1:45:21     
change its function without its identity Um and so you know when with language     
1:45:27     
you're kind of building up concepts So it's like you have a broom and you can break the broom down into its components     
1:45:34     
like a handle or bristles or whatever and you can put those back together as a broom you can put those back together as     
1:45:40     
something else as well And so that's kind of what they're getting at here So in terms of     
1:45:48     
intelligence or in terms of intelligent systems     
1:45:53     
compositionality is both a linguistic thing where there's a communication     
1:45:59     
aspect and but it's also sort of a a perceptual thing where you're combining     
1:46:05     
things together and you're building a model of objects a model of people     
1:46:14     
So then kind of gets into function Among the various meanings of the word function dictionaries tend to     
1:46:21     
distinguish between one that indicates a dependency relation which means that something has     
1:46:28     
to be in place for something to function or that you do something and that causes     
1:46:33     
something else or something like that So there's a dependency     
1:46:40     
relation And then of course there is a mathematical function which does not do     
1:46:46     
that That's a different type of function The construction is a function of is     
1:46:52     
most naturally taken in the former sense meaning like that there's this     
1:46:57     
dependency relation but can perhaps be understood in the latter as well So you could in     
1:47:05     
terms of say something is a function of something else You know that maybe that implies a     
1:47:11     
dependency relation So     
1:47:16     
um my fist is a function of punching your face or something like that     
1:47:22     
Um you know uh water is a function of plant growth     
1:47:28     
or something like that Um you know you could you could have that or you could     
1:47:33     
have a mathematical function that describes something like a continuous function that describes the shape of a     
1:47:40     
plant in its growth or a mathematical function A continuous function that describes your     
1:47:47     
deformed face or that process of punching someone in the face I don't mean to be like cheeky about this but     
1:47:54     
you know I'm just trying to think of examples So that's kind of the idea here And then when we say the height is a     
1:48:01     
function of age among other things we tend to read this as something stronger     
1:48:06     
than the bland claim that there is a function from age to height or other     
1:48:12     
things to height So you know we say okay I don't know what you know height is a     
1:48:18     
function of age is a you know I guess when you're in development when you're growing you know you get taller as you     
1:48:25     
age until you reach adulthood Um and but then you know that's kind of a weak statement because     
1:48:31     
it doesn't really I mean it describes the dependency relation perhaps but it     
1:48:37     
may not be a dependency relation there just might be something that is sort of co-aring or correlated and doesn't have     
1:48:44     
any real functional meaning This is one of the problems with thinking about function in general is that you know     
1:48:51     
again we ascribe things to functions like we we observe two things     
1:48:56     
changing together and we ascribe a function to that but it may be a     
1:49:02     
spurious function or a spurious relationship and so the function is not really there I mean there are things of     
1:49:09     
course in this relationship age is like a proxy for other things that are going on right     
1:49:17     
it's growth it's other things but we use age because we can observe age more     
1:49:23     
readily can observe like a growth process within the body so you know     
1:49:29     
there are a lot of things that go on there in terms of as a function of the meaning of a complex expression     
1:49:37     
or or we so we need to distinguish between the following two principles Okay so the meaning of a     
1:49:44     
complex expression is determined by of the meanings of its constituents and the     
1:49:49     
way they are combined So that's the first and then the second is there is a function to the     
1:49:55     
meaning of complex expressions from the meanings of their constituents and of     
1:50:00     
the way they are combined So there's this idea     
1:50:05     
that you have a function and versus it's determined by that function basically or     
1:50:12     
it's determined by Yeah So there's a deterministic aspect and then there's a     
1:50:17     
possibilistic aspect So that's another thing we need to think about Um the first of these     
1:50:25     
entails a second but not the other way around So if something is determined by something it's part of that possibility     
1:50:33     
space Uh and so you know you have to it has something has to be possible in order for it to be     
1:50:39     
deterministic But of course if it's possible then there's it doesn't imply determinism So that's just kind of what     
1:50:47     
they're     
1:50:57     
getting Okay in the interest of time I'm going to move on to the next paper So this is     
1:51:06     
um this is a paper the compositionality of neural networks integrating symbolism     
1:51:12     
and connectionism So this is where we get into like neural networks and how     
1:51:19     
neural networks can generalize in a way that's called compositionally So we're moving from     
1:51:26     
like kind of linguistics you know hardcore linguistics and some of the definitions     
1:51:31     
involved there to this form of compositionality and neural networks which is putting together concepts So     
1:51:38     
this is more of the perceptual aspect of this Okay So the abstract reads despite     
1:51:45     
a multitude of empirical studies little consensus exists on whether neural     
1:51:50     
networks are able to generalize compositionally A controversy that in     
1:51:56     
part stems from a lack of agreement about what it means for a neural model to be compositional     
1:52:03     
So what they mean by generalized compositionally is very similar to what we have in language which means you     
1:52:08     
acquire things you then put them together in a certain order that make sense and then     
1:52:16     
that's the behavior that's the complex behavior It's not necessarily reductionist but it is it does require     
1:52:23     
like you to learn things to acquire information and then from that information put it together in a way     
1:52:31     
that generates some behavioral output So you know you could have like um you     
1:52:37     
could think about motor control as a compositional um process where you learn different     
1:52:46     
movements you learn how to control your movements And you do this in a way     
1:52:51     
that's sort of like if you're like if you're learning how to ride a bike or sometimes when you learn a martial art     
1:52:57     
you usually learn the different movements You try to learn those things sort of you know one at a time or you     
1:53:03     
try to perfect your technique and then you go into a performance mode where you     
1:53:10     
apply that those movements and you try to refine them and you combine the     
1:53:15     
things that you've learned And so some of this of course you might be saying um     
1:53:21     
is expertise So you have to practice to get good to to be able to be     
1:53:26     
compositional Same holds with language You have to be good at a certain you have to have a     
1:53:32     
certain level of expertise with that language that you're trying to speak to be     
1:53:37     
compositional and to that I would say yes that's an aspect of that but that's not exactly what they're talking about     
1:53:43     
here So they kind of break out this compositionality from expertise They     
1:53:49     
break out compositionality from the acquisition of any specific thing So you     
1:53:54     
know you might it might be easier to be compositional about like internet memes     
1:54:01     
versus like you know some dense textual reading you know Um but     
1:54:11     
yeah it it's it's going to depend on the content Okay So what does it mean for a     
1:54:18     
neural model to be compositional we don't really have a good way of thinking about that No one's agreed on that But     
1:54:25     
we know that it's important for say a neural network to put together concepts     
1:54:30     
to put together words to put together things that you know so we can     
1:54:36     
generalize So if you have if you especially in the case of a neural network you're training it on exemplars     
1:54:44     
those exemplars don't represent the entire world they represent sort of uh     
1:54:49     
vignettes of the world or cases in the world and then you're ask what you're asking the neural network to do is to     
1:54:56     
generalize uh to new contexts to find slight     
1:55:01     
variations Okay it's not exactly like the input data but it's similar So it     
1:55:07     
belongs to this category rather than that category It's putting together all these things these pieces of evidence     
1:55:13     
and it needs to kind of come up with an answer So that's kind of what it means to be compositional but in terms of like     
1:55:21     
what it actually means we're not quite sure or how it actually happens     
1:55:27     
So as a response to this controversy we present a set of tests that provide a bridge between on the one hand vast     
1:55:35     
amounts of linguistics and philosophical theory about compositionality and on the other the     
1:55:41     
successful neural models of language So they're focusing on language They're focusing on sort of this these     
1:55:48     
definitions that we were talking about earlier um and then also kind of what neural     
1:55:55     
models are actually able to do We collect different interpretations of compositionality and translate them     
1:56:03     
into five theoretically grown tests that are formulated on a task independent     
1:56:08     
level In particular we provide tests to investigate um five things The first is     
1:56:15     
if models systematically recombine known parts and rules So models can take     
1:56:21     
extract features They can extract rules about the world and they can put them they have to put them together in some     
1:56:28     
way that makes sense or that produces a complex behavior that we might recognize     
1:56:34     
as something that isn't gibberish So that again this is this analogical     
1:56:41     
aspect You know the model could put together something in a way very different than we do We recognize it as     
1:56:48     
like successful composition because we can understand it in context So if I ask     
1:56:54     
a neural network to put together a new internet meme and it takes like a     
1:57:00     
database of internet memes and it puts together like this meta meme um it does it mean anything does it have any     
1:57:07     
resonance with the people looking at it and at the end of the day can it successfully combine sort of the rules     
1:57:14     
of internet memes the features of internet memes and produce an internet meme that is on its own you know uh     
1:57:23     
resonating with with a human audience Um so that's number one It you     
1:57:30     
know the models have to systematically recombine parts and rules Number two is the model     
1:57:37     
can it extend its predictions beyond the length that they have seen in the training data In other words can it     
1:57:43     
generalize beyond the training data um three if models composition oper     
1:57:49     
compositional operations are local or global So you might have local compositional rules It might be able to     
1:57:56     
do very good at composing things locally but not globally And that could be in     
1:58:02     
sentences that could be you know it could produce maybe part of an internet meme and then fail on the rest of it     
1:58:09     
Um and so that's and then uh number four if models predictions are robust to     
1:58:16     
synonym substitution So that's specific to language So in other words you're changing the structure of the the phrase     
1:58:23     
and you know can it identify when things are changed so a lot of times when you     
1:58:29     
know uh like jokes or other things there will be some you know synonym that's     
1:58:37     
used sometimes will use synonyms in a way that's you know you want to be able     
1:58:43     
to rec you want the model to be able to recognize those substitutions and maintain the integrity of that meaning     
1:58:50     
And then five if models favor rules or exceptions during training In other words can models do exception handling     
1:58:58     
can they kind of figure out if uh a rule is generally     
1:59:04     
true you know what are the cases in which it's not true so these are all things that are     
1:59:10     
kind of what we do in human language what we do in human composition and then can we replicate this in a neural     
1:59:17     
network and they've broken it down on these five points which I think are interesting um because they're really     
1:59:23     
kind of getting at that question of what are we doing differently than a large language model and so we're obviously     
1:59:29     
doing some different things but can we kind of demonstrate that those things     
1:59:35     
maybe if you know an artificial system can't do them what those are to     
1:59:41     
demonstrate the usefulness of this evaluation paradigm we instantiate these five tests on a highly compositional     
1:59:49     
data set called uh PCFG set So I don't     
1:59:54     
know that's an acronym for something I don't know what it means but anyways with this data set they apply the     
2:00:00     
resulting tests to three popular sequence to sequence models So these are language models uh a     
2:00:07     
recurrent a convolutional based and a transformer model So they have a     
2:00:13     
recurrent model convolutionbased model and a transformer model And these are     
2:00:18     
sequence to sequence models So these aren't larger language models but they're language models that um can you     
2:00:25     
know do translations of sequences Uh we provide an in-depth analysis of these results that uncover     
2:00:32     
the strengths and weaknesses of these three architectures and point to potential areas of improvement     
2:00:40     
So they're doing this sort of thing called distributional semantics Um and so this the advancements of     
2:00:49     
distributional semantics of the word level word word level allowed the field of natural language processing to move     
2:00:55     
from discrete mathematical methods to models that use continuous numerical     
2:01:01     
vectors references here Such continuous vector representations operational wise     
2:01:07     
the distributional semantic hypothesis stating that semantically similar words     
2:01:13     
have similar contextual distributions So you have you know words that are     
2:01:19     
semantically similar They produce these similar contextual distributions And we want to do this in     
2:01:26     
language models because we have a lot of words that we're trying to deal with a lot of potential contexts and we want to     
2:01:33     
be able to then take all of that training data and not only put it you know regurgitate it but put it together     
2:01:40     
in new ways Um so given that we have these     
2:01:45     
contextual distributions that are similar to sort of words in context um     
2:01:51     
you know words in embedded in in surrounding words Um they can then act as surrogates for     
2:01:59     
word meaning and be used for example to quantify the degree of semantic similarity between words by means of     
2:02:05     
simple geometric operations Words represented in this way can be integral part of the computational     
2:02:12     
pipeline and have proven to be useful in almost all natural language processing tasks So what they're saying is     
2:02:18     
basically what we want to do is we want to be able to extract uh like say lang uh words and word     
2:02:27     
context from training data We want to create this latent space that we can then draw from and build compositional     
2:02:34     
models or compose things from that latent space Okay so that's that paper Um and     
2:02:42     
then the third paper The third paper is this paper     
2:02:48     
break it down evidence for structural compositionality in neural networks     
2:02:57     
So the abstract of this paper through modern neural networks or though modern     
2:03:03     
neural networks have achieved impressive performance in both vision and language tasks we know little about the functions     
2:03:10     
that they imple One possibility is that neural networks implicitly break down complex tasks into     
2:03:18     
sub routines implement modular solutions of these sub routines and compose them     
2:03:24     
into an overall solution to a task So this is something they call     
2:03:29     
structural compositionality So this is a pos this     
2:03:34     
is a hypothesis about what neural networks are doing to do compositionality     
2:03:41     
They're taking these complex tasks if you ask it to do like propose a mean uh     
2:03:48     
which is not something that you could do in one step They need to break that down into a set of sub routines What do I do     
2:03:54     
first what do I do second then they need to figure out different solutions in these sub     
2:04:00     
routines and then produce an overall solution by composing different parts of     
2:04:06     
this different solutions different subutines together     
2:04:11     
So this is uh structural compositionality It's different of course we discussed function before and     
2:04:19     
sort of how that works in language So there's this functional compositionality     
2:04:25     
This is structural composition Another possibility is that     
2:04:30     
they may simply learn to match new inputs to learn templates a lighting     
2:04:36     
test decomposition entirely So this is another hypothesis a competing     
2:04:41     
hypothesis which says we don't really need to do compositionality This is something     
2:04:47     
humans do Easier way to do this is to just take a have a bunch of templates     
2:04:53     
and match the inputs to those templates So I mean this you know you could even argue that humans actually do this We     
2:05:00     
don't really I mean we kind of this is why I did the first paper     
2:05:06     
first because compositionality you can see evidence of this in linguistics people have developed this natural     
2:05:12     
language how you have the these sort of rules of compositionality you have this     
2:05:18     
process of compositionality you need to put together words in a natural language     
2:05:23     
but it could also be that humans just simply use different templates that we     
2:05:28     
um you kind of fit the data to So we have these mental model huge number of     
2:05:34     
mental models we get data we fit it into a mental model store it away and then compare the mental models Um that's     
2:05:41     
probably not how human cognition works But if you think about like how neural     
2:05:47     
networks do it we have these two competing hypotheses where we don't We either need     
2:05:54     
compositionality which is a way to sort of recombine things So we don't have to say rely on one standard template or the     
2:06:02     
best template or a series of things We just simply kind of put things together     
2:06:08     
or the neural network puts things together as it encounters things Those kinds of models are robust to error     
2:06:15     
They're robust to exceptions and they're very uh good at     
2:06:21     
handling you know linguistic data but also for other types of perception as well     
2:06:30     
Um and so these are the two hypotheses here We leverage model pruning     
2:06:35     
techniques to investigate this question in both vision and language across a     
2:06:40     
variety of architectures tasks in pre-training regime So they're looking at not just language but also envision     
2:06:48     
which are just you know like training data or training models on visual data     
2:06:53     
or images And so you know in vision of course you're segmenting images You're     
2:07:00     
not building a linguistic model but you're just taking those uh features and     
2:07:05     
you're doing something to features You're classifying them you're building     
2:07:11     
uh some sort of latent space and then you're putting things together just like you would in     
2:07:17     
language and so you know it's going to be different and of course you can have a model that combines vision and     
2:07:24     
language which we've seen in past meetings Um and so you know we want to     
2:07:29     
see if compositionality is the same in both modalities We also want to see if     
2:07:35     
compositionality is something that's required in artificial Our results demonstrate that models     
2:07:42     
often implement solutions to sub routines via modular subn networks Again     
2:07:48     
this is like the last paper um which can be ablated while maintaining     
2:07:53     
functionality of other subn networks So again we have modular subn networks The benefit     
2:08:01     
of that is that they're sort of have this redundancy they have this robustness where you can     
2:08:08     
ablate um one subm modular subn network and it     
2:08:15     
doesn't collapse the entire representational structure doesn't     
2:08:20     
collapse the function of the network So it's interesting um how they     
2:08:27     
can thought about this This suggests that neural networks may learn to a or     
2:08:32     
may be able to learn compositionality obiating the need for specialized symbolic     
2:08:38     
mechanisms So that's what they're doing here Um so we don't know with neural     
2:08:45     
networks we don't know about the functions that they learn to implement     
2:08:50     
Uh which means that we don't know how they build these complex outputs We     
2:08:56     
don't know how they build these complex behaviors In particular there is a debate over the role of     
2:09:02     
compositionality which has been touted as a key property of human cognition enabling humans to exhibit flexible and     
2:09:09     
abstract language processing and visual processing among other cognitive     
2:09:14     
processes So if you want some other references in compositionality and its     
2:09:20     
relevance to broader context of coal science uh Gary Marcus back in the days     
2:09:27     
he was doing linguistics Um wrote something on this Uh     
2:09:33     
Piantoidosi of course as we know from cognitive science wrote something on this lake Malinski     
2:09:41     
uh and those are some of the people who have written on this According to common     
2:09:47     
definitions Wilty Dunn quot a representational system is     
2:09:53     
compositional if it implements a set of discrete constituent functions that     
2:09:58     
exhibit some degree of modularity So we need to have sort of     
2:10:04     
these discrete functions and we need to have modularity And so modularity is where you take things and they're in     
2:10:12     
these like modules They're basically units subunits that so you have a bunch     
2:10:18     
of subunits that compose a larger unit And     
2:10:24     
so you have things that are not you know they're not all interconnected without     
2:10:30     
structure The modular structure usually means that they're you know clusters of     
2:10:37     
things and they're divided out functionally So you might have a module     
2:10:42     
for you know the thing with photo he used to think about cognitive modules So     
2:10:48     
different areas of the brain would do different things and they would kind of come together as as cognitive function     
2:10:55     
but you had certain parts of the brain that would do certain things specialize in certain things and so you can think     
2:11:01     
about um you know function in say neural networks is modular So different     
2:11:08     
concepts are embedded in different locations different shapes different variations are embedded in different     
2:11:14     
locations and so on So one example of this is how blue circle is represented compositionally     
2:11:21     
but a system is able to entertain the concept blue independently of circle and     
2:11:27     
vice versa So you can have blue circle you can have red circle you can have     
2:11:33     
green circle you can have blue square And so blue is this     
2:11:39     
module that connects to circle it connects to square and then circle is a module that     
2:11:47     
connects to green and I guess I said red So you can have different colors you can     
2:11:53     
have different shapes and they're all units that are sort of interconnected     
2:11:59     
And so if you want to know if a machine wants to know what a blue circle is or     
2:12:05     
how to represent a blue circle then it has to reference that blue module and then that circle module and they're put     
2:12:11     
together composition And you could blate the blue     
2:12:17     
module and still have a circle You can't have a blue circle but you could still have a circle So that's     
2:12:24     
what they mean by when you ablate something you maintain the functionality of other subn networks You don't ablate     
2:12:31     
the entire concept of blue circle You just ablate the idea of a blue circle     
2:12:36     
You can have circles of other colors And in fact if you had     
2:12:41     
um you know you could probably approximate blue in some way     
2:12:47     
Um so that you know that's something that you could do compositionally     
2:12:52     
It is an open question um as to whether neural networks require explicit     
2:12:58     
symbolic mechanisms to implement compositional solutions or whether they implicitly learn to implement     
2:13:04     
compositional solutions during training So do we need to hardcode symbolic     
2:13:10     
mechanisms into the model or can we just have it learn these symbolic mechanisms     
2:13:17     
this may seem trivial but think about like human uh cognition which we talked     
2:13:22     
about with linguistics where you have you sort of learn a language you know     
2:13:27     
you learn sort of the stuff first the words the the rules and then you learn     
2:13:34     
the symbolic mechanisms um not as like you don't learn the     
2:13:39     
symbols you don't learn the meanings necessarily directly you acquire the meanings through interaction by using     
2:13:45     
the language by interacting interacting with other people use the language and then you get this notion of symbolism     
2:13:53     
You learn some basic symbolism um like you you know like a star means this or     
2:13:58     
that but they're deeper symbolic mechanisms that you don't have to learn     
2:14:04     
explicitly So in other words you don't necessarily have to hardcode them into a model or train a model for symbolic     
2:14:13     
uh sort of behavior Historically artificial neural networks have been considered non-compositional systems     
2:14:21     
instead solving tasks by matching new inputs to learn templates So this goes back to sort of this idea that um you     
2:14:30     
know artificial neural networks have to be trained and they reflect the training data and they don't really do anything     
2:14:36     
outside of that So this is not something that's native to neural networks you have to have a way to build a neural you     
2:14:44     
know compositionality in the neural network Um so neural networks by themselves then in the native version     
2:14:51     
have this sort of lack of compositionality and so this has served as a key point in favor of integrating     
2:14:58     
explicit symbolic mechanisms into contemporary artificial intelligence systems So having this symbolic layer     
2:15:05     
and you know there's this whole idea of neurosymbolic models So we have the neural model and then the symbolic model     
2:15:12     
and you can combine those And the reason that people do that is not just to make the behave output behavior look more     
2:15:19     
human but because that gives you this compositionality that allows you to do     
2:15:25     
things generate things that are maybe more humanlike but definitely gives you     
2:15:31     
this uh functional flexibility Okay Um however modern     
2:15:38     
neural networks with no explicit inductive bias for its compositionality have demonstrated success at     
2:15:44     
increasingly complex tasks This raises the question are these models succeeding by     
2:15:50     
implementing compositional solutions under the hood so maybe these models     
2:15:56     
aren't explicitly compositional but maybe they do some sort of thing that approximates     
2:16:02     
compositionality and it works just as well     
2:16:07     
So they they have three contributions here Um the first is we introduce the     
2:16:12     
concept of structural compositionality which characterizes the extent to which neural networks     
2:16:18     
decompose compositional tasks into sub routines and implement the module We     
2:16:24     
test for structural compositionality in several different models across both language and vision So they want to look     
2:16:30     
at structural compositionality like they did in the first paper that want to understand how that works We discover     
2:16:39     
that surprisingly there is substantial evidence that many models implement sub routines in modular subnet networks     
2:16:46     
though most do not exhibit perfect task decomposition So there is maybe some     
2:16:52     
composition limited compositionality in uh in neural networks and they're not     
2:17:00     
they don't exhibit perfect task decomposition So the whole process just in a neural model and not a symbolic     
2:17:07     
model is maybe a little bit off And so maybe a symbolic model helps achieve     
2:17:13     
sort of human levels of compositionality So if you think about like people talk about human levels of performance we     
2:17:19     
also have human levels of compositionality Number three is we characterize the     
2:17:25     
effect of unsupervised pre-training on structural compositionality in fine-tuned networks and find that     
2:17:33     
pre-training leads to a more consistently compositional structure and     
2:17:38     
language So you could have uh pre-training on structural compositionality     
2:17:44     
This isn't creating templates but this is a sort of a an intermediate strategy where you     
2:17:52     
give it some information about structural compositionality and it's better at it     
2:17:57     
Not surprising Uh so I'm going to finish off     
2:18:02     
with this last paragraph This study contributes to the emerging body of work on mechanistic     
2:18:09     
interpability which seeks to explain the algorithms that neural networks implicitly implement within their     
2:18:14     
weights So they actually have like you have the weight structure or neural network but there are things going on     
2:18:21     
the consequences of those weight structures We make use of techniques from model pruning in order to gain     
2:18:28     
insight into these algorithms While earlier versions of these techniques been applied to study     
2:18:33     
modularity in a multitask setting our work is novel in that it applies the     
2:18:38     
method to more complex language and vision models studies more complex compositional tasks and connects the     
2:18:46     
results to a broader discussion about defining and measuring compositionality     
2:18:52     
within So this was presented at Nurips in 2023     
2:19:00     
Okay so that's all I have on on that topic on compositionality I know we kind     
2:19:06     
of went from hardcore linguistics into sort of cognitive science and then at     
2:19:11     
the end I put the cognitive science in     
2:19:22     
context ready to say something No it it's it's a it's a super important     
2:19:28     
concept Um yeah and those are those are different     
2:19:34     
different aspects but um yeah not not sure I have something at this Okay Yeah Yeah It's interesting     
2:19:44     
Compositionality I think is really useful for also for embodiment as well because     
2:19:50     
you're in embodiment You have a body that is developing and then you know if     
2:19:58     
you're uh thinking about developmental psychology you have a body it's developing it's growing it's you know     
2:20:05     
and then you have language learning language at the same time and then you     
2:20:10     
know there's this sort of or perceiving things at the same time and so there's this sort of putting things together but     
2:20:16     
in the context of a grow you know something it's always a body it's always changing the world that's always     
2:20:22     
changing as you and there's a lot     
2:20:30     
there and so I mean you know we can see what that means to be compositional right it's that you start with like this     
2:20:37     
baseline of knowledge it might be like acquiring a bunch of knowledge on a training set and then being able to put     
2:20:44     
things together in terms of cognition so it's not automatic that a model reason     
2:20:51     
or it can put things out there that are complex except for regurgitating things     
2:20:56     
So if I query a large language model I could ask it a question It could give me might not be able to give me an answer     
2:21:04     
because I didn't basically weed it with the question So it has to put together     
2:21:09     
things from different places and then but put them together in a way that makes sense And then that's not really     
2:21:16     
reasoning but it's enough to like make statements that one that follows the other that follows the other And so you     
2:21:23     
know this is part of you know when we talked about reasoning in large language models we might want to back up and     
2:21:30     
think more about the compositionality aspect as well and how that leads outward to reason     
2:21:36     
Yeah Um I'm gonna burn out that tomorrow     
2:21:42     
there's going to be a a journal club from the cortical labs journal club So this is the company making the the     
2:21:49     
bitors that they're gonna have I believe though it's not really a journal club     
2:21:55     
like it's going to be a presentation Yeah Um from from somebody at Hopkins uh     
2:22:01     
I'm not sure it's student postto excuse me um talking about     
2:22:08     
spatial maps Okay And and I just I think of that just in terms     
2:22:16     
of um some people talking about you     
2:22:21     
know our our again in in the context of kind of cognitive     
2:22:27     
development that our motor control system becomes this     
2:22:35     
Not not quite foundation but but     
2:22:40     
um but certainly um     
2:22:47     
seems can be seen as as um part of     
2:22:52     
compositional um component to to other systems after     
2:22:59     
that Yeah In a in a developmental um     
2:23:05     
U context Um so I'll see I'll see how much he covers in that It's supposed to     
2:23:10     
be kind of like a wide range of of neural     
2:23:16     
spatial but I'll see how much uh compositionality comes into All right     
2:23:22     
Yeah that sounds good Yeah Yeah It's interesting the the motor control people     
2:23:27     
also talk a lot about composition like you know like when you're putting together sequences of     
2:23:33     
move submovements and you put it together into a whole movement and it's very similar to the linguistic context     
2:23:41     
and then of course there's the whole idea of like language and movement and how those are related It it it comes up     
2:23:47     
a lot in the the meta papers just the recent ones that were focused on typing     
2:23:53     
Okay Right like like speech sorry speech I should say the meta speech decoding     
2:23:59     
right which were very much not speech but actually typing     
2:24:04     
um but the the the accompanying paper um was on     
2:24:11     
hierarchical language models or you know how again because they were looking at     
2:24:17     
typing they they got to kind of see the units of of the motor activity Yeah very     
2:24:25     
very much the units Um but in the longer     
2:24:30     
time context they could see the um the     
2:24:36     
the larger units Yeah And and building up into sentences and things like that     
2:24:43     
Um anyway yeah like like I think about think about     
2:24:49     
um William James of course talking about pianists     
2:24:56     
um but you know as as well as like the problem of you know how does how does     
2:25:03     
the pianist do it they seem to be cashing cashing     
2:25:10     
things in their fingers Yeah Yeah But but that that again kind of     
2:25:16     
speaks to you what what training what training allows you to do and and being     
2:25:22     
able to put together and start to play things by sight or you know play     
2:25:30     
things without the music and and then to actually improvise Oh yeah Yeah Yeah     
2:25:36     
Yeah Great example Yeah All right Well that's all for today     
2:25:43     
Thank you for attending Bye Take care Take care Bye See you See     
2:25:48     
you Bye
