## Meeting Recording

[YouTube link](https://youtu.be/wfIG_T3SN1c)

## Mastodon thread

[link](https://neuromatch.social/@OREL/115637191588164021)

## Feature Videos

[Overview of NeurIPS 2025 (pre-conference)](https://youtu.be/ey8xRdvz1WE)

## NOTES

## TRANSCRIPT
0:01   
So, how are you? I'm good. How are you? All right.   
0:08   
Oh, no. I think like nothing new again. Like last week I presented one project.   
0:14   
There was one more project that we had presented in college last week like this week and then now we have our final   
0:20   
theory exams from next week. So, I'll be busy with that. So, yeah, nothing new. And probably   
0:27   
after exams I can look into something new, a new project, a new   
0:32   
implementation, read more research papers,   
0:38   
that's good. Yeah. Thank you for your presentation last week. Yeah,   
0:48   
I didn't hear you. I was asking and then you spoke. So Oh, okay. Can you repeat your question?   
0:53   
Yeah. Uh, yeah. Thank you for your presentation last week. Yeah. Thank you.   
0:59   
Yeah. Anything else or   
1:07   
No, nothing else. Probably next week like if I join the meet I can show what   
1:13   
we presented last week. It was an optimization techniques project that we used hybrid TLB and PSO and tried out   
1:20   
different algorithms on one problem statement to see which is the most optimal. I don't have a teddy right now   
1:26   
otherwise I would have presented it but probably next week I can show that.   
1:33   
Sounds good. Yeah, I'd like to see that. Yeah. All right. Yeah. So maybe you can   
1:39   
present on some of your stuff next week. That'd be great. Um,   
1:44   
yeah. So, this week we're going to uh talk about NERIPS and some of the things   
1:51   
going on the next week and a half or so of their conference. And we're going to talk about some other   
1:57   
things. I want to follow up on last week's uh presentation that was on evolution   
2:03   
uh and large language models like evolutionary approaches to uh taking evolutionary programming and   
2:10   
and transforming it to the large language models arena. And they were a   
2:16   
little I was disappointed in the methods that they used there because they didn't describe what they were doing. They   
2:21   
basically said that you can use an evolutionary approach to   
2:27   
uh you know kind of sort the output of large language models or something with   
2:32   
the prompting. Uh but they and then then they said you know this is better than   
2:37   
constructing a fitness function which is sort of the core aspect of an   
2:43   
evolutionary algorithm or evolutionary computational technique that you have a a fitness function that evaluates every   
2:50   
solution and you know basically promotes it based on fitness. And so they said   
2:57   
they used prompts or something and I couldn't figure out what they were trying to do because if they were trying   
3:03   
to do something with like text and language and maybe semantic content that would be   
3:08   
really interesting, but I don't know if that's what they were doing or not. Anyways, it's all sort of proprietary   
3:15   
because it's Google. And so uh I have another paper that people uh that   
3:21   
someone put out that maybe clarifies some of that. Maybe not. We'll talk   
3:26   
about that. So, this past week we did uh we had one meeting. We had our uh DVOR meeting. Um   
3:34   
I covered the book The Art of the Soluble by um   
3:41   
uh by Peter Metawir, who was a Nobel Prize winner back in like 1960.   
3:46   
And he he took a bunch of books that had been published probably a hundred years   
3:52   
ago now and he critiqued them. And it was really interesting the critique. You   
3:57   
go back to that meeting, you'll see what I mean. And then I talked a little bit more about uh on growth and form book by   
4:04   
Darcy Thompson and how that all relates together. So check that meeting out on   
4:10   
the YouTube channel for div. Okay. Um so yeah, we're coming up on the   
4:17   
end of the year as you know. This is the last month of the year coming up and it means that we're thinking about next   
4:24   
year. So I wanted to make it clear that you know this uh we've got a lot of   
4:31   
things that have to kind of happen right away. First of all we have to maybe think about Google Summer of Code think   
4:38   
about what we want to do for next year what we want to achieve. And so that requires planning and that   
4:44   
requires thinking about that now and maybe next you know by January we can   
4:49   
get off the ground running.   
4:54   
So um you know just think about that. I don't know if people want to do   
5:00   
something in you know particularly uh ambitious or if they're just looking   
5:07   
for a small project or whatever. let me know. I'm also going to try to do a recap of   
5:14   
the lab's activities for the year and publish that on YouTube. So, you'll have that as well. Not sure what what will   
5:22   
happen because I've got a lot of things coming up towards the end of the year and I I try to do one every year. So,   
5:29   
okay. Yeah. Like to do GOC again in 2026. Yeah. This is u you know we'll   
5:36   
probably do the open source sustainability project um and you know   
5:41   
follow up on that. Uh we did do the presentation um that I did for the   
5:47   
active inference uh symposium that kind of goes over   
5:53   
sort of the a lot of the math that kind of connects between reinforcement   
5:58   
learning and active inference. And that's maybe where we want to go to into that area. So kind of connecting things   
6:07   
somehow. I know it's kind of getting maybe uh separated from the practical   
6:14   
aspects of the project, but I think that's useful because I think there's,   
6:19   
you know, a lot to say about collective behavior in open source communities and using open source communities as sort of   
6:26   
a proxy for that. So, we'll see what what happens there. But   
6:31   
yeah, if you have uh like an idea for a project or something, well, how you   
6:38   
think that things should, you know, happen, let me know.   
6:43   
Um, and you know, we'll cuz like you know, in the years past, we like to invite people to take a a wide   
6:52   
range of approaches to the problem. not just kind of like something that I set out or that you know someone else sets   
6:59   
out but to kind of approach the problem and make it your own. So,   
7:05   
okay. And then of course uh you know I'll kind of go over some of the things we've done this year. A lot of things   
7:12   
kind of get forgotten about. So we need to bring those back to the four as well.   
7:20   
So this coming week is uh Europe's 2025   
7:25   
and this is uh the website. This is the agenda. You notice that this year they have this   
7:33   
uh tab. It says San Diego and Mexico City. So from my understanding they're   
7:38   
doing two versions of the conference. One in San Diego, one in Mexico City.   
7:44   
They're doing this because of the visa problems we're having coming to the US now. And uh you know Mexico of course is   
7:51   
I mean they could have held it in Tijana that might have been a little bit more integrated but they they are doing the   
7:58   
second uh version of the conference in Mexico City for people who don't want to   
8:03   
go into the US and then so they have the San Diego sessions   
8:08   
uh which are I think a lot of the bulk of the uh sessions and and workshops and   
8:14   
then the Mexico City uh version which has its own schedule and workshops. Not   
8:21   
as many workshops, but still. Then I believe there's also a virtual   
8:26   
component. So if you can't make, you know, you don't want to pay for the whole registration, you can't make the   
8:33   
meetings in person, you can catch up online. But anyways, this is the uh I like to go   
8:40   
over this because I like to see what people are doing in the field and kind of get a good uh cast a wide net in   
8:47   
terms of the types of topics that are being approached here. Um so you know they have different   
8:54   
panels they have invited talks um and then of course they have their   
8:59   
workshops which are uh sometimes before the conference and you know I'll go through the list of   
9:05   
workshops in a little bit but it lets us go through the agenda.   
9:10   
So of course they have women in machine learning they have uh multimodal data foundations   
9:17   
industry they have this this expo talk panel beyond benchmarks, rethinking reasoning   
9:24   
in large language models. They have some things on synthetic data   
9:29   
generation. Um, you know, they have different types of large language models, discovery, uh,   
9:39   
sessions. They have Latin X and AI.   
9:45   
They have model merging, which is interesting. That's a tutorial that is uh we don't have any more   
9:53   
information about this but basically um this is model merging   
9:59   
theory practice and applications. There's human AI alignment   
10:05   
foundations methods practice and challenges. There's uh new frontiers in   
10:10   
hyperparameter optimization which is interesting. Uh it's always been a   
10:16   
interesting problem because you know people that's kind of the   
10:21   
secret sauce of a lot of models is tuning the hyperparameters and getting them optimized.   
10:28   
Uh then they have planning in the era of language models. They have uh explain AI models, methods   
10:36   
and opportunities and explainable AI, dataentric AI and mechanistic   
10:42   
interpretability. They have uh LAR processing   
10:53   
multimodal more multimodal stuff. This is intro to generative computing   
11:00   
and you know mobile video diffusion transformers   
11:07   
and uh let's see large language models power intelligent data engineering for   
11:12   
workflow design. Then this who needs attention anyway elastic state models for real time   
11:18   
streaming tests that looks really interesting. That's a demonstration. As you know, there was this paper about   
11:27   
eight or nine years ago now that said, "All you need is attention." That's the famous title. And now, who needs   
11:33   
attention anyway? As we move on, we always find that, you know, I know   
11:38   
there's a marketing in terms of like how people sell their own work, but like that's kind of an interesting take on,   
11:47   
you know, our progress. Uh this is interesting. Causal fairness,   
11:53   
an open source Python library for causal fairness analysis.   
11:59   
See, let's go up to this one here. On   
12:05   
Wednesday, so that was Tuesday the 2nd of December. Wednesday, there's an invited talk by   
12:10   
Rich Sutton, the Oak Architecture, a vision of super intelligence from experience.   
12:17   
and the abstract. As AI has become a huge industry, to an   
12:23   
extent, it's lost its way. What is needed to get us back on track to true intelligence? We need agents that learn   
12:29   
continually. We need world models and planning. We need knowledge that is high level and learnable. We need metalarn uh   
12:38   
do metalarn how to generalize. The oak architecture is one answer to all these needs. It is a modelbased   
12:45   
reinforcement learning architecture with three special features. So number   
12:51   
one, all of its components learn continually.   
12:56   
Number two, each learned weight is a dedicated step size parameter that is metalarned using online cross   
13:02   
validation. And then number three, abstractions and state and time are continually created   
13:08   
in a five-step regression. Feature construction posing a subtask based on a   
13:14   
feature. Learning an option to solve the subtask. Learning a model of the option   
13:20   
and planning using the options model. The FC stomp progression which is the   
13:28   
method that they have. The oak architecture is rather meaty.   
13:34   
You know uh in this talk we give an outline and point to the many works prior and contemporaneous   
13:41   
that are contributing to its overall vision of how super intelligence can arise from an agent's experience.   
13:48   
interesting take on super intelligence the rich sub.   
13:54   
Uh this is another talk Yin Choi who uh is the art of artificial reasoning   
14:01   
and the abstract here scaling laws suggests that more is more   
14:06   
brute force scaling and of data and compute lead to stronger AI capabilities. However, despite rapid   
14:13   
progress on benchmarks, state-of-the-art models still exhibit lagged or jagged intelligence, indicating that current   
14:20   
scaling approaches may have limitations in term of terms of sustainability and   
14:26   
robustness. Hold that thought because we're going to talk about that in a little bit um from this interview that   
14:34   
OAScover did with someone. So, I want to kind of think about that a little bit.   
14:40   
Additionally, while the volume of papers and archive continues to grow rapidly, our scientific understanding of   
14:46   
artificial intelligence hasn't kept pace with engineering advances and the current literature presents seemingly   
14:52   
contradictory findings that can be difficult to reconcile. In this talk, I   
14:58   
will discuss key insights into the strengths and limitations of large language models,   
15:03   
examine when reinforcement learning succeeds or struggles, reasoning tasks,   
15:08   
and explore methods for enhancing reasoning capabilities in smaller language models to help them close the   
15:15   
gap against their larger counterparts in specific domains.   
15:21   
So again, you know, thinking about, you know, just, you know, this whole focus on scaling where they just make the   
15:28   
models bigger and bigger and, you know, that's not necessarily leading us to something that's a very rich   
15:34   
intelligence. It's just kind of a bigger intelligence and those things don't kind of necessarily   
15:41   
uh, you know, match up. They don't they don't meet the moment as they say.   
15:47   
So that's interesting. people are starting to think about that a little bit more especially as you know you have bigger   
15:54   
and bigger models that still have some of the same problems that the smaller models did.   
16:01   
So this next talk is uh Kyong Huno uh from benchmarks to problems a   
16:06   
perspective on problem finding and AI and the abstract here during the past 15   
16:13   
years or so I worked in a series of seemingly distinct but eventually related problems including machine   
16:19   
learning algorithms generative modeling with neural networks machine translation   
16:25   
language modeling medical imaging a bit of healthcare protein modeling   
16:30   
and a bit of dirt discovery. I chose to work on some of these problems intentionally.   
16:36   
While it was pure serendipity that I worked on some others, it was only in hindsight that these seemingly different   
16:42   
problems turned out to be closely related to each other from both technical, social, and personal perspectives.   
16:48   
In this talk, I plan to do my own retrospective of my own choices, them intentional or not on these problems and   
16:55   
share with you my thoughts on what our own discipline, which is sometimes called computer science, data science,   
17:02   
machine learning, artificial intelligence is. That's kind of interesting. Kind of a retrospective of   
17:07   
the whole field and how it's evolved. Especially since it moves so fast, it's   
17:13   
hard to know kind of where we've been and think about that because even with our lab, you know, we have that problem   
17:19   
where we're just kind of churning away and we're not necessarily putting things   
17:24   
into some sort of sense making or order. I try to do that as much as possible,   
17:30   
but even then it's hard to do and especially in a fastmoving field where   
17:36   
you know results get buried pretty quickly under other results. things like that.   
17:43   
Uh then there that's so those are the invited talks. Um then we have some other things down   
17:50   
here. We have a bunch of sponsored content. We have queer and AI. We have   
17:57   
language model sessions, deep learning sessions, reinforcement states base sessions,   
18:05   
generation simulation sessions. Uh let's see if we have   
18:10   
have the actual talks. Now all this is required is registration but that's okay. I just want to go over the they   
18:17   
have a theory session. Uh they have the creative AI panel   
18:22   
design for intelligence humans machines in nature and emerging co-creation.   
18:29   
That looks interesting. Um then this is something that I know we   
18:36   
were talking about last week. Morgan brought it up in terms of what people are interested in in the tower. Um and   
18:44   
we we'll talk about a workshop that they have as well. This is using the virtual cell platform to accelerate machine   
18:50   
learning and biology. So there are a lot of groups that are interested in virtual cells   
18:56   
or like drug discovery and things like that and it's very interesting appro um   
19:01   
sort of approach to these things and I don't exactly know what they mean by virtual cell platform because we've   
19:09   
talked about virtual cells and devoorm but you know and they're very hard to sort of assemble but you know this is   
19:16   
this could be anything from biological modeling to actually modeling cells. at   
19:21   
the very detailed scale. So I don't really know kind of what the state-ofthe-art is. Perhaps we can talk   
19:28   
about that another meeting. Okay. So they also have the indigenous   
19:34   
and AI machine learning workshop. Um they have uh this is okay. This is   
19:41   
another invited talk. Um are we having the wrong nightmares about AI?   
19:49   
This is Zanep Tufeki. The abstract is though seemingly opposite doom and optimism regarding   
19:56   
generative AI spectacular rise will center on AGI or even super intelligence   
20:01   
as a pivotal moment. The generative AI operates in a distinct manner from human intelligence and it's not a le less   
20:09   
intelligent human or on a chip solely getting smarter anymore than cars or   
20:14   
mere horseless carriages. It must be understood in its own terms. And even if   
20:19   
Terminator isn't coming to kill us or super intelligence isn't racing to save us, generative AI does bring a profound   
20:26   
challenge, well beyond usual worries such as employment effects. Technology facilitates progress by transforming the   
20:34   
difficult into easy, the rare and ubiquitous, the scarce into abundant, the manual and automated, and the   
20:40   
artisan and the mass-produced. or potentially positive long term. These   
20:46   
inversions are extremely destabilizing into easy, rare into ubiquitous, the   
20:51   
scare into abundant, the manual into automated, the artisan into mass-produced.   
20:58   
All potentially positive. Uh, okay. Um,   
21:07   
where are we? I'm losing track. Okay.   
21:13   
Um while potentially positive long-term these inversions are extremely destabilizing during the transition   
21:19   
should uttering the correlations and assumptions of our social order they relied in superseded difficulties as   
21:25   
mechanisms of proof filtering sorting and signaling. For example, while few   
21:30   
would dispute the value of the printing presser books, their introduction led to such destructive upheaval that resulting   
21:37   
religious wars caused proportionally more deaths than all the major other major wars and pandemics since combined.   
21:44   
The historic way new technologies revolutionary impact comes from making what's already possible and desired   
21:50   
cheap, easy, fast, and large scale, not from outdated or ill-fitting benchmarks   
21:55   
that technologists tend to focus on. As such, artificial good enough intelligence can unleash chaos and   
22:02   
destruction long before, if ever, AGI is reached. Existing AI is good enough to   
22:08   
blur or pulverize their existing mechanisms of proof or accuracy, effort, veracity, authenticity,   
22:15   
sincerity, or even humanity. The tumult from such a transitional require extensive technological regulatory and   
22:22   
societal effort to counter. But the first step is getting started to having the right nightmares.   
22:28   
So that's another invited talk. Uh looks like there's this test of time   
22:34   
award which is again um I guess an award that they give at   
22:42   
the conference and this uh award is the winner faster RCNN towards real-time   
22:50   
object detection with region proposal networks. uh and this is u how king ren   
22:59   
king he ras gersik and gian   
23:04   
so this is a paper state-of-the-art detection networks depend on region   
23:10   
proposal algorithms to hypothesize object locations advances like spnet and   
23:16   
fast rcnn have reduced the running time of these detection networks exposing   
23:22   
region proposal computation as a bottle In this work, we introduce a region   
23:27   
proposal network or RPN that shares full-time convolutional features with   
23:32   
the detection network, thus enabling nearly costfree reading proposals. An   
23:38   
RPM is fully convolutional network that simulates predict sim simultaneously   
23:44   
predicts object bounds and objectiveness scores at each position. RPMs are   
23:50   
trained end to end to generate high quality region proposals which are used by fast RCNN for detection with a simple   
23:57   
alternating optimization. RPN and fast RCNN can be trained to share convolutional features with a very   
24:05   
deep VGG16 model. Our detection system has a frame rate of five frames per   
24:10   
second, including all steps on a GPU while achieving state-of-the-art object   
24:16   
detection accuracy on Pascal VOC 2007 and 2012 using 300 proposals per image   
24:25   
and they have their code available on GitHub. So that is the award that they have for   
24:31   
that. Um they have the creative AI panel.   
24:39   
They have some more oral sessions on generation and simulation.   
24:45   
They have some position papers, optimization and algorithms sessions   
24:53   
on Friday. Then they have the deep learning session, graph session, theory session,   
25:00   
and then a poster session at 4:30 on Friday. And then they have uh let's see   
25:13   
they have some other things going on on Wednesday evening.   
25:19   
And uh this is a social that I'm going to talk about in a minute. Role of AI in   
25:24   
scientific peer review. That's kind of interesting. The Muslims in our ML reception.   
25:31   
the nonprofits working in openness and trust in AI, the learning theory alliance agent safety panel.   
25:40   
Okay, then that's so that's the end of the conference uh Friday.   
25:45   
So Friday is the end of the main conference, the closing session, poster session towards the end. Um so yeah,   
25:53   
this is really interesting stuff. Um definitely worth uh you know if you can't attend at   
26:01   
least finding a way to to think about these topics. Um actually there are two more things   
26:08   
during the conference. Uh there's a Sagnowski Hinton award   
26:14   
and that is um I don't know what the who the speaker is here but the abstract is   
26:22   
the brain processes information through many layers of neurons. The deep architecture is representationally   
26:28   
powerful but it complicates learning by making it hard to identify responsible neurons when a mistake is made. In   
26:35   
machine learning, the back propagation algorithm assigns blame to a neuron by   
26:41   
computing exactly how it contributed to an error. To do this, it multiplies error signals by matrices consisting of   
26:47   
all the synaptic weights on the neurons's axons and farther downstream. This operation   
26:55   
requires a precisely choreograph transport of synaptic weight information which is thought to be impossible in the   
27:01   
brain. Here we present a surprisingly simple algorithm for deep learning which   
27:06   
assigns blame by multiplying error signals by random synaptic weights. We show that a network can learn from to   
27:13   
extract useful information from signals sent through these random feedback connections. In essence, the network   
27:20   
learns to learn. We demonstrate that this new mechanism performs as quickly and accurately as   
27:27   
back propagation on a variety of problems and describe the principles which underly its   
27:33   
function. Our demonstration provides a plausible basis for how a neuron could be adapted using error signals generated   
27:41   
at distal locations in the brain and thus dispels long-held assumptions about the algorithmic constraints of learning   
27:47   
in neural circuits. So an interesting uh uh award talk there and then finally   
27:56   
this last talk by Andrew Saxs demystifying depth principles of   
28:02   
learning in deep neural networks. So this is deep neural networks have   
28:07   
revolutionized artificial intelligence yet their inner workings remain poorly understood. This talk presents   
28:14   
mathematical analysis of the nonlinear dynamics of learning and several soluble deep learn deep network models offering   
28:22   
theoretical insights into the world of depth. These models reveal learning algorithms, data structure,   
28:28   
initialization schemes, and architecture choices interact to produce hidden representations that afford complex   
28:35   
generalization behaviors. A reoccurring theme across these analyses is a neural race competing pathways with in a deep   
28:43   
neural network by to explain the data with an implicit bias towards shared representations.   
28:50   
These shared representations in turn shape the network's capacity for systematic generalization, multitasking   
28:58   
and transfer. I will show how such principles manifest across diverse architectures including   
29:04   
feed forward, recurrent and linear retention networks. Together, these results provide analytical foundations   
29:12   
for understanding how environmental statistics, network architecture, and learning dynamics jointly structure the   
29:18   
emergence of neural representations and behavior.   
29:26   
So that was uh that and then so now we have the workshops. Uh so the workshops   
29:32   
I'm going to switch this tab and I'm going to talk about some of   
29:38   
the workshops maybe some of the things that are interesting some of the things   
29:43   
that are notable etc. This first one is foundation models for the brain body   
29:48   
workshop. So this is uh talking about foundation models. talks about foundation models   
29:56   
and how foundation models are sort of can be used for this embodiment problem   
30:02   
basically. Uh so our brains and body speak are rich in complex biological language of neural and physiological   
30:10   
signals. A language AI models are increasingly capable of deciphering as   
30:15   
large scale data sets become available. Recent advances in brain interfacing and   
30:20   
wearable technologies including EEG Intracortical electrphysiology,   
30:26   
EMG, MEG and ECG have enabled a broad collection of these signals across real   
30:32   
world contexts and diverse populations. This growing wealth of data is driving a   
30:37   
shift towards foundation models which are largecale pre-trained AI systems   
30:42   
designed for learn from bio signals and generalize across diverse downstream applications for brain computer   
30:49   
interfacing to health model. Realizing this potential, however,   
30:54   
requires addressing the unique challenges that come with bio signal time series, which is that they are   
30:59   
noisy, heterogeneous, and collected under variable conditions across subjects, devices, and environments. To   
31:06   
meet these challenges, this workshop brings together neuroscientists, biomedical engineers, wearable tech   
31:13   
researchers, machine learning experts, advancing foundation model approaches.   
31:18   
through interdicciplinary dialogue we can catalyze the next generation of AI models that capture the complexity of   
31:25   
brain body and behavior at scale. So this is of course something that we need   
31:30   
if we want to do embodied cognition and and kind of get different types of uh   
31:36   
data streams and then integrate them in a way that is uh informative of what the   
31:42   
body is doing as well as what the brain is doing in real time.   
31:48   
This is a workshop on AI virtual cells and instruments. So again as I said there's this interest in virtual cells   
31:56   
especially in terms of drug discovery and development. So uh it says as the US FDA phases out   
32:04   
animal testing requirements for drug discovery and development AI tools will become widely adopted to simulate the   
32:10   
effects of candidate drugs. We posit the building virtual cells and instruments with AI is poised to transform drug   
32:18   
discovery and development by enabling large-scale simulation and interrogation   
32:23   
of molecules, cells, and tissues. In our workshop, we will collaboratively define and promote this emerging scientific   
32:29   
paradigm of AI to accelerate the drug discovery and development process in   
32:35   
this new era. So, good luck with that. Um, I'm not sure   
32:42   
that this is, you know, this is kind of like not necessarily what I was thinking when   
32:47   
I was thinking of virtual cells, but um this is gen CC first workshop on   
32:54   
generative and protective AI for content creation. This is   
33:01   
uh thinking I think about um you know licensing and I talked about this in my project management class where thinking   
33:09   
about licensing content and how generative AI models have kind of   
33:16   
reached the typical intellectual property licensing agreements and how we   
33:23   
need new open source licenses for generative AI tools.   
33:29   
So the abstract here is recent advances in generative AI have empowered machines to create high quality content across   
33:36   
diverse modalities text, image, audio and video with impressive fluency and   
33:42   
creativity from GPT40 and stable diffusion to Sora and MM audio. The   
33:48   
explosion of X tox generation, which is just any combination of like text to   
33:53   
image or video to audio, is unlocking new frontiers in science, education,   
33:59   
entertainment, and art. Well, Gen AI has shown significant potential creative   
34:04   
applications. These breakthroughs also raise pressing concerns related to safety, copyright,   
34:10   
and ethical use. Generative models could be explored to spread of misinformation,   
34:16   
violate intellectual property rights, or diminish human agency and creative processes. As such, there is an   
34:22   
increasing need to balance innovation with protection, ensuring that AI powered creative tools are used   
34:28   
responsibly and ethically. This workshop um brings together researchers,   
34:34   
creators, and practitioners at the intersection of content generation and IP protection.   
34:40   
By uniting the generative AI and creator communities, the Gen Pro CC workshop aims to explore the latest advances,   
34:48   
challenges, and opportunities in the rapidly evolving field. So again, this is again one of these things that kind   
34:54   
of pops up when you have these new technologies that emerge and things that you need to sort of deal with as you go.   
35:03   
Uh this is embodied world models for decision making. This is um again   
35:10   
thinking about world models and embodiment. And here the abstract reads, "World   
35:17   
models infer and predict real world dynamics by modeling the external environment and they become a   
35:23   
cornerstone of embodied artificial intelligence. They empowered recent progress in decision- making and   
35:28   
planning for interacting agents. This workshop aims to bring together researchers working at the intersection   
35:35   
of generative model re modeling reinforcement learning computer vision   
35:40   
and robotics to explore the next generation of embodied world models or   
35:46   
models that enable agents to understand, predict and interact with the world   
35:51   
through models by focusing on embodiment decision making. This workshop seeks to advance   
35:57   
world models beyond passive prediction towards active gold driven interaction   
36:03   
with the physical and virtual world by emphasizing embodiment decision making.   
36:08   
We aim to move beyond passive sequence prediction towards goal directed interaction with physical and simulated   
36:14   
worlds. And then there's this uh AI for Matt. I   
36:20   
think we talked about that last year which is accelerated materials design.   
36:26   
This is like chemical synthesis, material characterization and using AI in that process.   
36:35   
Okay. Uh some things in combinatorial algorithms   
36:41   
and things on deep learning for code. Uh   
36:46   
imageomics discovering biological knowledge from images using AI. That's   
36:51   
kind of interesting. I didn't know they had the term imageomics for it, but you know, that's a new one to me. Um,   
37:01   
op 2025 optimization for machine learning.   
37:10   
This is lock large language models workshop. Prevent unauthorized knowledge use from large language models. deep   
37:17   
dive into undistillated, unfinetable, uncompressible, uneditable, and   
37:22   
unusable. So, this kind of sounds interesting. This is uh this kind of I   
37:29   
guess a a cornucopia of things. Large language models have emerged as a   
37:34   
transformative tool across research and industry, revolutioning how we   
37:39   
revolutionizing how we interact with information. However, their immense capabilities bring critical security   
37:45   
challenges. The same features that drive innovation can be exploited for malicious purposes, unauthorized   
37:52   
distillation, fine-tuning, compression, or editing. These vulnerabilities pose   
37:58   
severe threats, including intellectual property theft, the generation of sophisticated disinformation, the bypass   
38:05   
of safety alignments, and the erosion of user trust and AI systems. This workshop   
38:10   
aims to bring together researchers and practitioners from academia and industry. We're advancing the frontiers   
38:16   
of large language model security and protection. We seek to confront the unauthorized use of large language   
38:22   
models headon by exploring novel and robust mechanisms designed to make these   
38:27   
models inherently resistant to exploitation while maintaining their beneficial capabilities. The workshop   
38:34   
also hosts the 2025 trust AI rising star award.   
38:39   
So this is and of what they mean by all these un things. There's the   
38:44   
undistillable large language model which is preventing unauthorized model replication and intructual property   
38:51   
theft. Uh unfinetable large language models resisting malicious parameter   
38:57   
updates and behavior alterations. Uncompressible large language models is   
39:02   
maintaining model integrity against unauthorized compression. There's uneditable large language models   
39:09   
safeguarding against knowledge tampering and misinformation injection and then unusable large language models ensuring   
39:16   
traceability and preventing misuse through water marking and verification.   
39:22   
Well, some practiceoriented things there. uh   
39:29   
algorithmic collective action which looks kind of interesting which is looking at collective action in   
39:35   
economics and sociology and thinking about how to understand   
39:41   
like algorithms that enable collective action whether good or bad.   
39:47   
Uh this is unrepsying representations and neural models. when, how, and why do   
39:53   
different neural models learn the same representations? And this of course connects to neuroscience   
39:59   
and how brains do the same thing in terms of representations.   
40:06   
Uh this is cause science uncovering causality in science.   
40:13   
Okay. So this is cause causality in science. They're abstract. Many   
40:19   
scientific questions inherently possess a causal dimension from estimating   
40:24   
treatment effects and personalized health care, understanding biological mechanisms to evaluating the social and   
40:32   
environmental impacts of governmental policies. At the same time, the recent surge in causal learning has unlocked   
40:39   
the potential to extract reliable cause and effect relationships with complex highdimensional data. Despite promising   
40:47   
breakthroughs in causal reasoning and discovery, translating those methods into day-to-day scientific practice   
40:52   
remains challenging as it requires transitioning from controlled or simplified demonstrations   
40:58   
to robust applicationdriven research and problems. This workshop is designed to bridge the translational gap by   
41:05   
fostering collaboration in across the broad spectrum of disciplines including ecologists, biologists, and social   
41:12   
scientists with a shared interest of both the theoretical and practical aspects of causal influence.   
41:19   
And so they have three questions that they focus on here. Where does causality   
41:25   
manifest across different applied science domains? When can causal learning techniques   
41:31   
effectively accelerate scientific discovery and how can we best generate   
41:36   
causality with domain expertise in real world scientific data.   
41:41   
And so by promoting a bottomup research paradigm that starts with concrete real world problems, we aim to do a couple of   
41:48   
things. The first is surface unresolved challenges that the the theory must address. The second is releasing causal   
41:56   
benchmark tests that reflect real scientific constraints and third seed   
42:01   
collaborations between domain experts and machine learning researchers that outlive the event.   
42:08   
So they want to understand in this workshop the dual roles of causality   
42:13   
both as a tool for reasoning and interpretation and as a mechanism for planning and experimental design. Um and   
42:21   
so that's kind of where they want to go with that. A lot of speakers here, organizers.   
42:28   
So yeah, this is interesting work. Causality is definitely   
42:34   
uh you know kind of a necessary component of intelligence and learning   
42:39   
but you know kind of understanding how you can represent that in a model is a different story al together. It's very   
42:45   
hard to to get to. Okay. So   
42:53   
uh let's see there's this one dynamics at the frontiers of optimization   
42:59   
sampling in games. Uh this one is   
43:06   
go to the workshop website. Uh this is dynamical systems have played an   
43:12   
important role in the analysis and design of algorithms. Ideas ranging from variational methods, differential and   
43:19   
simplectic geometry, numerical analysis and control theory paved the way for   
43:24   
establishing nonasmatic convergence guarantees in optimization and sampling   
43:30   
is equilibrium computation and gains. Yet the distinct mathematical backbone   
43:35   
of these tools often creates barriers of entry. The barriers to entry for researchers and practitioners and   
43:41   
machine learning. This workshop aims to lower that barrier by highlighting the unifiable dynamical   
43:48   
systems across these domains. We will convene optimization, sampling and game theory experts foster   
43:55   
cross-disciplinary dialogue and collaboration. Emphasis will be placed on emerging   
44:00   
applications in machine learning such as diffusion models, distributed and adversarial training, genic AI where   
44:09   
dynamical systems perspectives are increasingly central. combination of talks, posters and open discussions, we   
44:16   
hope to catalyze new collaborations and broaden the accessibility of these foundational methods.   
44:22   
So this is again um kind of bringing dynamical systems into the into the mix.   
44:31   
uh mathematical foundations and operation integration machine learning that's MLX   
44:40   
the second workshop for genai and health uh AI for non-human animal communication   
44:47   
which is looks interesting let's see what that looks like uh the past few years have seen an   
44:53   
unprecedented surge in both the availability of bio acoustic data and the sophistication of AI/Machine   
44:59   
learning models This convergence presents a unique window of opportunity to revolutionize our understanding of animal   
45:06   
communication and biodiversity. However, achieving this requires a conscious effort to integrate the   
45:12   
disciplines of AI/Machine learning and ethology. This workshop will explore the   
45:17   
intersection of artificial intelligence and bio acoustics, aiming to address challenges in processing complex bio   
45:24   
acoustic data and interpreting animal signals in order to advance our understanding of non-human animal.   
45:32   
Join us for a poster session, keynote talks, and a panel discussion as we explore key opportunities to use AI to   
45:39   
decipher animal languages must deepen our understanding of the natural world.   
45:46   
workshop there. Here there here's the first workshop on efficient reasoning. This is of course   
45:52   
reasoning and large language models. Uh recent progress in large reasoning models or LRMS like open AI 01 and deep   
46:02   
sea garb been pivotal for tackling complex applications and mathematical   
46:08   
code reasoning to advance symbolic and agentic planning. Their success often relies on test time scaling which   
46:15   
involves increasing the generation length and depth. However, these approaches incur significant efficiency   
46:21   
bottlenecks during training and inference. To overcome these limitations, further advancements are   
46:26   
needed in data algorithms and systems applicable across various domains as   
46:33   
exemplified by work such as S1, Z1 and V. Uh the proposed workshop will bring   
46:39   
together researchers and practitioners to rethink efficient reasoning under tight compute, memory, latency,   
46:46   
throughput and cost budgets with the goal translating theoretical breakthroughs into practical deployable   
46:53   
solutions. Then there's this uh workshop math AI,   
46:59   
the fifth workshop on mathematical reasoning and AI. This this is on mathematical reasoning.   
47:08   
Then we go to the workshop website and this is uh the overview. Mathematical   
47:14   
reasoning is a fundamental aspect of human cognition that has been studied by scholars ranging from philosophers to   
47:21   
cognitive scientists and neuroscientists. Mathematical reasoning involves analyzing complex information,   
47:29   
identifying patterns of relationships, and drawing logical conclusions from evidence. It is central to many   
47:36   
applications in science, engineering, finance, and everyday contexts. Recent   
47:42   
advancements in large language models have unlocked new opportunities at the intersection of artificial intelligence,   
47:49   
mathematical reasoning, ranging from new methods that solve complex problems or prove theorems to new forms of human   
47:56   
machine collaboration and mathematics appear. This workshop is centered on the   
48:01   
intersection of deep learning and mathematical reasoning with an emphasis on but not limited to large language.   
48:08   
Our guiding theme is to what extent can machine learning models comprehend mathematics? What applications could   
48:15   
arise from this capability? To address this question, we aim to bring together diverse participants and   
48:22   
from different backgrounds, institutions and disciplines. And they're going to focus on sort of   
48:28   
the following areas. Humans versus machines. How we can have a comparative study of   
48:35   
human level mathematical reasoning and current AI techniques. How do they differ, complement one another or   
48:42   
intersect? Measuring mathematical reasoning. How do we design benchmarks that accurately   
48:49   
evaluate mathematical reasoning abilities, especially in a narrow marked language models? New capabilities. How   
48:56   
do we move beyond our current techniques? Education. What roles can deep learning models play in mathematics education,   
49:03   
especially in context of limited educational resources? And finally, applications. What   
49:09   
applications could AI systems enable in the near term? Example domains include   
49:14   
software verification, sciences, engineering, finance, education, and   
49:20   
mathematics itself. That's that one.   
49:37   
Uh we have uh practices in video generation and evaluation. What makes a   
49:43   
good video in workshop on multi-turn interactions and large language models?   
49:51   
Recent advances in time series foundation models. machine learning in the physical   
49:57   
sciences. This is ML4 PS which is happens every year.   
50:03   
Uh regulatable ML towards bridging the gaps between machine learning research and regulations.   
50:11   
COG interp interpreting combination and deep learning models.   
50:16   
Uh new perspectives in graph machine learning.   
50:23   
And of course in graph machine learning we have all sorts of connections with uh network   
50:29   
theory and complex network theory graph theory   
50:34   
uh let's see program this has a number of talks this has an entire agenda here   
50:42   
um so keynote here yuong learning   
50:49   
generalizable algorithm procedures via graph neural networks this oral presentation beyond sparse   
50:56   
benchmarks evaluating graph neural networks with realistic missing features.   
51:01   
Uh then there's this other oral presentation brass or steam graphs.   
51:08   
Uh another oral presentation robust tangent space estimation by a vector   
51:14   
gradient orthogonalization. This uh talk by Lujour Leco relational   
51:21   
foundation models and end of task specific graphal networks.   
51:27   
Another world presentation causal structure learning and hawks processes with complex latent co-founder networks.   
51:35   
Another royal presentation on graphs and tables zero shot mode classification with tabular foundation models.   
51:44   
There's this talk by Nino Molani top topological deep learning   
51:51   
and neert learning approximately equariant GNN's for simulations of physical systems.   
51:59   
Uh another one here teaching original language models of reason and grasp of reinforcement learning   
52:06   
and um yeah so that's that's those are the talks and then they have these other   
52:12   
areas that they were interested in which would be you know things like symmetry and equivariance and group theoretic   
52:19   
graph models uh different types of geometric models   
52:24   
graph diffusion models and graph generative models um continuous limit and infinite width   
52:30   
analysis of graph machine learning graphs for science and graph based simulations   
52:37   
causality and directed as cyclic graph learning self-supervised and self   
52:42   
semi-supervised graph machine learning and quantum graph machine learning so those are kind of hot topics in the area   
52:49   
that we all so interested in so I don't know BD had uh something   
52:56   
graph machine learning is part of what I present in the last week. So that's good. Yeah, we do that of   
53:02   
course in Gaworm and it's an area that I think is a nice fit to some of the things we're doing with networks.   
53:10   
Did you have any comments other comments? No, no, it's just interesting how um   
53:18   
they have like multiple needs or like different like timing slots and then they're doing different things. It's   
53:24   
interesting to know something like that. Yeah. and whatever is going on.   
53:29   
Yeah. Okay. So, uh let's see.   
53:38   
Let's go back to the workshops. A lot of workshops. We're getting towards the   
53:43   
end, I think. Um uh let's see. There's this learning to   
53:48   
sense which is exploring the joint optimization of sensors and machine   
53:54   
learning models pushing beyond traditional paradigms of data acquisition and processing. We aim to   
54:00   
rethink the foundations of how machines can sense the world by replacing handcrafted ISPs by merging learnable   
54:07   
sensor layouts and adopting task driven   
54:17   
And let's see.   
54:25   
So they they they welcome original contributions and position papers on the   
54:30   
following topics. Sensor optimization for say like computer vision. Uh raw to   
54:37   
task and raw to label approaches for visual tasks. Code design of neural networks and sensor hardware. Low bit   
54:45   
energy efficient sensing for embedded or mobile devices. Benchmark data sets and   
54:50   
metrics for evaluating sensor model pipelines. Uh generalization and robustness of   
54:57   
sensor model systems in real world conditions and then failure case studies and negative results joint optimization   
55:05   
pipelines. Okay, so that's learning to sense. Um, then there's this what can't   
55:12   
transformers do? And so this is the abstract here. With   
55:18   
most advances in large foundation models being empirical, our theoretical understanding of what transformers can   
55:24   
compute, express, and learn still lags behind. This workshop will convene theorists and empiricists to chart a   
55:31   
rigorous agenda for the next generation of LFMs asking what can and can't   
55:36   
transformers do. So this is again we talked about moving beyond transformers   
55:41   
or post transformer architectures. So this is actually kind of an interesting   
55:47   
uh thing to think about because we have to know what they can't do in order to   
55:52   
think about the post transformer landscape. uh they welcome both formal analysis and   
55:57   
empirically grounded studies that shed light on theoretical questions aiming to close the gap between proofs and   
56:03   
practice while fostering new interdisciplinary collaborations.   
56:09   
And if you go to the workshop website, this is of course   
56:15   
uh sort of the call for papers. Um so the core themes are theoretical   
56:21   
analysis of transformer capabilities including expressivity learnability   
56:26   
inference time scaling and context learning and the effects of architectural components. Uh there's   
56:33   
also empirical studies of transformal behavior that inform theoretical understanding including architectural or   
56:40   
training innovations, mechanistic studies of failures and comparisons of theorized and observed capabilities.   
56:47   
Um so the accepted papers here um yeah   
56:56   
there a number of different spotlights and posters. There's encoder only next token   
57:02   
prediction. There's on the role of transformer feed forward layers and nonlinear inline   
57:09   
inline context learning or in context learning.   
57:14   
Why do transformers fail to forecast time series and context? So there's some work on in context learning and uh time   
57:22   
series and nonlinearity. Um then there are the posters which   
57:28   
again focus on in context learning. Um   
57:34   
some things about circuit complexity limits, some things about delayed attention   
57:40   
training. Um in terms of how that affects of performance.   
57:47   
Uh let's see in context learning and diffusion language models in context learning is   
57:55   
implicit optimization. In context learning is not gradient descent unless you initialize your   
58:02   
transformer right out of distribution generalization of in context learning a   
58:08   
low dimensional subspace perspective. uh   
58:14   
towards the understanding multimodal in context learning transformers in the dark navigating unknown search spaces   
58:20   
via noisy feedback and when transformers can or can't   
58:25   
generalize compositionally at the data distribution perspective.   
58:31   
So those are all kind of uh thinking about these types of limitations of transformers   
58:39   
and the transformer architecture.   
58:45   
Then we have learning from time s to from time series for health which is   
58:51   
applying time series data to health contexts and using machine learning to   
58:57   
understand that data on the brain and mind   
59:02   
non- uklitian foundation models and geometric learning advancing AI beyond   
59:07   
uklitian frameworks and you know this again is thinking about n Uklitian learning.   
59:22   
So non- uklitian learning is quickly gaining traction in the field. Non-   
59:27   
uklitian spaces such as hyperbolic, spherical and mixed curvature spaces have been shown to provide more   
59:33   
efficient and effective representations for data with intrinsic geometric properties like hierarchy, symmetry, and   
59:41   
heterogeneity. Integrating foundation models and non-equity spaces has great potential to   
59:48   
enhance their ability to capture and model the underlying structures in relationships and conflict through world   
59:53   
data leading to better performance generalization and interperability. This   
59:58   
workshop focuses on the intersection of non uklidian representation learning   
1:00:04   
foundation models exploring its potential benefits challenges and future directions.   
1:00:15   
Okay. Uh then there's evaluating the evolving large language model life cycle   
1:00:21   
workshop on mechanistic interperability frontiers and probabilistic inference   
1:00:28   
AI for science the reach and limits of AI for scientific discovery   
1:00:33   
uh this is symmetry and geometry neural representations which they've done for a number of years   
1:00:40   
uh just kind of working on this area of topological learning geometrical   
1:00:47   
Uh and so yeah there are a lot of workshops here another workshop on space and   
1:00:54   
vision language and embodied AI. Uh there's a whole workshop on IIT   
1:01:02   
Delhi. So I guess that's just kind of what they're doing. Here's the computational neuroscy   
1:01:09   
workshop and yeah so that's it's and then there it in Mexico City there are a few other   
1:01:15   
workshops uh which we won't talk about right now but that will all look very   
1:01:20   
interesting um you know that's uh a huge brain dump of workshops I know but you   
1:01:27   
know this is again important to understand what what the shape of the field is looking like going forward and   
1:01:32   
kind of thinking about you know how our work interface that   
1:01:45   
so this is the thing I was talking about this is going to happen in San Diego this is the AI for science panel and   
1:01:52   
happy hour uh the only reason I mention this is because it's kind of interesting   
1:01:57   
uh that you know there's this sort of social component where you know people are thinking about using AI in science   
1:02:05   
uh whether you're developing foundation models for biology, working on materials discovery, or thinking about how AI can   
1:02:12   
accelerate research, this is a great opportunity to hear from experts pushing the boundaries and to meet others doing   
1:02:19   
the same. So that's something that's happening.   
1:02:28   
Okay, so the next thing I want to talk about is this. Uh so that's near rips 2025. Uh that's coming up this in the   
1:02:37   
next week and a half and so you know um this happens every year in December. So   
1:02:44   
uh just keep thinking about this and you know we'll maybe we'll talk about it next week.   
1:02:50   
Now this is a paper I want to talk about. This is an archive paper. This is on alpha archive. So this is a tool   
1:02:57   
where you can render archive papers and you can actually chat about archive   
1:03:02   
papers. Uh but I don't have the chat function open. So this is just kind of   
1:03:08   
the archive paper called evolutionary strategies at the h evolution strategies   
1:03:13   
at the hypers scale. Um this is a group from ma in Quebec uh Nvidia and   
1:03:21   
University of Oxford. So this is um from the archive uh last week.   
1:03:30   
So again I talked about how the uh Google uh tool alpha   
1:03:37   
alpha evolve uh how that you know the methods are kind of opaque and I was interested in how people are using   
1:03:44   
evolutionary computation in machine learning with large language   
1:03:50   
models and so forth. So this kind of gives maybe another kind of view on this   
1:03:55   
using an approach called evolution strategies. Uh so this is um the abstract. We   
1:04:03   
introduced evolution guided general optimization by a low rank learning which they use the acronym egg roll an   
1:04:12   
evolution strategies algorithm design designed to scale back properly optimization the large population sizes   
1:04:19   
for modern large language network architecture large neural network architectures with billions of   
1:04:25   
parameters. ES is a set of powerful blackbox optimization methods that can handle   
1:04:31   
non-ifferiable and noisy objectives with excellent scaling potential through   
1:04:36   
parallelization. Naive evolution strategies becomes   
1:04:42   
prohibitively expensive at scale due to the computational and memory costs associated with generating matrix   
1:04:48   
perturbations and the batch matrix multiplications needed to compute per member forward passes. Egg roll   
1:04:56   
overcomes these bottlenecks by generating random matrices and form a low rank matrix perturbation   
1:05:03   
that are used in place of the full rank perturbation. As the overall update is an average   
1:05:09   
across the population of end workers, this still results in a high rank update   
1:05:14   
with significant memory and computational savings reducing the auxiliary storage per layer and the cost   
1:05:21   
of a forward pass uh from ON to OM plus when compared to   
1:05:28   
full rank evolution strategies efficiency results in a 100fold increase   
1:05:33   
in training through billion or training throughput. for billion parameter models   
1:05:39   
at large population sizes nearly reaching the throughput of batch pure batch inference. Theoretical analysis   
1:05:46   
reveals our low rank update converges the full rank update at a fast 01 overr.   
1:05:53   
Our experiment showed that egg roll does not compromise the performance of evolution strategies in tabular rosa   
1:06:00   
reinforcement learning settings despite being faster. It is competitive with GRPO as a   
1:06:07   
technique for improving large language model reasoning. Then egg roll enables stable pre-training of nonlinear   
1:06:14   
recurrent language models that operate purely in energy data types. So they   
1:06:19   
have their code on GitHub and this is a schematic visualization of the platform.   
1:06:28   
So they have the initial rates, they have rank one perturbations, then they   
1:06:33   
have a fitness evaluation that gives you a weighted average and this gives you the final rank and   
1:06:39   
update. So they use a fitness evaluation here that is essentially where they   
1:06:46   
perturb the matrix and then of initial weights and then they give a fitness evaluation   
1:06:52   
by evaluating sort of the variety of each perturbation.   
1:06:58   
And so this is the fitness evaluation or the fitness function which then yields a weighted average and   
1:07:06   
then gives you this update. So evolution strategies as an approach   
1:07:14   
is is an old goes back to the 1970s. Um so they mentioned they didn't really   
1:07:20   
talk about like background too much but they say it's an attractive alternative   
1:07:25   
to first order methods based on gradient back propagation for several reasons. So   
1:07:31   
first evolution strategies does not require differentiability. So it can optimize a broader class of models like   
1:07:38   
models of discrete parameterization spaces cellular automa and can object   
1:07:44   
optimize objectives and gradients are unavailable or noisy like outcome only rewards in large language fine tune.   
1:07:53   
Second is that evolution of strategies is more robust and noisy and ill conditions   
1:07:58   
of things that uh aren't um aren't convex   
1:08:08   
unlike gradients. Population based exploration smooths irregularities, tolerates discontinuities, mitigates   
1:08:15   
issues like condition curvature or vanishing and exploding gradients and   
1:08:20   
long range or recurrent settings. Third evolution strategies is highly   
1:08:26   
amenable to scaling through parallelization. Since   
1:08:32   
since fitness evaluations are independent across population members require only the communication of scalar   
1:08:39   
fitnesses which map cleanly on modern inference infrastructures and yields nonlinear speedups on large   
1:08:46   
clusters. By contrast, back propagation requires communicating and aggregating   
1:08:51   
gradients across devices, yielding updates with high memory and computation   
1:08:56   
costs. Additionally, back propagation requires special care when training models with low precision data types,   
1:09:04   
whereas ES can directly optimize any model with the same data types uses at inference times. Together, these   
1:09:11   
properties position evolution strategies as a potentially powerful foundation for training large discrete or hybrid   
1:09:19   
architectures and end toend system and non- differentiable components including   
1:09:24   
large windows. So there are a lot of problems with uh   
1:09:30   
deploying evolution strategies at scale. Um so in deep learning architectures for   
1:09:37   
example the majority of trainable parameters form linear mappings represented by matrices.   
1:09:43   
Naively adapting evolution strategies therefore requires generating full rank matrix perturbations that replicate the   
1:09:50   
entire parameter set for every population. This inflates memory cost and forces   
1:09:57   
frequent movement of large weight tensors. evaluating these perturbations and requires a separate sequence of   
1:10:03   
matrix multiplications per member. So the total computed wall clock time scale roughly with the population size and   
1:10:10   
sequence in billion parameter regimes that's pretty untenable.   
1:10:17   
Uh to mitigate both memory and computational bottlenecks we introduce evolution guided general optimization by   
1:10:24   
a low rate learning or egg roll. This is an ES algorithm that allows for efficient training of neural network   
1:10:31   
architectures. This is analogous to Laura in their low rank adapters and gradient based   
1:10:37   
training. Egg roll generates low rank parameter space perturbations for evolution strategies. So instead of   
1:10:44   
sampling a full rank member, we sample uh different components and form this uh   
1:10:53   
matrix. This reduces auxiliary perturbation matrix matrix storage from MN to MN M   
1:11:01   
plus NR per layer proportionally reduces tensor movement.   
1:11:08   
So they kind of decrease the memory uh requirements for this.   
1:11:15   
So they kind of go through some of their methods and this is the evolution strategies methodology. So this is what   
1:11:21   
I wanted to see in the other paper. So um evolution strategies as they   
1:11:26   
define it here is a set of blackbox methods for optimizing general systems. ES has emerged as a useful alternative   
1:11:33   
to gradient based methods particularly when a system is noisy or non- differentiable.   
1:11:40   
Our problem setting focuses on fitness functions whose parameters are matrices.   
1:11:45   
Our goal is to find matrix MAR uh that maximizes the fitness function   
1:11:51   
MAR. In comparison to gradient based methods which use derivatives of the function FM   
1:11:58   
to update the parameters M directly. Evolutionary methods update a population distribution out of the parameter space.   
1:12:05   
This is achieved by learning a set of parameters theta to maximize the expected fitness   
1:12:11   
fz or a population distribution pi m   
1:12:18   
and this is I guess it's a jacobian taking derivatives of j theta yields the   
1:12:25   
gradient here which is used to update the population's distribution parameters   
1:12:31   
using a stochastic gradient descent with a suitable step size alpha t. The   
1:12:36   
gradient log gradient is known as the square function which avoids taking gradients directly through the fitness   
1:12:42   
function in equation one. Okay, so this is the Wikipedia page of   
1:12:47   
evolution strategies. Um this is just the best sort of summary I could come up   
1:12:53   
with. Uh this is it goes back all the way in   
1:12:58   
1973. So this has a very deep history. Um   
1:13:04   
evolution strategy is a subclass of evolutionary algorithms which serves as   
1:13:09   
an optimization technique. These is the major genetic operators mutation   
1:13:15   
with combination and selection of parents. So every evolutionary algorithm is consists of a program an encoding   
1:13:24   
and they're a population of encodings. So you have those encodings that are   
1:13:29   
replicated at a certain population size. The reason of course you need a population is because evolution works on   
1:13:36   
populations. Each encoding then can be mutated, can be recombined and then those individuals   
1:13:46   
are evaluated by a fitness function. Those programs can also replicate   
1:13:52   
and maybe sometimes reproduce in in ways that that involve crossover. So you get maybe like a sexual reproduction   
1:14:00   
and you end up with this system that operates kind of like a biological population subject to selection and then   
1:14:08   
that's supposed to give you yield you the best strategies. So your population of encodings might represent a bunch of   
1:14:14   
potential solutions to a problem and you uh you know recombine and mutate those   
1:14:20   
encodings uh and you can end up with the most uh optimal solution or maybe   
1:14:29   
very interesting solutions that you never would have come up with before. Um, years ago they've they had a lot of   
1:14:37   
different applications on the web where you could do like things like reading pictures using evolutionary algorithms   
1:14:45   
where you'd have a bunch of like pieces of abstract art that you could evolve by   
1:14:51   
generating a bunch of potential pieces of art and then select using the U   
1:14:57   
selection operator sort of you know maybe as based on the person who's   
1:15:04   
selecting it uh what they what they like their aesthetic preferences. So you just   
1:15:09   
simply select different images and promote them and then those would reproduce and you'd get variations on   
1:15:15   
that and then you'd pick the best one there and those would reproduce and you'd end up getting these populations   
1:15:21   
that gave you variation. You could select on that variation and you end up with sort   
1:15:27   
of the optimal image based on your aesthetic preferences. A fun exercise in   
1:15:33   
showing how an evolutionary algorithm works. So evolution strategies is a   
1:15:38   
subset of that or a subset of evolutionary computation but it has certain properties that are different   
1:15:44   
from the evolutionary algorithm. So this article here it talks about how   
1:15:51   
these these optimization techniques were actually created in the early 60s but then really kind of were developed   
1:15:58   
formally in the early 70s. So in 73 we had evolutionary strategies introduced   
1:16:04   
with mutation and selection. You had uh these meta evolutionary   
1:16:10   
strategies in 2007, weighted multi-rebination evolution strategies in 2006   
1:16:18   
uh natural evolution strategies using an evolutionary gradient. So you know these   
1:16:24   
are kind of predating a lot of the machine learning techniques the way they're built today. And so you know   
1:16:31   
there are a lot of ways you can use evolution strategies for pure optimization problems.   
1:16:37   
So you know in this case the gradient is a fitness landscape where you follow that fitness landscape to the highest   
1:16:44   
levels of fitness instead of following downward to the lowest area.   
1:16:51   
So there are a lot of different ways evolution strategies works. So uh some notes about the methods here.   
1:17:00   
Evolution strategies use natural problem problem dependent representations. So   
1:17:05   
problem space and search space are identical. In common with evolutionary   
1:17:11   
algorithms, the operators are applied in the loop. So you generate variation. You select on that variation or variation is   
1:17:19   
generated and you're improving the solution. As you do that, you're moving up to a peak in that fitness landscape.   
1:17:29   
An iteration of the loop is called a generation. The sequence of generations is continued until termination criteria   
1:17:36   
is met. Special feature of evolution strategies is the self adaptation of the   
1:17:41   
mutation step sizes and the co-evolution associated with it. So the ES is briefly   
1:17:47   
presented in the standard form. The real value chromosome contains in addition to   
1:17:53   
end decision variables n prime mutation step sizes   
1:17:59   
where the value often   
1:18:08   
one mutation step size is used for all decision variables where each has its own step size. Mate selection to produce   
1:18:16   
offspring is random. First new mutation step sizes are generated per mating by   
1:18:22   
intermediate recombination of parental mutation step size with   
1:18:27   
subsequent mutations. Uh and then they give some math here. This results in an evolutionary search   
1:18:34   
on two levels. First at the problem level itself and second at the mutation   
1:18:39   
step size level. In this way, it can be ensured that evolution strategy searches for its target and even finer steps.   
1:18:47   
However, there is also the danger of being able to skip larger invalid areas of the search space only with   
1:18:52   
difficulty. So you have this work out this procedure of sort of evolving your population and   
1:18:59   
in doing so targeting a certain part of the search space and then these strategies are sort of optimized for   
1:19:06   
that search space and you end up with sort of the best solution to finding the   
1:19:12   
optimal points on that search space. That's what you mean by strategies.   
1:19:20   
So the evolution strategies know those two variants of best selection for the generation of the next parent   
1:19:25   
population. So mu is the number of parents and then there's the number of offspring.   
1:19:32   
So that's where we have mu and the number of offspring. The mu best   
1:19:37   
offspring are used for the next generation. And so mu is usually the number of offspring divided by two.   
1:19:46   
And then mu plus offspring. The best are selected for a union of you parents in   
1:19:51   
the number of offspring. Um and so this of course there are   
1:19:57   
different ways that you can implement this. Bach and Schwaffle recommend the value for the number of offspring should   
1:20:04   
be approximately seven times uh the mu which is the number of parents whereby   
1:20:10   
mu must not be chosen too small because of the strong selection pressure. So you need to have a large initial population   
1:20:16   
of parents and then you know a sevenfold number of offspring   
1:20:21   
basically tuning up that replication parameter to produce more variation.   
1:20:28   
So values for newer application dependent must be determined experimentally. The selection in the   
1:20:34   
next generation evolution strategies is deterministic and only based on the fitness rankings not on the actual   
1:20:41   
fitness values. The resulting algorithm is therefore invariant with respect to monotonic transformations of the   
1:20:48   
objective function. The simplest and oldest evolution strategy   
1:20:54   
uh 1 + one operates on the population size of two. The current point parent   
1:21:00   
and the result of its mutation only if the mutants fitness is at least as good as the parent one becomes the parent of   
1:21:06   
the next generation. Otherwise the mutant is disregarded. more generally the number of offspring   
1:21:13   
mutants can be generated and compete with the parent. Uh so there's one plus the number of   
1:21:20   
offspring in one and then number of offspring. In that case best mutant becomes the parent of the next   
1:21:26   
generation while the current parent is always disregarded. For some of these variants of linear   
1:21:32   
convergence in a stochastic sense then derive ununimodal objective functions.   
1:21:40   
Individual step sizes for each coordinate or correlations between coordinates where surge are essentially   
1:21:46   
defined by an underlying coariance matrix are controlled in practice either by self adaptation or by coariance   
1:21:53   
matrix adaptation. Then the mutational step is drawn from a multivaried normal distribution using an evolved coariance   
1:22:00   
matrix that has been hypothesized that this adapted matrix approximates the   
1:22:05   
inverse hessen of the search landscape. This hypothesis has been proven for a static model relying on a quadratic   
1:22:13   
approximation. In 2025, China proposed a multi-agent evolution strategy or consensus based   
1:22:20   
distributed optimization or novel static step step adaptation method is designed   
1:22:26   
to help multiple agents control step size cooperative. So there are a lot of innovations in   
1:22:32   
this area and a lot of ways to apply these algorithms but the basic goal of   
1:22:37   
the approach remains similar. And so again there are different ways   
1:22:43   
that you can use evolution strategies. Of course we also have other forms of evolutionary computation. We have   
1:22:49   
different forms of simulating evolutionary processes and so forth.   
1:22:56   
So now I wanted to talk about this interview with Ilia Sutsk. Remember we talked about scaling and sort of the   
1:23:04   
problems maybe we're running up against with scaling. How we're making models bigger but not necessarily better. they   
1:23:11   
have some they have some of the same problems that the smaller models have. And so at this point, we're reaching a   
1:23:17   
place where, you know, maybe we need to rethink how we're building the smaller   
1:23:22   
models before we scale them up. And so this is an interview. This is   
1:23:28   
from Tim Kellogg's Blue Sky account. And he has a couple of threads on this. This   
1:23:34   
was from a few days ago. So this is November 25th. And so this is a quote   
1:23:39   
here. Um it's back to the age of research again just with big computers.   
1:23:45   
And so the idea is that we need to rethink our algorithm that we're scaling   
1:23:51   
up. So instead of thinking of scaling as sort of the holy grail of intelligence   
1:23:56   
or super intelligence or what have you, we need to go back to the drawing board in a number of ways. So um it's this   
1:24:04   
quote here. these models somehow just generalize dramatically worse than people. It's a very fundamental thing.   
1:24:11   
So our small models are generalizing worse than people. When we scale them up   
1:24:16   
in terms of size, they're generalizing worse than people as well. And that's kind of the idea.   
1:24:24   
So in other words, um we've hit a   
1:24:29   
is Harry Marcus would say we've hit a wall some type. So um and so Tim Kellogg says   
1:24:38   
this is the theme you can't have AGI without existing in and learning from the real world which of course is true   
1:24:44   
in terms of training but also in terms of embedded systems in terms of continual learning and things like that.   
1:24:52   
This is Dwar Patel. Um the thing that happened with AGI and pre-training is   
1:24:58   
that in some sense they overshoot the target. you will realize that a human being is not an AGI because a human   
1:25:05   
lacks a large amount of knowledge. Instead, we rely on continual learning.   
1:25:10   
If I produce a super intelligent 15-year-old, they don't know very much at all. A great student very eager. You   
1:25:17   
can say you go and be a programmer, you go and be a doctor, go and learn. So,   
1:25:22   
you can imagine that the deployment itself involves some kind of learning trial and error period. it's a process   
1:25:29   
as opposed to you drop the finish thing. So this is kind of uh drawing at this   
1:25:35   
distinction between training a model with information with data and then it   
1:25:41   
having some experience with the data. So you know the idea is that you have a   
1:25:48   
15year-old or a teenager whose brain is not fully developed and also has not had   
1:25:55   
a lot of experience in the world. uh can have a lot of information   
1:26:00   
but they will not be as successful without that sort of first of all   
1:26:06   
there's some biological development that still needs to happen some maturity but then also the experiential part which   
1:26:13   
needs to be in place how much experience do you need to be a great X or a great Y   
1:26:18   
that's the problem that they're trying to figure out so you can dump a bunch of training data into this model but you   
1:26:25   
know it doesn't necess necessarily translate into super intelligence is the point.   
1:26:32   
And so Tim Kellogg says, "Dwarash nervously kind of this quote, aa yes of   
1:26:38   
course the value function for human emotions makes perfect sense." Um then   
1:26:43   
he says again another Doresh Patel quote emotions are so simple it would be cool   
1:26:50   
to map them out in a human understandable way and then pauses an extremely awkward amount of time. Um and   
1:26:58   
then uh this is uh another quote from the interview.   
1:27:04   
Does hunger count as an emotion? It's debatable, but I think for example, our intuitive feeling, and that's in the   
1:27:10   
caption in the in the clip here,   
1:27:15   
um, he must be doing it on purpose, just handing out quotable quotes on repeat for an hour and a half. This is just   
1:27:21   
kind of like, you know, um, busting his chops, as they say, because um, it's   
1:27:28   
kind of like he's backtracking in a lot of ways as to what was promised in the past few years.   
1:27:34   
So um this is you know let's stop picking an   
1:27:40   
Ilia uh scaling can consume so much economic attention that it was difficult   
1:27:45   
to convince your boss or a VC to let you look anywhere else and that can't have good consequences that surely leads to   
1:27:53   
blind spots. That's basically the takeaway from this whole thing. So yeah I just wanted to go over that and talk   
1:27:59   
about that sort of uh outcome. Um   
1:28:04   
definitely there's a lot of rethinking of what people have ceases ceaselessly hyping for the last few years and it's   
1:28:11   
interesting to think about the larger context of modeling and and of um you   
1:28:18   
know some of the things that I think a lot of people already identified which is that you know we have a lot of we   
1:28:25   
have a lot more hype than sort of informative um outcomes.   
1:28:32   
So this is just kind of an opinion on that. Okay. So I think I'll finish up with   
1:28:38   
this article. Um this is a review. This is something that we've talked about.   
1:28:44   
We've talked a lot about metaphors in our group and we've talked about computational psychiatry.   
1:28:50   
And so this is kind of the intersection of those two areas. So this is an expert review on the   
1:28:57   
history of metaphorical brain talk and psychiatry. the molecular psychiatry journal   
1:29:05   
and kind of in the history of the field of psychiatry how they've used metaphors of the brain and how that's kind of you   
1:29:12   
know played a role in the formation of the field evolution of the field.   
1:29:17   
So from the abstract um from the very beginnings of our field in the late 18th century, psychiatrists have engaged   
1:29:24   
often extensively in metaphoric brain talk rephrasing descriptions of mental   
1:29:30   
processes and unconfirmed brain metaphors such as diseased working of   
1:29:35   
the brain convolutions which is kind of a description of some sort of mental   
1:29:40   
illness. In the late 19th century, uh, Crarapelin criticized the later   
1:29:46   
developments of such approaches turning brain mythology by the philosopher psychiatrist Jasper in 1913.   
1:29:54   
This essay, I will review the history, meaning and significance of this phenomena and reach four conclusions.   
1:30:01   
So the first is that this trend continued to the present day in metaphors such as the broken brain and   
1:30:07   
the use of simplistic and empirically poorly supported explanations of psychiatric illness such as depression   
1:30:14   
being due to an imbalance of serotonin. So things like broken brain imbalance   
1:30:21   
those sorts of things are all indicative of illnesses or of dysfunctions.   
1:30:27   
Second, our language stems from the tension in our professional profession that seeks to be part of medicine that   
1:30:33   
declares our main focus as treatment of the mental. We feel more comfortable with the reductionist approach to brain   
1:30:39   
metaphors, which even though at times are selfdeceptive, nevertheless reinforcing our commitment to in   
1:30:46   
membership in a brain-based medical specialty. Third metaphorical talk can also be seen   
1:30:53   
as a promisory note to our profession. A pledge that the day will come when we can indeed explain accurately to   
1:30:59   
ourselves and to our patients the brain basis of the psychiatric disorders from   
1:31:04   
which they suffer. Basically, you know, kind of guaranteeing that there's maybe   
1:31:10   
a cure on the horizon and that's irrepective of whether that's actually true. at speaking in those terms.   
1:31:18   
Finally, moving away from metaphorical brain talk would reflect the increasing maturity of both the research and   
1:31:23   
clinical aspects of our profession. So is just arguing against a lot of   
1:31:29   
these metaphors which are maybe counterproductive. So he focuses on this idea of   
1:31:34   
metaphorical brain talk which he defines as describing the disturbmental   
1:31:39   
processes and psychiatric illnesses in terms of brain function in ways that appear to be explanatory but actually   
1:31:47   
little to no explanatory part. So you can see this across the history of the field going way back to the at   
1:31:55   
least in this case to the 19th century. Thinking about asylum psychiatry,   
1:32:00   
thinking about the biological psychiatric revolution of the late 1800s, early 1900s and then kind of   
1:32:09   
thinking about brain mythology and then thinking about how we talk about   
1:32:15   
psychiatry today in terms of brain metaphors. So a lot of really interesting um   
1:32:22   
historical material here, a lot of interesting things going on in in history in the   
1:32:29   
history of the field and a lot of lessons of the modern day.   
1:32:35   
And so you know a lot of early metaphors involve maybe our limited understanding   
1:32:41   
of the brain. Um and so uh Maynard who is one of the people from that era late   
1:32:49   
1800s early 1900s used to construct brain pathways just kind of through   
1:32:55   
metaphor. So thinking about different ways in which things worked in the brain when we didn't know a lot about the   
1:33:01   
brain. Um, paradigmatic for the spirit of the time is the highly speculative   
1:33:07   
fusion of psychopathological findings with anatomical findings and pathogenic   
1:33:12   
claims which in minor following an old tradition related in particular to vascular dependent differences in brain   
1:33:19   
nutrition. Miner's own student dog foretell called   
1:33:25   
his brain pathways fantastical constructions. We conclude with one of further critique from felts. What about   
1:33:32   
my inert's work made it cogent and compelling? What about it seemed capable of dispelling the mystery of the nervous   
1:33:38   
system and dispensing with the unique inwardness of the mind? Part of the answer lies in Mayard's images of the   
1:33:45   
brain brain's material and collocation of its fleshy fibrous inner stuff with   
1:33:50   
the anteriority of the mind by delineating various fiber systems in the   
1:33:55   
brain and nerves and deducing their different functions on the basis of their winding pathways. Mayard   
1:34:00   
elaborated new shapes and textures inside the brain. By doing so, he elaborated and fleshed out functions of   
1:34:08   
the mind. But even as he imagined these fibers as pathways or trackcts   
1:34:14   
inside the brain, he co-extended them and colllocated them as pathways somehow equally inside the mind.   
1:34:21   
So again, you know, thinking about brain anatomy, not necessarily connecting that with the   
1:34:28   
function. And so you just kind of make up the story about what's going on in the brain   
1:34:35   
and you know how it's and but it's totally disconnected from reality or from some good functional model.   
1:34:44   
His success, Phelps suggests, was due to his   
1:34:49   
ability to connect what he saw inside the brain with an image of what he described inside the mind by his   
1:34:56   
combination of material metaphorical techniques. Instead of analyzing the facts in an   
1:35:02   
unbiased way and using a great extension of our experience and mental efforts to get square with things, they pass at   
1:35:09   
once to a one-sided consideration of the extra psychological components of the situation. Abandon the ground of   
1:35:16   
controllable observation, translate what they see into a jargon of wholly uncontrollable brain mythology.   
1:35:23   
All of that with the conviction that this is the only admissible and scientific way. says pretty, you know,   
1:35:30   
well, sounds like we're describing a scam artist, but we're not. It's just someone who's making up a story and   
1:35:36   
putting that out in front of the data, which, you know, again, is a lot of times how things work when you're trying   
1:35:43   
to interpret data. But I mean, you know, sometimes and and it's not bad   
1:35:48   
necessarily if you need a mental model, you need to map everything to a mental model. But of course, it's also you can   
1:35:56   
get carried away, I guess, is maybe one of the ways to do this. And then, you know, you're using metaphors too   
1:36:02   
loosely. This is always the the problem with metaphors. You use a metaphor and   
1:36:08   
it's always imperfect because you're mapping one thing to another, but   
1:36:14   
sometimes the metaphor takes over. Next, we examine a text on similar theme   
1:36:20   
from a quite different source, the psychiatrist philosopher Carl Jasper's. In the introduction to his first edition   
1:36:26   
of general psychopathology, which was in 1913, he writes, "The still widespread   
1:36:32   
somatic prejudice is everything mental cannot be examined as such. It is merely   
1:36:38   
subjective. If it is to be discussed scientifically, must be presented anatomically, physically, as a physical   
1:36:45   
function. For for this it is better to have a preliminary anatomical construction   
1:36:51   
which is considered heristic rather than a direct psychological investigation.   
1:36:56   
Such an anatomical constructions are quite fantastic which is in reference to manner and are rightly called brain   
1:37:03   
mythologies. Things that have no connection to one another such as cortical cells and memory images, brain   
1:37:09   
fibers and psychological associations are brought together. There's also no basis for these mythologies in so far as   
1:37:16   
not a single specific brain process is known that could be assigned to a specific mental process is a direct   
1:37:23   
parallel phenomena. So we might think that recent scientific developments over the rest of the 20th   
1:37:29   
century eliminated the need for metaphorical brain talk. As you know more about the brain, you have better   
1:37:36   
models, you have more constrained metaphors because you have the data. you   
1:37:42   
have the mechanism and you don't need to use them as sort of a way to think things   
1:37:49   
but we provide three examples here suggesting that this is not the case so   
1:37:55   
just because we know more doesn't mean we stop using metaphorism properly   
1:38:00   
first in a series of articles published over several decades the distinguished psychologist Paul Neil proposed a   
1:38:06   
cognitively and psychometrically sophisticated genetic simple locus model schizophrenia spectrum disorders where   
1:38:13   
part of this theory was equating cognitive and neurobiological parts of theory was expressed here in 1962.   
1:38:21   
The cognitive slippage is here conceived as a direct molar consequence of synaptic slippage potentiated by the   
1:38:28   
disruptive effects of aversive control and inadequate development of their personal communication sets.   
1:38:36   
So this phrase synaptic slippage is of course kind of uh   
1:38:42   
an incomplete sort of account of what's going on in the brain. It's just kind of   
1:38:47   
this metaphor that keeps replicating itself in the literature and it sounds nice but it's inaccurate.   
1:38:55   
Um second in 1985 a leading biological psychiatrist Nancy Andre published a   
1:39:03   
widely cited book whose title was parad a paradigmatic example of metaphorical   
1:39:09   
brain talk which is the broken brain. She writes for example that recent advances in research have taught us that   
1:39:16   
many forms of mental illness are due to abnormalities in brain structure chemistry. Psychiatry is moving from a   
1:39:22   
study of the troubled mind to a broken brain. So this is again these troubled and broken words are kind of giving us   
1:39:30   
this um image or this framework of dis dysfunction.   
1:39:36   
In a later section she describes using broad metaphors the kind of brain abnormalities that occur psychiatric   
1:39:42   
disorders. The various form of mental illness due to many uh many different   
1:39:47   
types of brain abnormalities. Sometimes the fault may be in the pattern of wiring or circuitry sometimes in command   
1:39:53   
centers and sometimes in the way messages move along the wires. So again, wires, command centers, pattern of   
1:40:01   
wiring or circuitry, and they're just kind of viewed as like they're, you know, when you have a mental illness,   
1:40:07   
those things are offbalance. And of course, all those are metaphors. You   
1:40:13   
know, command center being a very good example or messages moving along the   
1:40:18   
wires is another good example. And so, you know, it's kind of hard to, you   
1:40:25   
know, it's easy to kind of imagine what abnormality is, but then it's harder to   
1:40:30   
map it back to the science. Um, and so a lot of times, again, you get this these   
1:40:36   
metaphors that get ahead of what's actually going on. Third, in an important development of   
1:40:43   
the history of neuroscience in the early 1960s, cell bodies and neural pathways in the pitative monoim neurotransmitter   
1:40:50   
dopamine, neurobinephrine and serotonin were demonstrated in mamalian brains.   
1:40:57   
Within a few years, prominent psychiatric researchers abnormalities of function in these neurotransmitters were   
1:41:03   
the major cause of three of the most important psychiatric disorders, schizophrenia, mania, and depression. I   
1:41:11   
suggest that these theories reflect in more subtle ways than prior examples metaphorical brain talk. Or perhaps   
1:41:17   
these monoamian hypotheses could be seen as sitting somewhere in a continuum of naively enthusiastic scientific theories   
1:41:24   
but metaphorical brain talk. So he's getting at um this idea that you have a   
1:41:31   
new finding and then that new finding is translated into pause for everything.   
1:41:37   
So, you know, you have this new finding and it's exciting and it seems to, you   
1:41:44   
know, somehow explain everything. And so, again, you know, sometimes in theory we kind of have theories that are very   
1:41:52   
focused on specific mechanisms and maybe our pet projects, maybe things like that. Um and so you know these are   
1:42:01   
naively enthusiastic scientific theories meaning that we know about this new   
1:42:06   
mechanism but we don't you know spend a lot of time unpacking that new mechanism but we already built the theory around   
1:42:13   
it. Ah this is this is the thing that's responsible for the disorder. And in a way that's a metaphor because   
1:42:20   
you're using that as basically the explanatory. You're saying that there's something   
1:42:26   
that you can show is maybe you know involved in dysfunction if you have less   
1:42:34   
or more dopamine say for example   
1:42:39   
and that is and that is sort of the you know sets   
1:42:47   
the gain for your theory right so this is again you know and you'll see this   
1:42:52   
again and again in brain science Because again, we're uncovering things in very   
1:42:58   
complex systems in play. And when you have hyped things and this is the same thing in machine learning and deep   
1:43:04   
learning, you might have a new model or you might have a new approach and those new things   
1:43:10   
then maybe are the best thing ever or explain the most data at least until you   
1:43:17   
really kind of spend time unpacking in the exam. Okay, so this is kind of thinking about   
1:43:25   
how new findings can be sort of brisk for this mill.   
1:43:31   
Um, so these kind of theories and these kind of uh metaphors are grounded in   
1:43:37   
solid basic neuroscience and has support from pharmacological studies and mechanisms of action. However, trying to   
1:43:44   
clarify his disease ideology through the mechanism of action or pharmacological treatments is deeply problematic and   
1:43:51   
illustrated by the now common phrase. Headache is not an aspirin deficiency disease. So like you don't like describe   
1:43:59   
headaches is because you know being because you don't have enough aspirin on you. There's a cause for a headache.   
1:44:05   
Aspirin will take care of the headache for a little while, but the headache is not caused by less aspirin. It's just   
1:44:13   
that aspirin is a thing that can um you know help you with your headache, reduce   
1:44:20   
the pain. It's still it's the headache is still there and the causal mechanism is actually nothing to do with asthma.   
1:44:28   
Given the more than 100 neurotransmitters in the male brain, the plausibility that dysfunctions in the   
1:44:34   
first three can be traced in the brain cause the major psychiatric disorder stream breaking point any sense of   
1:44:40   
fragility. So you can't just say that like there's one causal mechanism that's   
1:44:46   
this brand new thing, you know, we should just focus all our efforts there. Unfortunately, sometimes that's the way   
1:44:53   
people act. And this is a thing you'll see in the literature. people just focus   
1:44:58   
on this one finding really propose okay we should really focus resources on this one new thing.   
1:45:06   
Um so this hurts us in terms of developing you know oftent times really   
1:45:12   
strong solid uh you know integrative theories is this   
1:45:19   
tendency to chase the shiny object. So that's kind of talking about that. Um   
1:45:32   
so why brain talk? Metaphorical brain talk has arisen out of a foundational feature of our profession. Psychiatry   
1:45:39   
began and remains a profession that treats disorders major clinical manifestations our mental space. So we   
1:45:46   
have symptoms but we have resulting signs and distributed behaviors.   
1:45:51   
Okay. So you have to think about sort of the the behavioral space of this. It's   
1:45:57   
very subjective in a lot of ways um and very hard to characterize with   
1:46:03   
mechanisms. But we are also medical specialty and consider association in medicine central   
1:46:09   
to our mission professional identity. So most other medical specialists have   
1:46:15   
organs of special focus. So opthalmology opthalmologists focus on the eye.   
1:46:21   
Cardiologists focus on the heart so forth. In the first decades of the late 18th and early 19th centuries,   
1:46:28   
psychiatry for quite logical reasons chose the brain. But some 80 years later, neurology has begun to develop   
1:46:35   
and took with it all the diseases where given the methods of gross and historical pathology that have been   
1:46:41   
available, one could track these disorders back to definable brain or nervous system.   
1:46:47   
So you know psychiatry developed before neurology neurology kind of took that   
1:46:52   
space of like physical uh problems with the brain and so now   
1:46:57   
psychiatry needs to have this also appeal to the brain and make explanatory   
1:47:04   
statements about behaviors and so they can trace that back to the neurology but   
1:47:09   
they're not quite making that connection between brain and behavior. So that's kind of maybe where a lot of problems   
1:47:15   
here lie. It's a unique problem to psychiatry I guess. Of course with   
1:47:21   
neurologists at least the way that this is classified. We have neuroscience now which incorporates a lot of this or   
1:47:28   
psychi or psychology department often just you know have all sorts of different specialties kind of in the   
1:47:34   
same place. There isn't so much that distinction anymore. So this is a a quote here. Um,   
1:47:42   
ever since the beginning of psychiatry, metaphorical brain talk has, as part of a professional conspiracy to believe,   
1:47:49   
helped our own self-im images of poor relation in medicine, and given us plausible metaphors to communicate about   
1:47:56   
the disease we treat with ourselves and with our patients. This conspiracy, I   
1:48:01   
suggest, was further reinforced through large advertising budgets of modern drug companies.   
1:48:07   
So again, this the view of the metaphoric brain talk is largely negative in this article and this is   
1:48:14   
something that the author, you know, wants I guess maybe wants to kind of root out of psychiatry um given the   
1:48:21   
venue. So the end part is so what? So we have a   
1:48:29   
very imperfect sense of brainbased disturbances that predispose our disorders. We should not be ashamed of   
1:48:35   
this. We've been working hard for a very long time in a set of problems of extraordinary complexity.   
1:48:42   
Talking about our profession and our disorders to ourselves, our colleagues and patients using metaphorical brain   
1:48:48   
talk is scientifically immature and ultimately disrespectful to our patients. Unless we know otherwise, we   
1:48:56   
should assume that our patients want us to tell it like it is. Doc, even when that means we cannot tell pretty stories   
1:49:02   
about serotonin imbalances. When we describe the suffering of our patients, we don't have to dress up the   
1:49:08   
descriptions of their mental anguish with problematic brain metaphors. We should tell them what we know with all   
1:49:14   
the uncertainty. We should take pride in being the only specialist in medicine that chose to treat disorders of the   
1:49:20   
mind, conditions that account for a large proportion of aggregate human suffer. We may not try to hard hide the   
1:49:27   
large amount we still do not know about causes of mental illness behind metaphorical brain death.   
1:49:35   
So I think that's a very interesting paper kind of approach to   
1:49:42   
a lot of these uh issues in psychiatry. It links to computational psychiatry and   
1:49:48   
that we can build computational models that sort of bridge that gap between behavior and what's going on in the   
1:49:54   
brain. But computational models can also fall prey to these problems of metaphors   
1:50:02   
because if we use a metaphor to inform our computational model   
1:50:07   
then you know we're just basically committing the same crime in this sense not crime but you know   
1:50:15   
any case it's a very uh good piece of food for thought and so I hope that like   
1:50:20   
in combination with a lot of the things going into Europe in this article we can kind pull those together   
1:50:28   
and get something interesting. Okay, thanks for attending. See you next   
1:50:35   
time.   
