## Meeting Recording

[YouTube link](https://youtu.be/tHyqx827W6M)

## Mastodon thread

[link](https://neuromatch.social/@OREL/114654821508131547)

## Notes
Using LLMs to synthesize meetings (individual, 6 month intervals).

* workflow, pattern for this function (ekkolapto, metascience).

* progress studies, frontier maps. Interesting lens, theoretical spaces to be explored.

* team --> builds things, formats of map vs. territory.

* intro-inter meetings --> we can analyze meetings.


Making accessible reference points to organization, interaction spaces, rough relation of the map to the territory.

* metascience and language models.

* Morgan --> C. elegans. LLM diplomacy match (expressing strategies).

* ekkolapto -- Electronic Skin for Human Augmentation (Paul Han -- Neurotech).

* Peter Voss and William Edward Hahn -- Machine Perception, Cognitive-level AI.

* Principles of AGI, self-awareness, cognitive AI.


Head of Model Behavior and Policy (OpenAI) --> post. Joanne Jang (reservoir samples).

* Dan Fagella --> disagree with Peter Voss trajectory.

* aigo.ai --> rate of generating tokens.

* Theoretical/Macro --> Practice. Lifespans and time-scales.

* how do we have more functional interactions? How do we have functional discusions about the way forward?

* destination-based research (discernment) --> chart trajectories through complexity.


Plot Twisters -- Governable Spacemakers. Quantum ML and Neuroscience.

* native image generation for 4o.

* Cosmos Institute (AI x Philosophy). Habermas Machines (AI can help humans .. democratic deliberation).

* Science paper. Not decision-making but mediator.

* social, ethical benefits of deliberation.

Bioeletronics --> MEAs, choose different materials for substrate. e-Skin --> sense of touch, at resolution 
of fingertips.


Challenge of Compositional AI: multiple levels of embedded, recursion.

* Case for Compositional AI: the way constituents are combined. Optional LLMs might be.

* the way constituents are combined (Case for Compositionality -- Szabo).

* comprehension -- recovery of relationships, representation.

* semantic parser -- predict next word vs. composition (decompose into entries, relationships).


Gato: LLM that integrates perception --> keep track of blocks, etc. Blocks World -- pose challenges.

* Marcus and Paul, 2022 --> representation of a sequence of actions.

* controllability -- LLMs fabricate things.

* Compositionality -- what is its nature? Explainable, verifiable, interpretable.

* does not match linguistic tree.

## TRANSCRIPT    
0:00     
hello morning morning     
0:05     
hi good morning hi all right so uh let's get started     
0:14     
um this week we did not have an evil war meeting um but we did have an open     
0:21     
source meeting and I thought it was a good open source meeting for the first     
0:26     
coding period we had reports from all three     
0:33     
uh Google Summer code scholars and uh Jesse also had a nice feature     
0:40     
on knowing when to ask questions and knowing when to read the documentation     
0:46     
of the manual and you know the other things in organizational     
0:52     
uh project management and things like that so that was nice uh Jesse's been hard at work     
0:59     
writing up uh his ideas his project management stuff seems like now that he's graduated     
1:07     
from his program he's uh you know catching up making up for     
1:14     
lost time so that's good and um I talked about a paper that the     
1:22     
active inference institute will be featuring uh soon     
1:27     
enough in a live stream so we'll maybe be involved in that or check that     
1:34     
out so why don't we get started with a few features here so the first thing I     
1:39     
wanted to talk about today is this article um Michael     
1:46     
Skooherski I think is a person from MIT     
1:51     
uh and the title is we can must and will simulate neimatode     
1:56     
brains and so it's written kind of in the way that's uh kind of a history of nematode brain     
2:04     
simulation which seems like a niche area but um the idea is that everything has     
2:11     
failed and he wants to try it again and I think that's kind of the way a lot of people     
2:17     
have thought about it even though as the article shows people made incremental     
2:22     
progress on it so you know this is kind of setting up motivating why you would want to do this     
2:31     
a nearperfect simulation of the human brain would have profound implications for humanity     
2:38     
it could offer a pathway for us to transcend the biological limitations that have constrained human     
2:44     
potential and enabled unimaginable new forms of intelligence creativity and     
2:50     
exploration this represents the next phase in human evolution bringing our cognition and memory from the limits of     
2:57     
our organic structure and so the idea is that it's     
3:03     
uh for a number of reasons it's not something we can attain right now     
3:08     
uh we can't really reverse engineer things but we can build up from very     
3:13     
simple nervous systems and so that's kind of the the motivation behind     
3:20     
simulating sea elegance and so the idea is that you know we have these simple     
3:26     
movements or these stereotypical movements that are created by smaller     
3:31     
circuits that we can identify and we can simulate and we can understand how they     
3:38     
work uh in in totality okay so this kind of goes     
3:45     
through the history of worm brains so one of the advantages of the seigans model is that you have the full conneto     
3:53     
and that was derived rather early it was in 1986 when they really kind of had     
3:59     
this complete uh conto map drafted and so that you know that     
4:06     
was pretty early in the uh scheme of connetoics i     
4:11     
mean have gotten other conneto since then we've talked about the fly     
4:18     
connetospha conneto before and you know this was but this     
4:24     
was in a time before it really applied computing power to it so this was a very     
4:33     
um a very simple operation to map out 302 neurons and by simple I mean you     
4:41     
know sitting beside a microscope and doing a lot of the work the annotation     
4:47     
work the drawings manually so um so this is all kind of you know the     
4:58     
sort of the earliest work on connectors and so     
5:04     
uh you know people started to apply computing to C elegance they used a lot     
5:11     
of the things that were built up in the community beforehand and so Sydney Brunner of course was the first person     
5:17     
to propose using sea elegance as a model organism in the 1960s and so once that     
5:26     
started you had people uh like uh Solston and White and they uh were able     
5:33     
to work out some of these details of these systems these cellular     
5:39     
systems and so um Ernest Neur and Paul Erdos kick     
5:44     
things off with a biohysical model of neatode locomotion in 1991 if you're familiar with the story     
5:52     
of Paul Rodos he's the mathematician who famously would wander around with a     
5:58     
suitcase collaborating with people and so there's the Euro number in uh     
6:04     
citation networks which is like you know how close are you to Paul Erdos and     
6:09     
people you know might be two or three steps away from Erdog and people are one they publish with them which is an     
6:17     
interesting aside um so that you know we had this     
6:22     
sort of biohysical model in 1991 offered in this paper here     
6:28     
[Music] um which is the theory of the locomotion     
6:34     
of nematodes um and so you know you have uh Ernest     
6:40     
Neber and Porto so you have this sort of mathematical or computational flavor to     
6:46     
it it's published in a biohysical venue but it's also you know you have to kind     
6:53     
of think about some of these kind of computational problems mathematical     
6:58     
problems uh in in these kind of simulations so um that that was in 1991     
7:07     
then two different teams one at the University of Oregon the other in Japan published plans for building more     
7:13     
ambitious models in the late 1990s so neither of these projects got off the     
7:20     
ground but in 2004 the virtual sea elegance project at Hiroshima University     
7:26     
got somewhat farther so they released two papers describing their model which     
7:31     
simulated the nematodes motor control circuits so these papers are     
7:37     
um this one is a model of motor control of the neatode segans with normal     
7:43     
circuits and so this is um in artificial intelligence in     
7:50     
medicine and they proposed this uh neuronal circuit for motor control the     
7:56     
simulated nematode could respond to virtual pokes on its head but it didn't do much else and even this was arguably     
8:03     
not a true simulation um and so that's where things     
8:08     
stood until the dawn of the 2010s and then they get in here into uh open worm and the history of open worm kind of     
8:16     
getting into the origins of open worm which uh involve uh Giovani     
8:24     
uh and he uh he actually was tweeting from the     
8:30     
Twitter account of the whole brain catalog and this is a project to consolidate data for mouse     
8:38     
brains and Steven Larson of course who was at the time a neuroscience grad     
8:44     
student at UC San Diego um decided to hook up with a dewy and     
8:50     
start open one and uh get some other people involved as well so I actually     
8:56     
joined open world a little bit later than this but the origins were kind of in 2010     
9:02     
2011 so it's um that's when it started the original vision behind open     
9:10     
was at the efforts of a decentralized group of academics with the goal of creating a     
9:16     
complete realistic and open source model of C elements and so yeah there was a lot of     
9:22     
press around that um and uh you know of course you make     
9:27     
these uh oh okay so yeah you make these predictions that probably won't come     
9:34     
true but people make them anyways so uh David Dela Rimple was     
9:40     
working on a parallel project at MIT which he dubbed Nemo load which I've     
9:45     
never heard of which maybe is kind of the point here openworm scientists largely used data from dead nematodes     
9:51     
but Dela Rimple wanted to use the then new technique of optogenetics to study living specimens     
9:58     
in a 2011 comment unless wrong Del Rimple wrote I would be extremely     
10:03     
surprised for whatever that's worth if this is still an open problem in 2020 so     
10:09     
it's now 2025 a nematode simulation remains an open problem     
10:15     
[Music] delwimp will abandon Nemo load in 2012 open worm still exists but has not made     
10:22     
substantial progress over the past 10 years where it's creating a truly scientific full grain     
10:28     
simulation due to lack of available data but of course there have been a lot of     
10:33     
tools that have been created but in any case um so I mean you know I guess you could     
10:42     
say yeah we still have this as an open problem on the other hand it seems like this is a problem that's always off into     
10:48     
the future because people's demands are kind of like I guess I want to see     
10:54     
something that's kind of like I don't know more than what we have it's really     
11:01     
kind of a hard standard mainly because there's no concrete standard to work towards in the first place it's kind of     
11:07     
a visionary but anyways um so he he this the author here     
11:14     
mentions we're not quite back to where we were in the 2010s we have much better data on the sea elegance nervous system     
11:20     
and as I'll discuss later much better tools to study it but we aren't much closer to simulating the whole brain     
11:28     
so where we got stuck of course he mentions the human brain project and     
11:34     
Harry Mark and how that was I guess seen as a failure of course we've talked     
11:40     
about the human brain project a number of times in the group and how it wasn't particularly a failure     
11:47     
um and then of course defining this definitional problem is important     
11:54     
because you know we have to kind of say what we're looking for and I guess     
11:59     
that's the most important part otherwise we could just be working towards something that we could always say we     
12:05     
never achieved or we could always say we achieved it if we just change the definition posttop and so we don't     
12:13     
really want to do that we want to have a good definition of simulation     
12:18     
so this person's view is that a good simulation of a nervous system is one that both accurately replicates its     
12:25     
functionality and reliably predicts the future activity of a real system under the same initial     
12:32     
conditions so this is saying that a simulated neatode and a simulated plate     
12:37     
of aar which is what they typically use in experiments you put the worm on this     
12:43     
aar plate or this this surface which is an aar gel and you put you know food on     
12:49     
top of it and the worm lives out its life on this slab of     
12:56     
agaros um and so whatever the neatode can do there the simulation should     
13:03     
produce behaviors that reflect that or that are basically the same of course the     
13:11     
interesting thing here is that agaros is not the nematode's native environment     
13:16     
their native environment is this three-dimensional environment in the soil but that's neither here nor there     
13:23     
for for I guess the purposes of this definition if we disturb the simulation say by     
13:30     
poking or shining a light on it it should respond the same way the real neatode would and it should keep acting     
13:37     
like a real nematode over time instead of accumulating more error as time goes on which I don't know what that means     
13:44     
because I don't know that like real neatodes don't accumulate more error but     
13:52     
whatever um this definition can help us clarify what is and isn't simulation     
13:57     
last October a consortium of scientists across 127 institutions published the     
14:04     
complete conneto of the fruitfly so we've talked about this uh this involves     
14:09     
this flyawware project in the flywware conneto and and so you know this is     
14:16     
something that is of course a data set it's rekindled the interest in brain     
14:22     
simulation and in a sense the flywire connect can be used to simulate a fruit flow when Philip Shu a researcher on the     
14:29     
project test fired the neurons responsible for sensing sugar the model     
14:34     
predicted that other neurons that extent the flies probiscus would fire as they     
14:40     
would in a real fly other researchers have since she used model to accurately predict neural neural patterns involved     
14:47     
in the fly sense of taste grooming and location so this is um not you know I     
14:55     
guess not really a simulation again we're playing with this definition and maybe trying to realize a definition     
15:03     
that can't be realized because this might be you know in in a academic sense this might be a     
15:09     
very good example of a simulation but I guess it isn't maybe maybe this     
15:14     
person is thinking more of emulation too which of course we've talked about with     
15:20     
some of the people interested in human brain emulation and whole brain emulation which you know we can talk     
15:26     
about that later in terms of what we think about that but um so uh this previous study     
15:35     
that I mentioned uh Philip Shu study which we talked about in the group a while back     
15:41     
um Chu himself has been clear that the model is extremely simplified makes     
15:47     
assumptions about key parameters governing how neurons behave when the     
15:52     
model can successfully predict the behavior of particular groups of neurons it cannot mimic the exact functionality     
15:59     
of an entire fly brain true but you can simulate different aspects of the brain     
16:06     
and behavior which is maybe more tractable that's because the flywire     
16:12     
model is missing the same thing as openly uh as well as other attempts to simulate     
16:17     
nematodes good data on the relationship between neural structure and neural function     
16:24     
so that's we're getting at this sort of relationship between structure and function which again you know it's I     
16:32     
don't know what you uh you know I guess the idea is that you can do this with uh     
16:38     
magic optogenetics or something or that there's some magical method that you can     
16:44     
use to gain this information and of course you know if you think about     
16:50     
this maybe as other people do maybe outside of this community maybe people     
16:56     
like an embodiment the argument that is basically that function is emergent from     
17:02     
structure that is it's going to be really hard to predict any specific function maybe even in C elegance um and     
17:12     
so you know it's it's kind of an interesting point i'm not really sure you know if you know     
17:19     
I guess the implication here is that you haven't cracked the code unless you     
17:25     
really have that map and what I'm saying here is that maybe you can't have that     
17:30     
map directly maybe it's something that is you just have to approximate and hope     
17:36     
for the best so it's you know it's a it's not just definitional the problem     
17:42     
here it's maybe expectation as well uh so okay this is this is a really     
17:48     
interesting article um it kind of gets into a little bit more     
17:56     
uh about collecting data and getting uh new types of data bringing them to bear     
18:04     
getting higher resolution with microscopy um and some of the other techniques that     
18:12     
we can use to look at the function of neurons so you can u look at the cells     
18:19     
themselves and their location and their contents in other words you know what     
18:25     
are their ion channel profiles uh what are the connections and     
18:31     
of course we have some of those data and we're getting more data all the time as you do in science     
18:37     
um and so because you have 300 neurons or so in C elegance that makes that     
18:44     
tractable so you can catalog all of that you can then build a model you can     
18:49     
simulate the model etc and then of course there's this goal     
18:55     
of producing mathematical equations or formulas that can explain the data and     
19:01     
this is where sort of this distinction comes into play between can we predict behavior with     
19:09     
like regression models or do we have to just kind of assume that these things     
19:15     
are emergent and build simulations that can maybe produce some of these behaviors and just leave it at that     
19:23     
so you know this is kind of uh you know I don't     
19:28     
know it's so this person is currently founded a nonprofit research based on     
19:34     
focus uh research institute focused on brain simulation so it's interesting     
19:40     
it's very interesting in the way that kind of it goes over the history here um     
19:47     
the thing about like one of the things open has done of course is build a bunch of     
19:52     
tools and what's interesting is like outside of the community you know it     
19:58     
would be nice to see people apply these tools and build onto these tools for     
20:04     
simulation but you don't necessarily see that it's just like kind of this     
20:09     
attitude of well if you failed I'm gonna have to throw that away and start over and you know it's it's just kind of     
20:17     
Um I don't you know I guess there's like this I want to say lack of vision but     
20:24     
there's sort of like this like I guess it has goes back to the definition of it     
20:29     
where you have this definition of what you want out of a simulation it maybe really mean more     
20:36     
like an emulation but then you know we don't know how to achieve that maybe we can     
20:41     
achieve that but it doesn't matter because that's sort of the standard we want and we're going to kind of define     
20:48     
things as we go along so everything that comes along is not really cutting     
20:54     
it and you know I I don't know well we'll see how this works out in the future     
21:01     
and uh it's worth noting also that open there's been a lot of papers produced     
21:07     
kind of around open world um you know sometimes we'll cover these in the meetings where you know they'll     
21:14     
have some new technique people who have been involved in open room in the past     
21:20     
and kind of using sort of that way of thinking about uh the neatode     
21:26     
conneto and you know there's been a lot of interesting stuff coming um like uh the conneto and the function     
21:34     
of the conneto the neurohysiology of the conneto so there's a lot of interesting     
21:39     
stuff there um to follow up on and as for the title we can must and will     
21:46     
simulate nematode brains i mean I guess we we can I I would argue we can now     
21:53     
it's just a matter of like you know is it really kind of uh matching every     
21:59     
behavior we can observe which is of course with simulations a tough question     
22:04     
we must I I mean you know must I guess we must in the sense that if we want to     
22:10     
simulate brain and behavior at all that would be the first target and we     
22:16     
probably want that for reasons having to do with C elegance being a model     
22:22     
organism and then will you know that's up to people in the future I guess is to     
22:28     
drive that research program forward all right uh looks like Jesse's     
22:36     
here welcome Jesse um so that's okay um     
22:44     
now the second thing I wanted to show this is really interesting this is something I think that uh Morgan posted     
22:51     
in the Slack one of the channels this is uh something called     
22:56     
genetic voids and this is by add attention mech     
23:02     
so this is a a nice little simulation think I showed a notebook last week where they     
23:10     
were you know mathematically modeling some meshes and shapes and things like     
23:18     
that this is actually a simulation that runs off of GitHub IO so this is uh modeling these     
23:25     
voids and so voids are these uh computational agents that um you know you usually have     
23:33     
a population of voids and they ex can exhibit collective behaviors so each one     
23:40     
of these dots is a void and you have these populations of voids that flock     
23:46     
together and produce these collective behaviors and they produce the     
23:52     
collective behaviors by sort of interacting with each other but individually having a set of rules that     
24:00     
they implement locally so each boy will implement a set of rules determining how     
24:06     
close they get to one another how far they're allowed to get from one another rules for like you know acceleration and     
24:15     
velocity and then all the voids in the collective in the population are doing     
24:22     
this at the same time so each void is observing its nearest neighbor but if you do that in     
24:30     
parallel you have this uh sort of mass of     
24:36     
behavior that you know sometimes if you're at sort of the core density of     
24:42     
the population that can have one set of effects sometimes if you're on the periphery of the population that can     
24:49     
have another set of effects and of course you can implement things like     
24:55     
steering and other types of responses from the collective from from the flock     
25:01     
so you can see in these flocks that you have you know they're kind of some of them are recombining some of them are     
25:09     
avoiding obstacles they're kind of floating through space here the space     
25:16     
and they're so some of them are colliding some of them are joining each other     
25:22     
um notice that you know they're forming all sorts of interesting looking shapes and patterns and that's actually one of     
25:30     
the things that really sparked people's interest in voids was that they you know not only     
25:36     
can exhibit this collective behavior but that the collectives themselves have     
25:41     
these interesting uh kind of forms and shapes that they take on so like you can     
25:47     
see that there there's merging behavior steering kind of a steering behavior     
25:53     
um and there's collision but the collisions of course     
25:59     
um you know aren't immediate you can steer away from each other so it's     
26:04     
really interesting and you know this is something we played around with a little     
26:10     
bit in terms of uh developmental brain vehicles several years ago um but it     
26:17     
there's a lot of I think really interesting research questions having to do with these kinds of flocks voids and     
26:24     
the shape of the flocks and the shape of the collective behavior and you know what's driving     
26:31     
that underneath is it something that's purely an epipenomena is it purely     
26:36     
um emergent behavior or is there something in sort of the local control     
26:42     
that's mapping the global control that's controlling these shapes in other words     
26:49     
uh in in a lot of the collective behavior research in birds they find that birds can kind of maintain flock     
26:56     
shape and you know they do this through not just having simple rules but they     
27:01     
have sensory systems that are you know a little bit more sophisticated than     
27:07     
um you know force feedback or some sort of you know s single uh     
27:14     
signal and so you can get this these sorts of behaviors in flocks and so can     
27:20     
you replicate this in voids and and what's the significance of it and what can we say about     
27:26     
um collective behavior in that way so with voids I just wanted to point     
27:32     
out that we kind of maybe suffer from the same problem as we do with brain     
27:38     
simulation as mentioned in the last article and that is voids model bird     
27:45     
flocks mainly i mean they model all sorts of collective behavior like fish schools and insect swarms but they     
27:53     
mainly model bird flocks or that's what they're supposed to be modeling and you know you can match up     
27:59     
voids and bird flocks and observe their behavior and they look very similar     
28:04     
right i mean they look like bird flocks but they're not really bird flocks     
28:10     
so the question is are we really simulating the collective behavior or something     
28:16     
similar well in this simulation we have a number of parameters here we can play with so we have a population that we can     
28:24     
set so we can start minimally we can have a small     
28:29     
population we have a median population a standard population of a     
28:34     
thousand and so as we increase the number of voids in the simulation denser everything is the more     
28:43     
flocks and interchanging flocks we observe we also have these movement     
28:48     
parameters so the each void is moving at sort of a certain speed with a certain     
28:55     
force and an initial speed range you have this flocking behavior parameter so     
29:01     
you have alignment separation and cohesion that's sort of managing the flock behavior um I don't know how these     
29:09     
map to individual voids maybe it just maps to the whole flock or the whole flock of voids     
29:17     
which you know is a an artifact of the simulation that's not necessarily     
29:22     
mapping to like a a real bird flock um then you have perception ranges     
29:29     
alignment range separation range and cohesion range again ways you can     
29:34     
control the flock but is this something that we observe in real bird flocks is     
29:40     
the question you have aging which means you know these uh birds will or these voids     
29:47     
will have a certain lifespan they die off at a certain point where they're     
29:52     
born and ostensively you know they have some memory what they're doing that's an     
29:58     
interesting question you could have like a developmental blades where you have like young birds and older birds that     
30:05     
acquire things throughout their life and then if they die off you get younger birds and they don't have the skills     
30:11     
that older voids have i keep interchanging voids and birds but you     
30:16     
get my point it would be interesting to see uh but this doesn't really offer that it just     
30:22     
offers a lifespan here and then genetic signaling so this is where you have uh I guess they     
30:29     
interchange like a genetic algorithm something with uh sensory uh     
30:35     
signaling which is interesting um then you have visual     
30:42     
performance i don't think there's a paper attached to this this is just kind of a     
30:47     
simulation and it actually shows like you can have different presets so you     
30:53     
can have different parameter values for these different like you have calm     
30:58     
chaotic swarm signal heavy     
31:03     
minimal set it here so chaotic instead of swarm and it gives     
31:09     
me a different set of parameter values well any case is that's from at     
31:15     
attention mech and that is on GitHub uh under genetic     
31:22     
voids so check that out if you're     
31:30     
interested and then finally I wanted to draw your attention to something that I've been doing last week or so maybe     
31:36     
two weeks is that I've been um getting into notebook LM which is a Uh it's a     
31:45     
platform from Google you you can use to build customized large language     
31:51     
models or train language models with uh input data and then     
31:57     
produce not just a text summary but you can also produce     
32:04     
um these sort of uh summ it's like a     
32:09     
summary where they simulate two people talking in like a podcast form and they kind of     
32:16     
take it takes the input data and it produces this uh     
32:22     
conversation so this is uh something I did for our meeting     
32:27     
archives but also I did it for so I did it for the uh Saturday morning neurosin     
32:32     
meetings i did this for the cybernetics meetings then I did this for the papers     
32:39     
that we published from 2020 to 2024 so you know this has gotten a a     
32:46     
good number of views already i mean good number for like what it is and you know     
32:51     
this this is so this is uh the netbook LM which is Google and they use Gemini     
32:58     
so this uses Gemini to digest like PDFs or YouTube links and it produces this     
33:06     
output so it's it's uh for the like uh meeting recaps I gave it six months of     
33:12     
YouTube data so you six months of meetings from YouTube it just kind of     
33:17     
went through that and it produces about 20 minutes or 25 minutes of commentary     
33:24     
uh for the cybernetics meetings which are like over two years but fewer meetings I think overall they produced     
33:32     
about 18 minutes of summary and uh you know the papers actually produce 22     
33:39     
minutes of summary so it's really interesting because it sorts things out in a way that's uh you wouldn't     
33:46     
necessarily think of um on your own but it also kind of puts it in a     
33:52     
conversational framework and so you can get this sort of uh you know and     
33:58     
sometimes it's not correct or it's it's kind of near correct but it's not really     
34:03     
correct but I think it's an interesting exercise yeah so Jesse says "Uh I saw     
34:11     
the cybernetics one listened a bit it's interesting what the large language models actually pick up     
34:17     
or yeah it is interesting that they'll like I guess pick up on a theme and run     
34:24     
with it." So I didn't actually go through the whole cybernetics one     
34:29     
um the meeting ones are interesting because it kind of hits you know the different kind of     
34:36     
emphases that we're putting on different things over six month periods so like you know in one six-month period we     
34:42     
might focus on like you know we've been focusing I think in this for the last     
34:48     
six months of 2025 we've been focusing on you know     
34:53     
large language models and reasoning and things like that i think in     
34:59     
2024 we had more of an emphasis on well we've always had this sort of     
35:04     
neuro imaging undercurrent but we talked about all sorts of uh different things     
35:09     
we talked more about like AI ethics and uh embodiment I mean     
35:15     
we talked about embodiment in the first half of 2025 but it's interesting um     
35:23     
kind of those shifts in in topics but also yeah what the large language model can pick up so it might pick up on a     
35:31     
relatively obscure concept or it might pick up on the main concepts over all of that     
35:40     
content so it also produces mind maps which I didn't put out I didn't put out i don't have them open but the mind maps     
35:48     
are just simply like kind of a classification of everything so it'll have these subheadings and then sub     
35:55     
subheadings and so forth which actually is really good for organizing content     
36:00     
over like a certain period of time and that's one of the things we've really struggled with in in the group is like     
36:08     
you know we have these meetings and we talk about things all the time and it's just kind of like things get buried and     
36:15     
we forget about things and you know it'd be nice to have a way to know what we're     
36:20     
doing over a certain time interval and pull those things out so we do have that     
36:26     
so we have a number of tools um at our disposal here uh I've been trying to     
36:32     
work on this because I noticed of course exactly that that we have this lack of     
36:39     
synthesis yeah the mind map feature um so we have this lack of synthesis and     
36:45     
it's like what I want to do is I want to make sure that we can go over sort of a larger time interval and pull out some     
36:52     
of the themes that we talk about and do things like that so you know we have     
36:57     
these AI summaries i'm going to be continuing to kind of go through our     
37:02     
archives posting things the summaries on YouTube um and you know those will be     
37:08     
good you can just listen to those um they're they're just audio files but I've turned them into videos um then we     
37:16     
also have I usually create a transcript of each meeting     
37:22     
uh using a larger language model a different large language model and those are like text summaries of the meeting     
37:28     
so like it has timestamps and then it says you know kind of what what's been     
37:33     
said so we have like the meeting level granularity we have the the large kind     
37:39     
of overview the sixmonth overview granularity uh and then you know so I I     
37:46     
hope with these kind of ways that we've we're applying large language laws that we can get something out of this uh so     
37:52     
we'll we'll come back to this no I'm actually really interested in that for a number of reasons one it's sort of like     
37:59     
adjacent to Frontier Map yeah uh in in in frontier map it's much more     
38:07     
trajectory oriented but for people like it's and it's also not really about kind     
38:12     
of like documentation but I've been thinking about this too and I'm in like between     
38:18     
being here and also being in excuse me being in Echolapto recently and some other     
38:26     
groups that are doing I think I think there's a tool to be made here or at least a procedure like a recommended     
38:33     
pattern uh for people doing like especially for     
38:38     
interdisiplinary work synthetic work um meta and there's like real ties to     
38:44     
meta science like like what what are I don't even know what related tools exist     
38:51     
in meta science but are you ever interested in basically making one or or trying to to to do such a thing like     
38:58     
do well again I don't know if it an app or an AI or whatever or at least a     
39:04     
procedure like like a methodology to approach to doing things because I think     
39:10     
what you pointed out were like extremely important and relevant to this lab but     
39:15     
also um people in the meta science community     
39:20     
people in the progress like I'm doing some I've been looking at like the progress study stuff and and uh roots of     
39:27     
progress institute cosmos institute which is like philosophy stuff i've been I've     
39:32     
been all those things I was busy with in this week but at the level and I like     
39:39     
this is the thing like I'm particularly interested in and I'm leaning heavily     
39:44     
into the space of speaking consulting doing things in and around building this stuff so I'm very     
39:52     
interest like what it's it's I find her to be such an interesting     
39:57     
um lens to to to     
40:08     
um to juxtapose the theoretical spaces that     
40:13     
are being explored sort of I don't want to say de facto but like     
40:18     
in and of themselves the spaces and then there's the trajectory element kind of the frontier mappy stuff and there's     
40:25     
like the the individual map like the individuals of the team that you're on     
40:30     
that's building or exploring the stuff it could be journal club can be this lab can be a working group it can be your     
40:36     
team that is trying to educate itself as it's learning the the technologies the     
40:42     
products you're trying to make whatever it is like what what is happening in that space is they're all different     
40:49     
formats of like map versus territory type problems they're all different formats of trying to document them and     
40:56     
so I'm I'm I am glad to see you experimenting with this and the tools that are     
41:02     
available but also I feel like there is a there's an interesting and unique set     
41:09     
of challenges that sparked my interest for the people you know French map is     
41:16     
basically existing historical contexts and potential future     
41:24     
trajectories at kind of macro levels like like you wouldn't friendship map     
41:29     
can inform what a team would be doing to explore our space but to explore the space and keep     
41:36     
track of like all the things we just mentioned from the different groups and and the themes and he had the in intra     
41:42     
meeting and then inter meeting across the meetings like transmeming the spans     
41:47     
and and the tendencies and like oh you know here's the path that we we didn't go down i think that would be     
41:53     
fascinating to and I think we can do that now like I think that is literally that's the best part of this you know as     
41:59     
a side side comment I was once again exposed to the debate of LLM are or are not the future to AGI but what what I do     
42:07     
think LLMs are great for is what we're talking about like these big time language processing models     
42:14     
um that can offer context and then the little things that nice little add-ons like the the the maps or the you know     
42:21     
giving giving kind of sequences of you know almost like     
42:28     
um the the not biblometrics maybe but but but like how like the Google when     
42:33     
you search how the usage of the term you know across time is is it more or less used or you're more or less talking     
42:38     
about you know Mat like the cybernetics video says I think it says very     
42:44     
awkwardly the name Matana he called him like Mc Martin     
42:50     
like who so I think he was I think he was explicitly referencing Matana in the first few minutes and and his take on     
42:57     
you know an observer or or an actor or whatever um but you know we don't we     
43:04     
haven't talked about we haven't said the word machana in in the meetings I've been in for several months maybe close     
43:09     
to a year at this point you know so it's interesting to kind of see who and what     
43:14     
and where uh things go uh so yeah I'm I'm really I'm super interested in     
43:22     
um making something there and and I don't maybe we can talk about that more     
43:27     
later at some point or something but uh I think it's a good a good thing to be     
43:33     
to be doing yeah yeah thanks for the feedback so this is a playlist um it's     
43:41     
called AI summaries if you go to the YouTube channel and you go to the AI     
43:46     
summaries playlist they'll be this will be getting populated over time so I've     
43:52     
just started with like five of them yeah I think we'll try to you know     
44:00     
maybe try to evaluate it and see what the meta themes are there's something     
44:05     
that's interesting i know with like the cybernetics meetings you know it's been     
44:10     
like this exercise in what do we want to do with it we we kind of reviewed a book     
44:16     
and then we went through some papers and then you know it's like we we kind of     
44:21     
have done a number of a variety of things in those meetings and you know they're all kind of focused around     
44:27     
different topics and cyberics but what is it that we're doing with those meetings like we're just like uh     
44:35     
shooting with a reason and forgetting about it and you know there's there's there are themes in there that you know     
44:42     
are we can go and directly address them and say oh yeah we should talk more about that or maybe that's a paper or     
44:50     
something like that yeah and and I know we kind of dubbed up     
44:57     
into sort of the physical memory space which is a very interesting space to be in and we keep keeps coming up even     
45:03     
other circles um and I know I've seen Amanda around i don't know if she's     
45:09     
going to want to start that back up again or not um but it is it is     
45:14     
certainly good to I don't want to say document but some kind     
45:20     
of make make some make make something of it in a non-combative way it's good to     
45:26     
make something of it and and make some even if it's just a general article     
45:32     
reference point that's that's a little bit more accessible that's as as kind of a disclosure for those who who aren't     
45:39     
um um savvy to the past here i I spent     
45:45     
previously a lot of time documenting things in like notion and and we we've     
45:50     
done various things of notion or like I know I think Bradley still maintains GitHub and all these other things and     
45:57     
it's good to do but um having things that are I think I     
46:03     
think we're in an era where the magic of what we can do right     
46:09     
now is sort of the I call it almost like the     
46:15     
the making everything have much a much easier user interface isn't to be a guey     
46:20     
but everything the point the like at you know it's not like what Bradley is doing     
46:27     
with the cybernetics meeting isn't isn't a user interface per se but it's taking this stuff that's kind of abstracted out     
46:33     
or or non interfaceable and making it     
46:39     
more you're putting you're putting something to it that you And you know     
46:44     
now you can you can scroll on the timeline of a YouTube video to hear     
46:52     
different parts of a discussion that have taken place over months and that that's the accuracy     
46:58     
of it is what it is but the the sort of     
47:04     
rough you know     
47:09     
uh relation of the map to to the the interface is much more     
47:18     
accessible and I think that's that's what we're doing in many fronts right now and I think it's really appealing and fun but also like     
47:25     
we're we're learning how to both do that and to process it individually and I     
47:30     
think there's a lot like I I wish I wish I had a little better connection to some people in the     
47:37     
meta science tools space right now because I really am curious what what they're dealing with in terms of these     
47:44     
language models and the tools and the ease of creating certain interfaces right now to to do to bring to light a     
47:52     
little bit of clarity around the path that has been traversed because you and you and I know the path but the The act     
48:00     
of communicating what that has been to other people and making it something they can interface with     
48:07     
is is new and exciting and challenging but also really good if it can happen in     
48:13     
a decent form uh so that's uh I don't know Jesse if     
48:20     
you had I know you said yesterday at the open source meeting that you had     
48:25     
something talk about at this meeting kind of saving up some of the more sort     
48:31     
of uh the meteor stuff for this meeting um but I wanted to first ask maybe VT or     
48:38     
Morgan if they had any other thoughts about Yeah the stuff that I presented     
48:44     
well I'd love to say more about the u about     
48:51     
Cigan's simulations um but I'm still waiting to get more more     
48:58     
in anyway I I was just going to bring up the um the large language model     
49:04     
diplomacy match if you're gonna if you're going to be talking about LLMs um did you see     
49:12     
that uh which one was that the th this is where they had you know kind of the     
49:20     
four big models uh all play diplomacy against each other oh yeah I did see     
49:26     
that yeah okay i mean not not a fully serious thing but I just thought that     
49:32     
was hysterical yeah I think that was uh in the I think     
49:39     
you put that in the slack it's like where I guess became a tyrant and like     
49:45     
different models took on different personalities or something yeah well we we we we gave them we gave them     
49:52     
personality but it is like expressing that     
49:59     
um I'm on the bus right now so Okay I'll be able to say more in just a bit all     
50:04     
right yeah yeah that that's it we talked about a paper like similar to that     
50:11     
um probably last year i don't know it was like where uh definitely it's     
50:16     
they're not the first to do diplomacy yeah yeah it just it got at the the     
50:23     
whole you know because diplomacy seemed like such     
50:28     
a human game in terms of you know the the alliance formations and things like     
50:34     
that um how Yeah so in the in the the     
50:39     
original one they played with humans if you Yeah     
50:48     
okay yeah and then Vi uh said "Uh not really     
50:53     
any thoughts of listening but I really like the new playlist and want to see more." Okay     
50:59     
yeah coming soon I guess um so yeah Jesse why don't you uh     
51:07     
discuss talk about some of the good things you've been doing     
51:14     
oh [Music] um I think I think the easiest and     
51:23     
most there's there's just been so much this week and that's that's that's I     
51:29     
guess a good a good thing um but it's just I I realized I think my I think     
51:35     
last night I realiz like my voice is just tired from talking sers this week like my throat was like I thought I     
51:42     
don't know if I was sick but I was like oh I need I need to rest my voice so I will it's good     
51:49     
news for everybody here i I'll probably be somewhat restrained in my my speaking today but     
51:55     
um I'll share I'm going to take the easy route and just share I'm just going to     
52:02     
share some things on um that I posted on LinkedIn because     
52:08     
that's the easiest way to do it my main is going to be talking about the the     
52:16     
um Oh yeah I'll mention plot threshers too but yeah we had a for a really brief     
52:24     
thing that was a busy day at Echolato um that was     
52:30     
that yesterday no that was Thursday and there was a session with Peter Voss     
52:37     
and William Edward Han on principles of AGI the second one was with Paul Han     
52:44     
we're going to talk about that one if Morgan wants to say things later though and it's also fun because Paul is     
52:50     
literally a builder and thing and there's a lot of really cool stuff happening in in in this space     
52:57     
here um Peter Boss uh and and William Edward Han I don't     
53:06     
he's I don't see any great links for but machine perception cognitive robotics so     
53:13     
um cool stuff and a pair of us interested in human     
53:18     
level or sorry cognitive AI and I don't know if there's a good     
53:25     
image here that I can show but basically cognitive AI and he's he's of the     
53:30     
opinion with John Mun that LM are a dead end for AGI type stuff he has a very     
53:37     
positive view on AGI in the sense of you know     
53:44     
um it will improve improve the world and and things like that looking for     
53:50     
engineers well five months ago maybe not but uh Peter Boss is a very interesting guy he's got a lot of opinions very     
53:56     
interesting take one of his interesting takes is basically um um I I documented some some things     
54:05     
there Yeah so this there's an interesting discussion here which I'll really I really quickly go through this     
54:12     
but there's just some notes from the talk with with Han and and others     
54:18     
um but basically there was an interesting side     
54:25     
I wish we talked a little bit more about it but there's an interesting sidebar about Dev AI and developmental AI so of     
54:30     
course I plugged us and I plugged um Josh Josh who like does a lot in the     
54:37     
computational cognitive side of developmental space and others at MIT um     
54:43     
but but I it would have been funded to summon both sort of our talks there and     
54:48     
sort of the the Josh Tenbomb agent uh to the conversation     
54:55     
um boss has an interesting differentiation between consciousness and     
55:00     
self-awareness and I think it was quite interesting because it is it is the case that     
55:07     
there's a lot of consciousness is sort of very murky philosophical thing a bit     
55:14     
like defining intelligence you know you can kind of get in the space of definitions and and whatever     
55:19     
self-awareness is is is I think he's I think he's     
55:25     
demarcated it relative to the general consciousness thing so like instantly self-aware or not um and and so on let's     
55:33     
see uh so we boss made a very there was a     
55:39     
lot of interesting talk about you know can a model be updated in real time     
55:46     
and if not it's it's an inherent limitation if it cannot be like let's say biological intelligence or or things     
55:53     
that we have to you know deal with whereas like you know he was saying like oh cognitive AI what he's calling that     
56:00     
you know would be more adaptable and flexible that way Um and I don't I'm     
56:05     
trying to see if there's anything down here that says what cognitive AI is to him maybe you know Bradley can say it     
56:10     
very well um I I know what it is but it's not coming to my mind clearly right     
56:18     
now one of the other interesting points was also if there's no common data representation and they have     
56:23     
disadvantage of both systems um and I I wish I wrote down which systems that was     
56:29     
in reference to i think it was it might have actually been a reference to the Daniel Conaman system one system two as     
56:35     
opposed to just LMS or hybrid things in general     
56:40     
um the leon stuff there was an interesting also discussion point that     
56:46     
we've talked about here many times um and I think they even wrote this in our slack but basically saying     
56:52     
um I remember being at an event four or five years ago and having the same     
56:57     
conversation about how you know funding and deep learning and the economic incentive to be deep learning oriented     
57:04     
just tilt so much emphasis around it so even with people like Yan Mun saying you     
57:11     
know when you do some different things XYZ um there's there's there's you know the     
57:17     
markets and and the push and the data and people that have the data there's a lot of reasons for     
57:24     
why deep learning is what it is as a reminder for later     
57:30     
um if I if I can remember this or someone can remind me there's a there was a post by the head of like model and     
57:37     
behavior policy at OpenAI that I saw earlier and     
57:44     
maybe will be good to touch upon too but um other other topics intelligence     
57:50     
versus spar transfer analysis and extraction I I I tagged Yan Dr johan     
57:59     
John who I kind of wish was in in that conversation um because that's his he's put a lot     
58:05     
done so much good writing and discussion in that space cognitive lyones from Levan fast slow meta brains from from us     
58:16     
uh generalizations versus instances that bring about the generalization these are     
58:21     
all kind of things as discussing like components of AGI I guess     
58:31     
Um I I whenever I mentioned Daniel Fella I     
58:37     
feel like um I feel like I I you know I'm sure I'm sure Daniel would disagree     
58:43     
strongly with Peter Boss's views in the future and what I like about Dan is that Dan um is doing a very very very good     
58:51     
job of demarcating a specific trajectory and     
58:57     
whether or not I agree with all all aspects of what he's saying um is what     
59:03     
it is but much more I think people I think it's so important and I I wrote     
59:09     
this I wrote this somewhere but um it's so important at     
59:15     
this time or where the future is so uncertain is to find people that are regardless of whether or not you agree     
59:21     
with them but like find people that are delineating if things do go in this direction here's where where it can go     
59:28     
and what does that look like and how do we navigate relative to that because I find that to be there's so much sort of weird     
59:36     
bickering about what to do and and and the the the squabbbling part of it like     
59:44     
that's nice but like we really need to steal man the the roots that are going     
59:49     
to go there and make them as clear as possible so if we don't if we are traveling down that road like what like     
59:55     
let's know what the on-ramp and the on-ramps and all these other things are going on going to be that's my take on it anyway but     
1:00:02     
um uh yeah the diamond age you know all these all these all these     
1:00:10     
great interesting it was interesting slightly future discussion a lot of illusions to it um and     
1:00:17     
[Music] then yeah excuse     
1:00:22     
me um oh this was too a lot this is kind of     
1:00:28     
this seems to be out of order some but whatever the systems one systems two stuff was there there was a really fun     
1:00:34     
session which I wish I wish we spent a little more time on the ready at hand transparency stuff i mentioned that I I     
1:00:40     
I was I eventually got to calling it to Haidiger's stuff um the     
1:00:47     
the boss is very interested in this Helen Keller Helen Hawin theory of AGI     
1:00:53     
which he talks about here and I'm not going to get into it right now but um     
1:00:59     
it's the he has his own particular view of of you know what it's going to be and     
1:01:05     
and um this is a nice post for it just just to show it here i thought there was another image that would explain some     
1:01:12     
things but um yeah and yeah so that that's pretty much it     
1:01:19     
was a very wide ranging conversation it was very fun um and it was sort of interesting to have this juxaposed     
1:01:25     
directly to uh to this one because you had like big theoretical macro and then     
1:01:32     
how do we build skin and human like uh a     
1:01:37     
couple hours apart so that was fun uh that was Thursday um there's a few I'll     
1:01:42     
talk a little more about the Cosmos um event also sort of the main event too but before that any questions or     
1:01:49     
comments on on this stuff so I get that ready uh no but I'm glad you had like a     
1:01:58     
good like summarize that yeah it's always good to see like how people are     
1:02:03     
thinking about theory versus putting things into practice and then how you     
1:02:09     
you mentioned at the open source meeting yesterday about like or we had this     
1:02:14     
discussion about like how there are these debates or how we have like these     
1:02:22     
kind of discussions in the literature like you know we talk about the AI     
1:02:27     
literature as an example uh where people will frame things as debates or they'll     
1:02:33     
frame things as sort of like their pet theory or they'll frame things as something that's maybe not so     
1:02:39     
controversial as being this great controversy and then like that's how like the the conversation proceeds so     
1:02:47     
the priorities are based on those kind of uh debates or those you know those kind     
1:02:54     
of frameworks whether they're warranted or not so it's you know like we could     
1:02:59     
take like the AI debates that um uh you know we had what's his name     
1:03:05     
had Gary Marcus and like it was like okay well these are debates about you     
1:03:11     
know some of these distinctions of course are maybe semi-technical so it's     
1:03:16     
like you have um you know neuros symbolic systems versus neurosystems     
1:03:24     
versus symbolic systems and you know like how do we think about it and of     
1:03:29     
course you know maybe the the correct answer is of course neurosymbolic systems are superior but we'll frame     
1:03:37     
this as like a debate so that we can say well this thing versus that thing and right kind of facilitate     
1:03:44     
uh different different uh argu arguments and things like that but at the end of the day there there's no real     
1:03:50     
controversy it's just kind of like you know we're we kind of know the answer     
1:03:55     
maybe or maybe we kind of assume the answer maybe it's not the right answer but um you know and that's kind of why     
1:04:04     
people do this in the first place but I think a lot of times we use these things as mechanisms for like kind of getting     
1:04:10     
at um you know or or sometimes we use these mechanisms in a way that sort of assumes     
1:04:17     
that we're going to get something out of them     
1:04:23     
yes i mean like I guess what I'm getting at here is that you know we we talked about that     
1:04:29     
yesterday and then I think there's this really interesting kind of followup to be had about     
1:04:36     
like you know how do we think about the way in which we discuss these things how     
1:04:41     
do we put this together as like you know a set of debates or like you know what     
1:04:49     
is what you know what what's the priority in a certain     
1:04:54     
Yeah and and what's what's what's act and I think this is something that this is why I keep mentioning some of the     
1:05:00     
meta science stuff like there was there's certain things from I was at part of the uh meta-cience conference or     
1:05:07     
I I wasn't there I listened to to one of the recent conference um I don't know discussions from it was     
1:05:14     
on somewhere online and I was listening to that a while ago but both meta science and and progress studies and and     
1:05:24     
these is I I I think there is a lot there and I think that's like     
1:05:30     
an a lot there in terms of how do we actually have     
1:05:35     
functional discussion that     
1:05:42     
evaluates pathways i I think I think that's really what it is is I I as a as     
1:05:48     
a as a as a side well I mean     
1:05:54     
I guess this also happened this weekend i haven't I haven't really um uh I     
1:06:01     
haven't really um talked about it and it's still in     
1:06:07     
development and I have to incorporate some of the edits that that you that you've helped me with but I don't know     
1:06:13     
if this is where you're going with things or not but I'm I'm particularly interested in I I kind of want to make     
1:06:21     
something that that I'm going to call almost like destination based research is my working title and I I have to make     
1:06:27     
a a like an OSF page around the project and I'm I'm about to do it so it's like     
1:06:34     
a soft a soft a soft tease here but in in this essay which which I did for     
1:06:43     
um it basically was adjacent to the roots of progress blog fellowship thing     
1:06:48     
i I decided to basically take this concept of of longevity and say "Hey we need to do more than just     
1:06:54     
[Music] um biotech basically or at least     
1:07:00     
thinking of the level of of of biotechnology is what it is." And I'm not going to go through this whole essay     
1:07:05     
right now i don't I don't I don't have the the stamina for that today but what     
1:07:11     
I will mention is sort of I use this term destination discernment um and I     
1:07:18     
use I haven't spell it correctly in too um but basically the ability to chart     
1:07:25     
meaningful trajectories through complexity and in this case the development care and innovation through social institutional technological     
1:07:32     
complexity but side of what matters okay that's that's that's pretty     
1:07:38     
uh that sounds pretty handwaving to just dive into that that definition but where I'm going with this is     
1:07:45     
like I I'm I'm trying to take the longevity debate the longevity arena and     
1:07:51     
turn its focus a little bit onto these essentially what we talked about here um like I talked about mentorship and the     
1:07:57     
ver like the infrastructure of making these these these these changes and the mechanism specifics about reading     
1:08:03     
without burning out cognitive longevity all this stuff how do we have more functional interactions     
1:08:09     
um on on these kind of things so um I'll leave it at that you can read it there     
1:08:15     
if you want to and and I'll I'm going to be discussing this more later but well for destination discernment as a as a     
1:08:24     
thing um and and generally getting at these like kind of what I was saying     
1:08:30     
before about the the recapping the the meetings like how do we demarcate this     
1:08:36     
stuff and then specifically how do we actually have really good discussions that describe where things are going and     
1:08:42     
I think I think I do give I do give credit to Dan Fella for inspiring that     
1:08:50     
that view some uh because he's uh     
1:08:56     
he did a really nice presentation that I was able to attend I think last year     
1:09:02     
also Dan Elton was there so shout out to Dan Elton um I miss him i think he's     
1:09:07     
gonna come back to Boston so hopefully be back here in Boston with us soon um     
1:09:13     
but anyway it like how do we actually have more functional discussions and yes     
1:09:18     
also the synthetic stuff we've talked about we've had this sort of recurring theme here about     
1:09:24     
um you know um not just having discussions but     
1:09:30     
putting some time in the synthetic part of it so yeah um to any I'm going to     
1:09:35     
make two quick shout outs and then I'm going to say the Cosmos stuff and then I'll I'll move on say anything before I     
1:09:42     
do that no okay shout out for plot twisters because the plot twisters crew     
1:09:51     
um got got this they folks that have done the fellowship jenny is sort of     
1:09:57     
fearless leader and then Amanda is a longtime person and Joanna are all to this and and they've applied to this uh     
1:10:04     
particular fellowship and uh they got it so we'll be working on     
1:10:10     
um this small hassles court it's sort of a miniame in this this thing and it's     
1:10:17     
you can read the article and get into it but it's it's sort of building out more more of the actual land and sort of the     
1:10:23     
the functioning and the ways of of things that are going to happen in the Twister Land game itself so um check out     
1:10:30     
this uh post for more uh but congratulations to to them and and     
1:10:36     
looking forward to hopefully furthering that this summer um and then really quickly before I     
1:10:43     
forget [Music] um this post I'm not even going to talk about it i'm just going to mention it     
1:10:48     
maybe if we have time later I'll come back to it but this post about um you know Sam Alton was like yeah this     
1:10:56     
is an important post joanne is the person running the the the     
1:11:03     
uh I don't know model and behavior yeah lightly model behavior at OpenAI and we     
1:11:09     
we they're what they're saying is we build model surface first increasingly the eye we're priing research on how it     
1:11:16     
this impacts your emotional well-being so all the mental health uh computer     
1:11:21     
interfacing folks out there maybe you're getting a little shy and more opportunities here obviously important     
1:11:27     
in general but yes and then I pull these other quotes out saying this you know     
1:11:32     
three ways they're they're three questions they're they're looking at why people might attach emotionally how we     
1:11:38     
approach this question of AI consciousness which is again that particular interesting     
1:11:45     
Cword and and how that informs that try to shape model behavior in the coming months we'll expand targeted evaluation     
1:11:52     
of all behavior that we contribute to emotional impact social research and and hear directly from all this stuff and     
1:11:59     
I'm just really curious both what they're going to do and like I don't know it's kind of funny     
1:12:06     
because [Music] um there's there's so much inertia     
1:12:15     
about like I mean I just say just just the word Cambridge Analytica all right     
1:12:21     
that that that's something that we know is is is a major actual factor in     
1:12:26     
presidential elections that's that's sort of somewhat uncontroversial to say     
1:12:32     
and there's even more more stuff there at the level of you know stirring the pot emotion or     
1:12:39     
uh social emotionally politically and then you know it's sort of it's curious     
1:12:47     
to see what OpenAI's public facing version of this is going to be versus what what they do and what they you know     
1:12:53     
subcontract out to to others and in terms of their their you know are they going to     
1:13:01     
try to basically become the um the Facebook meta of     
1:13:09     
um you know Facebook has all those personal data on interactions but not interactions with necessarily an     
1:13:15     
agent uh or or an agentic AI LM chat GPT like interaction so we'll see um but as     
1:13:26     
the saying goes I told you that story to tell you this one and so the actual main     
1:13:31     
point of what I wanted to get to was this this is this is a really really really fun event i was lucky to get into     
1:13:37     
it um for super quick background I think I put the thing here i just did something     
1:13:46     
weird uh sorry for a quick background I'm not     
1:13:53     
going to go to this article but there's a big Oxford seminar     
1:13:58     
um uh AI philosophy um McCord's sort of the leader of the     
1:14:05     
Cosmos Institute and and they've had a whole you know different different different things for each week um I     
1:14:14     
happen to be able to attend this one virtually i wanted to do all of them uh but there was just there just so many     
1:14:19     
people so many popular things going on um but I'm actually kind of I'm actually pretty glad I got into this for a few     
1:14:26     
reasons which I'll say later unbeknownst to me I would find out later this week that that Platish has got a similar     
1:14:34     
governance type thing going on too so it may help with that what they're doing     
1:14:39     
and the fellowship is sort of tied to this too but basically uh the habis machine is sort of this um     
1:14:49     
uh is this going to be a good link for it are there any pictures here     
1:14:56     
uh it it's sort of a way of generating some     
1:15:02     
uh useful consensus i'll read this uh     
1:15:07     
however this can be a challenging when discussing the present very difficult opinions tesla and co- uh investigate     
1:15:15     
whether artificial intelligence that's what AI stands for could help groups reach a consensus     
1:15:22     
during democratic debates the authors trained a large language model called paper machine to serve as an AI mediator     
1:15:28     
that helped small UK groups find common ground while discussing divisive political issues such as Brexit and so     
1:15:35     
on compared with human mediators AI produced more palatable statements that     
1:15:41     
generated wide agreement and left groups less divided the AI statements were more     
1:15:47     
clear logical and reformative without a alienating minority perspectives the     
1:15:53     
work carries policy implications for AF attempts used to unify GP divided groups     
1:15:59     
and sure um it was interesting to compare this to and this is based off     
1:16:06     
neighbor's theory communicative action and you know philosophy behind it is is there um I'll come back to sort of the     
1:16:15     
meat of that in in a second perhaps but it's very interesting to compare this to     
1:16:20     
to this which is um I I attended this in May and this     
1:16:29     
this is sort of an MIT variant of a similar project in it they actually I     
1:16:34     
just you couldn't go I won't go this whole year but they basically have these different modules that do different     
1:16:39     
things like socratic dialogue basically crowd dynamic deliberation and and the different these     
1:16:46     
different um you know um I think this is a decent     
1:16:52     
one to show yeah like they they was a totally separate project by the way um     
1:16:59     
they found um But they found     
1:17:05     
um you know more it's sort of it's a     
1:17:10     
depolarization effort what they found in their own in their own work for the Socratic dialogue uh show the face the     
1:17:17     
crowd demonstrates how much we agree with each other um and modeled conversations increase     
1:17:23     
nuance discussion and under and the legitimacy of the     
1:17:29     
platform and I think I think what that means is Is is     
1:17:36     
this discussion itself viable or like you know is it fake news it just bias     
1:17:43     
like it it's saying it it's it's making the discussion itself more legit     
1:17:49     
um and then comment ordering um representation literacy in the     
1:17:56     
process and sense of respect so this was this is a really interesting um comparison and I'm going to do I'm     
1:18:03     
going to do more in the future probably with data and direction honestly because this is a super great topic for them uh     
1:18:09     
which is the newer project I'm doing and also um interns and stuff more about that     
1:18:16     
later but to compare this to what's happening here     
1:18:23     
um you know this this mediator stuff Uh yeah I like I like this summary     
1:18:32     
not just because I wrote it or whatever but it's talking about it's not a decision maker but a mediator and I     
1:18:38     
think that was a very interesting approach to what's going on it's like this this this habus machine talk and     
1:18:45     
even though it was done with much it was done with a model like much older models than are currently state of the art um I     
1:18:52     
forget I think it was it was some awkwardly named one that I can't remember right now um     
1:18:59     
but the the talk and I don't think I say this here um what was really good     
1:19:08     
about Chris Summerfield's talk     
1:19:13     
was he he had a very interesting point that I'll I'll kind of center and then     
1:19:19     
maybe we can talk about it or move on other things because I know I've had the mic for a long time     
1:19:24     
but a lot of this discussion this is mostly just other papers um yeah this is     
1:19:30     
this is this is this is the point about kind of using an older model um and and     
1:19:36     
they're going to update that yeah uh oh I didn't see this     
1:19:49     
before oh that's cool um Oh it was 14 hours ago that's what happened anyway     
1:19:56     
the point the point the point Chris made     
1:20:01     
is sort of one a well one of two points one     
1:20:07     
was differentiating AI and sort of psychology or the personhood of it um     
1:20:16     
which is like very everything's agentic AI right now which has this sort of connotation of almost personhood to it     
1:20:24     
but differentiating the AI and psychology of AI from AI mechanisms or     
1:20:30     
structures that afford or allow things to happen like yes this was an AI     
1:20:40     
um mediator I guess but it was more looking at what can AI do     
1:20:47     
mechanistically in terms of how it's structuring a debate or discussion which kind of ties into a little bit what     
1:20:53     
we're talking about too like not exactly what would a haver must be for you know     
1:20:59     
uh synthesizing orthogonal lab meetings notes whatever But this is how do we use     
1:21:07     
AI to constructively actually to constructively and meaningfully um in a     
1:21:13     
in a in a in a you know legitimacy appre in a legitimacy     
1:21:20     
building way actually have people feel like what they're doing is a meaningful     
1:21:26     
discussion are you building on something and so that was one of the points uh     
1:21:32     
well I guess that's both the points together like both sort of the differentiation from AI as psychology or agential stuff     
1:21:41     
um in in in in a it has to be about how like the mind     
1:21:48     
or artificial mind works to AI as tools and means and infrastructure and     
1:21:54     
mechanisms that facilitate the things that we want uh so I think that was a sort of a very interesting point that he     
1:22:01     
made in the talk it wasn't the central point of his talk most of his talk was basically going through     
1:22:06     
um uh basically this paper and other papers i'm curious if there's any other good diagrams here but     
1:22:14     
um yeah he he he talked at length about the the you know um the data drivenness     
1:22:23     
of of what was going on and how you know AI helped um you know good things happen     
1:22:30     
basically so yeah um there was something else I was going     
1:22:36     
to say but I think that's I'll leave it at that um for any for any questions or comments um because there's a lot of a     
1:22:44     
lot of good things there and I do look forward to basically doing a deeper dive and comparing it to     
1:22:49     
um some of the the Gov Labs work from the size group     
1:22:58     
yeah so um Echalopto seems to be     
1:23:04     
um doing events with with a couple members of our     
1:23:11     
neuroch so Yoyo had one last     
1:23:16     
weekend um and uh Paul Han was     
1:23:23     
the eastkin and um     
1:23:30     
He went through some a bit of a review     
1:23:36     
on you know material properties     
1:23:43     
um manufacturers of     
1:23:49     
um manufacturers of of products that     
1:23:55     
um perhaps used with prosthetics uh things like     
1:24:00     
that and um you know definitely some some um a     
1:24:09     
little and and some some coverage of just the issues that you have     
1:24:15     
with you know bio electronics and in particular um the the issue around     
1:24:24     
meas and how you need to choose uh different     
1:24:30     
material for a successful     
1:24:36     
um MEA device other than you know what we use for kind of traditional um say     
1:24:44     
electrodes certainly non-invasive electrodes because neurons just won't     
1:24:51     
grow on silver as he points out um uh     
1:24:57     
so some some some good stuff there you know um as it relates     
1:25:05     
to more um you know I think one of the things     
1:25:13     
about Ekkin that has people most interested is of course giving people a     
1:25:19     
sense of touch and and in particular you know the sense to touch with     
1:25:26     
the with the sensitivity that you have in your     
1:25:32     
fingertips for instance um would be would be awesome but is is particularly     
1:25:42     
difficult um uh yeah um so just nice to see nice to     
1:25:51     
see people that are working here getting out um I I do you know the     
1:26:01     
echalapto organizer Jess i'm just wondering you know I don't     
1:26:09     
know you mean or what do you mean well just I I I haven't actually talked to     
1:26:15     
Yo-Yo or Paul about like did did he reach out to them or did they     
1:26:22     
reach out you know to did did Yeah just just not sure how     
1:26:28     
they they both ended up in the same week um you know like like I don't think they     
1:26:35     
know you know like I don't think they know each other here um     
1:26:41     
uh Yoyo is a student at um Manurva     
1:26:46     
right and uh Paul like you know Paul     
1:26:51     
still kind of works from from his own     
1:26:57     
space even though he's a member here at the tower um     
1:27:02     
yeah I I don't know how the connection was formed um but I mean I could     
1:27:08     
probably ask Addie about that but there's you know he's is trying to     
1:27:14     
get together a lot of um bringing people especially in sort of the     
1:27:19     
sensing and um new new senses kind of spaces he's he's trying to do stuff     
1:27:26     
there so that's probably how they found each other yeah     
1:27:31     
yeah no it's it's it's cool um it's uh it's also funny to bring up     
1:27:39     
Cambridge Analytica since um I I've now met Alexander     
1:27:46     
Kogan seemed to be a he's not a member here or at least I don't don't think he     
1:27:52     
is yet um but he was a member of the the last uh kind of um co-working space it     
1:28:02     
was yeah that was that was a funny conversation didn't really know what to say to him     
1:28:11     
um but uh we had a you know this     
1:28:18     
isn't totally totally related but just one of the updates I have is     
1:28:23     
uh having some meetings with uh Katarina     
1:28:29     
Voyto um the now postoc at UC Santa Cruz     
1:28:36     
working on organoid culture and hoping to have her come speak     
1:28:43     
u like mid or end of end of July     
1:28:50     
so really excited to learn more about what they are trying to what she's     
1:28:58     
trying to commercialize as well as just um you know she she seems open to     
1:29:04     
helping us in our our nent efforts to get a um dedicated organoid culture     
1:29:11     
facility going here so So that's that's awesome     
1:29:20     
great sounds great uh yeah thank you Jesse for the     
1:29:26     
conversation about this and looks really interesting yeah uh so Morgan did you     
1:29:35     
want to talk about uh did you want to say anything else or do you have more     
1:29:40     
time to um so I mean     
1:29:46     
um this this week is Edge Esmeralda um it's one of these upup     
1:29:54     
villages and just hoping I mean one I'm going     
1:29:59     
because there's a planned neurotch summit um that is run by that's being     
1:30:08     
organized uh by Patrick Mino and um Son     
1:30:15     
Escola so you know a good opportunity to talk     
1:30:21     
with um neuroai people uh there's also going to be some um an     
1:30:31     
opportunity to pitch projects for they're offering uh up to     
1:30:38     
$500,000 to support what we hope is um community lab     
1:30:48     
uh around these kinds of neuroi projects     
1:30:53     
um and yeah so working working with some people including you know     
1:31:01     
um Elliot here at Biopunk and um Sam at     
1:31:07     
Metamorph Labs um to yeah work work on a pitch hopefully for Monday     
1:31:14     
um and that's yeah then then there's um     
1:31:23     
um the neural interface meeting the week after and um and then I'll be up to the     
1:31:30     
Allen Institute for Open Science and Undergraduate Education     
1:31:36     
um kind of an educator's workshop so look looking forward to that     
1:31:41     
that's great yeah okay yeah let's move on to this paper     
1:31:48     
this was something I think bey shared in the slack as well so this is uh from this is from the     
1:31:57     
archive this is a survey on compositional learning with AI models     
1:32:03     
theoretical and experimental practices um the authors are from Michigan State Department of Computer     
1:32:10     
Science uh so this talks about compositional learning and we talked about that in a     
1:32:18     
previous meeting it could have been last week or the week before where we talked about     
1:32:23     
compositional or or what compositional learning or compositionality is both in     
1:32:30     
or I guess in three aspects in linguistics in AI and then in like     
1:32:37     
behavior so you know we had in cognitive science more broadly than     
1:32:43     
linguistics just in linguistics which was actually a pretty technical definition and then of course in AI     
1:32:50     
where you're trying to assemble things you know things like uh you know     
1:32:55     
different parts of a program in a neural network so they're going to talk in this     
1:33:01     
article about compositional learning kind of going over thinking about reasoning in an intelligent agent so     
1:33:09     
they actually um going to talk about this researchers have examined this phenomena from a cognitive linguistic     
1:33:16     
and psychological perspective so they have these references here talk about     
1:33:21     
sort of the diversity of the definition the abstract reads     
1:33:28     
compositional learning mastering the ability to combine basic concepts and     
1:33:33     
construct more intricate intricate ones is crucial for human     
1:33:39     
cognition especially in human language comprehension and visual perception we talked about in     
1:33:45     
linguistics language comprehension and then of course there are these visual     
1:33:50     
primitives that get put together for visual perception and there are other aspects     
1:33:56     
of cognition that involve compositionality as well so you can see where you want to be able to simulate     
1:34:02     
this ability to build upon artificial models this notion is tightly connected     
1:34:09     
to generalization over unobserved situations so the ability to     
1:34:15     
generalize is especially things you haven't seen before is tied to sort of     
1:34:21     
the compositionality so if you can put things together in pieces you can say     
1:34:26     
this thing is only this thing or you can scaffold upon previous things that     
1:34:32     
you've learned you can generalize to things that you've not seen before     
1:34:39     
despite its integral role in intelligence there is a lack of systematic theoretical and experimental     
1:34:44     
research methodologies making it difficult to analyze the compositional learning     
1:34:50     
abilities of computational models so you know this this is something that     
1:34:56     
if you're simulating intelligent system or you have an intelligent agent and you want     
1:35:02     
to figure out how it's learning things compositionally it's hard to really know how to to go back and trace it out and     
1:35:09     
we talked about some of the uh tracing tools that exist for AI models     
1:35:16     
um where you can trace out things in a neural network we talked about that last     
1:35:21     
week so those are just one set of tools possible tools that we might     
1:35:27     
use in this paper we survey the literature on compositional learning and AI models and the connections made to     
1:35:34     
cognitive studies we identify abstract concepts of compositionality and     
1:35:39     
cognitive and linguistic studies and connect these to the computational challenges faced by language and vision     
1:35:47     
models and compositional reasoning we overview the formal     
1:35:52     
definitions tests evaluation benchmarks variety of computational models and     
1:35:59     
theoretical findings we cover modern studies of large language models provide     
1:36:05     
a deeper understanding of the cutting edge compositional capabilities     
1:36:10     
exhibited by state-of-the-art AI models and pinpoint important directions for     
1:36:15     
future research this introduction I just mentioned that you know this is a diverse kind of topic     
1:36:23     
you have many different fields that have kind of approached compositionality in different     
1:36:29     
ways one way that they define compositional learning is uh they say     
1:36:35     
here the compositional learning and reasoning of an intelligent agent first     
1:36:41     
the ability to understand and manipulate complex structures by decomposing them into     
1:36:47     
simpler parts and compos then composing those parts to form new complex concepts     
1:36:55     
with a coherent understanding so the way they're kind of thinking about compositionality here is that you     
1:37:03     
have this complex structure um that you maybe emerges and then the     
1:37:10     
agent can take that complex structure decompose it into simpler parts and then     
1:37:16     
recombine them in different ways and you can actually then get these new emerging     
1:37:22     
features that give you a coherent understanding and so this is something     
1:37:28     
of course again that relates to generalizability in other words if you     
1:37:34     
learn something you can generalize that skill to other areas you can transfer that     
1:37:40     
training to other areas sometimes you've not observed those things but you can actually leverage what you've learned     
1:37:47     
before to to help you in that situation um now they have this formal     
1:37:54     
notion of compositionality down here okay so this is this originated in     
1:38:01     
natural language and semantics research and of course we talked about some of the theories     
1:38:07     
there that elaborate on this concept so their principle of compositionality and     
1:38:13     
this again comes from natural language and semantics research it's defined as the meaning of     
1:38:19     
a whole is a function of the meanings of the parts and of the way they are     
1:38:26     
syntactically combined so this is again very specific to language is that you have parts that     
1:38:35     
they're combined syntactically in certain ways and then those provide meaning     
1:38:42     
so you might have like for example um different word structures or     
1:38:49     
different uh different parts of speech things like     
1:38:55     
that that get put together maybe into a sentence and they're so syntactic means     
1:39:02     
that it's syntax and how those are combined and     
1:39:07     
then this provides the basis for the meaning of a whole so the meaning     
1:39:12     
emerges from the way different things are combined and built     
1:39:18     
up so there are actually this is one way to do this and there are three methods     
1:39:24     
of getting here so you have new meanings new basic parts new constructions     
1:39:31     
so you can have so for example you can learn new words you can learn uh variants of     
1:39:40     
words you can construct those new words into new sentences that you've never seen     
1:39:46     
before and then they can have new meanings both new constructions and old     
1:39:52     
constructions new and old types of sentences maybe you've seen them before maybe you haven't acquire new meanings     
1:40:00     
So you could think about this in terms of memes i talked about that last week with memes where you have you know an     
1:40:08     
image that's like maybe a photograph from some context some famous photo semi     
1:40:15     
famous photograph or some drawing uh maybe a cartoon and then you know     
1:40:22     
it'll have like this meaning original meaning and then you take that and you     
1:40:28     
use it to as a response to something in the world so this thing it doesn't     
1:40:35     
necessarily acquire I mean it does acquire new meanings but the original     
1:40:40     
intent is sort of thrust into these new contexts so the new basic parts of the meme are     
1:40:47     
kind of like you know you maybe get a new image uh maybe it's a the sickos meme     
1:40:54     
where you have this cartoon of this creepy looking guy looking through a pain glass window and     
1:41:00     
saying "Yes yes." You know uh mocking someone's suffer then you might post     
1:41:07     
that into like as a response to someone you dislike getting their comeuppance or you     
1:41:15     
might post it as a way to sort of uh you know express your um sort of some sort     
1:41:23     
of uh ironic detachment or something like that so there are all sorts of new     
1:41:28     
ways you could build memes new basic parts new constructions and new meanings     
1:41:34     
that it'll take on new meanings as you apply it to the     
1:41:39     
world one of the earliest formalizations of compositionality was grown in grammar     
1:41:44     
trees and cognitive science proposed an information processing approach to     
1:41:50     
create a model of the mind so this is this goes back to I guess early     
1:41:56     
cognitive science where you know part of that uh     
1:42:01     
cognitive science hexagon is linguistics and building models of language and then linking that to     
1:42:08     
cognition and you know cognition of course is information processing and the     
1:42:13     
brain or um of the mind and so you're creating this model of the mind where     
1:42:21     
you build this grammar and you say this is how you know the mind processes or the     
1:42:27     
brain processes this cognitive stuff so you know there are all sorts of     
1:42:32     
computational models of cognitive science you have things like grammar trees which grew directly out of     
1:42:38     
linguistics you have connectionist models which kind of grew indirectly out     
1:42:44     
of a lot of the ideas about how the brain worked you     
1:42:49     
have some other cog uh you have cognitive models so these are where you have these boxes and arrows models that     
1:42:56     
show like different cognitive functions that are connected to other cognitive functions or maybe parts of the brain     
1:43:04     
connect to other parts of the brain where you hypothesize about what that part of the brain does and then you put     
1:43:10     
that together into a systems model and so you know you have these     
1:43:16     
different models of the mind that you know the key thing that links all those models together that the brain and the     
1:43:24     
mind is doing information processing that it's doing it kind of like a vonoman computer where it's you know     
1:43:31     
doing these discrete operations it's operating from some code or some     
1:43:37     
instructions and that this is operating a way that we can you know that's a     
1:43:43     
systematic way we can analyze so you know this is really kind     
1:43:50     
of um sort of goes back to the birth of modern cognitive science and it grows out of     
1:43:58     
linguistics and you know linguistic constructs provide good examples and     
1:44:03     
good lessons about what compositionality is and its capacity so compositional     
1:44:09     
understanding of linguistic constructs as multiple aspects so for example a nesting     
1:44:15     
description such as the black tall woman on the left of the car conveys the     
1:44:21     
intersection of multiple adjectives and spatial relations so much like the meme     
1:44:26     
you have like you know each part of the image is a meaning uh there spatial     
1:44:32     
relations you can map that to language in this case we're talking about a sentence so it's a description and you     
1:44:38     
can map that to a visual image and that's you know there's this sort of     
1:44:44     
aspect that involves information processing so the composition is defined     
1:44:51     
as the intersection of multiple concepts however there are cases in which the direct intersection is not applicable     
1:44:58     
and the meaning should be inferred from the concepts in the global context such as recognizing the sentiment of the     
1:45:04     
following sentence the pizza is so good i hate this place and so that's you know     
1:45:10     
obviously If you hit that literally that would be an oxymoron but it's actually     
1:45:15     
that I hate this place is sort of means I don't hate this place i love this     
1:45:22     
place but I'm just kind of not happy about it or something like that so     
1:45:28     
there's a sentiment buried in here that's not obvious say maybe if you don't have the context right if you     
1:45:35     
don't know that you're using hate as like a term that's like um you know I     
1:45:40     
actually love it but I I in spite of myself basically so this this is you know what     
1:45:48     
compositionality is and what it can allow of course this has a language large language models where you can say     
1:45:56     
you know there's a model it's learning this language it's naive to the language uh     
1:46:02     
as a speaker so it has to learn not only the syntax but also the way in which     
1:46:08     
it's constructed and the meaning and so the thing about like humans is that we     
1:46:15     
learn a language as a first language we grow up in this sort of millu of the     
1:46:21     
language so we never really think about having to learn and maybe if we learn a     
1:46:26     
second language or a third language we have to learn the context and you know if you learn more     
1:46:33     
language directly from Dualingo you don't necessarily get that context so when you actually go to a place where     
1:46:39     
they speak that language it's a little confusing because you don't know the context that native speakers     
1:46:46     
have and so it's it's it's hard to do and then imagine if you're a     
1:46:51     
computational model on top of that where you're very naive to natural language and you don't have     
1:46:58     
necessarily when you have maybe you have access to the visuals maybe not so that     
1:47:04     
makes it harder yet still despite natural language being a     
1:47:09     
prominent manifestation of compositionality this can be expanded to other areas of human intelligence such     
1:47:16     
as vision the same notion of intersection as well as particle compositions is essential for visual     
1:47:23     
intelligence and so compositional learning is important in complex tasks     
1:47:29     
where high level goals must be decomposed into smaller sub goals and plans for example when instructing an     
1:47:37     
agent to navigate from one point to another from the computational modeling     
1:47:43     
perspective traditionally formal grammarss have been the means to address the compositional understanding of     
1:47:50     
various modalities which maybe are you know rooted in language but extended     
1:47:57     
division while these models inherently address computational structures using them alone that is parsing raw and noisy     
1:48:04     
data into a structure with manually designed grammarss will be brittle in     
1:48:10     
real world situations so this is an interesting passage here     
1:48:16     
um so you can have a model that addresses compositional structures where you're parsing data     
1:48:24     
into some sort of artificial grammar it's contrived and because of     
1:48:30     
that it's brittle in these real world situations because it hasn't acquired the context and it hasn't had the     
1:48:37     
experience of the language whatever that means so it's a really interesting     
1:48:43     
implication for large language models where you know how do you provide that experience is it just main name main     
1:48:48     
name main name main name main name main name main name main name main name main name mainly working with the language over and over again or is there something else there     
1:48:55     
um and so they're actually in this uh paper they talk about data-driven approaches     
1:49:02     
uh but also combining that with neuros symbolic techniques okay um and then uh they talk     
1:49:10     
about several studies providing much experimental and theoretical analysis indicating the competitive     
1:49:17     
competitiveness of these models and expressing compositional structure such as context for grammarss their     
1:49:24     
expressive power added to the robustness in dealing with noisy data makes the neural technique applicable to realistic     
1:49:31     
situations so we're talking about using kind of a neural network approach     
1:49:37     
um in here somewhere so that's what they're saying is that there's this expressive power and robustness to     
1:49:45     
dealing with noisy data that makes those uh so yeah they talk about that up here     
1:49:50     
um they talk about neurosymbolic techniques versus uh datadriven approaches based on     
1:49:56     
artificial neural networks and so this approach this former approach here is     
1:50:03     
what they're referred to down here so there's this expressive power of datadriven     
1:50:08     
approaches and they can express these computational structures such as     
1:50:13     
contextf free parameters and I guess they're maybe arguing that neuros symbolic techniques don't have that     
1:50:20     
ability but I'm not really sure um in this paper we examine multiple aspects     
1:50:26     
of compositional learning including cognitive aspects computational models     
1:50:31     
and evaluation paradigms so if we go down to this figure here this is the outline of covered     
1:50:38     
concepts so they actually uh kind of talk about important data     
1:50:46     
sets so um there's this one set of data set systematicity or novel     
1:50:53     
composition um there's this data set called crepe which is compositional representation evaluation     
1:51:00     
benchmark there's scan which is simplified a simplified version of the     
1:51:05     
commai navigation tasks uh there's gcan which is uh where     
1:51:13     
grounded version of scan so this one up here the kamei     
1:51:18     
navigation tasks are where you have this     
1:51:23     
data set that evaluates the model's compositional generalization across primitive commands     
1:51:31     
uh where you have these sort of the model has this experience with both the primitives and similar compound     
1:51:39     
structures then they test for unseen compounds dcan is where you have this     
1:51:44     
grounded version of scan uh so it's where I guess you have these splits     
1:51:52     
of the data set and they focus on some form of novel composition of concepts     
1:51:59     
uh then there's uh PCFG set which is probabilistic contracts for grammar stream edit task and cogs which is     
1:52:07     
compositional generalization challenge then there's the set of     
1:52:12     
productivity or link generalization data sets of course crepe is involved in uh     
1:52:18     
also under that category uh PCFG set is also under that category     
1:52:24     
then there's another data set called CFQ which is the compositional freebase questions data     
1:52:30     
set and then the COBS data set so they give some interesting     
1:52:38     
information about generalization criteria um so they have a couple of tests uh     
1:52:46     
this is from the PCFG set data set for the benchmark um they have this concept     
1:52:52     
called Substitutivity or synonymity test this     
1:52:59     
uses an input sequence with an atomic unit replaced by a synonymous atomic     
1:53:05     
unit to allow the model prediction changes so you have these different     
1:53:11     
primitives and you replace it with another primitive to see if it changes the model's prediction     
1:53:18     
localism is tested by using input sequences opposed to smaller sequences A and B the model is used to translate the     
1:53:26     
full sequences first and then forced to process A and B separately this evaluates how models     
1:53:33     
deal with the local versus global concepts and how that contributes to propositional propositional reasoning     
1:53:41     
then overgeneralization is a test that evaluates the model's results at input sequences that do not conform with the     
1:53:49     
general rules of the data set so input sequences that are exceptions to the     
1:53:54     
data set rules um enable us to look at over     
1:54:00     
generalization and some of these other types of uh     
1:54:06     
exceptions so the discussion in future directions there's been a large amount of research on the compositional     
1:54:12     
learning ability of humans from the cognitive perspective um however from the AI     
1:54:19     
machine learning perspective ideas are borrowed from both cognitive and linguistics and compositional tasks and     
1:54:26     
models and design focusing on narrow aspects of compositionality     
1:54:32     
so their investigation of AI models indicates several challenges regarding the design tasks benchmarks and     
1:54:39     
theoretical frameworks uh so this is uh the first one is synthetic and     
1:54:44     
unrealistic evaluations so one issue in current     
1:54:49     
evaluations is that controlled and clean tests of compositionality mostly synthesized     
1:54:56     
so these are where you don't really have really realistic data to something     
1:55:03     
that's been created for the purposes of the benchmark so um synthesized questions     
1:55:10     
are used to query knowledge graphs however more recent studies in language models evaluations of compositionality     
1:55:17     
focus on more challenging problems such as multihop question answering and     
1:55:23     
complex puzzles um another issue and this applies to     
1:55:30     
large uh mostly the large language models is data contamination     
1:55:35     
um meaning that you have uh issues with     
1:55:41     
the realistic nature of a data set um but also uh you know when you train a     
1:55:48     
model it will see some of these things that you're trying to test for so if     
1:55:54     
you're looking for compositionality the training set of more language model is going to involve     
1:55:59     
some of these compositional uh sort of     
1:56:05     
compositional components in the flesh so to speak so it recognizes those things from its training now whether that's     
1:56:14     
contamination or whether that's how we actually decomposition it's hard to say but it'd     
1:56:20     
be nice to have um you know a system where we can pull apart the effects and and the causes of     
1:56:29     
composition um then in a lot of studies we have this inconsistent theoretical methodology so understanding like     
1:56:36     
between methods like between transformers and neural networks and other types of     
1:56:43     
um you know how does composition happen there what are the tests being applied     
1:56:49     
etc and then there's this cognitive motivation so the fundamental capabilities of current AI models have     
1:56:56     
been debated and criticized by scientists in cognitive science and psychology despite giant leaps of     
1:57:03     
performance progress in modern AI there are distinct differences between these     
1:57:08     
machines and human intelligence evaluating different models reveals that they often rely on simple     
1:57:15     
pattern recognition instead of a holistic understanding of a problem grounded in reality and     
1:57:22     
situation understanding human intelligence from cognitive science literature suggests that we must move     
1:57:28     
beyond current engineering trends to build causal models of the world that     
1:57:33     
support knowledge and understanding the key ingredients of such human like rich     
1:57:38     
and efficient learning are compositionality and learning to learn     
1:57:44     
60 so that is this paper um it's interesting     
1:57:50     
um it kind of gets in the weeds of some of these methods and I'm not familiar with a lot of the methods but I think     
1:57:57     
it's an interesting kind of follow up to the compositionality stuff we talked about last time and how maybe like a     
1:58:05     
language model deal with this but also how to think about this in terms of cognitive models or we're trying to     
1:58:12     
figure out how maybe like the mind deals with compositionality or clarifying that     
1:58:18     
process um assuming that we actually do information processing     
1:58:25     
thank you um are there any questions or comments about that no just u     
1:58:32     
yeah a super important topic yeah don't uh     
1:58:40     
great great survey so this is uh I'm going to finish up     
1:58:46     
with this paper here and this kind of talks this kind of goes back to the thing we were talking about with genetic     
1:58:53     
voids so remember the genetic voids we have these agents that are give them     
1:58:58     
parameters to behave conditions to behave under and they behave these     
1:59:04     
collectives they form these patterns that are emergent patterns from their     
1:59:09     
collective behav from their individual behaviors and we find that fascinating     
1:59:14     
and it's also you know adaptive and intelligent to some extent and so that's     
1:59:20     
really interesting you know it's just an interesting set of observations and we     
1:59:26     
can maybe analyze it um but there are things going on with the individual     
1:59:32     
agents and so um this is a paper from PNAS     
1:59:37     
Nexus and this is collective decision making by embodied neural agents guom     
1:59:43     
Dumas is on this paper marco Duro is on this paper axel Axel clear     
1:59:51     
as well so these are all people either doing AI or like swarm intelligence or     
1:59:59     
other areas of this kind of consciousness yeah consciousness yeah     
2:00:04     
yeah okay so this is um you know they're going to be talking     
2:00:10     
about collective behavior and these embodied neural agents so you know our     
2:00:15     
genetic voids are not embodied point dots or points and you know there's no     
2:00:21     
assumption of embodiment there it's just kind of like there's this agent it's this thing this program that kind of     
2:00:28     
does interacts with things in the environment but this is where we're assuming some sort of embodiment     
2:00:35     
so the abstract reads collective decision making using simple social     
2:00:41     
interactions has been studied in many types of multi- aent systems including     
2:00:46     
robot swarms and human social networks however existing multi-agent     
2:00:51     
studies have rarely modeled the neural dynamics that underly sensory motor     
2:00:57     
coordination and embodied biological agents so you know aside from the swarms     
2:01:04     
we're interested in these sort of embodied agents that exhibit sensory motor coordination that is given a     
2:01:12     
stimulus it produces a a movement output or a motor output uh not quite like what     
2:01:18     
we have with voids but it's you know has this sort of feedback loop this closed loop feedback that works from being in     
2:01:25     
its environment um in this study we investigated collective decisions that resulted from     
2:01:33     
sensory motor coordination among agent with simple neural dynamics so they are     
2:01:38     
agents that have very simple neural dynamics that enable this sort of positive feedback from the environment     
2:01:46     
we equipped our agents with a model of minimal neural dynamics based on the coordination dynamics from     
2:01:54     
um we talked about coordination dynamics a little bit but this is uh the     
2:01:59     
framework that u jelso     
2:02:05     
developed and then it's been refined through sort of thinking about cognition     
2:02:12     
as a complex dynamical system maybe instead of information     
2:02:17     
processing and so this is a different perspective on cognition and     
2:02:23     
coordination dynamics is where you coordinate you know different things     
2:02:29     
like neurons or agents and you are basically coordinating oscillators and     
2:02:34     
we talked about that last time about oscillations and coordinating oscillations and how there's a history     
2:02:42     
of that in chaos and complexity theory we talked about how that actually goes     
2:02:48     
back to uh Norbert Weiner maybe and so this is just another way to kind of     
2:02:54     
think about cognition um so we have this minimal neural dynamics based on the     
2:03:01     
coordination dynamics framework and then embedded these agents in an environment with a stimulus gradient so a stimulus     
2:03:09     
gradient is where you have a source and it decays over space and your agent is     
2:03:15     
exploring a gradient to go from like low concentrations to high concentrations and they do this in space and of course     
2:03:22     
in time because it takes them time to move across the gradient if the gradient     
2:03:28     
diffuses there's a time of course for the diffusion of the gradient and so forth so you can do a lot of interesting     
2:03:35     
d uh dynamical systems modeling with a stimulus gradient and an embodied     
2:03:40     
agent in our single agent setup the decision between two stimulus sources     
2:03:46     
depends solely on the coordination of the agents neural dynamics with its environment in our multi- aent setup     
2:03:54     
that same decision also depends on the sensory motor coordination between agents     
2:04:00     
so you have this interesting coordination dynamics framework where     
2:04:05     
you're coordinating the environment and the minimal neural system in one agent     
2:04:12     
and then you have multiple agents that are exhibiting parallel behaviors     
2:04:17     
they're all sort of exploring this gradient they all have this coordination     
2:04:22     
dynamics pairing between the environment and the agents minimal neural system but     
2:04:30     
then each minimal neural systems coordinating with themselves so it's a     
2:04:35     
bit like when ants explore a pheromone trail ants will lay down like they'll     
2:04:41     
explore their environment they'll lay down a pheromone trail other ants will     
2:04:46     
kind of move towards that pheromone trail and reinforce it um if they find that if there's like say     
2:04:53     
like food on the other end of it so their collective behavior they kind     
2:04:59     
of interact with the source which is the food they form an initial trail to the     
2:05:05     
food of pheromone and then other ants will pick up on that pheromone scent and if they can confirm that there's food on     
2:05:12     
the other end by through their own sort of neural processing they then lay down     
2:05:18     
more pheromone and that signal gets reinforced and then other ants will follow that signal and keep reinforcing     
2:05:27     
so there's this interesting relationship between sort of coordination of behavior     
2:05:33     
and there is actual reinforcement learning aspect here which they're not talking about but um you know that's     
2:05:39     
that's just kind of what's going on here they don't really imply but they imply it but they don't talk about     
2:05:47     
reinforcement okay so um so in our multi-agent setup the same     
2:05:55     
decisions also depend on sensory motor coordination between agents via their simple social interactions our results     
2:06:02     
show that the success of collective decisions dependent on a balance of intra aagent inter aent agent     
2:06:10     
environment coupling as I mentioned there are these different types of interactions that are all important but     
2:06:17     
we use these results to identify the influences environmental factors on     
2:06:22     
decision difficulty so you know we have this um you know how depending on how     
2:06:28     
difficult the decision is different these different factors influence it     
2:06:34     
more generally our results illustrate how collective behaviors be analyzed in     
2:06:41     
terms of the neural dynamics of the participating agents this can contribute to ongoing developments in     
2:06:47     
neuroi and self-organized multi- aent systems modular So     
2:06:54     
um in this uh paper of course they're talking about collective decision making     
2:07:01     
and what they're getting at is this consensus idea so we talked about consensus with the copper moss machines     
2:07:08     
and that's one way to do this this is in agents embodied agents where they are     
2:07:14     
trying to develop a consensus about the environment so where are the     
2:07:19     
resources how do we behave how do we reinforce each other's behavior to find     
2:07:25     
a sort of a consensus um solution so     
2:07:30     
[Music] um that every group you know could be     
2:07:36     
embodied agents could be ants it could be people you have to have these uh     
2:07:42     
consensus uh decisions and so uh collective decisions that are made by     
2:07:48     
the group itself without external intervention meaning that some there isn't some agent or force telling them     
2:07:56     
how what to do typically requires that a consensus emerge in the group consensus     
2:08:02     
entails that all or at least a large majority of individuals agree either on an approximate continuous     
2:08:09     
value for example a position in continuous space or a discrete option     
2:08:15     
such as voting for an arbitrary item from the list so it's like you know     
2:08:20     
basically you have to have this reinforcement of the pheromone trail you     
2:08:27     
have to have an initial sort of hypothesis about where the source is and     
2:08:33     
then you know other members of the population verify that uh that decision     
2:08:40     
that that um hypothesis and they reinforce it and eventually become sort     
2:08:46     
of the consensus view there may be resources in other places but that's the     
2:08:51     
most reliable path to a resource so this gives it it it it eases     
2:08:58     
cognition in the sense that it makes the decision process easier you don't have     
2:09:03     
to run through all the options every time you want to find a path to food you have the path laid out and it results     
2:09:11     
from this sort of self-organized um sort of exploration     
2:09:17     
decision because there's no you know there's no topdown decision making this is all from just the agents     
2:09:26     
interacting consensus is achieved in this way through a distributed process that is not under the control of any     
2:09:32     
single agent all G agent models have been instrumental in investigating how the distributed interactions of     
2:09:39     
individuals can result in a consensus um individual agencies in most models     
2:09:47     
behave according to rather simple rules or heruristics so in opinion dynamics models agents     
2:09:53     
typically update their opinions according to the majority or to the voter group some recent models aim to     
2:10:00     
replicate human cognitive processes more closely by using neuro inpired     
2:10:06     
approaches such as the drift diffusion model so this is a model in uh I think     
2:10:12     
in like in diffusion uh models the class of diffusion model i     
2:10:18     
think we talked about that in this group as well um where this is kind of a     
2:10:24     
neuroinspired approach to this uh type of cognitive process so this is an     
2:10:31     
interesting type of cognitive process that again is not directly based on     
2:10:38     
information processing it's this sort of physics analog uh these opinion dynamics     
2:10:44     
models have greatly advanced our understanding of peer-to-peer interactions and give rise to collective     
2:10:51     
phenomena such as polarization or consensus so this is you know applicable     
2:10:59     
to opinion space or physical space so you know if we think about how animals     
2:11:04     
choose a new nest site or humans find an exit during an emergency     
2:11:10     
evacuation we can use these type of models as well to find that consensus path     
2:11:17     
uh also in these more embodied models behaviors are typically governed by simple rules and heristics these models     
2:11:25     
have been eliminated for example how animals can resolve differences in initial movement direction and move     
2:11:31     
towards a single location using only local implicit     
2:11:36     
communication so their um approach to this is a little bit you     
2:11:42     
know it's it's very minimal embodiment so they're not drawing very heavily from     
2:11:48     
the body part of embodiment it's just kind of like it's in a space it's in an     
2:11:53     
environment it's in a context okay so this is where they kind     
2:12:01     
of get into u into uh coordination dynamics in the     
2:12:07     
interest of time I'm not going to get deeply into that i'm just going to kind of outline it so um they actually do     
2:12:14     
mention four ecognition here so considerations of the brain body     
2:12:19     
environment interplay a gradually perminated cognitive science culminating     
2:12:24     
in the 4E cognition framework which sees cognitive processes as being embodied     
2:12:30     
and active embedded and extended um and so that's they kind of     
2:12:37     
bring that up and then they start to talk about     
2:12:42     
coordination dynamics so um you know there are all these     
2:12:48     
challenges to understanding sort of the brain and sort of you know thinking about cognition not necessarily as     
2:12:55     
information processing but as a complex system     
2:13:00     
uh if you want to operate successfully in an environment and you have neural     
2:13:06     
activity you have this sort of bio inpired model of the you know the thing     
2:13:12     
that's driving the behavior of the environment uh the biological agent must     
2:13:18     
be attuned to characteristics of the environment the neuroscience brain activity is typically studied in terms     
2:13:24     
of oscillations so this is where we get into neurocillations we talk about different     
2:13:30     
rhythms that are generated by those oscillators and how that leads to synchronization with the environment and     
2:13:38     
how brain rhythms can rapidly shift to accommodate changing environmental tasks     
2:13:43     
and environmental demands so this is like kind of framing this in this oscilly framework and how a bioinspire     
2:13:51     
model is based on these sort of oscillators that are entrained or become     
2:13:57     
entrained so this brings us then into coordination dynamics because coordination dynamics     
2:14:04     
really kind of came out of this idea of oscillators as being the drivers of behavior so a lot of the stuff in     
2:14:11     
coordination dynamics originated from uh either movement studies where they were     
2:14:16     
like moving trying to synchronize their body movement their finger movements to a metronome or studies of fMRI where     
2:14:25     
you're looking at synchronization of different brain brain cognition so this is kind of it     
2:14:34     
and coordination dynamics is based on a physics model we'll talk about in a minute but it's been widely used to     
2:14:40     
study how the activity of these dynamically interacting components is coordinated so one advantage of the     
2:14:47     
coordination dynamics approach is that it can be used to study the metastable regime in which the brain usually     
2:14:54     
operates so there there's this focus in coordination dynamics of metastability     
2:15:00     
where these points of stability that are sort of poise the brain     
2:15:06     
towards going into one or one or two states or one of multiple states so one     
2:15:13     
advantage of like looking at cognition in this way is that you cannot just you     
2:15:19     
know say that something is a result of information processing but by saying that sort of the brain is poised to take     
2:15:28     
advantage of different behavioral regimes at any one time metastable with     
2:15:34     
respect to different behavioral regimes and these different aspects of the environment and interacting with other     
2:15:40     
agents can kick it into one of these other you know one of these different     
2:15:46     
states so that's kind of the idea here um and so you know this allows us to     
2:15:53     
model the dynamics of a system so the system goes from metastability to going into one state or     
2:16:00     
another and then returning to metastability and then you can look at the trajectory of that to see what     
2:16:07     
states the brain visits and you know over time so you can actually look at     
2:16:13     
whether the dynamics are stable or unstable whether the brain is being     
2:16:18     
overwhelmed by environmental input and how that plays a role in     
2:16:24     
preventing or facilitating adaptive behavior so this is another part of     
2:16:29     
their embodiment is that they're looking at the agents minimal neural system as a     
2:16:35     
set of oscillators that are in you know synchronized and that have these     
2:16:40     
dynamics that are you know allow us to describe how     
2:16:47     
um it synchronizes both its environment and its other fellow     
2:16:53     
agents so a metastable regime resolves the problem of sort of uh being stable     
2:17:00     
or unstable by allowing the brain to dynamically switch between several stable oscilly states thereby being     
2:17:08     
neither completely stable nor completely unstable so you can it it sort of     
2:17:14     
balances outstability and instability and it does this over time     
2:17:19     
so it gives us a new way of thinking about cognition not as like this information processing machine but as     
2:17:26     
this dynamical system and so the hake and kelso booms equations the HKB     
2:17:33     
equations are sort of the way that we modeled this metastability and it's this uh it's     
2:17:41     
basically comes from physics it comes from looking at uh stability in physics     
2:17:48     
where you have metastable states and you have stable states and the metastable     
2:17:53     
state is up at the top of a energy well and then the system will go down into     
2:18:00     
one energy well or another you'll see these metastable diagrams i don't know if they have one in here but usually the     
2:18:07     
system is poised at the top of a hill and then it can go down one side of the hill or the other into these stable     
2:18:15     
states which are these basins of attraction and then of course it can be     
2:18:20     
poised back up at the metastable state ready to go into uh into another state's     
2:18:26     
well and so on and so forth um so that's kind of a qualitative     
2:18:33     
description of this um two oscillating components when modeled with the HKB     
2:18:39     
equations show inphase attraction similar to the coramomoto model which we     
2:18:44     
talked about last week and also anti-phase attraction which is another behavior     
2:18:51     
the simultaneous existence of inphase so-called symmetrical anti-phase     
2:18:56     
so-called asymmetrical attraction produces a simple form of metastability     
2:19:02     
so you can have metastability by having these inrained     
2:19:07     
oscillators they can be inphase or anti-phase and sometimes you can have     
2:19:12     
both so this is really kind of a a good I think uh way to think     
2:19:19     
about some of these stabilities and instabilities and cognition it's definitely different from the     
2:19:26     
information processing approach and of course it's going to have consequences for how we might think of     
2:19:32     
compositionality if you know I mean compositionality might be possible in this model i don't know if people talked     
2:19:38     
about it or thought about it but it's going to be a very different way to achieve     
2:19:44     
it in studies of continuous collective decision making an offstied question is     
2:19:49     
under which conditions can agents with different preferred movement directions reach a consensus so in this model     
2:19:56     
they're actually just looking at the movement direction of an agent and the oscillators are controlling that     
2:20:02     
movement direction and as they communicate with each other they sort of all sort of reach a consensus about     
2:20:09     
which direction is best so you know you might have a population of a thousand     
2:20:15     
agents and they're all pointed in slightly different directions and so you could just simply take an average of     
2:20:22     
those agents and look at like how their direction changes over time and over     
2:20:29     
time what you should see is that those the uh average direction should even out     
2:20:36     
to some average that has a very low standard deviation and that you know this happens where you     
2:20:43     
basically destroy a lot of the wildly different     
2:20:48     
um directions and the directions that are kind of close but not really where     
2:20:55     
they need to be get aligned so this is um and we can think about this in terms     
2:21:02     
of this dynamical systems model by saying you know that there's certain     
2:21:07     
states that are going to be more likely to be achieved so     
2:21:15     
uh let's see if they yeah they have u well they have a model of gradient descent and decision making here they     
2:21:22     
show the agent architecture first of all where they show uh these uh four nodes     
2:21:28     
and they have this fully connected network they have sensor inputs coming in and then they have some output of     
2:21:36     
motor control so they have this motor oscillation from the inputs processing     
2:21:43     
through this very simple network and then they have this angular displacement which is the angle or the direction of     
2:21:51     
movement and so as it's monitoring the gradient as it's monitoring its     
2:21:56     
neighbors it's processing this through the network and it's producing this     
2:22:02     
angular displacement which is the angle of movement and so that angle of movement should become aligned over     
2:22:10     
time and so this just shows gradient ascent which is ascending that gradient     
2:22:15     
that sensory gradient towards the greater concentrations it kind of ascends in a linear fashion until it     
2:22:22     
gets near the apex at which point it kind of explores that apex or near the apex to make sure     
2:22:30     
that it's hit the the global optimum in decision- making when you have two     
2:22:35     
options when you have two stimulus gradients that kind of overlap you have to make a decision between one uh source     
2:22:44     
or another source so in this case there's kind of this line down the middle and then the agent veers off     
2:22:51     
towards this option exploring this gradient linearly until it reaches near     
2:22:57     
the global optimum explores that for a while and then hits the global optim and then this shows the brain     
2:23:04     
dynamics or the dynamics of this network and it shows the sensory motor left the     
2:23:09     
sensory motor right and the motor motor connections and then those are all kind     
2:23:14     
of plotted out here where you have this um basically over time you have this     
2:23:21     
variation so as as like as it's making this linear     
2:23:26     
move towards the gradient and up the gradient the brain dynamics are sort of     
2:23:32     
you know all the same and then when it starts to make this exploration move when it starts to kind of wander around     
2:23:39     
the global optimum that's where you get these uh very these highly fluctuating     
2:23:45     
dynamics and so then this shows where you have     
2:23:51     
successful and failed consensus so a successful consensus is where the entire     
2:23:56     
population aligns and moves towards one option or another a failed consensus is     
2:24:02     
where you still get like you know different parts of the population going to different sources     
2:24:08     
this is reflected in the movement dynamics which is the agent     
2:24:14     
orientations and how those separate out and then the brain dynamics which     
2:24:19     
actually show um intra and intra aagent brain dynamics     
2:24:25     
and so the brain dynamics separate out as well or actually in the case of this     
2:24:32     
failed consensus they converge and in the successful consensus they diverge     
2:24:39     
which I mean I could go into the paper a little bit more but in the interest of time than that but just put a marker in     
2:24:48     
there so     
2:24:53     
okay so I think that's it for that paper um I think it was a pretty interesting     
2:24:58     
paper a lot of interesting things especially with respect to embodied agents and and modeling cognition     
2:25:08     
yeah i mean yeah always has the coolest papers     
2:25:16     
uh really interesting really interesting um going to need to need to play with     
2:25:23     
that like um anyway and you know blast from the past to     
2:25:30     
see Kelsa you know people talking about     
2:25:38     
Kelse he he Jim is on a roll this this     
2:25:44     
year I I don't know uh     
2:25:51     
Anyway he he just got a he just got a grant     
2:25:57     
on you know quantum machine learning     
2:26:03     
and you know neuroscience agents     
2:26:10     
so you know and and definitely Yeah     
2:26:17     
like like building building on Quiskit uh you know like like coding coding     
2:26:25     
quantum computers for you know fun and profit     
2:26:32     
uh um look looks super interesting and um uh I'm just trying to     
2:26:39     
[Music] remember anyway there's there's another project     
2:26:47     
is that is also super interesting so just to see this I don't know how I     
2:26:52     
missed this uh this particular paper but     
2:26:58     
I think it was it was it in the slack or not uh I don't it could be     
2:27:08     
um uh but I have not gotten into it and     
2:27:14     
um uh Yeah     
2:27:20     
great great stuff yeah good all right well I think that's it for     
2:27:26     
today thanks for attending it was a great meeting see you next week take     
2:27:32     
care take care bye see you bye     
