## Meeting Recording

[YouTube link](https://youtu.be/hmB7fErCY9Y?si=MHWiPv00vAsKjjr2)

## Mastodon thread

[link](https://neuromatch.social/@OREL/112506071930484034)

## NOTES:
Hussain: reaching out to Paola. Brain GPT ‚Äî allows for counterfactual articles, pro-con literature searches.

techniques of fine-tuning. Align brain embeddings.

canonical neurodevelopment trajectories. CALM team.

gradient-based approaches (neurodevelopment datasets).


‚ÄúHow to grow almost anything‚Äù course: microscopy n‚Äî FijiSc.

databases, foundation models. #dataviz ‚Äî Allen Cell Atlas.

Richard Leahy ‚Äî NeuroGPT. 

TUH dataset ‚Äî long clinical recordings. Weight Watchers tool, Statistical Mechanics ‚Äî> look @ training in physics ways (with EEG in Physics models).

MetArc ‚Äî fMRI. ‚ÄúFoundation Models‚Äù. OpenML ‚Äî community (stability AI-related). Brain transformer.


ECoG data ‚Äî June 3. Foresight sessions ‚Äî AI-focused. ‚Öï of talks were brain imaging-focused.

WBE (Whole Brain Emulation). nm-resolution connectomics (fMRI, EEG). How much functional representation achieved from structural connection?

 statistical mapping vs. microscopy. Dynamic Causal Modeling.

infer physiology from electrical signals.


ERP paradigm ‚Äî waveform phenomenology.

organoid intelligence ‚Äî as a stepping stone, extend compute to include biology.

very necessary first step. High-res EM Dishbrain 2-D neural network.

cortical labs Club ‚Äî meeting with student in Braingeneers.

Adam Safron ‚Äî quasi-dev AI approach. how do you instill values?


JoPro ‚Äî mentorship aspect to Project Management and development.

NYCWiC ‚Äî chair in a very small conference.

tie into mentorship, pedagogy (educational banner for lab).

how do you deal with being a mentor? Update JoPro web presence (working groups). Early career access. 

larger, longer-term community for SET, NYCWiC involvement.

importance of mentorship paper ‚Äî moments matter for involvement.


Inferring Physiology (CompuCell3D) vs. Atlas (Big Brain) approach.

capture world models with LLMs.


Whole Brain Emulation: 1000 ideas of what this is (like AI alignment, benchmark -driven).

black box. Physics, expansion microscopy. Imaging does not equal physiology.

highlight very small aspects of physiology. What can you do that‚Äôs FlyWire-like?

give structure some physiology. 


Kariko article ‚Äî brutal description of academia.

simulation work ‚Äî polycapillary x-ray approach. Expert in ML-Monte Carlo sims.

MATLAB >> OCTAVE ‚Äî> move to Julia, Python.

Slicer 3D community. Deep algebra proposal (Isabelle). Agentic AI ‚Äî> EGRT and compositional abilities. How things got into place and why.

 adult brain ‚Äî understood in the light of development.


Artificial Molecular Machines >> Neurons.

developmental AI + Weight Watchers + Brain Emulation.

grounding with perspective. Failure Modes >> Benchmarks. Failure modes are where kids are learning.

position paper on where Developmental AI could be. Piagetian and Continual Learning approaches.

Phase transitions, set of solutions are fundamentally different.

forging a unique perspective (how much GPT should we reference in previous iterations of GPT?).

quantum analogy ‚Äî> we are 4D objects.

demarcate developmental AI, what could we constructively do? What is missing?




Morgan Hough (he/him)
Morgan Hough (he/him) says:
Good morning 
9:01

Jes (OREL)
Jes (OREL) says:
I will be in and out a bit during the meeting for a while 
9:03

Morgan Hough (he/him)
Morgan Hough (he/him) says:
Let me get my coffee 
9:03

Jes (OREL)
Jes (OREL) says:
snippets of updates for me: lots of work on JOPRO administratively, and, there's mentoring work in development also ; I'm appreciating the break from Cognition Futures as I finish up the term and make other changes ; The inclusive gaming conference has yielded a lot of positive contacts, plot twisters is still on break but looks to do more later this summer. Also I had a NYCWiC 2025 first meeting for that conference this week and it's exciting to see new volunteers and ideas come into play. 
Jes (OREL) says:
whose notion? 
Jes (OREL) says:
ok 
Jes (OREL) says:
ty 
Jes (OREL) says:
I'd like to see more examples of using discord 
Jes (OREL) says:
that link in the slack 
Jes (OREL) says:
unforunately doesn't work any more 
Jes (OREL) says:
if you can find another updated one 
Jes (OREL) says:
üëç 
Jes (OREL) says:
There's a Boston neuretch chatper right 
Jes (OREL) says:
logan is a champion 
10:14

Hussain Ather
Hussain Ather says:
yea let me try to find it 
Hussain Ather says:
did someone post it in slack? 
10:31

Jes (OREL)
Jes (OREL) says:
üëç 
Jes (OREL) says:
Hello E ! 
Jes (OREL) says:
IDK if you want to say anything or just listen in  but it's good to see you here. 
Jes (OREL) says:
oh good i wanted to go over this more too 
10:50

Hussain Ather
Hussain Ather says:
"keep in mind" 
10:50

Jes (OREL)
Jes (OREL) says:
Large Mistake Model 
10:52

Erinn
Erinn says:
I wonder how consistently activation pattern ata are used from truly representative-of-the-population sample sizes 
10:56

Jes (OREL)
Jes (OREL) says:
should we try to make a ... working paper .... position paper... something on what devai is or could be? 
Jes (OREL) says:
üëç 

## TRANSCRIPT
0:03     
hello how are     
0:09     
you hey I'm F how are you all right Morgan's     
0:16     
hereo Jesse morning so a lot of stuff has been     
0:23     
posted in various slap channels we can go over some of those things um I am     
0:28     
still getting together the uh reaching out to I'm reaching out to pa pa pa for     
0:34     
the paper on the ethical consideration of neuro of AI neuros stimulation see how things go with that     
0:40     
so okay just happy to see where things go um yeah see there's Neuroscience     
0:46     
networks so let's go back into Neuroscience networks and see what we have here all right I think we'll start     
0:55     
maybe up here somewhere oh this is fun uh this looks like the brain GPT stuff     
1:01     
for March 23rd and yeah I put this in here got     
1:07     
GPT uh there all sorts of really interesting papers coming out on different types     
1:13     
of uh approaches to like systems neuroscience and they're kind of linking     
1:18     
to large language models and machine learning which we'll talk about later because I have some references on that     
1:26     
um that are going to be interesting to look at how they've kind of evolved uh this is universal     
1:33     
differential equations is a common modeling language for neuroscience and so this is uh the image     
1:41     
here so they talk about uh modeling in terms of Black Box models transitioning     
1:48     
to white box models so you have these Universal differential equations you go from a blackbox model where you don't     
1:55     
know what the process is inside but you know like kind of with the D dyamics are     
2:01     
and what the inputs and outputs are and then white box models which are where     
2:06     
you can see the process inside and so you know it becomes less opaque across     
2:12     
this so the most Black Box model here that they highlight is neural     
2:18     
differential equations and these are kind where you don't know so the     
2:24     
structure and the parameters are both unknown which is dispelled and estimated from data so this is like a neural     
2:31     
network where you're just putting in data and you're getting a set of classifications out and you don't     
2:36     
necessarily know what the in you know what the mechanism is you just know that     
2:41     
you're getting a bunch of weights and so of course those are not interpretable models nor do you really know what the     
2:48     
substrate is um this epitomizes fully data driven modeling this is you know the standard     
2:55     
data science approach uh then as you move away from blackbox Models you have differential     
3:02     
equations with residuals so this is where we have this traditional neural network model augmented with a function     
3:09     
approximator to model residual Dynamics not captured via the model and then next we have differential     
3:17     
equations of known unknowns where the structure of the Dynamics of that neural network is known     
3:24     
but the values of some parameters are unknown and estimated from data so this is where we know know some of the     
3:30     
structure we know some of the Dynamics that we should be getting so we're not operating in in the dark like we are     
3:36     
with no differential equations or differential equations with residuals we actually know most of it but we don't     
3:42     
know some of it and so we're just trying to infer that part that we don't know so     
3:47     
collectively these middle ones are sort of the gray box that was actually     
3:53     
proposed back in the days of cybernetics where they would have these box and arrow models and they would have these     
4:00     
processes and they wouldn't know what was in them but they would use them as sort of a a regulator and so you know     
4:07     
this is their black box models are kind of these gray box models and then white box models and sort of the bitter lesson     
4:14     
of cybernetics is that you know every gray box has some black boxes embedded in it     
4:20     
so even when you work the problem down to some of you know to where you know a     
4:26     
fair amount about the structure and the Dynamics you find the things you don't know and so that's you know kind of the     
4:32     
problem with you know modeling the brain even understanding neural networks and     
4:38     
then the white box model is this differential equation with known structure and parameters so this is     
4:45     
where we know the system but we don't know the Dynamics we have to drive the Dynamics and this is where we calibrate     
4:52     
the Dynamics from first principles and domain knowledge so you know we like to     
4:58     
use first principles uh in Biochemistry and in physics we     
5:04     
have these abono models where you just use first principles to build a model of     
5:10     
the Dynamics but you have to know what those are and first principles just simply means like if you have chemical     
5:15     
laws or you know standard values for equations that that's what you put into the model and then you get an     
5:23     
output so this is what we think of as mechanistic modeling and the rest of these are not mechanistic the sense that     
5:30     
we either can't know or don't know all the details so you know you could have     
5:35     
emergent models or you could just have simply unknown mechanisms here so that's     
5:41     
a cool paper that's actually from Gom Dumas um and this is a great review and     
5:48     
perspective um this is a paper talking about     
5:54     
Reservoir Computing we talked about Reservoir Computing I think in Dil a while back where where you know you're     
6:00     
modeling the brain as this Reservoir computer and you're getting different     
6:06     
scales uh of the brain so you have the micro scale where you have neurons you have the misoc scale where you have     
6:12     
little small networks of neurons connected into a larger Network and then a ma macro scale where you have those     
6:20     
connected into even larger networks and it's worth thinking about brain networks in the sort of fractal way where you     
6:26     
have like you know each node has things within it a node and then things within that node and this summer we're working     
6:33     
on some things in evil worm related to U hyper networks and Hyper graphs where     
6:40     
you have that very structure you have you know an initial Network that we're     
6:45     
looking at it at the brain scale and then you have like sand neuron where you have a little patch of tissue and then     
6:52     
within that patch of tissue you have things that are connected and then within that patch you know within those     
6:58     
connections you have things within that so it's you know it's it's working down in scale and representing     
7:04     
everything within the node in different ways and then of course with this     
7:10     
multiscale approach they plug everything into these Reservoir computers which are of course where you have these sort of     
7:17     
randomly connected networks of nodes you get an input layer and a readout module     
7:22     
so it's like a conventional neural network except that you know you want to     
7:28     
basically train it to get some structure at the end and since it's     
7:34     
a I can't if you want to talk about blackbox models Reservoir Computing is really one of those because you don't     
7:40     
know at the beginning what the structure is you're just kind trying to get some     
7:46     
emergent structure and get an output um given some input and then of     
7:51     
course so that's a reservoir Computing part your Reservoir has these components     
7:56     
these different activation functions these different types of behaviors and you know different first     
8:02     
principles like neurom Mass models and then that leads us to the computational phenotyping of network     
8:09     
structure uh add you know applications to like understanding lifespan IND individual differences in     
8:17     
Behavior Network perturbation so what happens if I exercise or get injured or     
8:24     
I get old or I forget I guess these little figures down here and then of course Evolution how does it how does     
8:31     
the brain vary between species so that's a pretty um that uh that's a pretty ambitious     
8:39     
project there uh Jesse posted this on the on the     
8:44     
transmitter uh that's I guess a a site where this is neurons making memory     
8:49     
shush their neighbors so this talks about how neurons kind of Silence their     
8:55     
neighbors and building uh you know memories and building short small     
9:00     
networks that are encoding things you know at the synapse level so when     
9:05     
neurons strengthen their synapses they infects surrounding cells with a virus like protein to weaken these cells     
9:11     
excitatory connections according to a new print and then uh Morgan and     
9:17     
fascinating stuff um you have a lot of really interesting     
9:24     
things with respect to Quantum Computing using Quantum computing for dynamic     
9:30     
behaviors of biological and artificial neural networks uh this one functionality of     
9:36     
arousal regulating Rin circuitry at rest predicts human cognitive abilities so     
9:42     
this is about arousal and how some of these things are regulated and you know what's going on     
9:50     
there uh an algorithm for neuronal wiring and ring mystery this is from the inria blog I guess from     
9:57     
their uh you know uh featur one of their papers so in a     
10:03     
paper published in the journal physical review letters uh these researchers outlined a     
10:09     
breakthrough in our understanding of the development of the architecture of natural brains their research has shown     
10:15     
that the connections between nerve cells inside living organisms follow simple algorithmic rules that can be modeled so     
10:21     
this is where you know we want to infer how brains get wired in development how     
10:27     
brains change their wiring and plasticity and under those conditions     
10:32     
and so we can actually extract different principles from that so uh some of the     
10:39     
principles of people are proposed of an age uh of the cell you know if the cell     
10:44     
is born then it gets connected there are other rules as well so this is kind of     
10:50     
an interesting paper in that respect you know this is not something we it's an     
10:55     
easy problem we have to kind of figure out from data how you know how a neuron     
11:01     
knows what other neuron to connect to and maintain that connection and of     
11:06     
course it has relevance not only to development but learning in memory uh this Innovative Concept in     
11:12     
complex systems paves the way for exciting clinical applications that could hold uh help to     
11:19     
deepen our understanding of the progression of neurod degenerative diseases or how people recover from     
11:25     
Strokes so this is really interesting um maybe open that up a little bit we can     
11:31     
look at it so this yeah this is the uh so     
11:37     
they're searching for an evolutionary algorithm looks like it was some sort of     
11:43     
uh dissertation but this was uh so this is the physical review     
11:49     
letters paper here exploration exploitation Paradigm for Network biological systems so they're talking     
11:56     
about exploration versus exploitation and those kind of tradeoffs     
12:02     
um there uh so in order to survive these systems are forced to choose configurations which produce optimal     
12:09     
functions which can be summarized as configurations which maximize their     
12:14     
capacity to survive in their environment of course that's what we're interested in in evolution and in metabolism or     
12:23     
general they're also governed by functional constraints resulting from the laws of physics time and energy all     
12:31     
of which dictate evolutionary compromises as a result analyzing biological systems remain a significant     
12:37     
challenge those researchers seeking to model such systems so we need to uh     
12:43     
grasp how sort this neural network or neurons within the network explore their     
12:49     
space of possible configurations or a functional landscape in order to discover new things that's     
12:55     
exploration and then how to identify optimal state for responding to specific biological     
13:02     
functional requirements which enable them to survive and that's exploitation so this is this is this balance and then     
13:09     
of course you can use celegans for this because you know you have a very small number of neurons and you know the     
13:15     
connections and so that's an interesting um set of things here uh so     
13:21     
this is the worm connecto where you have these networks that change their shape     
13:27     
you get uh over these observation points so from 0 to 45 hours so the worm is I     
13:35     
guess this is where I guess this is from birth or you know kind of the birth point of yeah so     
13:43     
this is L1 which is a developmental stage so e is the embryo they're not measuring looking at the embryo they're     
13:49     
looking at the when when the worm hatches so that's zero hours then     
13:55     
they're looking at the L1 developmental stage the L2 development stage L3 L4 and     
14:02     
then the adult up to 45 hours so you know during this time all the net     
14:07     
neurons are in that Network or most of the neurons there are a few neurons that are born post     
14:14     
embryogenesis and you know they're changing their connections throughout development uh especially laral     
14:21     
development because they're encountering a lot of different things in their environment there is some of that post     
14:27     
embrionic uh plasticity and you know so it's a really interesting time to look at that problem     
14:33     
and then of course in the adult you do get changes in the connections you don't get changes in the number of cells but     
14:39     
you do get changes in the connectivity depending on you know what the     
14:44     
environment of the worm is and aging even can affect that so this is a really     
14:49     
interesting uh paper uh I'm not sure what kind of data set they have it' be     
14:55     
kind of interesting to look at the data set in this paper so so I don't know if they have a link to the paper directly     
15:01     
but we know what the paper is now so we can take a look at that later it might be interesting to Diva     
15:09     
one so this is a seminar from Paul CAC     
15:15     
this is the Mind core seminar and you know this is kind of talking about functional decomposition     
15:21     
of the Mind looks like he's got one of his trees that he likes to put in his slides so that's that's an interesting     
15:28     
talk uh from pen minec core their lecture     
15:33     
series um we have this paper from nature     
15:40     
alignment of brain embeddings and artificial contextual embeddings and natural language points to Common     
15:47     
geometric patterns this this is kind of uh what they're getting at here is they're     
15:53     
trying to find langar or they're trying to make a connection between large language model and Bings     
16:00     
and looking at activity patterns in the frontal gyrus inferior frontal gyrus and     
16:06     
trying to discover a common neural code for language so we look at the figure we     
16:13     
have this sampling of brain embeddings we have these two areas of the well the     
16:19     
inferior frontal gyrus and the precentral gyrus and we go cross     
16:24     
participants then we have this uh zero shot mapping where we look at the training set and     
16:31     
the testing set where I think this is I don't know if this is an a language model I guess it is the     
16:37     
gpt2 where you sample a single occurrence of each word in the story and then you get so you could do this I     
16:44     
guess with the participant or with a model uh basically you have this training set and this testing set or     
16:50     
this training uh period in this testing period so you're training it on sampling     
16:57     
a signal occurrence of each word in the story and you're looking at brain activity you're looking at the model     
17:02     
activity and then you're looking at these embeddings so you know we look we can compare between gpt2 and inferior     
17:10     
frontal gyrus we have this zero shot decoding using not overlapping     
17:16     
words we have this alignment between encoding and decoding and that's what     
17:21     
we're trying to do we're trying to align these two types of models so we can see that the uh you know these this featur     
17:28     
space in the gpt2 and this uh space in the brain embedding space in the inferior frontal     
17:36     
gyrus they're not I guess they're not aligned exactly I don't know how they map these factors between each model the     
17:44     
model in the brain but basically if I take this as like a naive     
17:49     
viewer uh these words are in different positions or locations in this embedding     
17:56     
space so I'm assuming that there is not not necessarily alignment here although I don't know so nonhuman for example     
18:04     
it's shifted between gpt2 and the inferior frontal gyus     
18:09     
copyright so a lot of these are shifted in different ways but just shows like     
18:15     
the comparison between these two spaces so that's interesting work uh we'll talk     
18:20     
more about large language models later in the meeting uh yeah this one taming the     
18:26     
Neuroscience literature with explanatory predictive models this is where we have     
18:32     
uh this we're using brain GPT which we've had some great fun left and     
18:37     
talking about the different types of flavors of GPT that are coming out now     
18:42     
and you know looking at the Neuroscience literature and kind of getting a handle     
18:47     
on the different categories and you know being able to prompt uh different terms     
18:53     
and see what comes out you know different resources so that's that's interesting stuff that's a     
18:59     
video that Morgan posted he's even trying to get it at     
19:05     
being able to um find     
19:11     
counterfactual articles like like like I I've got this     
19:16     
Theory you know and and allow you know these the large language model to kind     
19:24     
of yeah give give you Pros pros and con uh literature     
19:30     
searches um and you know certainly the idea being that at some point you know     
19:38     
again it acts as an aid right like it acts as a a kind of scientific     
19:44     
a um and you know whether whether it's there or not you know yeah but but     
19:51     
certainly that was that was a big part of his his talk oh okay yeah that sounds     
19:57     
that sounds like something I well me I could do but maybe do a lot better with     
20:02     
GPT you know like yeah I mean it's it's a it's um     
20:10     
it's it's kind of a lore I mean the other the other thing that's nice about it is is     
20:16     
is discussion of what are the techniques to find tuna model to to be appropriate     
20:22     
for nursing or or to be appropriate as a Nur scientific Aid right you     
20:33     
know yeah like I said we'll talk more about GPT or Le larger language models     
20:39     
later in terms of their like uh well we'll see what what I'm going to get     
20:45     
into interesting the last the last paper in Neuroscience networks is is a     
20:52     
um uh is is what I would say is by some of the the people who brought us you     
20:58     
know these these gradients and um yeah a lot of this work     
21:04     
in gradient stuff the last one I mean this this is     
21:10     
this is this is interesting and this is that's a breakdown of the oh this one I mean like like all the way at the bottom     
21:18     
most Rec yeah yeah as like Daniel marillis in terms of okay this yeah yeah     
21:28     
like you know he was sort of instrumental in the first you     
21:36     
know Str structural gradients structural and functional gradients yeah um anyway     
21:45     
that was that was interesting to see too yeah this is organizational gradients so     
21:51     
yeah we should talk about this one then so this is uh about gradients in I     
21:58     
guess is in brain like in in uh in the brain not in our models uh so this is     
22:06     
right yeah this is this is definitely more kind of like a typical structural functional analysis paper right yeah so     
22:14     
this is canonical neurodevelopmental trajectories of structural and functional manifolds this is the calm     
22:19     
team which is out of Cambridge I guess um yeah and then people associated with     
22:25     
that um so this is where they're talking organizational gradients which are these     
22:31     
continuous low-dimensional embeddings of brain regions and this allows us to quantify     
22:37     
core organizational principles of human brains or complex systems more generally     
22:42     
so they're focused on the brain here sort of the structural functional studies that we can     
22:47     
do uh mapping how these organizational principles are altered or refined across     
22:53     
development and another phenotype so you know in development we get these changes that Ur uh but also during plasticity or     
23:01     
during learning in memory we can look at different things and how you know the brain is altered and you give it a     
23:08     
perturbation and it responds and we should be able to use these techniques to get these organizational principles     
23:16     
sort of extracted or at least put everything in a common     
23:21     
framework uh taking a developmental approach in leveraging longitudinal and cross-sectional data and this from two     
23:29     
multimotive Neuro Imaging data sets spanning the full neurotypical neuro     
23:34     
Divergent Continuum so we have a lot of data sets from neurod Divergent     
23:40     
populations but also uh data sets from your neurotypical populations we charted the     
23:47     
organizational variability of structural and functional Radiance across childhood     
23:52     
and Adolescence across data sets despite different phenotypes we observe highly     
23:58     
similar structural and functional gradients so we have two different types of gradients we have the structural     
24:04     
gradient and then the functional gradients the structural gradient is like the conect     
24:09     
connectivity via you know both both both tons and     
24:14     
diffusion okay yeah yeah and so yeah these gradients     
24:21     
organizational principles are highly stable across development so this is like the SE alans paper it's very     
24:28     
different system but we have these kind of organizational principles throughout development that are actually somewhat     
24:35     
you know there are number of them that are highly stable if you just say look at connectivity on its face but also if     
24:41     
we take an embedding and we look at it we can also discover these uh principles     
24:48     
with the exact same ordering across the early CH childhood and midadolescence however there is substantial     
24:55     
developmental change in the strength of the embedding Within those gradients so this is where the grad the embedding     
25:02     
strength changes uh within the gradient or the embedding strength changes within the gradient by modeling developmental     
25:10     
trajectories as nonlinear splines we show that structural and functional gradients exhibit sensitive periods that     
25:17     
are refined across development so this is where you know we get this we we can     
25:22     
identify uh critical periods using this type of approach the gradients are     
25:29     
established early in life refined through development and they're coupling is a robust predictor of working memory     
25:36     
we look at the PDF so we can see maybe some of these figures this is U and of the sensitivity     
25:45     
of these gradients so let's see if we can look at this a little bit more in depth so we     
25:52     
have these different types of networks we get uh the structural connecto the structural apine same thing     
25:59     
for the functional connectum and the functional apine we get this uh connectivity Matrix we normalize by a     
26:07     
diffusion parameter Alpha we then use a random walk to sort of find the     
26:12     
transition probabilities we then do an igen decomposition where we find sort of the     
26:19     
orientation of the different uh I vectors and then we put this into U this     
26:28     
space and we end up with the gradient and so we get a sense of you know we're doing a lot of transformation of the     
26:34     
data and finding the sort of the I guess principal components of variation and     
26:40     
we're putting this in a in a common space and so yeah I mean I'm kind of     
26:45     
glossing over this but yeah it's you know what's um again     
26:53     
like marulas U who's one of the authors get you know know kind of start at this     
26:59     
trend and gradient based approaches yeah and um this is the first paper or well     
27:06     
this looks like you know his work applied to a nerve developmental dis or in this case     
27:15     
two so uh nki and Comm are just two kind     
27:20     
of like it's like 500 subjects data sets or is um     
27:28     
and um yeah and if you scroll just a little bit more you can just see the um     
27:36     
yeah that that that's the the it's using like a 200     
27:42     
parcel parcelation so that's that's how you're making that matrix it's probably like a 200 by 200 Matrix you know you     
27:51     
are taking like very small regions and then yeah yeah um     
27:58     
using something like that at that each of those locations um and yeah like again this     
28:08     
diffusion map embedding you know got some interesting     
28:16     
properties right they they yeah I I still don't know why they     
28:24     
they're not using the child mind Institution they' got you know again like that one's     
28:31     
got like 3,000 yeah yeah     
28:36     
but can I can ask them about that oh yeah it' be great uh so yeah this is     
28:41     
sort of the functional and structural embedding if you compare them and you know you have these it's the structural     
28:49     
diffusion and then resting e right right and then you have the coupling between     
28:54     
structure and function so there are a lot of things you can do here where you have you know uh you can make a     
28:59     
connection between when structure and function are coupled when the embeddings are very similar and you can extract     
29:06     
some principles out of that and those those are the the labels     
29:12     
kind of the kind of well-known dominant networks     
29:17     
that the seven networks that are typically extracted from resting     
29:22     
these you know dmn you know default mode Network you know say     
29:29     
things like that yeah yeah that's     
29:35     
um see so yeah that's that paper um and we have some other Hussein posted on     
29:42     
this GitHub repository AI powered 3D face detection rotation tracking so this is a lot of     
29:50     
stuff with uh face description body pose tracking hand finger tracking Etc is this a data     
29:59     
set or is this a yeah this is kind of a set of demos I     
30:06     
guess does does remind me of the Lisa Barrett Fel Feldman yeah um the     
30:16     
talk that she gave talking about her     
30:22     
um kind of academic career and how as a     
30:27     
young research she was sure she was she was going to finally solve the emotion Problem by by doing face processing     
30:35     
right right yeah yeah well looks yeah looks     
30:42     
like they have she found that it was more complicated yeah yeah it looks like they have a demo I'm not going to run it     
30:47     
but you can get capture your base you can run different models and that's it     
30:53     
or anything you put in the camera's view I guess uh or you can process images     
30:59     
that's a nice uh demo and then this is software that kind of allows you to do     
31:04     
this too so that's really interesting um yes is the human     
31:11     
Library uh so yeah allows you to do a lot of the stuff and and execute it either a web demo or like on process it     
31:19     
more fully so yeah you can do all sorts of things uh you know build an electron     
31:25     
app or you know do something virtual model tracking so it's great great     
31:33     
stuff yeah you know it's one thing neuros science a lot of people don't think about is like tracking the body     
31:39     
and the sort of embodied aspect of it but yeah     
31:45     
it's uh so yeah we have uh the brain image Library a community contributed     
31:51     
microscopy resource for neuroscientists so this is um I guess just kind of like taking a     
31:58     
lot of these data sets and putting them into a library uh things like the brain     
32:03     
initiative cell census Network which is we have a lot of different uh old brain     
32:08     
images and we can look at different uh neuronal circuitry patterns and cell     
32:14     
phenotypes and it yeah the the out of grow almost     
32:20     
anything of course that Celsius has been teaching or I should say Elliot Roth has     
32:26     
been teaching um uh we did the microscopy component this     
32:31     
this week and um uh you know there's some great great     
32:36     
resources you know if you're once you're um highly recommend Fiji     
32:44     
dosc which is kind of like the the imagej batteries included     
32:51     
version and then just lots of there's more and more kind of these um I don't     
32:58     
want to call them Foundation models but just yeah dat databases that that are becoming coming     
33:06     
online yeah and I I yeah I haven't I haven't     
33:12     
looked at that um the U the discussion that we had in the data     
33:19     
viz Channel about um I think it was the Allen Institute um cell Atlas     
33:28     
anyway I I haven't tried the zero zero respond about was asking if we actually     
33:36     
tried some of the the Allen Institute tools for for looking at that data set     
33:41     
oh yeah yeah I haven't gotten yeah and then of course going circling     
33:49     
back to neurog GPT oh yeah this is great yeah uh Hussein put this link to the     
33:54     
GitHub here where it's like the neurog GT sort of their stuff that they have here     
34:01     
this is this is great group from USC um and Richard Ley being the last author     
34:08     
who's the one of the kind of you know original developers of brainstorm so     
34:16     
wide widely used mat lab um Source Imaging package and um yeah this is U     
34:23     
this is awesome I think they've trained off of um uh     
34:30     
is it if you scroll down do this is it um the Temple University     
34:38     
Hospital let's see yeah okay data set yeah yeah so so T is templ University     
34:44     
Hospital e Corpus and then BCI competition I think is like     
34:49     
a it's an old that's kind of an old data set the the the T data set is is pretty     
34:56     
large um very long very long clinical     
35:03     
recordings so I I I think this this is I mean this is awesome you know and it's     
35:09     
awesome that they've released everything um you know I I would be interested to     
35:17     
to talk about how we just decide whether something's a foundation model or not     
35:23     
yeah you know like like again the people who using this term have been mostly     
35:29     
using text right you know which is you know     
35:35     
like the largest amount of data that we have yeah     
35:40     
yeah and it would be it would be good to     
35:45     
use um with the kind of competition in large     
35:51     
language model um large language models right now yeah um it's interesting to     
35:57     
see Charles Martin's kind of analysis of the weight     
36:02     
matrices using his Weight Watchers tool so he's he's using some of his you     
36:09     
know um statistical mechanics background or     
36:14     
condensed matter physics um background to to talk about you know the um yeah he     
36:26     
he can look at the in in in interesting physics ways yeah and you know I think I     
36:34     
think it would be good to do the same thing with some of the EEG you know Foundation     
36:41     
models um I think it's it's you know fine to call them models I I I I     
36:49     
hesitate to you know I don't know if you'd want to take these these particular models and apply them um fine     
36:57     
tune for language or something like that if you see what I mean     
37:02     
yeah but again like not not sure I've got the definitions     
37:08     
correct but this is this is really interesting what these guys done yeah so     
37:13     
you know briefly they're taking EEG data which are signals and they're putting it     
37:19     
into this encoder and they're getting learned embeddings and they have a mask as well and they're feeding it into a     
37:25     
GPT model which takes it embeddings and optimizes and I guess puts what do it     
37:31     
output a like some sort of reconstruction loss of the data or they     
37:37     
train it with data but you can do they do a query of the model uh or you know     
37:44     
what the I not not the yeah I would need I'd like to to     
37:52     
look at this more you know I I I because it's from Le's group I'm sure they're     
37:57     
doing something good yeah uh but it's saying we fine to the     
38:03     
model on the motor imagery task so it's the the you know the BCI competition 2A     
38:11     
data set that's down there the second data set right like like you know I I     
38:16     
gotta you know I I know it we use it in Moab which is the the mother of all BCI     
38:23     
benchmarks and um you know it's not a big data set     
38:30     
so um but but it's but it's fine too right     
38:36     
so you you at least know what they're trying to do with it right     
38:43     
um yeah I mean they're trying to get like they they have a lot of data they want to be able to get a good I guess     
38:51     
yeah yeah they' say that it's a nine nine subjects yeah okay well I mean yeah     
38:57     
you can have a lot of training data but you have to have something with good discernable features in order to be     
39:03     
useful if it doesn't really have the features you want then it's not going to be a very good Training S I mean so you     
39:10     
know just throwing data at it isn't necessarily the answer it's having good structured data is better I guess but     
39:18     
yeah Foundation model yeah we've been through that about you know the definition of those and what qualifies     
39:25     
as a foundation model and all that well yeah I mean so are they using large     
39:32     
language model there uh s maybe they are a GT GPT model they they call it GPT     
39:40     
I guess a GPT model yeah they don't really specify which version I mean     
39:46     
there you know there are a lot of different arge language models I guess GPT is just kind of like the generic form of     
39:54     
the different versions that have come out     
39:59     
and again you know your with the GPT model you have like basically some weights and some structure inside and     
40:06     
you want to you they basically with GPT say three or four they train it with     
40:11     
language the idea is you're finding sequences and you're putting together things from sequences and that's what     
40:18     
they're doing here we've talked about these with respect to DNA um you know     
40:23     
people have used DNA sequences or protein sequences even uh and plug them into L language models     
40:31     
and you know they're able to reconstruct things so if you query it with a you     
40:36     
know it's kind of like in bioinformatics we developed all these tools where you can query a gene     
40:42     
sequence and given like a full genome you can find the location of the     
40:47     
candidate locations of that sequence and you know that's that's uh those models     
40:54     
are I guess the idea is they can be improved with with a larger language model and that's kind of maybe the     
41:00     
principle here is where you have these EG signals that can be treated as     
41:05     
sequences and you know you build a set of tokens and you embeddings and then     
41:11     
you can put like a bunch of candidates like if you have like canonical SE or G     
41:17     
or EEG sequences you can make those as the output and you know you can     
41:24     
basically predict if you have any sequence you can predict maybe the state of you know if it's a sleep state or     
41:31     
something else that make sense yeah I I need to I need to give     
41:37     
this paper more time yeah I mean it's also got     
41:43     
um yeah it's it's got Kum jerby as well oh and so yeah Kum was in I think did a     
41:50     
sabatical with with Richard Le yeah this this might have been     
41:56     
the uh yeah so I just I just need to figure out     
42:02     
how they're using this the GPT     
42:09     
the or whether they're just using you know kind of the Transformer part there     
42:16     
right yeah yeah yeah yeah y sorry that's F uh trying to figure it out yeah yeah     
42:25     
we have a lot of interesting stuff in here um I'm not going to get into any     
42:30     
more of it because you know in interest of time did you have something you wanted to highlight     
42:35     
or um of the of Neuroscience networks     
42:40     
um the well just wanted to say I don't know if I talked about Med Arc before     
42:47     
but um that's a really interesting you know um Community     
42:52     
online that uh is working on some from     
42:57     
Ry let's let's call Foundation models yeah and you know so it's it's kind of     
43:06     
an ml it's an open ml [Music] community that is     
43:12     
um I don't want to say has the backing of but it it's got some people     
43:17     
associated with stability AI yeah oh yeah heard this and yeah like     
43:25     
like um I'm blanking on his name right now but um Paul Scotty is the head of     
43:35     
neuroimaging and AI at at um or at stability AI okay and um they've got um     
43:46     
I think I might have talked about they were working on a a brain Transformer model and what they mean by that is     
43:53     
really like can they can they develop a you know a neuro AI or a neuro inspired     
44:00     
AI model that's that's you know on some metrics is is     
44:07     
better um and you know just would Point people to that and say that there's     
44:15     
there's people working on a foundation FM model people working on some some     
44:21     
image some like like some other kind of you know Community projects under under     
44:28     
that on that server yeah that looked really interesting and one one of those     
44:34     
that that I really want to highlight is the EOG one so there is a lot of EOG     
44:40     
data and so that's that's you know in these are these be invasive recordings     
44:45     
right um but yeah and the next the next     
44:51     
meeting for that is June 3 uh and you know since join join the     
44:57     
server you can check out their notion um that has notes from their previous meetings and um you know I     
45:05     
think it's it's really interesting seems to be a stabil it's like you know     
45:12     
stability notion but it's medar yeah it's medar EOG Foundation model you know you can     
45:19     
check it from there um yeah events page or something like     
45:24     
that I I I've got to learn my Discord terminology as well     
45:30     
yeah oh yeah so that's yeah that's interesting definitely and like uh     
45:36     
stability AI they like run their whole thing off of a Discord server so it's     
45:41     
kind oh okay you didn't know that yeah I don't know what how it actually works     
45:47     
but like that's the basis of like a lot of their community and things like you     
45:53     
see more examples in Discord yeah I think they got a I think they've got a pretty good that might explain why their     
46:00     
their Discord um seems yeah is     
46:06     
is quite quite a well-run ship yeah     
46:11     
yeah um and um yeah I'm trying to I'm     
46:16     
trying to remember the the former head he gave an interesting talk as well um     
46:24     
the former head of stability is like seems to be applying his you know     
46:31     
he's left he's no longer CEO but I think he's doing some     
46:37     
work that's somewhat bof focused somewhat mental health focused that that     
46:45     
I thought was really interesting sorry I I'll see if I can find that talk     
46:50     
okay but I did wanna I did wan to um talk a little bit about the uh     
46:58     
the foresight uh whole brain emulation Workshop that was this week okay and it     
47:05     
was um uh you know it was very AI alignment     
47:12     
focused I I should say like like and I knew that going     
47:17     
in so um I wouldn't say you know I'd say maybe     
47:25     
like one of the talks were kind of you know perhaps like brain brain Imaging     
47:34     
focused or yeah not sure what the right terms are for     
47:39     
it but I think there's there is a big disconnect in terms of     
47:45     
what what is extractable from Nur Imaging really and     
47:53     
yeah well you there was a lot of focus on     
47:58     
on pricing out in a kind of back of the envelope     
48:03     
way um what it would what it would take to get you know like nanometer     
48:10     
resolution connectomic and um pH Phil Shu was there     
48:17     
who was on that Flywire AI paper um that done some work     
48:24     
using dropa connectomic and like like you know how how     
48:31     
much how much functional representation can you can     
48:38     
you achieve from structural connectomics right and     
48:46     
and you know yeah and I I think I think that     
48:53     
that was also problematic in terms of it's um     
48:59     
like like the Lessons Learned there um but but the main main thing being     
49:06     
that like there was a lot of discussion of of you know using large scale FM data     
49:13     
sets and not enough understanding that you know e fiz is statistical mapping     
49:19     
technique yeah you know like like we're we're we're we're definitely not doing     
49:24     
microscopy right you know and and it just not being really clear what um     
49:33     
um yeah what what information would come from that like other than you know kind     
49:39     
of foundation models for FM researchers you know and then then when the     
49:44     
discussion turned to well should we be using EEG and you know again there's this     
49:52     
popular you know popular idea that e G     
49:57     
represents brain activity right right which it does in the sense that it     
50:04     
represents the electrical activity of of some of the brain right right but but it     
50:12     
it's super important to remember that it's like we we we talk about it as     
50:18     
being um the the mass action of a particular cell type right so it's even     
50:27     
like what's the all you know like like the data set that we're talking about in data viz is like 3,000 cells or     
50:35     
something like like like I mean that's maybe like a mouse or something but but     
50:40     
maybe let's say that's human right like we're looking at one out of 3,000 cells     
50:47     
and and we can maybe talk about its connectivity to two other cell types     
50:52     
right in terms of a Jansen RIT model um um then we we usually have three cell     
50:59     
types in a Jansen RF you know uh we are not we are not representing the brain     
51:07     
activity right and and there's there wasn't     
51:13     
enough you know it's um yeah like like what we're trying to     
51:20     
extract with um Dynamic causal modeling or or techniques like that where you're     
51:27     
inferring physiology from the electrical signal it has to be the phys physiology     
51:35     
that's tied directly to one of those three cell types right right that's that's that we're making you know very     
51:42     
limited very limited uh I mean Dynamic CM modeling is all about shrinking your     
51:50     
um shrinking your expectations right in a     
51:57     
way you know right uh so that you can make modelbased you so that you have     
52:03     
model based analysis as opposed to you know what had been traditional in in     
52:09     
event related potential research which was kind of this wave shaped phenomenology     
52:15     
right and it was really you know foren you know pioneered extracting yeah like     
52:23     
like like again physiological you know information extraction from     
52:29     
from these farfield Babas signals um which which again I think is     
52:35     
I think is awesome but like that is not giving us you know um a complete picture     
52:41     
of of the brain activity right so um anyway it was good you know I     
52:49     
still I I don't know if we're going to um um have much success with with so     
52:58     
they they are uh offering grants okay and um I'm pitching organoid     
53:05     
intelligence okay as a as a stepping stone you know that that that     
53:12     
as or organized intelligence is is a research program you know that is     
53:20     
attainable um grounded you know like like extending um     
53:27     
extending our comput to include biology     
53:32     
would be a necessary first step towards any kind of um whole brain emulation you know     
53:41     
right um and or at least yeah as I said to many meeting like I'm working on my     
53:49     
pitch I don't know if it's convincing Uh u i I talked to Phil Shu about it who's     
53:55     
getting the first author on this that Berkeley paper and he's he said as developmental     
54:04     
as a former developmental neurobiologist I don't think that's     
54:10     
possible like ouch okay yeah um uh but     
54:16     
that was uh that was cool and it was great to see a bunch of people in person     
54:21     
like I'd never met Adam zaffron before yeah um and you know it's um he said     
54:28     
that he doesn't um he he started as a Nur imager but he     
54:34     
hasn't you know that that's not kind of what he does these days right and so I I     
54:40     
don't know but I do think we're gonna I might see him at     
54:46     
um excuse me he asked about um uh being in Tokyo around this around     
54:53     
just after hbm and um and I've got a a new University     
55:00     
Tokyo student Nar techx chapter so I think we're gonna I think we're gonna     
55:05     
meet up and he'll um we'll at least host a talk for him or something like     
55:11     
that so that was that was really great I got to meet Logan oh yeah yeah yeah there's a     
55:18     
there's Boston Boston's the Boston big chapter like like yeah yeah but no glad     
55:26     
you got to meet Adam and Logan soan yeah yeah so complete somewhat for     
55:32     
the lab I got to I got to have lunch with Logan and um and you know I think I     
55:41     
I I think I got him on board in terms of seeing seeing organoid     
55:47     
as as you know a very necessary First Step you know like like and I I think it     
55:55     
helps that he's so molecularly focused you know um in terms of you know it's     
56:04     
most mostly like Gene therapies and he he he was pitching a great program in     
56:12     
terms of electron microscopy and I mean sorry expansion microscopy and and and     
56:18     
you know em or like like high high res     
56:23     
em that I I still want to talk to him more     
56:29     
about in terms of the the kind of light sources that he needs for that em is the     
56:36     
kind of things that you only kind of find at National Labs but I think that would be really really interesting to     
56:43     
actually I think yeah I own a paper on something on that um but uh but that was     
56:49     
great um Patrick minol um so CCO of     
56:55     
neurom match yeah yeah yeah and um you know it was cool     
57:00     
too because some people were also like oh you you exist you're not like I only     
57:08     
I only know you online too so that that was um that was great and um Pamela     
57:15     
Douglas is someone that I I knew of via     
57:21     
the main Montreal neuro like AI neur science     
57:27     
meetings I think she was she was a keynote speaker and she's doing um tuss now     
57:36     
transcranial focused ultrasound and so that that is awesome for a group that     
57:42     
we're gonna have meeting here in San Francisco um and um that's the that's     
57:49     
the second student of Mark Cohen that I've met heard about in recent recent     
57:54     
days so this is this is interesting um and I'm trying to think any other um     
58:02     
outcomes from that oh yes um     
58:08     
[Music] so so because I was pitching organoid     
58:13     
intelligence um the few people who knew what I was talking about     
58:18     
and came up and one of those is um is a UCLA student and he's going to uh     
58:27     
Michael levans lab this summer okay yeah so um so I'm hoping to keep in touch     
58:35     
with him also here yeah like like yeah as as Michael uh expanded his uh his     
58:43     
interest to include organizes at this point but it was really great to talk to him about yeah what what he's been doing     
58:52     
uh himself just like he he's bu quite a quite a setup in his garage or his     
58:59     
apartment oh wow like like yeah yeah really interesting you know sort of in     
59:06     
the kind of dish brain um like level like not organoid culture     
59:12     
but it's a you know 2D neural network right so it's like     
59:20     
it's a bit more than just neurons in a dish like there's certain amount     
59:28     
structure yeah and yeah anyway that that was that was that was great and um and     
59:36     
you know following up from the Discord from the cortical Labs Journal club uh a     
59:43     
week ago I'll be meeting with the one of the students that presented there too um     
59:49     
so he and he's one of the undergrads of the brain engineers at UCSC so     
59:57     
it was it was definitely it was definitely good to go to the meeting um     
1:00:03     
I did have to I you know I've got a lot to say about AI alignment oh yeah but I     
1:00:09     
don't I don't know if that's yeah this isn't maybe the venue but um     
1:00:16     
uh yeah and I'm gonna stop there so yeah I I     
1:00:23     
wanted I know you had put some things in the slack so what channel was That where they where you had the images from the     
1:00:30     
event oh uh cognition features I think um you know and here we go yeah     
1:00:39     
the um this is Adam s there's Adam yeah yeah Adam's great I mean you know um     
1:00:49     
there he's pitching his um his take on     
1:00:59     
on I think he had the the closest to our kind of Developmental AI approach you     
1:01:06     
know but but it was very much about how how you know like development     
1:01:13     
or like like raising a child how do you how do you instill empathy and     
1:01:23     
um yeah the the how do you instill the the the values that you     
1:01:29     
want um your child to have you know did     
1:01:34     
he is he mentioned like any like projects that he's doing with that or is he     
1:01:41     
just so so as I as I said in my notes like I felt like he made a pitch for     
1:01:48     
just the difficulty of this in terms of you know like we shouldn't be surprised     
1:01:54     
this is difficult because we don't really know how how best to do it with our own     
1:01:59     
children uh and you know that that everybody's talking about these you know     
1:02:06     
these um quite high goals in terms of thing     
1:02:13     
right and that like like it would obviously yeah but um but then he was     
1:02:18     
really saying like if you are doing something along these lines or if you're     
1:02:24     
doing something um with large language models that um that really speaks to     
1:02:34     
their um their ability to capture World models please get in touch because I've     
1:02:41     
got this this special issue you know I've got this RFP     
1:02:48     
um I forget I forget what he calls that is it a special issue yeah it's it's a like he mentioned that uh they're doing     
1:02:55     
doing the special issue and they're going to do like two installments so they're trying to get like as many papers as they can and but yeah it's     
1:03:04     
like a special I guess compendium and it was a good it was a     
1:03:10     
good time to to pitch that because again like this meeting was super heavy on AI     
1:03:18     
you know AI related or adjacent people and not so much you know nerve imageries     
1:03:27     
right but there I mean there were some there were some people that were kind of     
1:03:33     
doing neuro AI right you know like like some some some good examples um yeah I     
1:03:41     
didn't know Andre Sandberg should I know yeah I don't know but okay anyway I I     
1:03:50     
but um I I liked I liked again like Adam's pitch you know as I like the     
1:03:56     
whole RFP or at least the the the papers that he's got listed there you know in     
1:04:02     
terms of you know how how much how much of a world model is developed by a large language model and how how usable is it     
1:04:10     
as an aid for you know like Discovery right so yeah this whole idea of Marcus     
1:04:18     
Kaiser was on there yeah probably you know yeah but yeah I didn't     
1:04:25     
I didn't yeah you didn't see him there I I should get in touch with him but um oh Andrew Payne was there yeah E11 bio yeah     
1:04:33     
yeah I mean there's definitely some some people doing I I didn't see Max     
1:04:39     
there um okay okay this is um I should     
1:04:45     
have looked at this but um yeah there a lot of interesting people here oh yeah I     
1:04:51     
mean so great oh yeah sharena of course um it was a lot of you know a lot of     
1:04:58     
great people um I didn't see John cumbers there but I did see some AE     
1:05:07     
Studios anyway it was     
1:05:12     
um it was nice as to to pitch organized intelligence there yeah so this whole     
1:05:19     
brain emulation thing is kind of fascinating I mean the history of it is kind of science fictiony but like     
1:05:26     
what I mean do they have like sort of is it a unified field or is it just kind of     
1:05:31     
this Pie in the Sky idea what what's going on well well I think it's one of those things where you know it's like     
1:05:38     
it's like AI safety right yeah where it's just like there's there's actually like a thousand ideas of what that is or     
1:05:45     
you know and and you know you you say you say alignment and it's just like     
1:05:51     
okay what what do you mean by uh um and you     
1:05:58     
know there there was um um Lisa thei grp um forgive forgive     
1:06:07     
me if I I got her last name right wrong but um the     
1:06:13     
um she was she was saying that what we mean by AI alignments is actually the     
1:06:19     
Benchmark that we're proposing right which I which I thought was much more     
1:06:24     
prac I much prefers to be talking about the particular but you know like like     
1:06:29     
again like that's we can't we can't see into these models so obviously what     
1:06:35     
you're what you're actually talking about is what are your what are the metrics that you're using right and um it was also nice to     
1:06:43     
see her because she's a she started the nech X chapter in Germany okay so that     
1:06:51     
was it was nice to see some more NCH ex people uh but uh yeah and Randy con     
1:07:01     
um with carbon copies like you know together together with um he had an     
1:07:09     
archive paper that he did with Logan right book like like the day before the     
1:07:14     
workshop like hit hit archive yeah and you know and like their     
1:07:22     
proposal was you know super Imaging Focus you know it was a it was a very grounded physics proposal or you know     
1:07:29     
physics plus expansion microscopy so whatever you want to call that kind of you know molecular approach to to change     
1:07:37     
the cells and make everything more imageable     
1:07:43     
right make make the structure more IM imageable is very practical proposal I I     
1:07:49     
would just say that like that was you know it's still like a connectomics     
1:07:54     
proposal right where it's a structural Imaging proposal you know and and that     
1:08:04     
um what I was trying to say was that like you know Imaging does not equal     
1:08:10     
physiology right and that what we're you know what what     
1:08:15     
you what I see microscopists doing is trying to um is is trying to     
1:08:24     
use molecular cellular techniques to to highlight a very small aspects of     
1:08:32     
physiology right you know it's like like that's that's that's that's best they     
1:08:39     
can do with you know Advanced is like four     
1:08:45     
chro you know four chromophores something like that you know and and so     
1:08:52     
you you you're taking just a very narrow narrow slice of physiology and and kind     
1:08:59     
of highlighting that or you know trying to fix down a number of other things so that you can highlight say something     
1:09:06     
concrete about a little bit of physiology and you know that x-ray is     
1:09:12     
just not even coming close to that you know um but it was good you know like     
1:09:18     
again like Logan you know is is super um     
1:09:23     
yeah he's super smart super you know like super receptive to new information so he he wasn't familiar with big brain     
1:09:32     
project so I I I think it would be great for him to spend some time with that data set and     
1:09:39     
see like like how much can you get from you know big brain exists right so there's one brain at that this kind of     
1:09:46     
resolution that exists you know what what can     
1:09:52     
you yeah what what can you do fly are like yeah yeah he's totally he's smart     
1:09:59     
he's a smart cookie uh um and you know like like I     
1:10:06     
don't see enough I mean I I don't see you know the like     
1:10:12     
last big brain Pro um project meeting in Iceland like I don't think anybody was     
1:10:20     
trying to infer function or physiology from     
1:10:25     
from the images right it was it was still very much a catalog right you know     
1:10:32     
yeah yeah that's uh yeah it's always a problem like we have a lot of these     
1:10:37     
atlases and they're just kind of like cataloges it's like you look up something you you characterize something     
1:10:44     
there isn't any more like analysis than that and like the analysis is really     
1:10:50     
kind of the standard analysis if you do do an analysis so it's kind of like what     
1:10:55     
are the ways that we can uncover the physiology um and almost suggest that we     
1:11:00     
need new analyses to be brought to bear or have tools that would allow us to make sort of easy to make statements so     
1:11:08     
you could just plug in like an analysis and say this is what's going on with the D these data if you ask a question and     
1:11:15     
you can get an answer maybe that's not maybe that's a little bit there's a cave out there     
1:11:22     
which is that we don't want a analytical model we can't observe you know we can     
1:11:27     
just ask a question then it's an uninformed answer but um but no I mean     
1:11:32     
like a lot of the atlases are still at the stage of just kind of describing what's there and that's it right right     
1:11:40     
yeah yeah that and that was yeah like like I I thought it would be good for     
1:11:47     
him to look at some of the talks about big brain and just like like they're     
1:11:52     
actually dealing with this this kind of d data what are the problems that they need solve solving right now you know     
1:12:01     
and um as as well as kind of pitching the the James Glazier you know at all um     
1:12:09     
open Virtual tissue umbrella right so like compell 3D     
1:12:16     
physia Cel you know Morpheus you know all these tools that that are     
1:12:22     
are would be again like a necessary first step towards you know trying to go     
1:12:31     
from yeah trying to give structure agency and Physiology right     
1:12:39     
like like you know um anyway that was     
1:12:46     
um uh yeah so yeah so yeah that's great so     
1:12:53     
I'd like to move on to like uh had a what okay uh Jesse had an update here so     
1:12:59     
he said Snippets of updates for me lots of work on Joe Pro administratively so     
1:13:04     
yes uh I'm glad to see Joe Pro coming back into the view uh we've been doing a     
1:13:10     
lot of stuff with our open source uh meetings yesterday we had a very good     
1:13:15     
meeting where we had a lot of people presenting on their work which is good     
1:13:20     
and we're going to be doing that over the course of the Summer where we're going to have you know we're just going to ro kind of get our ideas out there     
1:13:27     
and hopefully it'll drive some work you know and and we can have some good things by the end of the summer but I     
1:13:33     
think Joe Pro is an essential part of that because you know there is this mentorship aspect that I want to cover     
1:13:40     
and I want people to know kind of these professional norms and aspects of things     
1:13:46     
like that so um there's mentoring work and development also I'm appreciating     
1:13:52     
the break from cognition Futures yeah we've taken a bre from cognition Futures and you know Jesse's had you know he's     
1:13:59     
trying to finish up his program and other things so I I think that's a good     
1:14:05     
you know break we can take some perspective on what we've done in the last year we've done a lot of stuff     
1:14:11     
there in that group and um you know we kind of move from Reading to reading but I think going back and reflecting on it     
1:14:18     
a little bit is important um the inclusive gaming conferences yield a lot of positive     
1:14:24     
content tax yeah that's good plot Twisters is still on break but looks to do more later in the summer so yeah we     
1:14:32     
we I guess we did we ever publish the inclusive gaming conference uhst no um that's one thing     
1:14:40     
that it's it's basically ready I have to submit it to the medium but um yeah that's that continues     
1:14:48     
to be I know I kind of talk about it U maybe glowingly but it's um     
1:14:55     
just just uh because there's there's some other things I'm trying to do through uh Joe Pro that that that people     
1:15:04     
from there uh you know fit well with so     
1:15:09     
that's been really great but also um I think it     
1:15:17     
will it it it's interesting to talk about plot Twisters right now because there's sort of this um     
1:15:28     
it could be a huge summer uh but like I I can only predict     
1:15:33     
or say or allude to or do so much right now so it's kind of this it's kind of     
1:15:40     
this like what you know I'm kind of on this holding pattern about it but like     
1:15:45     
I'm I'm really so much I'm I'm I'm so glad and that I went to that event um it     
1:15:53     
just has had so much good stuff continuing to come from it um and I can I'm kind of like having to dis     
1:16:00     
disseminate it very it's almost I almost feel like I'm     
1:16:06     
I'm laundering like money like I feel like I'm laundering outputs from it very     
1:16:11     
slowly um but like it's been it's been a great great thing um excuse me and and     
1:16:18     
and you know more about plish as as it comes to but the post will be there I think I think maybe maybe next week I'll     
1:16:25     
submit it or over the weekend Memorial Daye whatever stuff     
1:16:31     
um and then I guess the last part of that was yeah Nick Wick um you know um     
1:16:38     
it's it's been it's been interesting and fun experience to chair a very small conference or be I'm I'm like the lowest     
1:16:47     
uh at least like I I'm kind of along for the ride in terms of being the coach chairs like there people much more     
1:16:53     
experienced than I am there but it's been great to to see what that's like and then deal with the venue it's     
1:16:59     
because ni ni was specifically has very specific venue sort of requirements so like that part     
1:17:06     
of why and how does it relate to being a firsttime event and the community that we're trying to serve and and the region     
1:17:13     
like all these Packers are at play but it's it's exciting you see people who are and this can kind of tie into     
1:17:21     
um you know one of the things I wanted to do with show Pro also is not just a     
1:17:26     
mentoring service but also uh um it's like Mentor training like training other     
1:17:33     
mentors in certain things um and building off of some of our pedagogical     
1:17:39     
like a lot a lot of things just just to put this sort of on the record or to say     
1:17:45     
this in an acknowledgement sense um like long     
1:17:51     
before um well we don't we don't really talk about     
1:17:57     
it as much in the last year but there's sort of the educational Banner of the lab would like all the stuff about mind     
1:18:04     
maps all the stuff about teaching you that that was like a major thing it wasn't like I     
1:18:10     
feel I know we we kind of mentoring and GoPro we kind of throw them together now but like that's something that's been     
1:18:16     
here for a long time and I've always appreciated that um and I I had the Good Fortune of a long time ago par     
1:18:22     
participating in a very very good like just general leadership development program When I Was An     
1:18:28     
undergraduate um and and there's just sort of this interesting evolution of     
1:18:34     
things that's happening in that space and I feel like I'm I'm looking to     
1:18:40     
to tailor some of the stuff that I'm doing not just for like oh you can like sign up and get get mentorship stuff or     
1:18:49     
or like be a mentee um like like almost like a Google summer code you know like not just be a     
1:18:56     
contributor but like how do you how do you deal with being a mentor     
1:19:02     
as well specifically um and that's something that's come about a little bit more     
1:19:08     
recently as things I want to pursue um so nothing to really say about that     
1:19:14     
right now but I think that's something that I see a lot of doubling back over things that we've done in the past in     
1:19:20     
the lab a lot of our um yeah event the like the things we'll discuss during the     
1:19:27     
open source um and even here in the Saturday meetings too but open source Friday discussions too will leave into     
1:19:33     
that but just like that's that's of what's happening and then also like like     
1:19:38     
I'm I'm I'm deciding to like really update Joe Pro's like website and web presence U like we've talked about the     
1:19:45     
DSM project a lot but formalizing that into okay like there's a new structure I'm trying to do a lot of things with     
1:19:51     
Joe Pro with it's not just mentoring there's there's sort of a whole set of I'm basically going to call them     
1:19:58     
working groups um like like cognition Futures is kind of like the original one     
1:20:03     
like that that's essentially a model for things that I'm going to be doing with a bunch of other topical areas and you     
1:20:10     
know a major goal of it is like some Niche Niche Niche things but also just like ear like specific early career um     
1:20:19     
access to getting some functional uh like research support in     
1:20:27     
them like it's not it's not I'm not an expert in all these fields and and I'm     
1:20:32     
I'm working with some other people to get those like who are more expertise to do certain things but like it's not you     
1:20:39     
know it's not a it's a different kind of a thing and it's very targeted um at at     
1:20:45     
like certain a access to certain things and developing certain things and it's been exciting it's just taken a lot of     
1:20:51     
work um because obviously there's other stuff going on in our lives and in my life too so um but like that's that's a     
1:20:59     
little bit of a uh a little bit of a deeper update about     
1:21:05     
things um so I'm kind of went up and down that paragraph but to go back down to Nick Wick um it's been it's been     
1:21:14     
really I really appreciate the the experience of being part of that group now and like doing I kind of came in at     
1:21:21     
this point last year in terms of oh fre conference and I was like yeah I really want to do more this year and I kind of     
1:21:28     
done with them into the whole a whole tour and now it's it's kind of the Next     
1:21:34     
Generation and it's it's just exciting to see the people who want to make that Community better and we're kind of at a     
1:21:41     
little bit of a Crossroads in terms of okay do we want to just have this     
1:21:47     
like two-day event that Corell has been at for a long time um and I've been at     
1:21:52     
since 2019 or do want have a few things like maybe a more active LinkedIn group     
1:21:58     
or something that engages the community Beyond just that day and so that's     
1:22:04     
that's sort of one thing that we're dealing with and it's sort of the The Challenge and kind it's very it's kind     
1:22:10     
of like a lot of Open Source projects forly whereas you have this challenge of hey it would be great to do this we have     
1:22:15     
people who want to do this we have talent we have interest then it's like okay is it sustainable and what do you     
1:22:24     
put but like what do you want to build out that may wash away and you know the End of Time the ever flowing time and     
1:22:30     
changes so it's like you have to be careful because if you try to build too much it blows away then you lose all you     
1:22:36     
know it fades out and then it look like okay you got it's almost like you're taking a step back even though you had all this good stuff going so we're we're     
1:22:43     
dealing with that part of it um and you we'll see where it goes but the it     
1:22:49     
continues the the core event was really great this year I didn't attend in person I think I showed many of the     
1:22:55     
Great posts but we're still getting wonderful LinkedIn posts particularly but also feedback but I'm really happy     
1:23:02     
LinkedIn post with people talking about their experience getting used to talking about uh what they did and and and the     
1:23:10     
event so it's like hosting these spaces that let people have these firsttime     
1:23:15     
research experiences that let people have a sense of community that let     
1:23:20     
people get uh professional a technical and some Community Support like that's I     
1:23:27     
think that's huge and like that I'm really happy to continue to to be a part of that and and hopefully um continue to     
1:23:34     
to make the sort of onramps in British the things that um will blow matter     
1:23:39     
especially ahead so that's that's kind of my uh wrap about that um I don't know     
1:23:45     
there's any questions but it's U that's my update on those     
1:23:52     
things it was great to see that that paper supporting     
1:23:57     
supporting you know the importance of mentorship keeping people in     
1:24:06     
Stam yeah it it it it matters um and like I I'm not gonna I'm gonna be very     
1:24:14     
dis very very very um vague about what I say next but I I have been in a ma like     
1:24:23     
really good environments with really really talented people and really really you know good     
1:24:29     
good institutions or like good enough institutions and good enough but there's just certain things     
1:24:37     
that happen that turn people totally off and it's like unless you can communicate     
1:24:43     
to those people hey this isn't on you this isn't your fault or this isn't like there's forces that played that are     
1:24:49     
Beyond you and what your contributions matter um and get them opportunities to     
1:24:55     
do this stuff like there's there's such a very clear one of the things I I love to write write more about like is baked     
1:25:03     
into the some of the efforts that I'm doing is like those those moments and     
1:25:09     
those things really matter uh because a lot of like I I have very strong     
1:25:16     
memories and in recent experience with people who are like really really talented or just passionate people like     
1:25:22     
who want to do great things in a field to study or in the world or whatever and     
1:25:28     
they don't quite know where to go or they've just     
1:25:33     
received a lot of like negative energy and feedback and it's like uh okay so     
1:25:40     
it's basically you just like tuned them out totally so how do you deal with that as a mentor     
1:25:46     
or someone a supporter how do you deal with that as someone who doesn't have a mentor like how do you you know all     
1:25:52     
those things are are kind of on on uh those are that's not everything I'm     
1:25:57     
doing but like they're foundational elements to like a lot of the spaces I'm talking     
1:26:05     
about yeah yeah yeah I'm I'm also just thinking of     
1:26:10     
that um the I think somebody shared an     
1:26:17     
article somewhat recently about just um how how to survive an     
1:26:22     
Academia something and I just reminded of this um this tweet that um the the     
1:26:29     
woman who who won the Nobel Prize mRNA um at     
1:26:35     
upen yeah yeah yeah it's just um somebody was was had a snippet from her     
1:26:43     
book and you know and it was H it was a brutal description of Academia     
1:26:51     
yeah and and you know and sort sort of saying like like you     
1:26:58     
know we we we all know that this this is true like like there should be yeah more     
1:27:07     
more mentorship for for just you know     
1:27:12     
the um um but um some     
1:27:18     
somebody there was like how to survive in Academia I don't know it was maybe it     
1:27:23     
was on Twitter I think it was on professional Dev maybe I don't know I remember I remember     
1:27:30     
but I don't remember where it was posted okay but yeah and then then I saw this on Twitter in terms of just her her I     
1:27:38     
mean she she she she was she was talking about the transition from you know PhD student to to     
1:27:48     
professor and like like what what it what it what it meant to be a professor     
1:27:54     
um um but that there should be you know anyway yeah yeah mentorship is important     
1:28:01     
in a bunch of different levels and it's good to remind the     
1:28:07     
anybody who's who is interested in can do this Nur match is looking to to match     
1:28:14     
people with more with mentors yeah I got emails about that unfortunately it's unpa it's not voluntary it is it is and     
1:28:24     
you know like like like so many of the positive um the     
1:28:31     
positive aspects of Academia it     
1:28:36     
is yeah which says a lot about the in I think the the mentoring I was     
1:28:43     
actually gonna mention us I'm GL that you did Morgan I think the mentoring is kind of like a     
1:28:49     
couple like it's just spending an hour like having a mentoring session so it's     
1:28:54     
not like a big commitment for what I just actually just applied to one of the things for it um I wasn't G to do it but     
1:29:02     
then it's like I think I'm going to be free during one of those things so we'll see we'll see how that hopefully you     
1:29:08     
know see how that goes I don't know it's in separate from it's one like career this one there's like being a mentor or     
1:29:15     
like I forget what they call it there's like being the TA I guess that's a TA the TA the TA is are paid position but     
1:29:21     
the mentorship the mentorship is sort of the like this talk about you know living     
1:29:28     
it um so that's cool um but yeah shout out to NE mat for T     
1:29:35     
like I just finished the application earlier and I was like oh yeah like I had this flashback to like to 2020 2021     
1:29:43     
when there was the conference and and all that stuff like wow like you guys you know they they're trying to I I'm     
1:29:50     
not that I don't quite understand some of their organizational structure yet it looks like they're trying to spin off     
1:29:55     
into like hey we can do Research Services too I saw some post about that anybody see that yeah so so again like I     
1:30:04     
I think they are trying to also come up with ways to get paid yeah yeah yeah oh     
1:30:09     
yeah absolutely you know but but like you said like you     
1:30:15     
know again like what got them started was the community coming together and     
1:30:22     
saying like hey you know what we can actually organize we can organize conferences in a in a more you know     
1:30:30     
inclusive humane way right you know and and and yeah and and potentially provide     
1:30:39     
course workor provides you know other other opportunities I loved the the old     
1:30:46     
school Nur match where it was just put us in a room and give us some give us some uh questions to ask each other to     
1:30:54     
have a conversation and just you know meet meet people from outside your your     
1:30:59     
particular [Music] discipline um yeah yeah     
1:31:08     
yeah all right um so yeah did US did you have an update you want to share oh yeah     
1:31:15     
my apolog for being Mia I was in the meeting um had some personal stuff so just turned off my camera for a bit but     
1:31:21     
I've been following along so yeah um no yeah thank you all for the updates on everything and things are going fine so     
1:31:27     
I already spoke with I think Morgan wasn't here yesterday but I did give some brief updates regarding the uh um     
1:31:33     
the couple things I'm working on including like my volunteer work for the startup for alter learning the educational Tech startup which is you     
1:31:39     
know so that has nothing to do with oral I'm just working there but things are taking off there but more importantly U as it relates to us um I so yeah excuse     
1:31:48     
me the startup with alter learning things are taking off we're now almost at the point where we're not going to be a startup we're going to be a business     
1:31:53     
and they've confirmed um like we've got investment offers from DCS it's about when not if and we're getting very very     
1:32:00     
close but um you know everything really depends on you know our ability to function and cooperate and get the job     
1:32:06     
done as we need to so and more importantly for this lab I've been working with uh under dick under Dr     
1:32:13     
Richard Gordon meeting with him once a week having some pretty uh pretty strong updates between me and him we're doing a     
1:32:19     
lot of simulation work on the so just just to briefly recap this is on the polycapillary approach to X to     
1:32:27     
polycapillary x-ray approach to breast cancer detection being able to optimize the performance of how we can steer     
1:32:33     
Dynamic x-rays by performing simulations using um 2D and 3D software like mat lab     
1:32:39     
octave unreal and see how we can adopt them to uh calculate and process     
1:32:44     
information more effectively and take advantage of machine learning approaches like treating it like as a compression     
1:32:50     
problem and classification and clustering analyses and ultimately make the um make the problem of make excuse     
1:32:56     
me ultimately make breast cancer detection much more efficient much more effective much more easier much more     
1:33:03     
reliable and um yeah yeah uh this is definitely something that could lead to being patented to having a startup     
1:33:10     
that's why we're reaching out like Morgan mentioned somebody named stepen Alward as an expert in machine learning     
1:33:15     
to reach out to um he is not g back so basically I'm asking um if anyone knows     
1:33:22     
an expert in machine learning I posted about this in SL last week     
1:33:27     
um uh we are excuse me we're looking for any in oh in Monte Carlo simulations     
1:33:33     
Monte Carlo simulations excuse me um I mean machine learning approaches as well ultimately Monte Carlo simulations     
1:33:39     
that's what we're looking for so being able to expan things in that direction um is uh you know by taking advantage of     
1:33:47     
like the robust Computing resources and seeing where things go seeing where things head because this is this is really exciting because I feel like I'm     
1:33:53     
at the Forefront like publishing papers because we are publishing book chapters and papers from this too so I'm writing     
1:33:58     
a lot as well and it's going to be something that turns into a startup into a venture capital idea and that's so     
1:34:05     
that's really exciting too so I'm being able to leverage both things as I need to and yeah ultimately the one thing     
1:34:10     
I've learned is octave is somehow worse than mad lab and no octave I I am sorry like it's     
1:34:18     
it's it's um maybe not as bad as for Trend but it's it's pretty down there pretty     
1:34:24     
closely down there um if anything I'm just trying to move forward to like Julia python but you know like Julia is     
1:34:31     
great because Julia may be high level like python but Julia has a lot of functionality I know if you really want to get down to lower level things you     
1:34:37     
know you should embrace C and C++ for maybe like particular scripting language that has some specific ways of defining     
1:34:44     
like like pointer variables or like um like a like specific structures and     
1:34:49     
variables But ultimately what we're doing probably doesn't need to get that low like we're not um this isn't but one     
1:34:57     
thing I will say and point out as it relates to like a mathematical foundational theoretical approach if it does turn out that um this     
1:35:05     
depends on different actual laws of PHX and theoretical constructs themselves     
1:35:11     
then on some level I might even need to make my own language to make this work I know that sounds crazy but it does     
1:35:16     
happen people do that you know or um see see what needs to be done from a computer scienceprogramming     
1:35:23     
scientific slath point of view and everything moving together so we can make breast cancer breast cancer     
1:35:29     
screaming more effective see this it's like it's like trying to move a tree by     
1:35:35     
looking at the leaves and The Roots and everything all together and you got to move that tree so yeah um anyways it's     
1:35:42     
really exciting really really exciting stuff and um dick has some let's let's just say he's like he has some     
1:35:48     
interesting takes on things I'll just say that he's he's quite the character to talk to he's quite the person one to talk to um yeah     
1:35:55     
um yeah it's exciting stuff exciting stuff so I'll keep you guys yeah that's     
1:36:00     
great might try in um uh the slicer 3D     
1:36:09     
Community I'm just trying to trying to give you a forum where yeah you know     
1:36:15     
that that instead of just trying one person you can you can you know ping     
1:36:20     
ping a community that is is very Radiology um yeah you know familiar     
1:36:28     
familiar with all the kind of things that you're um you know the problems that that     
1:36:36     
you're facing in mography and and would have you know     
1:36:41     
would have good suggestions you know it's it's develop it's a development Community all of all the approaches to     
1:36:48     
breast cancer detection you know you got some ultrasounds mography this is CT computed tophy so this this     
1:36:54     
St yeah you know and it's ultimately like you know that this like 50% of the     
1:37:00     
human population is going to benefit from this I mean easily among them like it's so relevant so topical and uh hard     
1:37:07     
to understate it's uh it's relevant so so yeah yeah really exciting stuff um     
1:37:14     
the people I talk to about this they always want to know like is this going to make breast cancer screening breast cancer detection like easier on the     
1:37:20     
answer is it is it is it is but that's what people want to hear you got to show     
1:37:26     
so yeah well that's great that's great work I look forward to seeing more of it     
1:37:31     
when it's at a better stage or more advanced stage um and yeah the struggles     
1:37:37     
with programming languages are always a problem if you want to you have to kind     
1:37:43     
of pick the right language for your problem or you know and then don't worry about like the you know whatever an else     
1:37:49     
is using because as it turns out it's it's more problem is frustrating the academics they they     
1:37:56     
want to learn whatever programming things they can for their scientific mathal problems yeah computer scientists like the theoreticians and the people     
1:38:02     
that are more lower level they make things for kind of different purposes you know maybe as it could follow from     
1:38:07     
the advaned in Hardware architecture by you know the you know the new like a new     
1:38:13     
like a new computer that comes out can that use takes advantage of say for example Quantum Quantum Computing then     
1:38:18     
you can actually make new programming anges based off of the new problems that you can solve by that sort of thing too but it's like at least for myself for my     
1:38:25     
Approach I need to be asking like where is this project heading how much can I devote to different sort of tasks and     
1:38:31     
aspects and see how I can leverage those as effectively as I can so you know ultimately that's what I'm going through     
1:38:36     
but like realistically given how even with advancements like from from like the actual languages perspectives right     
1:38:42     
like with like Julia python R mat lab octave you know all of them with their own limitations and what they can do and     
1:38:49     
what what can happen if we would just benefit from something new it's it's tough it's tough to tough to show that     
1:38:55     
but you know things can happen things can happen whatever happens happens so yeah yeah it's always a challenge I know     
1:39:03     
that uh when I talk to Dick about like a lot of the stuff he's doing with Mathematica he's always frustrated     
1:39:10     
perpetually because Mathematica is very poor support and you know allows you to     
1:39:16     
do some things but not others and so it's like shifting between languages is     
1:39:21     
sometimes a little tough but sometimes you have to do it to get the sorts of things you want to do yeah I thought     
1:39:28     
octave would be easier to use now it's just as convers um like uh I mean ideally     
1:39:38     
ideally I would like to create like a like a software gooy     
1:39:43     
interface you know being able to input data everything itself as you need specifically for this form of breast     
1:39:50     
cancer computed tomography I would like to be able to do that and um you know I probably wouldn't need     
1:39:57     
to go so low level other than maybe like cc++ uh if that would to happen but you     
1:40:02     
know whatever happens happens so yeah yeah so thanks for that update uh     
1:40:09     
looks like Aaron is here I don't know if Aaron wants to say anything or put it in     
1:40:14     
the chat or hey everybody just grateful to listen in I'm having a busy morning but I could     
1:40:21     
use the uh intellectual stimulation while I do a bunch of chores so I'm I'm     
1:40:27     
using you all thank you for sharing everything you're working on oh no problem yeah thanks for uh attending     
1:40:34     
yeah things are going great for you yeah okay yeah always good to stop     
1:40:42     
by um and um yeah I just did a bunch of     
1:40:47     
updates I think before everyone was here on like and just and nickx and Joe for mentoring things but I I'll I'll recap     
1:40:54     
those later or catch up with Aon yeah um yeah I didn't know um were you g to do     
1:41:02     
like papers next Bradley or what yeah I'm gonna do a a feature of several papers and okay so     
1:41:09     
yeah uh did you have anything before we do that or no um     
1:41:17     
I I basically said said what I all I need to say right now but I'll I'll call     
1:41:23     
up those things um more ahead to so you know really we were going     
1:41:29     
through the uh Neuroscience Network's Channel and we were talking we found this threat of like large language     
1:41:36     
models and you know kind of comparing them to brains and and their uh you know     
1:41:42     
brain Imaging and things like that and there's a sort of field of um machine     
1:41:49     
learning and looking at neuros neuroscientific data so people have been     
1:41:54     
trying to do uh take networks as they learn look at the weights of those     
1:42:00     
networks and then map that to like neuroimaging data and I've actually     
1:42:06     
mentored a couple projects in uh neurom match where students were doing this where they would take like some Network     
1:42:13     
they train it it was some deep Learning Network with a bunch of layers they'd go to sort of some Neuroscience data where     
1:42:21     
you have either layers of cortex or some brain Network and there are some tests     
1:42:28     
you statistical tests you can do to see how the different layers correspond to different parts of the brain and how     
1:42:34     
they process uh information during a task and it's interesting work it's not     
1:42:41     
necessarily very interpretable because we don't know what that means does that mean that they kind of share a     
1:42:47     
structure uh or does that mean that they're doing similar things or what is that means um it it certainly doesn't     
1:42:55     
mean that they're kind of a onetoone mapping we know that because the brain is much more complex than a deep     
1:43:01     
Learning Network but we know that like there may be some shared features and so     
1:43:06     
we talked about the feature space uh you know uh previously when we were talking     
1:43:12     
about some of those papers where they were trying to develop this representational space this lower     
1:43:20     
dimensional space where you can understand some of the sort of featur features of these networks and so it's     
1:43:27     
all very hazy at this point but there's also this discussion and maybe it's not     
1:43:32     
a very good discussion about like how uh neural networks how large language     
1:43:39     
models are sentient or how they exhibit sort of aspects of uh intelligence or     
1:43:45     
cognition or whatever and so that that's another controversial area but I guess it depends on that mapping between     
1:43:53     
the artificial networks and maybe real brains doing things so the reason I'm     
1:43:59     
saying all this is because I'm going to present a series of papers that are going to go through sort of large     
1:44:06     
language models and then biological modeling and then some other things so     
1:44:11     
why don't we get started here I'll share my screen and get     
1:44:19     
going so this is uh something that anthropic put out uh a couple days ago     
1:44:25     
and it's this resource on mapping the mind of a large language model so again     
1:44:31     
like I said you know we have these models and they generate we can train them on real world data and we can     
1:44:37     
generate this uh latent space and we can actually uh you know analyze a brain     
1:44:43     
Network and we can create a a a feature space there and we can kind of map     
1:44:48     
between them we can look at different aspects of the network uh the networks might share motifs or other types of     
1:44:56     
features and you know that's something that we can kind of draw parallels what     
1:45:01     
they're saying here is they're trying to map the mind of what a larger language model is so you have these networks that     
1:45:08     
you're you're trying to analyze you're trying to find kind of map the mind and you know this is kind of a weird seems a     
1:45:15     
little bit weird if you think about like the history of uh neuroimaging and green     
1:45:20     
networks you know there's this history persistent history of assigning     
1:45:25     
different regions of the brain to different behaviors sometimes it's you know the face processing neurons sometimes it's     
1:45:33     
like very high level behaviors and so and sometimes it's just kind of like     
1:45:39     
activations so you know what are we what are we doing when we're mapping the mind and that's just something to keep in     
1:45:44     
mind in the back of our head so uh this is by anthropic AI so they published     
1:45:50     
this uh today we were report a significant advance in understanding the inner workings of AI models we have     
1:45:58     
identified how millions of concepts are represented in inside Claud one of our     
1:46:03     
deployed large language models so they gave it a name here um there's I guess     
1:46:09     
it's Sonet uh this is the first ever detailed look inside a modern production grade large language model this     
1:46:16     
interpretability discovery could in future help us make AI models safer so     
1:46:22     
this is where they kind of talk about this idea of interpretability if we can map the mind of what a large language     
1:46:28     
model is doing how it's processing the training data and producing these uh outputs if you prompted it gives you an     
1:46:36     
output how is it getting there and you know we if you actually look at how     
1:46:41     
large language models are deployed and used you know you find that a lot of times they can basically take it a     
1:46:48     
prompt or take some question and produce some sort of coherence text but     
1:46:53     
sometimes they make uh large scale mistakes let's just say you know things like hallucinations or even     
1:47:01     
misinformation in some cases uh the latest Google model people have been prompting it to get like ridiculous     
1:47:08     
results so you know we want to be able to if not avoid these things at least know what the model is doing to you know     
1:47:15     
kind of Safeguard against um these kind of mistakes and     
1:47:21     
problems so they treat AI models as a black box something goes in and the     
1:47:26     
response comes out and it's not clear why the model gave that particular response instead of another this makes     
1:47:32     
it hard to trust these models uh if we don't know how they work how do we know if they won't be harmful biased     
1:47:38     
untruthful or otherwise dangerous in their responses and so opening the Black     
1:47:43     
Box doesn't necessarily help so you know you might just say well let's just open up the black box and look inside but     
1:47:50     
that doesn't necessarily help because the internal state of the model what the model was thinking before writing its     
1:47:56     
response consists of a long list of numbers or a neuronal activations     
1:48:01     
without a clear meaning so basically if you have the weights that doesn't tell you a lot because it just tells you kind     
1:48:07     
of how it you know it doesn't you can't tell it's reaching a conclusion by looking at the weights any more than you     
1:48:13     
can look at like a neuroimaging data set a connectivity Matrix and say that's you     
1:48:19     
know a memory being encoded or that's an intentional gained I mean we can kind of     
1:48:24     
make inferences about what a pattern means in data but we can't say for sure     
1:48:30     
that this is characteristic of this thing so we can't make diagnoses     
1:48:35     
necessarily um and so from interacting with a model like Claude it is clear     
1:48:40     
that it's able to understand and wield a wide range of Concepts but we can't discern them from looking directly at     
1:48:46     
neurons it turns out that each concept is represented across many neurons and     
1:48:51     
each neuron is involved in representing many Concepts and so in that sense it's kind     
1:48:57     
of like in the brain where you have you know sometimes you're going to have like     
1:49:03     
different type you know you'll have different types of activations for the same type of activity or concept and     
1:49:10     
it's flexible but we know that like there's a basic maybe some basic brain regions that are involved in it we just     
1:49:16     
don't know exactly which in you know in the case of like neuroimaging it could be voxels it could be brain or could be     
1:49:23     
cell types whatever the point is is that this is not like you can't give a recipe     
1:49:29     
for what this you know how to produce a certain output uh you just have to sort of observe it and you kind of get a     
1:49:36     
sense of the sort of the first principles previously we made some     
1:49:41     
progress matching patterns of neural activations called features to human interoperable Concepts we use a tech we     
1:49:48     
used a technique called dictionary learning borrowed from classical machine learning so they use this Term     
1:49:54     
Dictionary learning which isolates patterns of neuron activations that recur across many different contexts in     
1:50:02     
turn any internal state of the model can be represented in terms of a few active features instead of many active neurons     
1:50:09     
so instead of just using things at the neuron scale we're looking at features     
1:50:14     
and that's how we can understand it because I can't give you a recipe of this neuron was activated this neuron     
1:50:20     
was activated this one was activated it's really about the feature and that's what we want to know and the feature can     
1:50:27     
be encoded in different sets of connections different instantiations but     
1:50:32     
when we think about something as being interpretable we think of it in terms of the feature not the connection     
1:50:39     
patter um just as every English word in a dictionary is made by combining     
1:50:45     
letters and every sence is made by combining words every feature in an Aon     
1:50:50     
model is made by combining neurons and every internal state is made by combining features so you have neurons     
1:50:57     
that connect to the network it makes an internal or it it creates a feature then     
1:51:03     
features are connected to make an internal State and those changes can be you know they they're sort of nested and     
1:51:10     
cascading so like we saw with the paper before you have these nodes and there     
1:51:15     
things within the nodes and things within those nodes and if you changed something at the higher level like you     
1:51:22     
changed the feature or you know maybe the internal State changes the internal     
1:51:27     
State can affect the connectivity of the model which can then go back upward and     
1:51:33     
affect the state then the next state you know or the evolving State and then     
1:51:38     
affect the feature so any perturbation you make to the model can have these sort of cascading     
1:51:44     
effects and so in October 20 2023 they reported success applying dictionary     
1:51:51     
learning to a toy Lang anguage model a very small model using uh different     
1:51:56     
types of linguistic data DNA sequences surnames and citations nouns and     
1:52:03     
Mathematics are function arguments in Python code so going Beyond just the     
1:52:09     
general natural language uh examples to other types of     
1:52:14     
sequential uh symbolic data so this is you know kind of going through this and     
1:52:20     
I don't want to get too much more into this uh but this just kind of shows some examples of uh you know how we parse     
1:52:29     
features uh in these sequences of text and Abstract     
1:52:34     
features you know and uh then this nearest neighbors to the inner conflict     
1:52:40     
feature so you have these Maps where you can like kind of get it's almost like a     
1:52:45     
sort of a conceptual map of these different states and showing the outputs     
1:52:51     
here uh we have some things in the chat here as well let's see um so Jesse says     
1:53:00     
uh large mistake model which is lmm I guess and then keep in mind yeah and     
1:53:07     
then uh Erin says I wonder how consistently activation patterns ATA are used from truly representative of the     
1:53:14     
population sample sizes U yeah I mean the activation     
1:53:19     
patterns there's no like they don't necessarily get repeated I mean you get     
1:53:26     
like maybe similar activation patterns in networks but it's hard to that's     
1:53:32     
that's kind of why you know kind of we have maybe a class of activation patterns for a     
1:53:39     
feature or is for an internal State and then a class of internal States for a     
1:53:44     
feature it's very interesting to think about this also in terms of like neural Imaging and what's going on in the brain     
1:53:51     
because we kind of think about inter internal we talk about internal States we talk about the neurons that are     
1:53:56     
involved in internal States and in that case we have a lot of different combinations of activation patterns that     
1:54:03     
could be responsible for a single internal state but also you know changes in those patterns can result in changes     
1:54:09     
in the internal state so there there are a lot of connections here between sort     
1:54:16     
of what we can do in large language models and kind of getting these sort of broad insights into how you know maybe     
1:54:24     
the brain manages internal States or you know some of these other things and we     
1:54:29     
can look inside the model and get you know information out of them um so this is yeah this is an     
1:54:35     
interesting map um but yeah I'm not going to get into it too much I'm just showing you     
1:54:41     
this as a sort of a way that they've kind of characterized a lot of this so that's this uh publication from     
1:54:49     
anthropic this was recently um this is another so they're going to     
1:54:55     
be I'm going to go through a couple more articles here on kind of thinking about large language models and quantitative     
1:55:01     
reasoning so I'm going to talk about this article here where they talk about grounding reasoning with autof     
1:55:08     
formalization and then I'm going to talk about this other one that says GPT for can't reason so the reason I'm doing     
1:55:15     
these two papers is because there's this sort of controversy about what you're ascribing to a model kinds of     
1:55:22     
behaviors or abilities are you're ascribing to a model so this first paper is don't trust     
1:55:28     
verify grounding llm quantitative reasoning with auto formalization so this is where we have     
1:55:36     
our large language models such as Google's manura or open AIS GPT families     
1:55:42     
these are becoming increasingly capable of solving mathematical quantitative reasoning problems so this one class of     
1:55:49     
problem and in this case you know with the anthropic they're looking at a huge     
1:55:54     
class of problems this is one class of problem where they just want to know you     
1:55:59     
know with mathematical quantitative reasoning so however they still make unjustified logical and computational     
1:56:06     
errors in their reasoning steps and answers in this paper we leverage the fact that if the training Corpus of     
1:56:14     
large language models contains sufficiently many examples of formal mathematics so in formal you know in     
1:56:21     
mathematics we rely on formalizations WE rely on sort of this     
1:56:27     
style of sort of proofs and things like that where we can build uh you know sort     
1:56:34     
of these reasoning Frameworks so um in     
1:56:39     
Isabel which is a model this is a formal theorem proving environment so this is     
1:56:44     
the kind of model that we want to sort of translate to larger language mods people have worked on like scientific     
1:56:51     
discovery not in large language models but in automated form so that's another     
1:56:56     
type of thing where you're trying to build like hypotheses and and trying to     
1:57:01     
do scientific reasoning in automated systems as well so there's a history of     
1:57:06     
doing this there's automated theorem improving etc etc but we're trying to build put incorporate this into a large     
1:57:13     
language mod so uh if you you know when you have a training Corpus that contains     
1:57:20     
sufficiently many examples of form mathematics those models can be prompted to translate or autof formalize informal     
1:57:28     
mathematical statements and turn those into formal Isabel code which is what     
1:57:34     
they're talking about here which is the standard uh which can then be verified automatically for internal consistency     
1:57:41     
so if you give it enough training examples of the style of uh sort of     
1:57:46     
building theorems uh then you can actually get some sort of code that's outputed that     
1:57:52     
can then be internally consistent which is you know the sort of the goal of sort     
1:57:58     
of reasoning is this internal consistency this provides a mechanism to     
1:58:04     
automatically reject Solutions whose formalized versions are inconsistent within themselves or with the formalized     
1:58:11     
problem statement so this is where you can actually do the step of sort of     
1:58:16     
sorting through things that are maybe true or not true or you know obviously     
1:58:22     
not the case like you know if if I get a recipe that includes putting gasoline in     
1:58:29     
a dish of like ice cream or something um so you have to train it with the     
1:58:34     
structure of the problem the type of formalism that you need you know you could do this maybe with recipes as well     
1:58:41     
where you give it the style of recipe making where you have a list of ingredients what are the plausible     
1:58:47     
ingredients how would they go together and you don't want to get things that are ridiculous l or     
1:58:54     
illogical we evaluate our method on gsm 8K math and multi- arth data sets so     
1:59:00     
these are data sets that I guess involve theem proving I'm not familiar with them but this is the training data and     
1:59:08     
demonstrate that our approach provides a consistently better heris than V vanilla     
1:59:13     
majority voting the previously best method to identify correct answers so in     
1:59:19     
the theorem proving Community they use this Billa majority voting juristic which you know gives you I gave you a     
1:59:27     
decent answer in this case you can get a 12% increase in identifying correct     
1:59:33     
answers using the GSM 8K datasite and just as an example so that's their     
1:59:39     
Benchmark in our experiments it improves the results consistently across all data sets and large language model sizes and     
1:59:47     
they have the code here in GitHub so this is the code here where uh they kind     
1:59:52     
of walk through the uh the pipeline here where they have this informal statement     
1:59:59     
they have an informal solution you then plug it in to this where you you find     
2:00:04     
this informal statement you translate it into a formal statement so you go from something that has a natural language     
2:00:11     
basis to something that has sort of a formal statement in a in a Computing     
2:00:18     
language or I guess a logical language and then you have you go from this informal solution to this formal     
2:00:25     
solution which just gives you the steps and gives you work the formalization and then you have these in different     
2:00:31     
informal solutions that you can then generate the formal statements you have this automated theorem proverb which     
2:00:38     
checks if it's internally consistent and then it verifies it so that's the idea     
2:00:43     
here so again we have this paper don't trust verify so this says that you can     
2:00:48     
do sort of this reasoning and this is the way they're doing reason in this paper it's gp4 can't reason so this is     
2:00:56     
sort of a counterfactual to what we were dealing with there and of course we had reasoning in a very limited scope and so     
2:01:05     
in this case this is a more general statement about the reasoning ability of a large L mod so this is specific to gp4     
2:01:13     
so it's not that they're saying this for all large language models just for     
2:01:19     
gp4 so gp4 was released in March 2023 to w a claim making a substantial     
2:01:26     
improvement over GPT 3.5 this is these are the open AI models in their     
2:01:32     
iterations um however despite the genuinely impressive Improvement there are good reasons to be highly skeptical     
2:01:39     
of GPT 4's ability to reason this position paper discusses the nature of     
2:01:44     
reasoning so going to the nature of reasoning and you know this is using a natural language data set this is not     
2:01:51     
theor improving this is a more General case where the model was trained on     
2:01:57     
natural language on some Corpus and then has to reason from that Corpus and you're not giving it formal a formal     
2:02:04     
sort of framework for reasoning you're just giving it data that involves maybe like informal reasoning where people     
2:02:12     
make statements that are you know uh involve reasoning but it's not that     
2:02:17     
you're giving the model explicit instructions on how to reason so that's an important distinction so this     
2:02:23     
position paper discusses the nature of reasoning criticizes the current formulation of reasoning problems of the     
2:02:30     
natural language processing Community as well as a way in which the larger language model reasoning     
2:02:36     
performance is currently evaluated introduces A small collection of 21 diverse reasoning problems and performs     
2:02:43     
a detailed quanti qualitative evaluation of gp4s and performance on these     
2:02:50     
problems before based on the this analysis the paper concludes that despite its occasional flashes of     
2:02:56     
analytical Brilliance GPT for present is utterly incapable of reasoning which is     
2:03:02     
kind of a strong statement um but I I wonder if we can look at some of these     
2:03:07     
reasoning problems so these are the test problems um you know this section will     
2:03:15     
start the usual caveat gg4 is a non-deterministic     
2:03:20     
system that might produce different answers on different runs even with the same parameter settings so you know we     
2:03:27     
can do these kind of reasoning problems and sometimes depending on the Run it'll give a reasonable answer and sometimes     
2:03:34     
it won't so that's a that's a a uh caveat but you can actually throw these     
2:03:40     
tests at it to see if it can do these things and that's kind of what people have been doing with some of these     
2:03:46     
models it's one of the weaknesses of large language models is that they're not consistent they're reason     
2:03:52     
so uh this is this one is simple arithmetic where you have to add two     
2:03:57     
numbers together and Report the result so you know you query the model and you     
2:04:04     
say select two random numbers and multiply them together or you give them the numbers as a prompt and it gives you     
2:04:11     
the answer and so okay so you can get the correct     
2:04:17     
answer uh and you know sometimes you can sometimes you can't so the point he     
2:04:23     
points out here that gp4 is not a train complete framework it cannot perform general purpose computation so it can't     
2:04:30     
add multiply or divide it can't sort lists but what it can do is kind of get     
2:04:35     
the answer from its training so it can't do all the you know it can't drive     
2:04:41     
theorems unless you tell it to how to drive a theorem so you have to teach it how to add and you know it's not going     
2:04:48     
to do it on its own because it's not true and complete so calculator can do it because it's train complete it can     
2:04:54     
generate a number it can do order of operations in a certain way um so this is an interesting point about models the     
2:05:02     
problem with this approach is it circularity planning itself requires reasoning so this is a catch22 situation     
2:05:10     
we can't solve reasoning by delegating to appropriate agents because figuring out the delegation how the problem     
2:05:16     
should be decomposed which agents to call and how how to compose the result results itself is computationally     
2:05:24     
infeasible so you know you have to have two components to have some reason and     
2:05:29     
capability in large language models need to have a training set that has examples     
2:05:34     
of reasoning in it uh being able to sort of understand natural language but also     
2:05:40     
these reasoning uh tools and so this is where you actually also have to assume     
2:05:47     
that you have you know some good tools for program pramming the agents and a     
2:05:53     
fixed collection of agents that are give a reliable answer so this is simple     
2:06:00     
arithmetic talks about simple counting uh medical Common Sense     
2:06:06     
Elementary logic um simple quantifier semantics so this     
2:06:15     
is where we have these quantifiers um     
2:06:23     
this is a long section simple graph coloring which is of course an algorithmic problem which you know     
2:06:30     
requires a mult a multiple multiple steps to do     
2:06:36     
um subset sum and that there others I'm not going     
2:06:43     
to get into them now but the point is is that there are a lot of tests you can through with these models some of them     
2:06:49     
have like multiple steps some of them are formalizations and so in that sense     
2:06:55     
larger language models can't reason without being trained to reason okay so I have two other papers     
2:07:02     
and this departs from large language models in the sense that we have these     
2:07:08     
uh sort of larger sets of issues so this is the first paper here this is by     
2:07:14     
ricara and louisone uh on the evolution of brain and computers the road's not taken so we     
2:07:21     
talked about uh like you know large language models and they assume sort of     
2:07:27     
a uh sort of a vanon noyman architecture or they also assume you know U other     
2:07:35     
types of things about modern Computing so you know what if we were to build something like the larger langu model in     
2:07:41     
a different Paradigm and we've talked about this in our physical Computing series we talked about some of this and     
2:07:48     
how you know we don't need to necessarily go down the route that we've gone down with Computing there other     
2:07:53     
types of computing and so this is a paper on uh sort of the evolution of     
2:07:59     
brains and computers and comparing brains and computers and how that you know how this could be done     
2:08:06     
differently so the abstract reads when computers started to become a dominant part of Technology around the 1950s     
2:08:14     
fundamental questions about reliable designs and robustness were great relevance the development gave rides of     
2:08:20     
the explor ation of new questions such as what made brains reliable and so you     
2:08:26     
know brains are well known for their robustness neurons can die the brain can     
2:08:32     
rewire and overcome a number of you know uh deficits like you know neurons dying     
2:08:38     
or neurons having to wire themselves in or changes in the connectivity of the network so these are all things that we     
2:08:46     
want to capture our artificial models in some sense we can but in a lot of sense     
2:08:51     
as we can so brains are you know we know brains to be reliable they're energy     
2:08:58     
efficient there are a lot of arguments you can make that you know about biological brains that can't be matched     
2:09:03     
by our current models uh so you know there are new questions that we can ask     
2:09:10     
and how computers could get inspiration from neural systems so people have been trying to do a lot of in a lot of Bio     
2:09:16     
inspired Computing space they've been trying to mimic what the brain does and sort of mimic those mechanisms with     
2:09:23     
limited success because there's a lot we don't understand about how these uh you     
2:09:29     
know features of biological brains can be sort of abstracted and then modeled     
2:09:34     
and then implemented so we got the first artificial neural networks and those     
2:09:41     
have some features of biological brains but not a lot of them not enough to be     
2:09:47     
like really uh for people to be satisfied with it let's put it that way     
2:09:52     
um since then the comparative view between brains and computers has been developed in new sometimes unexpected     
2:09:58     
directions with the rise of deep learning and the development of conomics an evolutionary look at how both     
2:10:05     
hardware and neural complexity of evolved their design is required so again this is this uh connection     
2:10:12     
between uh brains and models and how those are different and you know maybe     
2:10:19     
some of the aspects of the bi biological systems can be instantiated in the     
2:10:24     
Technical Systems you know but we have to figure out how to do that what the pars are and what the Deep uh structure     
2:10:32     
is there in this paper we argue that important similarities have resulted     
2:10:37     
both from convergent evolution which is the inevitable outcome of architectural constraints so     
2:10:44     
you see architectural constraints in both Mo artificial models technological models and biological brains and so     
2:10:52     
there's this I guess they're using the idea that those that both technological     
2:10:58     
systems and biological systems evolve and that they've sort of seen this convergent evolution to these kinds of     
2:11:05     
architectural constraints and the inspiration of hardware and software principles gutted     
2:11:11     
by toy pictures of neurobiology so you know the way we build our hardware and software a lot of     
2:11:18     
it in the neural network space any way is based on a toy picture of     
2:11:24     
neurobiology so a lot of the stuff that uh we you know the inspiration from     
2:11:29     
biology that we've used and neuron networks are inspired by biology uh Mulla pittz was inspired by     
2:11:37     
neurobiology you know connect uh connection machines or U connectivism     
2:11:43     
was inspired by neurobiology but you know in a in a toy sense we're not replicating the sort of the secret sauce     
2:11:51     
so this is you know something that we we know that we're kind of hitting on something but we don't really know what     
2:11:57     
and we're not completely hitting on what makes biological brains biological     
2:12:03     
brains uh moreover dissimilarities and gaps originate from the lack of major innovations that have paved the way to     
2:12:10     
biological Computing including brains so there gaps or dis     
2:12:16     
similarities uh these there these major innovations that happened in the evolution of bi ological brains that we     
2:12:22     
haven't hit upon in our artificial models as it occurs within synthetic bio     
2:12:29     
computation we can also ask whether alternative Minds can emerge from AI     
2:12:34     
designs and so we don't know that we have like sort of uh we have these     
2:12:40     
representations perhaps but we don't know if they're Minds we don't know if     
2:12:45     
they have you know if you can build uh build multiple representations of minds     
2:12:50     
or anything like that here we take an evolutionary view of the problem and discuss the     
2:12:56     
remarkable convergences between living and artificial designs and what are the preconditions to achieve artificial     
2:13:03     
intelligence so this is from the journal entropy this belongs to the special     
2:13:09     
issue foundations of biological computation so if you want to know more you can read the article or look at the     
2:13:15     
special issue looks like a really interesting special issue looks like we have some you know some basic review of     
2:13:22     
some of these Concepts some of the parallels between artificial systems bio     
2:13:28     
inspired artificial systems and biological brain so the second paper is     
2:13:33     
the development of human causal learning and reasoning and this is Mario kodou     
2:13:39     
and Allison gnik so this is uh developmental psychology has applied to sort of this uh problem of learning and     
2:13:47     
reasoning and so this is uh from nature reviews iology um and so this is let let's just     
2:13:55     
go through the abstract I don't think I have access to this paper actually so um     
2:14:01     
so the abstract reads causal understanding is a defining characteristic of human cognition like     
2:14:07     
many animals human children learn to control their bodily movements and act effectively in the environment like a     
2:14:14     
smaller subset of animals children intervene they learn to change the environment in targeted ways so when     
2:14:21     
they talked about uh sort of this reasoning aspect one of this is the     
2:14:27     
intervention into the World by an agent so you're learning to change the     
2:14:32     
environment targeted ways and that's part of the you know this interactive aspect of reasoning you have to interact     
2:14:39     
with the world you have to learn about the world and interact with it and do these sorts of things so it's not just     
2:14:45     
about learning a formal framework and a agent that you know reasons there's probably this embod body aspect this     
2:14:52     
developmental aspect where you're learning the rules of the environment you're learning the rules of the the     
2:14:57     
world and you're maybe making changes and seeing what the consequences     
2:15:02     
are unlike other animals human children grow into adults with the causal reasoning skills that develop abstract     
2:15:09     
theories so you know animals non-human animals will do this humans will do this     
2:15:15     
in terms of the children or the the juveniles but in humans we also use     
2:15:22     
abstract theories to interpret the reasoning that so we we develop reasoning skills but then we build these     
2:15:28     
abstract theories and so this is something that's unique to humans and     
2:15:33     
you know something that I guess people have I'm not going to get into how they represent on large language models but     
2:15:39     
large language models will come up with theories but they're not very good sometimes they're conspiracy theories so     
2:15:45     
and not saying that humans don't do that as well but it's kind of interesting to see kind of the con consequences of uh     
2:15:53     
reasoning and interacting with data so uh human children you know will develop     
2:15:59     
abstract theories invent sophisticated Technologies and imagine alternate pasts     
2:16:05     
distant Futures and fictional worlds in this review We explore a development of human unique causal learning and     
2:16:11     
reasoning from evolutionary nonto genetic perspectives so they're taking this developmental perspective but also     
2:16:17     
an evolutionary perspective comparing across human and non-human     
2:16:22     
animals we frame our discussion using an interventionist approach first we situate causal understanding in relation     
2:16:29     
to cognitive abilities shared with non-human animals we argue that human     
2:16:34     
causal understanding is distinguished by its depersonalized objective and decontextualized general     
2:16:41     
representations using this framework we next review empirical findings on human     
2:16:47     
early human cause of learning and reasoning and consider the naturalistic context that support development then we     
2:16:54     
explore connections to related abilities we conclude with suggestions for ongoing collaboration between developmental     
2:17:01     
crosscultural computational neural and evolutionary approaches to clausal understanding so     
2:17:08     
this is something you know sort of a framework for AI that we don't have these sorts of un sort of approaches to     
2:17:15     
understanding Incorporated in our view of AI what maybe we have is is at best     
2:17:22     
being able to train our models on these sort of logical Frameworks or something     
2:17:28     
that's easy to sort of uh give the rules to the model and then it can follow the rules but you know these sort of     
2:17:35     
interactive things like developmental approaches to causal understanding or you know evolutionary     
2:17:42     
approaches those are crosscultural approaches those are lacking in our     
2:17:47     
models so I hope that gave you a good a good sense of where I was trying to go with that making those parallels between     
2:17:55     
human systems animal biological systems and model computational models but also     
2:18:01     
sort of in that reasoning domain how those things can be approached and what we have and what we don't     
2:18:08     
have yeah um I appreciate it I'm gonna have to go back and and look at that     
2:18:13     
because I I I appreciate what you were trying to     
2:18:19     
do and I didn't I didn't really get to grasp it there um but no thank you for     
2:18:28     
that yeah really interesting I mean I I I love the first one in terms of um just     
2:18:35     
bringing Isabelle into the loop you know in terms of um again that um that     
2:18:43     
project that deep algebra project proposal from     
2:18:49     
like 2016 or something like that like it's it's yeah so interested to follow up on     
2:18:58     
that just in terms of of how how that you     
2:19:04     
know gives you yeah an interesting Benchmark for     
2:19:09     
things yeah right um the I I dropped a link in     
2:19:17     
datai ml about this new this new     
2:19:22     
French you know llm company and one of the things you know what let out at me     
2:19:30     
was not you know like the fact that more people are willing to you know put     
2:19:35     
billions of dollars into uh starting up an AI company it's not surprising um but     
2:19:41     
that they were pitching it as um agentic     
2:19:47     
Ai and and their description of it was that it knows how it knows how tasks are     
2:19:56     
composed and and it can break them down into subcomponents right and which which     
2:20:04     
certainly sounds like reason or like like again just the the brief view I had     
2:20:11     
of that that second paper in terms of how it was trying to Define reasoning which I I think would     
2:20:19     
um you know also gets back to the FR was like like do we do we actually know what     
2:20:25     
we're talking about like yeah uh and again it's just     
2:20:31     
yeah it's it's so many of these things are only as good as the benchmarks that we have for and and you know our our     
2:20:40     
descriptions are are um very very     
2:20:46     
um uninformative but um uh of course the compositionality is     
2:20:53     
the thing that they tout to neuro AI that you know there's this aspect and this is a developmental thing that you     
2:21:00     
can you know really kind of get at with development is how to put together tasks or how to put together information and     
2:21:06     
these logical steps or this formalization that give you this ability to read it and and one of the things     
2:21:13     
that I was pushing at the the the you know whole brain emulation you know was just like like a     
2:21:21     
kind of a variant on the everything in biology needs to be understood in the light of evolution or like like like     
2:21:29     
everything in the adult brain needs to be understood in the light of that it developed yeah you know right and     
2:21:36     
and you know so so putting putting all this um putting all     
2:21:44     
this effort in terms of scanning and imaging an adult brain     
2:21:51     
like like you're you're missing all that developmental context for how the you     
2:21:58     
know like leaving aside that you're still not capturing physiology but just you know you're not capturing how how     
2:22:06     
those structural elements got in the places that they they did and why yeah     
2:22:11     
you know which is that development story and um you know I I I I you'll be you'll     
2:22:19     
be happy to know that I also was just like I I haven't heard I've heard a lot of people talk about neuro Ai and I I     
2:22:26     
haven't seen a good example of what neuroi is except in this kind of handwavy sense that like these     
2:22:32     
mathematical abstractions are inspired by neurons right right uh you know and     
2:22:38     
again this is why I love you know the idea that we talk about artificial molecular machines so that we get away     
2:22:45     
from neuron you know like we don't need neurons they're not they're you know     
2:22:51     
super special uh but just also like nobody's brought up developmental     
2:22:59     
AI I think yeah just and and and I'd love to put that into     
2:23:06     
context with Charles Martin's Weight Watchers in terms     
2:23:12     
of you know the the potential for both you know     
2:23:21     
structure and functional um re yeah fa phase changes     
2:23:27     
let's I mean it's so to like trying to use more solay kind of terms you that     
2:23:34     
that that you could have you know very different Dynamics as as as the system     
2:23:41     
evolves I if the if that system under goes phase changes right and and now the     
2:23:49     
governing equations for that system are fundamentally different you     
2:23:54     
know there's still it's still a system existing in the world and still solving     
2:24:01     
problems uh um you know but like its own internal representations of that of of     
2:24:09     
those uh yeah its internal representations have fundamentally     
2:24:15     
changed yeah and again like capturing it at a particular time point     
2:24:21     
would would you know would miss would miss that yeah well that's something we     
2:24:26     
go over in the uh in the egrt paper like that example yeah but I mean you know     
2:24:33     
that's that's a an interesting point because we talk about out of distribution things that we want to     
2:24:39     
identify and that's certainly a problem when you have a system that has like phase Transitions and systems that are     
2:24:45     
stochastic how do you know like when there's a change uh you know what the change looks     
2:24:51     
like but those changes sometimes are unique sometimes they you don't know     
2:24:56     
about them until they happen so there are a lot of things that you can't do with an artificial system of those kind     
2:25:02     
of I mean at least with you know a human you can't you can barely understand it you have to sort of reason about it and     
2:25:08     
sometimes the reasoning is wrong uh the way people will interpret you know have interpreted rare events in the past like     
2:25:16     
you know when you would look up and see an eclipse and you wouldn't know what it was and you have to kind of invent a     
2:25:22     
story around it but if you see enough eclipses you kind of figure out what it is and you know it relies on this     
2:25:29     
historical knowledge this sort of integration of that and other things as     
2:25:35     
well as reasoning so that's yeah and and yeah absolutely absolutely um and I I     
2:25:43     
was trying to also you know like people were willing to talk about Quantum yeah     
2:25:49     
yeah and and I it's just like well you know I think the most the most relevant Quantum     
2:25:56     
uh analogy is is just that the the     
2:26:02     
um is that we're 4D objects right you know like like we exist in time yeah and     
2:26:10     
yeah so so you know we we are we are wave packet that is changing over     
2:26:17     
time and and yeah any any 3D description is is is fundamentally     
2:26:27     
lacking so Jesse pointed out in the chat that we should do maybe a position paper     
2:26:33     
about developmental AI or at least I think that' be a good idea because we don't think we have that like right now     
2:26:40     
I I say this almost like I feel like I'm in a in this conversation I feel like I'm in this I don't think I don't think     
2:26:47     
wormholes will live the right right way but like I feel like I'm I'm in a conversation with like     
2:26:53     
2022 and 2021 like we've had this comt we've had     
2:26:58     
this exact we've had this and i' I've we've had hey maybe we should really demarcate this space in developmental AI     
2:27:06     
or whatever and I'm you know I'm not I'm not trying to be like     
2:27:12     
Petty or sarcastic or whatever it's it's more like     
2:27:18     
um I I want like I I'm thinking like what could we constructively do here     
2:27:25     
like what what kind of paper would that even look like right now or like would it just be sort of a like a position of     
2:27:32     
like here's some tenants we think would be important in this space or like here's what we're see missing like like     
2:27:38     
Morgan just said like oh there's nothing about this developmental approach like like something like that or I don't know     
2:27:45     
what people is it is it can still just be like oh well this is slow nice and we don't to say yet they got up that's fine     
2:27:51     
too I just don't know well I think maybe what's missing and that because we don't     
2:27:56     
you know we're not proposing like the latest state-of-the-art whatever but we do have some ideas about like what's     
2:28:03     
missing and sometimes you can say what's missing and it can be very vague sometimes you can really Target what's     
2:28:09     
missing in terms of what do we need to do like very     
2:28:14     
specifically um I don't know how to put it any better that but basically the     
2:28:20     
negative experiment or like sketching out maybe future experiments or sketching out like a very specific set     
2:28:27     
of principles it's almost like if you were doing Theory and you were making     
2:28:32     
predictions or you wereing out of formalization so yeah I mean that might     
2:28:37     
be something we'll have to think about how to do that but you know I guess it were easy it would have been done     
2:28:43     
already right yeah for sure I mean I it would     
2:28:48     
really be it would be it' be good to talk about it though yeah you know I mean just in terms of um I     
2:28:56     
don't know maybe even just thinking about how you know again trying to take a     
2:29:01     
perspective that that others aren't taking right yes and one of one of them might be you know     
2:29:10     
um you know the the various iterations of ch gbt right how how much should     
2:29:16     
should je gbt um try to understand it previous     
2:29:22     
iterations yeah for instance you know and and you know just again thinking     
2:29:27     
about um thinking about um yeah pan     
2:29:34     
stages and and you know somewhat again putting things in a     
2:29:42     
context of continual learning um um you know there was this     
2:29:47     
also this this you know un stated but I thought I felt like everybody     
2:29:53     
assumed um that like AGI you know AGI when it comes is gonna     
2:30:01     
be complete right right right right like like     
2:30:06     
like you know no no such object     
2:30:12     
exists right so so you know again like it's it's I think there's just a number     
2:30:18     
of ways that we can kind of around it and and you know try and look     
2:30:25     
um look with some perspective uh in a     
2:30:30     
you know Marcus kind of way     
2:30:38     
yeah but you know there certainly you know not enough of of the     
2:30:46     
um you know keep it keeps on going for these benchmarks where you're showing performance on things and not enough in     
2:30:55     
terms of where the you know where are the failure modes and and you know those     
2:31:02     
failure modes are actually where kids are learning yeah too and um how how     
2:31:11     
important it might be for uh um a continual Learning System to understand     
2:31:19     
the limit itations of It kind of its previous models     
2:31:25     
I all right well I think that's great uh let's leave it there for now and let's think about that     
2:31:30     
more so yeah thanks another great meeting uh keep in touch on slack and     
2:31:36     
everything and see you next week thank you take care take care bye
